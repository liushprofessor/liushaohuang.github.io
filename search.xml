<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[七层和网络传输通讯的理解]]></title>
    <url>%2F2021%2F09%2F21%2F%E4%B8%83%E5%B1%82%E5%92%8C%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E9%80%9A%E8%AE%AF%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[七层和网络传输通讯的理解简介之前项目使用Netty构建TCP请求来构建应用，在项目上线后项目有很多问题，而之前对网络七层方面的了解只停留在口头和表面，导致排查问题的时候没有这方面的知识走了很多弯路，在排查问题时顺便复习了这块的知识，并且写下自己的理解 网络七层模型图 以上 从网上搜索出来的七层模型图，我这里举例说明 物理层：物理层（Physical Layer）在局部局域网上发送数据帧（Data Frame），它负责管理电脑通信设备和网络媒体之间的互通，我们知道现在网络中传输的大多数都是数字型号，就是0和1，那么我们就可以用电信号（高电平和低电平）或者光的强弱（光纤）等来代表0或者1，来传输信号，这部分我们统一的称作物理层。 数据链路层：数据链路层负责网络寻址、错误侦测和改错,具体理解我我们物理层发的数据01在通讯中会可能会存在干扰或者丢失，物理层可以辅助纠错，并且其一个重要的功能就是进行寻址，二层交换机或者HUB就是在这一层，每台计算机都有一个网卡，这个网卡都有独一无二的MAC地址，数据在经过物理层，在经过数据链路层处理后会在包中带上要传输目标的MAC地址，这样就能知道数据是发给其它那台计算机的了 网络层（Network Layer）决定数据的路径选择和转寄，在实际传输中，如果只使用MAC地址去传输，那么将会非常不方便，因为MAC地址一长串，于是为了方便寻址抽象出了网络层，我们使用的IP和路由器就是在这一层，数据在经过网络层后，网络层会将数据链路层的数据加入IP的信息，比如目标IP和端口，在数据传输到对于的路由器，路由器再将IP解压提取对于的MAC地址，然后再交给交换机分发到对于MAC地址的电脑上。 传输层：网络层只是负责转发数据，并没有实现如何传输数据。比如TCP是在IP上是为了解决可靠传输而生的，在发送数据是通过序列号码和应答标志位ACK来确认数据是否送达，其保证了数据只要发出那么数据就能送达。 会话层：其表示数据传输何时建立连接，比如软件的开启就建立连接，这部分属于会话层的范畴. 表示层：数据如何展示，比如HTML页面就是表示层，他将来HTTP请求返回的数据包解析了也页面 应用层：就是我们定义的具体的协议，比如HTTP就是基于TCP协议而实现的应用层协议. 那么他们之间具体的关系是咋样的呢？我们从2个角度来看 发送端 应用层-&gt;表示层-&gt;会话层-&gt;网络层-&gt;数据链路层-&gt;物理层 接收端 物理层-&gt;数据链路层-&gt;网络层-&gt;会话层-&gt;表示层-&gt;应用层 我们可以看到发送端是由上而下发的数据，接收端是由下往上接收数据，在发送端，每经过一层都会将对应一层的协议的信息加入到数据包中，然后再传给下一层，而接收端每进过一层就会将那一层的协议信息解析完后给去掉，然后返回给上一层 数据是如何在网络中传输的 如图中所示了电脑发送的数据是如何传输的，我们以发送数据为例结合上问提到的7层来详细说明 应用层，表示层，会话层，传输层，这部分都在我们电脑中实现，应用层，表示层，会话层，都由我们开发的应用去实现，传输层(如TCP,UDP)这部分由操作系统去实现（比如我们运行操作系统的命令能查看到我们应用具体的端口，所以这些应用的传输都是依托操作系统），首先我们在我们的应用中如通讯软件发起一条消息，这个通讯软件就是应用层，而通讯软件展示出的节目就是表示层，而当我点击发送按钮这时候触发发送消息，则我们这里点击按钮才发送消息的这个机制就是会话层。 传输层，接上面，我们发送TCP消息后，应用调用Sock方法将数据发送给操作系统，让操作系统进行TCP传输，这时数据包里除了我们应用层那边规定传输的数据协议外（如JSON），系统实现的会自动加上TCP协议的协议头。 网络层，接上，现在传输层已经将数据打包好，系统判断这个数据包的目标地址是否在同一个网段，如果是，字节将数据下发到数据链路层，现在我们需要将我们的数据发送到对应的收消息IP地址上，所以操作系统又将TCP包加上IP的数据包头接着往下发送到数据链路层，注意同网段数据传输其实不需要真正的用到IP,因位其通过同网段内广播就能获取到目标MAC地址。 数据链路层，这一层由网卡和网卡驱动实现，系统将IP包和MAC地址等下信息进行包装后，发送给网卡，由网卡去发送消息，那这里我们是如何知道目标电脑的MAC地址的？答案是还是操作系统，本地系统中会存在一张静态ARP路由表，如果我们要查询的目标IP是和发送端在相同网段内，如果ARP路由表中没有，则操作系统将通过交换机发送一条地址MAC地址FF:FF:FF:FF的的广播，询问该IP是是属于哪个MAC的，在得到MAC地址后，将MAC地址信息添加到包中，封装成数据链路层的包，再经过网卡驱动和网卡将数据变成01发出去，如果在ARP中找不到路由，且不是同网段，那么将会使用默认路由（一般是路由器的地址）交由路由器去一层层的去寻找目标MAC，获取到MAC地址后，再回操作系统组成数据链路层的包再发给物理层。 ​ 物理层：现在数据变成了01的电信号或者光信号往外传输 现在数据经过双绞线发送给交换机(同网段)或者路由器（不同网段），交换机由于实现了2层(也有3层交换机)，交换机在收到物理层传来的数据后，根据目标的MAC转发给对应的MAC地址设备，如果是同网段，直接转发，如果不是则发送给目标网关让它进行转发。同样目标地址的数据链路层收到数据后在往上一步步解析，最终变成应用层的协议]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Netty构建TCP通讯中通讯错误问题的排查和详解]]></title>
    <url>%2F2021%2F09%2F21%2F%E4%BD%BF%E7%94%A8Netty%E6%9E%84%E5%BB%BATCP%E9%80%9A%E8%AE%AF%E4%B8%AD%E9%80%9A%E8%AE%AF%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%E7%9A%84%E6%8E%92%E6%9F%A5%E5%92%8C%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[使用Netty构建TCP通讯中通讯错误问题的排查和详解简介最近上线的项目中使用Netty构建tcp服务去连接设备来收集设备运行的状态，在试运行一段时间后发现kibana中偶尔出现设备端发送了我们的数据，后端解析出错的问题，但是设备端又死活不承认他们的问题，无奈下本着做事要拿出证据的原则，这边被迫再次学习了TCP等知识来打他们的脸。 问题描述我们和设备端定义的协议核心为传输的时候在前面带上一个2个字节的数据域来表示数据域的长度，后端收到数据再读取这个数据域的长度，再获取接下来数据载体的长度，并且将其读出，再运行一段时间后我们发现kibana中的日志经常报以下两个错误 错误：1 1Connection reset by peer 错误：2 1在解析协议时出错 问题分析错误1：明显是由于连接被关闭而报出的，这个在现场是有可能的 错误2： 在解析协议时出错，服务端逻辑是应用层协议解析出错将关闭连接，所以接着日志引发错误1 那么我们排查问题的重点就放在为啥会出现解析错误。 问题解决问题1，数据域长度问题一开始我们我们查看代码就发现之前应用层定义的2个字节来存储数据域太少了，2 个字节是16位，在java中用short来表示，2个字节能表示2的16次方 65 536个数字，但是java中要用一半表示负数一半表示正数，所以一共最多数据域可以发送32768个字节，在将其换算成k大概为32K，也就是一次最多传输32K 的数据 问题2，TCP协议在限制传输大小后，后端仍然报解析错误。这是排查处理粘包和拆包的代码是Netty提供的LengthFieldBasedFrameDecoder 类，这部分基本不可能出现问题，为了排查出原因复习了一下TCP协议 我们知道TCP建立连接时会发起3次握手，如图 1231:客户端（通过执行connect函数）向服务器端发送一个SYN包，请求一个主动打开。该包携带客户端为这个连接请求而设定的随机数A作为消息序列号。2:服务器端收到一个合法的SYN包后，把该包放入SYN队列中；回送一个SYN/ACK。ACK的确认码应为A+1，SYN/ACK包本身携带一个随机产生的序号B。3:客户端收到SYN/ACK包后，发送一个ACK包，该包的序号被设定为A+1，而ACK的确认码则为B+1。然后客户端的connect函数成功返回。 那具体什么是ACK什么是SYN呢？我们对照一下TCP协议就知道了，我们着重看下标志位的内容就是下图保留位000后面的数据，可以这样理解，这个标志位就相当于我们写接口，这个接口有一个参数，分别为1,2,3 这3个参数分别表示不同的3种状态，我们根据这个状态执行不同的逻辑操作，这个表示位相当于这个参数，至于为什么保留000，我想应该是为了后续协议扩展，如果后续出了更多的状态码，只需要补上就好了，不需要重新定义协议 来源连接端口（16位长）－识别发送连接端口 目的连接端口（16位长）－识别接收连接端口 序列号（seq，32位长） 如果含有同步化旗标（SYN），则此为最初的序列号；第一个资料比特的序列码为本序列号加一。 如果没有同步化旗标（SYN），则此为第一个资料比特的序列码。 确认号（ack，32位长）—期望收到的数据的开始序列号。也即已经收到的数据的字节长度加1。 资料偏移（4位长）—以4字节为单位计算出的数据段开始地址的偏移值。 保留（3比特长）—须置0 标志符（9比特长） NS—ECN-nonce。ECN显式拥塞通知（Explicit Congestion Notification）是对TCP的扩展，定义于 RFC 3540 （2003）。ECN允许拥塞控制的端对端通知而避免丢包。ECN为一项可选功能，如果底层网络设施支持，则可能被启用ECN的两个端点使用。在ECN成功协商的情况下，ECN感知路由器可以在IP头中设置一个标记来代替丢弃数据包，以标明阻塞即将发生。数据包的接收端回应发送端的表示，降低其传输速率，就如同在往常中检测到包丢失那样。 CWR—Congestion Window Reduced，定义于 RFC 3168（2001）。 ECE—ECN-Echo有两种意思，取决于SYN标志的值，定义于 RFC 3168（2001）。 URG—为1表示高优先级数据包，紧急指针字段有效。 ACK—为1表示确认号字段有效 PSH—为1表示是带有PUSH标志的数据，指示接收方应该尽快将这个报文段交给应用层而不用等待缓冲区装满。 RST—为1表示出现严重差错。可能需要重新创建TCP连接。还可以用于拒绝非法的报文段和拒绝连接请求。 SYN—为1表示这是连接请求或是连接接受请求，用于创建连接和使顺序号同步 FIN—为1表示发送方没有数据要传输了，要求释放连接。 窗口（WIN，16位长）—表示从确认号开始，本报文的发送方可以接收的字节数，即接收窗口大小。用于流量控制。 校验和（Checksum，16位长）—对整个的TCP报文段，包括TCP头部和TCP数据，以16位字进行计算所得。这是一个强制性的字段。 紧急指针（16位长）—本报文段中的紧急数据的最后一个字节的序号。 选项字段—最多40字节。每个选项的开始是1字节的kind字段，说明选项的类型。 0：选项表结束（1字节） 1：无操作（1字节）用于选项字段之间的字边界对齐。 2：最大报文段长度（4字节，Maximum Segment Size，MSS）通常在创建连接而设置SYN标志的数据包中指明这个选项，指明本端所能接收的最大长度的报文段。通常将MSS设置为（MTU-40）字节，携带TCP报文段的IP数据报的长度就不会超过MTU（MTU最大长度为1518字节，最短为64字节），从而避免本机发生IP分片。只能出现在同步报文段中，否则将被忽略。 3：窗口扩大因子（3字节，wscale），取值0-14。用来把TCP的窗口的值左移的位数，使窗口值乘倍。只能出现在同步报文段中，否则将被忽略。这是因为现在的TCP接收数据缓冲区（接收窗口）的长度通常大于65535字节。 4：sackOK—发送端支持并同意使用SACK选项。 5：SACK实际工作的选项。 8：时间戳（10字节，TCP Timestamps Option，TSopt） 发送端的时间戳（Timestamp Value field，TSval，4字节） 时间戳回显应答（Timestamp Echo Reply field，TSecr，4字节） 从上面资料中可知ACK和SYN或者是 SYN-ACK包其实就是将来TCP请求头对于的位置1而已 知道了标志位的信息我们还需要状态TCP的状态码，其实我们理解成HTTP的状态码就好了，每个状态码对应的TCP现在处于的不同状态 下表为TCP状态码列表，以S指代服务器，C指代客户端，S&amp;C表示两者，S/C表示两者之一：[15] LISTEN S 服务器等待从任意远程TCP端口的连接请求。侦听状态。 SYN-SENT C 客户在发送连接请求后等待匹配的连接请求。通过connect()函数向服务器发出一个同步（SYNC）信号后进入此状态。 SYN-RECEIVED S 服务器已经收到并发送同步（SYNC）信号之后等待确认（ACK）请求。 ESTABLISHED S&amp;C 服务器与客户的连接已经打开，收到的数据可以发送给用户。数据传输步骤的正常情况。此时连接两端是平等的。这称作全连接。 FIN-WAIT-1 S&amp;C （服务器或客户）主动关闭端调用close（）函数发出FIN请求包，表示本方的数据发送全部结束，等待TCP连接另一端的ACK确认包或FIN&amp;ACK请求包。 FIN-WAIT-2 S&amp;C 主动关闭端在FIN-WAIT-1状态下收到ACK确认包，进入等待远程TCP的连接终止请求的半关闭状态。这时可以接收数据，但不再发送数据。 CLOSE-WAIT S&amp;C 被动关闭端接到FIN后，就发出ACK以回应FIN请求，并进入等待本地用户的连接终止请求的半关闭状态。这时可以发送数据，但不再接收数据。 CLOSING S&amp;C 在发出FIN后，又收到对方发来的FIN后，进入等待对方对己方的连接终止（FIN）的确认（ACK）的状态。少见。 LAST-ACK S&amp;C 被动关闭端全部数据发送完成之后，向主动关闭端发送FIN，进入等待确认包的状态。 TIME-WAIT S/C 主动关闭端接收到FIN后，就发送ACK包，等待足够时间以确保被动关闭端收到了终止请求的确认包。（按照RFC 793，一个连接可以在TIME-WAIT保证最大四分钟，即最大分段寿命（maximum segment lifetime）的2倍） CLOSED S&amp;C 完全没有连接。 在linux中我执行了 lsof -i pid 查看我的程序,我的主服务在等待客户端连接所以其状态为LISTEN，下面状态都为ESTABLISHED说明我目前有这么多的TCP连接在同时通讯 123456789101112131415161718192021COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEjava 272641 root 41u IPv6 288726424 0t0 TCP *:ospf-lite (LISTEN)java 272641 root 43u IPv6 288846370 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.116:62294 (ESTABLISHED)java 272641 root 46u IPv6 288903360 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.112:62309 (ESTABLISHED)java 272641 root 47u IPv6 288883851 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.109:56469 (ESTABLISHED)java 272641 root 48u IPv6 288846374 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.105:49538 (ESTABLISHED)java 272641 root 49u IPv6 288849436 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.117:63780 (ESTABLISHED)java 272641 root 52u IPv6 288846378 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.104:62634 (ESTABLISHED)java 272641 root 56u IPv6 289743582 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.118:62854 (ESTABLISHED)java 272641 root 62u IPv6 289434904 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.106:56702 (ESTABLISHED)java 272641 root 63u IPv6 288846379 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.103:53834 (ESTABLISHED)java 272641 root 71u IPv6 288740012 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.111:55792 (ESTABLISHED)java 272641 root 72u IPv6 291875760 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.114:59756 (ESTABLISHED)java 272641 root 76u IPv6 292145489 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.102:58032 (ESTABLISHED)java 272641 root 79u IPv6 292105805 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.101:51138 (ESTABLISHED)java 272641 root 211u IPv6 288846384 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.108:65527 (ESTABLISHED)java 272641 root 213u IPv6 288846385 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.110:53628 (ESTABLISHED)java 272641 root 216u IPv6 288849433 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.107:51733 (ESTABLISHED)java 272641 root 217u IPv6 288818776 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.113:54426 (ESTABLISHED)java 272641 root 218u IPv6 288818777 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.115:54173 (ESTABLISHED)java 272641 root 219u IPv6 288818778 0t0 TCP cdh1:ospf-lite-&gt;192.168.7.119:53698 (ESTABLISHED) 那么现在重点来了TCP如何结束通讯，且如何处理结束时当前还在缓冲区未发完的数据？如图，我们上文得知TCP发送FIN状态码代码代表结束通讯，因此我们知道当应用主动关闭连接时TCP并不会马上关闭连接，而是将缓冲区的数据发送完毕后再调用FIN标识码码去关闭连接，这样保证了主动关闭连接下数据的准确性，如果应用被强制杀掉，或者应用被关闭时没有调用close时，这时TCP通道并不会主动关闭，而是在一端调用write或者read时报Connection reset by peer错误，而这就解释了为啥会报第一个错误，时因为我在Netty中开了心跳坚持如果30秒没有从tcp通道中读取数据或者写数据的话那么就关闭这个通道，当客户端崩溃或者没有关闭通道退出时，Netty 去Write写入心跳数据时报出这个错误，因此得出此所以报错是由于客户端人员发送协议错误 123456连接终止使用了四路握手过程（或称四次握手，four-way handshake），在这个过程中连接的每一侧都独立地被终止。当一个端点要停止它这一侧的连接，就向对侧发送FIN，对侧回复ACK表示确认。因此，拆掉一侧的连接过程需要一对FIN和ACK，分别由两侧端点发出。首先发出FIN的一侧，如果给对侧的FIN响应了ACK，那么就会超时等待2*MSL时间，然后关闭连接。在这段超时等待时间内，本地的端口不能被新连接使用；避免延时的包的到达与随后的新连接相混淆连接可以工作在TCP半开状态。即一侧关闭了连接，不再发送数据；但另一侧没有关闭连接，仍可以发送数据。已关闭的一侧仍然应接收数据，直至对侧也关闭了连接。也可以通过测三次握手关闭连接。主机A发出FIN，主机B回复FIN &amp; ACK，然后主机A回复ACK.[13] 总结在TCP由应用调用close方法去关闭TCP会主动将TCP缓冲池的数据发送完毕再发一个FIN标示位,因此主动关闭tcp并不会导致数据丢失。 *如果应用被强制杀掉，或者应用被关闭时没有调用close时，这时TCP通道并不会主动关闭，而是在一端调用write或者read时报Connection reset by peer错误 *]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划和回溯算法]]></title>
    <url>%2F2021%2F07%2F12%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%92%8C%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[动态规划和回溯算法简介前几天在朋友圈中看到一个富士康面试题，题目是9个球放入4个袋子，如何保证每个袋子都有球且每个袋子中的球是单数。正好这几天又巩固下基础算法，想到个题不是可以用回溯和动态规划去解决吗？其实算法一个非常重要的东西就是建模，如果将现实中的东西抽象成模型，这个问题我们可以将其模型抽象成一个二维数据，一维代表背包的个数，二维代表一个包的所放的球数，对于不同算法，这个模型也有着不同含义，比如对于动态规划，同样使用二维数组去建模，动态规划二维数组代码的确实现在包中一共放了多少个球，另外数组加链表也是一种常用的建模工具，类似HashMap就使用了数组加链表来存储hash冲突的数据，在计算图相邻顶点时我们也会使用这种数据结构，数组下标代表的是当前点，数组中又加了一个链表来存储这个顶点相邻的点。 回溯算法简单的来说回溯算法就是列举出所有可能性，选出一个满足条件的结果。就好比我们走迷宫，当我们遇到一条死路就原路返回到上一个入口，然后接着走，直到我们找到出口，所以顾名思义这个算法就叫回溯。我们知道贪心算法不能得出最优解，但是使用回溯我们列举出所以的可能，然后从中筛选出一个最优解即可。 回溯算法是我遇到这个问题的第一个想到的解法,解决的思路就是我们根据常理得出要保证每个包就有球，那么每个包最少要有1个球，那么得出一个包最多只能有6个球，那么我们我们可以使用递归去实现，一个包最多放6个球，我们列举出这4个包从放1个球到6个球的所有可能，并且其它包要根据之前包放的球个数的变化二改变最多可以放的球数量的变化，实现这个是这个算法最绕的地方，为了将这个题目抽象成代码我用一个二维数组来建模，一维表示包的编号(从0-4)，二维数组的下标表示当前背包中有多少个球，如果当前坐标维true，那么这个背包中就有多少个球(二维数组的下标)，具体代码如下, 最后得出根本不存在这样的解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package com.nebula.orderpublish;import java.util.ArrayList;import java.util.Arrays;import java.util.List;import java.util.StringJoiner;/** * @author Liush * @description * @date 2021/7/9 14:40 **/public class Main &#123; static List&lt;String&gt; results=new ArrayList&lt;&gt;(); public static void main(String[] args) &#123; calculate(4,9); System.out.println(results); &#125; public static void calculate(int bagNum ,int ballNum)&#123; getBallNumPut(6,1,4,new int[4],ballNum); &#125; public static void getBallNumPut(int currentBagBallNumMax, int currentBag, int bags, int[] result, int ballNum)&#123; //递归结束条件当袋子都遍历完时 if(currentBag==bags)&#123; int lastBagBallNum=ballNum- getBallNumPut(result); if(lastBagBallNum%2==0)&#123; return; &#125; result[currentBag-1]=ballNum- getBallNumPut(result); results.add(Arrays.toString(result)); return; &#125; for(int i=0;i&lt;currentBagBallNumMax;i++)&#123; clean(result,currentBag); //查询时候为偶数，如果是偶数的话跳过 if((i+1)%2==0)&#123; continue; &#125; //保存当前袋子中所放球的个数 result[currentBag-1]=i+1; int nextBagBallNum= countNextBagBallsMax(result,ballNum,currentBag,bags); getBallNumPut(nextBagBallNum,currentBag+1,bags, result,ballNum); &#125; &#125; //清除结果，每次不满足条件(偶数)时吧结果清除，循环回溯去排查下一个结果 public static void clean(int[] results,int currentLevel)&#123; for(int i=0;i&lt;results.length;i++)&#123; if(i&gt;=currentLevel-1)&#123; results[i]=0; &#125; &#125; &#125; //计算本次计算的单个袋子最多可以放多少个球 public static int countNextBagBallsMax(int[] results, int balls, int currentLevel, int level)&#123; int ballNumPut = getBallNumPut(results); //+1 是为了计算最少还要预留多少个球放入后面的袋子 比如4个袋子当前是第一个袋子，现在要计算第二个袋子，就至少还要预留2个球(3和4袋子)才能保证每个袋子都有球 return balls-ballNumPut-(level-currentLevel)+1; &#125; //查询已经放入袋子的球 private static int getBallNumPut(int[] results) &#123; int result=0; for(int a: results)&#123; result+=a; &#125; return result; &#125;&#125; 动态规划能使用动态规划解决问题一般都满足以下三个原则 最优子结构最优子结构指的是，问题的最优解包含子问题的最优解。反过来说就是，我们可以通过子问题的最优解，推导出问题的最优解。如果我们把最优子结构，对应到我们前面定义的动态规划问题模型上，那我们也可以理解为，后面阶段的状态可以通过前面阶段的状态推导出来。 无后效性无后效性有两层含义，第一层含义是，在推导后面阶段的状态的时候，我们只关心前面阶段的状态值，不关心这个状态是怎么一步一步推导出来的。第二层含义是，某阶段状态一旦确定，就不受之后阶段的决策影响。无后效性是一个非常“宽松”的要求。只要满足前面提到的动态规划问题模型，其实基本上都会满足无后效性。 重复子问题这个概念比较好理解。前面一节，我已经多次提过。如果用一句话概括一下，那就是，不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。 这个问题可以满足这3个条件，于是我尝试使用动态规划去解决此问题,不同于回溯，我用二维数组来建模，一位数组同样代表的是背包编号，不同的是二维数组，我使用二维数组的下标来表示目前一共在包中放入了多少个球，根据动态规划的定义，我把问题分解为4个重复的子问题，就是每个包要放入多少个球，我们把每个包中放的球的所有可能都列举出来，并且将所有背包里的球的数量累加(这是数组的二维不是代表本个袋子放了多少个球，而是代表这个袋子放好后，一共装到袋子的球有多少个)，最后相加发现根本不可能放入9个球（二维数组的[3][8]坐标为0） 0 1 2 3 4 5 6 7 8 0 √ √ √ 1 √ √ √ 2 √ √ √ 3 √ √ √ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * @author Liush * @description * @date 2021/7/12 16:04 **/public class Main2 &#123; public static void main(String[] args) &#123; int[][] matrix=new int[4][9]; int everyBagBallMax=getEveryBagBallMax(9,4); for(int i=0;i&lt;matrix.length;i++)&#123; //初始化第一个背包 if(i==0)&#123; for(int z=0;z&lt;everyBagBallMax;z++)&#123; if((z+1)%2==0)&#123; continue; &#125; matrix[0][z]=1; &#125; continue; &#125; //根据上一个放入球的背包计算本次背包能放入多少个球 for(int k=0;k&lt;matrix[i].length;k++)&#123; if(matrix[i-1][k]&gt;0)&#123; //计算本个背包最多能放多少个球4-（i+1）为计算后面没放球的背包，每个背包最少要放一个，K+1为已经放入的球树 int cycleTime=9-(4-(i+1))-(k+1); for(int c=1;c&lt;=cycleTime;c++)&#123; if(c%2==0)&#123; continue; &#125; matrix[i][k+c]=1; &#125; &#125; &#125; &#125; System.out.println(matrix); &#125; //计算出每层最多可以放几个球 public static int getEveryBagBallMax(int ballNum ,int bagNum)&#123; return ballNum-bagNum+1; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何将FTP挂载在linux的本地磁盘并在挂载机上发布FTP服务.md]]></title>
    <url>%2F2021%2F03%2F07%2F%E5%A6%82%E4%BD%95%E5%B0%86FTP%E6%8C%82%E8%BD%BD%E5%9C%A8linux%E7%9A%84%E6%9C%AC%E5%9C%B0%E7%A3%81%E7%9B%98%E5%92%8C%E5%B9%B6%E5%9C%A8%E6%8C%82%E8%BD%BD%E6%9C%BA%E4%B8%8A%E9%87%8D%E6%96%B0%E5%8F%91%E5%B8%83linux%E6%9C%8D%E5%8A%A1-md%2F</url>
    <content type="text"><![CDATA[简介需求是这样：客户公司对我们开发了一台FTP服务器以供我们上传数据回流给客户，但是客户为了安全原因只对我们开放了固定一台服务器才能进行FTP登录，由于想偷懒，也为了加快该功能的上线使用，所以思考时候能将FTP类似像NFS一样挂载在linux的本地，然后再在我们的服务器上开放一个FTP服务往挂载的客户FTP的目录上写入文件，这里使用的是Centos 7.5 需要的模块FTP挂载使用curlftpfs来将来远程FTP目录到本地 FTP服务vsftp 安装过程详解挂载本地yum源由于服务是在内网，无法使用外面的yum源，为了方便安装需要制作一个本地的yum源，在我们下载的ISO包下已经包含了大多数的常用软件（不包含curlftpfs和其一些依赖的组件）,那么我们在使用yum去安装时就会去改ISO包中寻找时候有包含合适的软件 挂载镜像，首先我们将我们的镜像上传到服务器，并且挂载在本地目录如 1mount /tmp/CentOS-7-x86_64-DVD-1611.iso /test/iso 然后我删除了默认的所有yum源，因为服务器是在内网不可能连接到外网，进入/etc/yum.repos.d/目录，删除该目录下所有文件 创建新的yum源文件 local.repo 注意其后缀必须为repo,编辑以下内容,其中baseurl为你镜像挂载的目录，然后我们的本地yum源就完成了 12345[localrepo]name=localrepobaseurl=file:///test/isoenabled=1gpgcheck=0 安装curlftpfs 由于我的服务器无法连接外网，所以使用yum install curlftpfs无法安装，所以这里只能去下载其源码自行编译然后安装 源码下载地址 http://sourceforge.net/projects/curlftpfs/files/?source=navbar 接下来编译安装三部曲 123./configuremakemake install 不幸缺少一些依赖 glib 该包在CentOS 7.5中提供的镜像里并没有，所以老样子下载源码编译之 http://ftp.acc.umu.se/pub/GNOME/sources/glib/ 然后一样执行 123./configuremakemake install 接着继续编译curlftpfs，还会发现缺少fuse，FUSE使用镜像自带的yum源就可安装 1yum install fuse-devel 提示libcurl 缺失但是使用 1rpm -qa |grep libcurl 发现其已经存在，在网上找了资料后使用自带yum源安装libcurl-devel后通过编译 接着将远程FTP服务挂载到本地，并且授权所有用户可以访问，其中uid和gid可使用cat /etc/password |grep 用户,实际过程中需要先进行目录绑定才能开启FTP服务器 1curlftpfs –o rw,allow_other,uid=0,gid=0 ftp://username:password@192.168.1.1 /ftp 部署本地FTP目前已经完成远程FTP挂载到本地，那么为了让使用则能够上传文件到映射的目录，我又在本地开放了一个目录，将其的目录地址映射到之前远程FTP目录的地址 vsftpd，此软件使用镜像中自带yum源即可安装 其中安装教程依照如下所示 https://www.linuxprobe.com/linux-ftpserver.html 安装完成后，本来想将用户的权限规定到特定目录，且不能切换根目录，所以在配置文件中加入如下配置 123chroot_local_user=YES # 用户不能跳出根目录allow_writeable_chroot=YES #在新版本中必须要加，否则在开启chroot_local_user参数后无法进行账号密码验证local_root=/ftp #指定根目录地址 但我们开启FTP服务后，发现我们在使用FTP服务进行登录时找不到之前我们FTP映射的目录 接着在控制台执行，然后就能看到目录了 12setsebool allow_ftpd_full_access 1setsebool allow_ftpd_use_cifs 1 大坑本人下载最新的0.9.2版本，在挂载后，写入文件一直出现I/O错误，在找了大量资料后，重新安装 0.9.1版本并且参数中加入direct_io后解决 1curlftpfs -o codepage=gbk,rw,allow_other,uid=1001,gid=1001,direct_io ftp://password@ip:port /file]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES RestAPI示例]]></title>
    <url>%2F2021%2F03%2F07%2FRestAPI%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[简介在实践中最常使用的就是查询，而Elasticsearch又提供了丰富的HTTP接口供人们调用（JAVA的高级API其实也差不多），这里借用kibana提供的开发者工具，使用HTTP API对遇到过的常用查询进行总结。 数据集我采用科大讯飞的长文本分类数据集提供测试 https://github.com/CLUEbenchmark/CLUEDatasetSearch 其为json格式的文本集，具体示例数据如下 12345&#123; "label": "11", "label_des": "薅羊毛", "sentence": "活动新用户领5元现金即日起成功注册酷划的新用户，填写邀请码80008即可领取5元现金奖励哦。小伙伴们不要错过，赶快来酷划锁屏领红包吧~每天解锁50次，一年可赚上千元酷划锁屏是一款可以自动赚钱的手机锁屏APP，每次解锁手机均有数额不等的现金奖励。赚到的钱可以极速提现到微信钱包、支付宝，也可以用来购买爆款商品。除手机解锁可以赚钱外，酷划还提供邀请赚、分享赚、高额赚等十余种赚钱方式，零成本可得高额回报。三年时间里，酷划已累计服务了超一亿名用户。在手赚软件中处于无可争议的领先地位。手机赚钱，用酷划锁屏就对了功能介绍手机解锁领现金每次解锁均有现金奖励锁屏精选新鲜资讯，边看边赚零花钱十种以上赚钱方式邀请赚、分享赚、试玩赚…多种赚钱方式任你选每天花上五分钟，酷划收入翻倍领邀请徒弟收入加倍邀请好友体验酷划，建立师徒关系徒弟挣钱，师傅得现金奖励提现购物任你挑选您的收入可提现，购物，话费充值微信一元提现，极速到账官网www.coohua.com微信公众号酷划在线客服邮箱help@coohua.com,每天解锁50次，一年可赚上千块,1、客户端个人中心电商相关功能下线2、锁屏改造客户端SDK"&#125; 索引类创建索引调用了HTTP PUT方法创建一个索引，且创建了Mapping和设置了索引的分片和索引信息，因为我只有使用一台节点（在Elasticsearch中节点默认即是Master，Data，Coordinating节点，如果需要子开启对于的设置可以配置yml文件，开启对于的节点角色即可），其指定了一个数据主分片（number_of_shards）和0个副本分片（number_of_replicas），且在mapping对各个字段做了定义，且label_des和sentence字段指定了分词器为IK分词器（中文分词器）的两种分词策略 1234567891011121314151617181920212223242526272829303132333435PUT /data_test&#123; &quot;settings&quot; : &#123; &quot;number_of_shards&quot; : &quot;1&quot;, &quot;number_of_replicas&quot; : &quot;0&quot; &#125;, &quot;mappings&quot; : &#123; &quot;properties&quot; : &#123; &quot;id&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 100 &#125;, &quot;label&quot; : &#123; &quot;type&quot; : &quot;integer&quot; &#125;, &quot;label_des&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;ik_smart&quot;, &quot;fields&quot;:&#123; &quot;keyword&quot;:&#123; &quot;type&quot;:&quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125;, &quot;sentence&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;ik_max_word&quot;, &quot;search_analyzer&quot; : &quot;ik_smart&quot; &#125; &#125; &#125; &#125; number_of_shards：分片数量 number_of_replicas：副本数量 分词查询在优化查询的时候我们需要对我们使用的分词器的分词情况进行查看，就可以使用该API,以下时候是使用ik_smart分词器的情况下对休闲益智这个词进行查询其分词情况 123456GET /_analyze&#123; &quot;text&quot;: &quot;休闲益智&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot; &#125; 结果如下 123456789101112131415161718&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;休闲&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;益智&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 1 &#125; ]&#125; 查询Term查询（对输入的词不进行分词） 注意：这边我们查询的是休闲益智，在IK分词器中这个词被分为休闲和益智两个词，所以我们这里使用label_des的子字段keyword来查询不分词的数据（该子字段的类型为keyword），如果直接对label_des字段查询则查询不出任何数据，因为根据上面我们设置的Mapping这中定义其为text，在es倒排索引中其呗分隔成休闲和益智两个词 12345678GET /data_test2/_search&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;label_des.keyword&quot;: &quot;休闲益智&quot; &#125; &#125;&#125; Match查询（对输入的词进行分词查询） 12345678910GET /data_test2/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;label_des&quot;: &quot;休闲益&quot; &#125; &#125;&#125; 查询结果能查询出label_des包含休闲益智的文档，因为ik分词器将其分词为休闲和益两个词，只要文档中出现其中一个倒排索引即可完成匹配 Match and 查询上文我们进行了Match查询，match对搜索词进行分词后再查询，只要有一个词命中文档，那么就返回文档，如果要两个词都要命中才返回文档那么就要使用bool 和must包含多个match,以下只能查询出同时包含休闲和益智两个词条的文档 1234567891011GET /data_test2/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;label_des&quot;: &quot;休闲&quot; &#125;&#125;, &#123; &quot;match&quot;: &#123; &quot;label_des&quot;: &quot;益智&quot; &#125;&#125; ] &#125; &#125;&#125; Match phrasematch phrase和term有些类似其核心在于时候分词match phrase会对输入的词进行分词，比如term中查询休闲益智，那么会执行查询文档中是否包含休闲益智这个词条，但是ik分词器中并没有这个词，只存在休闲和益智两个词条索引term无法查询出，如果使用Match phrase查询休闲益智这个词，则会将其分隔成休闲和益智两个词，再去文档中查询同时包含这两个题词条的数据，另外其还可指定slop来规定查询的这两个词之间可以间隔多少个词 123456789101112GET /data_test2/_search&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;sentence&quot;: &#123; &quot;query&quot;: &quot;点击自动&quot;, &quot;slop&quot;: 10 &#125; &#125; &#125;&#125; aggs聚合ES聚合查询分为Bucket和Metric ，Bucket类似SQL的Group By ，Metric 类似SQL 的 AVG ,MAX ,MIN函数,并且在返回的Bucket桶中可以查看到当前桶下数据的条数 以下语句类似SQL的 select label_des as group， max(label) as max_name from data_test2 group by label_des 1234567891011121314151617181920GET /data_test2/_search&#123; &quot;aggs&quot;: &#123; &quot;group&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;label_des.keyword&quot;, &quot;size&quot;: 10 &#125;, &quot;aggs&quot;: &#123; &quot;max_name&quot;: &#123; &quot;max&quot;: &#123; &quot;field&quot;: &quot;label&quot; &#125; &#125; &#125; &#125; &#125; &#125; Pipeline aggregations和aggs不同的是，aggs针对的是文档的聚合，而pipeline aggs针对的aggs后的数据再做一次aggs(类似对SQL的Group By语句再做一次查询) 以下查询类似sql语句 123select max(label_num) from ( SELECT label_des , max(label) as label_num from data_test2 group by label_des ) t 具体的pipeline类型查看官方文档 https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-pipeline-max-bucket-aggregation.html 12345678910111213141516171819202122232425262728293031323334353637GET /data_test2/_search&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;label_des&quot;: &#123; &quot;value&quot;: &quot;工具&quot; &#125; &#125; &#125;, &quot;aggs&quot;: &#123; &quot;tool&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;label_des.keyword&quot; &#125;, &quot;aggs&quot;: &#123; &quot;label_num&quot;: &#123; &quot;max&quot;: &#123; &quot;field&quot;: &quot;label&quot; &#125; &#125; &#125; &#125; , &quot;max_label&quot;: &#123; &quot;max_bucket&quot;: &#123; &quot;buckets_path&quot;: &quot;tool.label_num&quot; &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES设置]]></title>
    <url>%2F2021%2F03%2F07%2FES%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[简介前文只是简单的介绍了ES的使用，但是实际使用中会涉及到一些设计和服务器上参数的调整，这里对其做个简介 JVM 内存：Xms和Xmx设置一样，避免堆Resize引发的停顿，Xmx设置不要超过物理内存的百分50,最大不超过32G，JVM在内存小于32G时会对内存进行指针压缩，如果大于32G可能会导致性能下降 JVM使用Service模式 关闭JVM Swapping 硬件内存内存的大小需要根据Node所需要的数据来估算 搜索类的比例1:16 日志类的比例 1:48 -1:96之间 MappingES的Mapping分为动态的Mapping和手动设置的Mapping，所谓动态就是在创建索引时不指定字段的类型，由ES在插入数据时，自动生成对应的类型，比如一下是一个ES自动生成的Mapping，其为content和title自动创建了文本类型，并且为其创建了keyword类型的子字段为了精确匹配，这样导致了资源的浪费，或者在索引效率等问题，所以一般情况下我们会选择手动创建Mapping和关闭自动创建索引功能 1234567891011121314151617181920212223242526&#123; &quot;news&quot; : &#123; &quot;mappings&quot; : &#123; &quot;properties&quot; : &#123; &quot;content&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125;, &quot;title&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125; &#125; &#125; &#125;&#125; 如果 写操作优化对ES的写优化前先大致了解一下ES的写策略,总体ES的写入策略和KAFKA类似(WAL)，分为Refresh和Flush。ES的数据分片的最小单元成员Segment，ES中只有文档变成了生成了Segment才能被检索到，那么文档生成Segment的实效决定了写入了数据多长时间能被检索到，而ES写入的策略是先将数据写在内存的缓冲区，当达到一定条件后将数据生成Segment，这个过程就叫Refresh。我们知道文件系统中存在缓存区，Linux系统中需要调用fsync才能将数据由文件缓存区写入到磁盘，在Refresh时，ES并没有调用fsync，只有当ES在Flush阶段在调用fsync，数据才真正写入磁盘，为了避免数据在Refresh和Flush的阶段中丢失，ES也引入了WAL，在数据写入时写入磁盘日志，来避免数据丢失，那么这里优化的方法其实和kafka没有太大区别，就是优化缓存数据和日志刷新到硬盘的策略。]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch基本概念]]></title>
    <url>%2F2021%2F01%2F18%2FElasticsearch%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[简介之前一直有计划学习Elasticsearch，刚好最近趁着项目空档期学习了Elasticsearch 7，且也打消了Elasticsearch和Hadoop MapReduce的使用情景有疑问，因为之前认为这两个框架都是对海量数据进行分析，且Elasticsearch的实时性更好为那么Hadoop的使用场景在哪？这是因为Elasticsearch对于精确复杂的统计分析并不支持，其更多是解决全文搜索而生，而MapReduce更多是为了精确分析而生，具体可看维护篇中关于索引的部分。 基本概念简单的来说就是Elasticsearch对Lucene进行了封装，Lucene是Apache开源的搜索引擎库，但是使用它需要太多的专业知识，Elasticsearch对其进行了封装，并对外提供Rest服务，方便不是很了解全文检索的人使用。 节点篇 Master：主节点,总体机制和其余高可用的主节点没有太多区别，比如写入由主节点统一写入保证数据写入等操作唯一,还有支持部署多个主节点在主节点挂掉后选举出新的主节点，且7.0中加入的防止闹裂等功能。 Data：数据节点，就是保存节点数据的地方，在查询中在各个节点中做查询后统一返回做处理 Coordinating：协调节点，用户请求直接访问到协调节点，由协调节点将数据路由到各个数据节点，数据节点完成查询后，再在协调节点进行统计处理返回，所以ES能承载多少的并发量，部署多少台协调节点是个重要的考虑点 Ingest：ingest 节点可以看作是数据前置处理转换的节点，举个例子在写入文档时不由业务层在每个文档加入时间戳,由ES自动处理，其实这些操作都可以在业务层面去实现，网上看到的说法是，为了解决业务层性能问题(比如上文中说到的每个文档加入时间戳) Machine learning：机器学习节点，高科技没用过。 由上述节点构成的一组服务器就叫做Cluster集群 索引篇首先了解一下倒排索引，以下是网上找的说明 倒排索引（英语：Inverted index），也常被称为反向索引、置入档案或反向档案，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。 用个直观的例子说明一下：下面有两句话 中国是社会主义国家 美国是资本主义国家 如果我们用关系数据库去查找的话且为这个字段建立了索引，我们做模糊匹配Like搜索，那么其实这个索引的作用就不大，因为他要全表扫描这个字段，让后再在每条记录中和你搜索的字符串做比较，而且假设我现在想搜索同时包含中国和国家的文档，那么关系型数据库就嗝屁了，那么在搜索引擎中为了解决这个问题，对上面的两句话进行了分词（分词的一种原理就是查询字典，比如中国这个词在字典中有没有，如果有的话他就是一个词，如果没有就不是，所以很多分词器为了定制化的远程都支持使用自己的字典库），让后再对每个词建立索引。比如下面那个表格就是一个倒排索引 词 文档ID 中国 1 是 1,2 社会主义 1 国家 1,2 美国 2 资本主义 2 Index:索引，就是存储上文说的倒排索引的地方，对比关系型数据库的表(网上资料都将关系型数据库中数据库类比为ES的Index，个人感觉在ES7中有点不太形象，因为7移除了Type，Mapping直接和是和Index关联的) Mapping：这里可以类比成关系型数据库的表结构 Field：对应关系型数据库表结构下的字段 Document： 文档，这里可以对于关系型数据库中的一条条数据，每条数据存储在Index中，其字段通过Mapping来定义 Sorce Type: 在7中后移除了这个属性，具体的原因参考官方文档，里面提到了在Lucene 中一个Index中的相同的字段都存储在一起，如果一个Index下后多个不同Type且其存储Mapping字段相同，那么会对索引管理和效率等产生影响，所以删除 https://www.elastic.co/guide/en/elasticsearch/reference/current/removal-of-types.html Score：ES中对文档的搜索的相关度以算分来区分，在多字段查询中其颇为有用，假设我们需要对文档的标题和内容进行检索，假设我们认为标题中如果有搜索词的话其更匹配用户需求，那么我们可以在使用搜索API时提升标题的算分，如果一个字段同时出现在两个文档中，那么标题中有这个文档的算分跟高，就会排在更前面 查询篇说道查询还是要提起一下上文说道的分词，ES和其它数据库最大的不同就是在分词，所有查询都是围绕分词进行的，在建立索引的时候我们要制定对应Mapping 下的Field字段的类型和采用什么样的分词器，我们查询的时候其实是查询我们查询的词是否命中了倒排索引，而不是像关系型数据库那样全表扫描数据让后再进行比对，如何对查询的词进行分词和组合也是查询的关键 Term：不对查询的词语进行分词，以上文为例，我查询的词语为“中国是”，那么在ES中无法匹配出任何文档，因为假设ES对文档的分词内容如上文所示，那么按照Term查询的定义来说不对查询的词进行分词，那么它就会查询文档中是否有包含“中国是”这个词的索引，显然我们的索引中并没有“中国是”这个词，所以无法命中 Match：对查询的词进行分词，还是以上文为例，我查询“中国资本主义”，那么分词器会把词分为“中国”，“资本主义”去索引中查询文档，那么这里命中了 文档1，2,这两个文档都一起返回，另外Match查询又有Match and (同时匹配中国和资本主义的文档) ，Match Phrase查询(对查询进行分词关联查询) Aggs：聚合查询，其中又重要包括Bucket和Metric查询，其中Bucket是对数据进行分桶，类比关系型数据库中的Group By，Metric对比关系型数据库的语法为 Min ，Max ，AVG，Distinct等操作，对数据进行统计计算等，一般和关系型数据库一样和Bucket(分桶函数搭配一起使用) 维护篇 Index：和数据库一样，一个索引数据多了为了查询性能就要对数据进行分片，且为了高可用防止硬盘损坏导致数据丢失可对索引做备份，索引如果ES的数据节点不需要对硬盘做磁盘阵列存储数据(如RAID5等)，这样节省了硬盘资源。注意:索引一旦创建就不可以修改Mapping(对于动态Mapping可以添加新的字段)和分片信息，如果需要修改只能reIndex重建索引，但是ES和MongoDB一样会对数据进行再平衡，举个例子，我们只有一台数据节点，并且在上建立了一个索引，并且指定了2个主分片，那个新增文档的时候数据会均匀分配在这两个主分片上，假设后续又加入了一个节点做数据节点，那个这两个主分片的一个会自动迁移到另一台数据节点上。至于一个索引要建立多少个分片需要看对数据量进行评估，官方推荐是搜索类文档单分片不超过20G,日志型不超过50G，但是分片也不是越多越好，分片越多查询就越不准确，假设现在执行一个聚合操作(group by)并且返回各个分组数最多的那个，其会在各个数据节点进行分组计算，再将计算后的数据发送到Coordinating节点进行重新聚合，那么数据节点会返回单前节点最大的那个分组给Coordinating节点，但是这样是不准确的，所以业务是需要精确统计的那么ES就不适用，应该选择Hadoop MapReduce这类离线计算的框架，且Index支持冷热数据的切换，假设现在有2台服务器，一台性能很好，一台较差，那么我们可以将热点的Index指定存储到较好配置的节点上，待这部分热点数据变冷后，通过Setting设置将其转移到较差的那台服务器上。 health：Index的分配情况决定了集群是否健康查看集群可通过以下API如果集群中所有索引都是green说明索引分片和副本都正常，如果是yellow说明至少一个副本分片分配失败，如果是red说明至少有一个主分片分配失败， 1GET /_cat/health 那么我们下一步可以查看所有索引的健康情况，再做对应的处理，如果是红色的话可以查看是否设置了一个node只能有一个分片，如果是黄色，可以查看是否节点不够，因为ES不允许主分片和副本分片同时分配在一台节点上 1GET _cluster/health?level=indices Mapping：以下是我之前定义的一个Index的Mapping 我定义了id,label，label_des，sentence这几个字段，每个字段的类型又不同字段， id：字段类型keyword，该类型不会对其进行分词，因为ID都是进行精确匹配的，且aggs聚合操作不能对Text类型使用 label：字段为整型 label_des，这个字段我们需要注意一下,其类型为text类型，且我指定了使用ik_smart进行分词，并且我指定了第二个数据类型为keyword，这是为了后续我可以使用该字段进行聚合和精确term查找，因为如果是text格式的话其是进行分词存储，所以无法精确匹配和聚合，且定义子数据类型有其它使用场景，比如我们在搜索中文数据时同时需要对拼音和中文进行检索，那么我们可以定义一个子字段，且其采用拼音的分词器，那么在查询时同时匹配中文和拼音字段中的索引 sentence：字段同上，只是区别在与对其存储时和查询时使用了不同的分词器（在进行查询时对查询字段采用ik_smart进行分词） 1234567891011121314151617181920212223242526272829303132333435PUT /data_test&#123; &quot;settings&quot; : &#123; &quot;number_of_shards&quot; : &quot;1&quot;, &quot;number_of_replicas&quot; : &quot;0&quot; &#125;, &quot;mappings&quot; : &#123; &quot;properties&quot; : &#123; &quot;id&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 100 &#125;, &quot;label&quot; : &#123; &quot;type&quot; : &quot;integer&quot; &#125;, &quot;label_des&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;ik_smart&quot;, &quot;fields&quot;:&#123; &quot;keyword&quot;:&#123; &quot;type&quot;:&quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125;, &quot;sentence&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;ik_max_word&quot;, &quot;search_analyzer&quot; : &quot;ik_smart&quot; &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于领域驱动设计和manve spring的模块化开发的实践]]></title>
    <url>%2F2020%2F10%2F12%2F%E5%9F%BA%E4%BA%8E%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E5%92%8Cmanve-spring%E7%9A%84%E6%A8%A1%E5%9D%97%E5%8C%96%E5%BC%80%E5%8F%91%E7%9A%84%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[简介基于领域驱动设计(DDD)开发的项目，它具有代码层次分明，业务更好的贴合业务，使代码的可维护性和可读性大大提高等优点，而MAVEN和Spring天生就是为模块化而设计开发的，最近结合之前的DDD使用经验，结合使用MAVEN和Spring对项目的模块化进行一次实践。 为什么要模块化和为什么需要微服务之前本人参与过的项目中有些采用了SpringCloud全家桶对项目进行微服务化，但是经过一番实践后发现大多数项目并不需要进行微服务化，大都数使用微服务只是为了强制使各个服务的代码隔离，甚至很多情况下所有的服务的数据库还在单个数据库中存储，当我问他们为什么使用单体应用时他们常说为了让各个服务的代码隔离，日后好维护。但是在日常开发中这种四不像赶鸭子上架的开发行为并没有使代码变得更简洁，而且采用微服务在配套设施(如全链路追踪，系统异常检测等)没有发展起来的时候，对线上的问题排查，应用的部署和维护简直是噩梦。所以解决代码业务隔离的问题并不只有微服务这种方法，我们使用maven和Spring就能很好的处理代码业务隔离性的问题，而且使用模块化避免了日后重复功能的开发，比如权限模块，如果之前已经将权限功能进行模块化后,那么后续就不需要在开发，只需要使用MAVEN将需要的模块组装起来即可，个人认为也可类比为中台。 为什么要使用领域驱动设计(DDD)简单的来说代码的核心是你的业务，所以代码能很好的体现业务，并且将业务代码剥离出来那么代码的可读性和维护性就会更好，举个例子，代码写完后一个月你不去动它，那么你就会忘记，但是业务却没那么容易忘记，而且业务往往有详细的设计和使用文档，如果我们的代码很很好的映射成我们的业务，那么时候意味着日后的扩展会更好？关于领域驱动设计的基础概念可查看之前的文章。 系统分层 本次实践采用的项目结构依旧是六边形架构，此架构凸显了越是核心的代码就要放在项目的最底层，这样才能避免核心代码免受其它非核心代码的干扰。简单的举例来说，对于项目而言，最核心的代码应该是项目逻辑代码，这部分代码不应该受到数据库持久层等代码的干扰(持久层代码的变化不应该影响业务代码)，这里举个例子，大家编写代码的时候都依赖过其它项目的包，你需要调用依赖包的方法，经常会出现你依赖的包版本升级导致了你的代码编译报错，为什么会出现这种情况？这是因为你依赖了它的包，那么带来的问题就是你依赖的包发生了变化，那么你的代码就有可能出问题，但是相对你而言，你的代码才是业务的核心，你只是调用了第三方的方法去实现了一个功能，这里相对你来说业务代码才是最重要且在项目中最稳定的一部分，他不应该受到其它层次代码的干扰，如何解决这个问题？其实Spring已经给了我们答案。 依赖倒置和依赖注入 在刚刚接触到Spring时常常听人说Spring的核心理念就是依赖导致和依赖注入，至于什么事依赖倒置什么是依赖注入，即为什么要使用依赖倒置和依赖注入在接触到领域驱动设计之前其实也是一知半解，这里结合我的实际经验和体会谈谈为什么我们需要Spring需要依赖倒置和依赖注入。 依赖倒置：依赖倒置我们可以首先根据直面上的意思去理解，就是依赖的关系发生倒置，举个大家都理解的例子，你的领域层(如果不了解领域驱动设计可以将其理解为service)需要将数据持久化到数据库，那么你就会调用DAO去持久化，那么按照领域驱动的设计来说，你的领域层代码才是最核心最稳定的内容，他不应该受到DAO的影响，假设我这里将之前service调用的一个DAO的方法删除，那么service就报错了，又由于我们系统的核心是领域层，它应该是最稳定的代码不应该受到其它非核心代码的干扰。好的做法是将依赖倒置，让我们的DAO去依赖领域层(Service)，这样即使DAO再怎么变化也不会影响到领域层(Service)，为了实现这个目的我们在领域层(Service)上开了一个java接口，由DAO层去实现这个接口，那么现在代码就变成了DAO依赖领域层（Service），如果你用过maven现在的依赖关系就变成了DAO的pom文件中依赖了领域层（Service），因为DAO需要实现到领域层的接口，那么在领域层中需要使用到DAO的实现时只需要调用自己开放给DAO的接口即可。 依赖注入:仅仅使用依赖倒置是不足以使依赖发生倒置的，因为虽然现在领域层使用DAO的实现时调用了自己开放给DAO的接口，但是接口需要实现，如何让接口知道现在使用的是哪个实现类呢？如果在领域层去告诉代码DAO的接口具体是由哪个类实现的，那么这里又会出现了循环依赖的问题，即DAO依赖领域层(DAO实现了领域层的接口)，领域层也依赖了DAO(需要在领域层中配置接口是由哪个DAO的实现类实现的)，这样会导致更加严重的循环依赖问题。那么如何解决这个问题呢？答案就是我再引入一个通用的模块，所有层去依赖这个模块，你把你DAO需要实现的对象注入到Spring中，同样领域层需要渠道DAO的实现时去Spring中去获取，那么现在领域层不再依赖DAO层，而是依赖了更加通用稳定的的中间层Spring，这样就处理了系统层次划分的问题。 项目结构的划分以下是项目结构的划分，以下是使用maven和Spring进行模块化进行的实践，其中app负责组装各个模块，auth是我创建的一个模块，模拟用户角色系统，开发完各个模块后，我们把auth创建层springboot starter，以下是我为何这样分层，和一些个人的的见解： 关于文档 文档我采用Spring Rest doc，因为个人不喜欢Swagger的侵入的注解。 关于持久层框架 持久层我没有采用mybatis plus 因为我不喜欢它的类的命名方式不够直观，感觉有违领域驱动的理念，我更喜欢类Spring data 关于依赖倒置 上文说到，我创建了领域层domain，和基础设施层infrastructure，持久层就是在这个包下实现的，根据上文所说，领域层是最核心的层，需要放在依赖链的最下层，但是domain又需要调用持久层中的代码去持久化数据，所以我在domain下写了一个接口，由基础设施层infrastructure去实现，而我又使用Spring去管理对象的什么周期，使用依赖注入去注入对象从而调用infrastructure层的方法，这样达到依赖倒置的目的。 关于各个层的反腐 在我之前项目中我见过的大多项目没有明确的区分各个层次的对象，常常就是controller中传入一个DTO对象，然后这个DTO对象一直往下传，一直到DAO中进行持久化，这样会导致什么问题？这违反了领域驱动中领域层需要放在项目最底层的理念，因为领域层传入参数是controller中的DTO对象，导致了领域层依赖了controller层，而且最近在维护之前公司的一个老项目，且没有任何文档，在这种情况下走查代码，只能通过controller层一层层往下看，但是你又会发现DTO被各个层无限复用，入口传入的DTO中有许许多多不需要的对象属性，让我根本不无从下手。为了避免这种情况下，我讲controller，domain，repository层的对象严格区分，在这些包下都创建了pojo包或者dto的包，在进入每个层次前都需要进行防腐转换，不要让不相关的代码污染到其它的层次，这样导致多了很多对象加大了工作流，但是如果能让代码更加清晰多一些对象又何妨？所有涉及模式基本都是采用增加类和换区代码的灵活度。 关于批量操作 在领域驱动中所有command操作(insert，update)都需要走领域逻辑，但是批量查询为了兼顾效率等问题，我们可以直接从repository中读取对象然后直接返回回去。 方法体现意图 在领域驱动中，你需要将你的意图封装成方法，你的方法名需要体现出你需要执行意图。这样的好处就是当你查看方法时，一进入方法就知道你要执行什么东西，印证了那句话，代码是给人看的，只是顺便让机器执行以下而言。 123456789101112131415161718192021222324252627282930313233343536373839├── app| └── src| ├── main| | ├── asciidoc| | ├── java| | | └── com| | | └── liu| | └── resources| └── test| └── java| └── com| └── liu| └── auth└── auth └── src ├── main | ├── java | | └── com | | └── liu | | ├── common | | | ├── pojo | | | └── utils | | ├── controller | | | └── dto | | ├── domain | | | ├── client | | | └── repository | | └── infrastructure | | ├── mapper | | ├── pojo | | └── repositoryImpl | └── resources | ├── com | | └── liu | | └── infrastructure | | └── mapper | └── META-INF └── test └── java]]></content>
      <categories>
        <category>领域驱动设计</category>
      </categories>
      <tags>
        <tag>领域驱动设计，模块化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用SpringRestDoc和AsciiDoc来构造项目文档]]></title>
    <url>%2F2020%2F08%2F21%2F%E4%BD%BF%E7%94%A8SpringDoc%E5%92%8CAsciiDoc%E6%9D%A5%E6%9E%84%E9%80%A0%E9%A1%B9%E7%9B%AE%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[简介程序员最讨厌的事情之一就是写文档,特别是word文档,写好word文档是并不是一件简单的事,以个人经验来看如果有人提供了一份word文档给我阅读,往往阅读效率是很低下的,于是催生出了类似于Markdown或者AsciiDoc这种以编程方式来写文档的工具,通过这些工具的语法,我们可以不需要学习各种排版样式而写入清新的文档,提到rest文档,不可绕开的就是Swagger,目前项目中全部使用了Swagger,但是使用Swagger的优缺点都很明显,优点:方便的工具让前端联调接口更简单,缺点:入侵式的注解让代码看起来杂乱无章,且文档不够直观等,在这些原因的驱使下让我去寻找一款更加清晰的文档工具,本人发现了2款文档工具 1:smart-doc 它是一款非入侵似的文档框架,采用类似java doc的标准注释来生成文档,这也强迫用户必须写注释,但是缺点是由于采用了注释,很多情况下不够灵活,第二个就是Spring Rest doc,来自Spring官方的Spring res doc, 生成的文档样式可以参考Spring的官方文档,其采用AsciiDoc作为编写文档的工具,美观,且更加灵活,并且其于单元测试强制绑定,也驱使我们培养出写单元测试的良好习惯,所以我这里采用Sprng rest doc来编写文档 效果图 创建项目 demo代码https://github.com/liushprofessor/hase_repository/tree/master/spring_test 以下是我创建的MAVEN工程的Pom文件,由于Spring rest doc 是和单元测试签字绑定所以我这里引入了Springtest的包,并且引入Sprig rest doc的包spring-restdocs-mockmvc 我们重点来关注一下plugin,其定义了3个maven插件,spring-boot-maven-plugin没什么好说的,springboot打包插件,asciidoctor-maven-plugin其作用将为asciidoctor文档打包成html样式的文档,其绑定了maven的prepare-packet生命周期,在执行到该周期时自动将asciidoc的文件转成html,还有一个参数我们需要注意${snippetsDirectory},该配置规定了生成asciidoc文件的目录,第三个插件就是maven-resources-plugin,其同样绑定在prepare-packet什么周期,该插件的左右就是在打包时规定资源生成的路径,比如我这里将${project.build.directory}/generated-docs 目录下生成的html文件在打包时放入到static的docs文件下, 因为Maven规定 resources 下的static 目录是放置静态资源的目录,所以我们将生成的html放在该目录下,那么可以直接访问里面的文档. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;spring_test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;snippetsDirectory&gt;$&#123;project.build.directory&#125;/generated-snippets&lt;/snippetsDirectory&gt; &lt;/properties&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.9.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.restdocs&lt;/groupId&gt; &lt;artifactId&gt;spring-restdocs-mockmvc&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.asciidoctor&lt;/groupId&gt; &lt;artifactId&gt;asciidoctor-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.8&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;generate-docs&lt;/id&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;process-asciidoc&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;backend&gt;html&lt;/backend&gt; &lt;doctype&gt;book&lt;/doctype&gt; &lt;attributes&gt; &lt;snippets&gt;$&#123;snippetsDirectory&#125;&lt;/snippets&gt; &lt;/attributes&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.restdocs&lt;/groupId&gt; &lt;artifactId&gt;spring-restdocs-asciidoctor&lt;/artifactId&gt; &lt;version&gt;2.0.5.BUILD-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;!-- 自定义打包插件讲文档位置打包时放入固定位置 --&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-resources&lt;/id&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;project.build.outputDirectory&#125;/static/docs&lt;/outputDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.build.directory&#125;/generated-docs&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 创建接口并且生成单元测试 下面我写了两个简单的Rest 接口 12345678910111213@PostMapping(&quot;/addUser&quot;) public User addUser(User user) &#123; return user; &#125; @PostMapping(&quot;/updateUser&quot;) public User updateUser(@RequestBody User user) &#123; return user; &#125; 为接口编写单元测试 为了方便我将很多方法import模块时时采用了import static的方式 在写单元测试的时候我们需要注意一点,我们需要填写接收请求体的和响应请求头的 header,比如下面 的accept(MediaType.APPLICATION_JSON)和contentType(MediaType.APPLICATION_JSON),不然在采用非 MediaType.TEXT_PLAIN 格式的请求体的时候会报错,然后我们关注一下 andDo(document ….这后面的代码,这部分代码就是编写 文档的代码,以下第一个测试接口为例,我们在documet方法内指定了addUser参数,这个参数代表我们会在之前在 maven plugin中配置的配置的 ${project.build.directory}/generated-snippets 目录下生成了一个addUser文件夹,这文件夹下存放了asciidoc的文件 到这里你可能不太明白,到后面我们编译出文件后你就会明白了,requestHeaders是设置请求头,里面的方法headerWithName 设置了请求头说需要的参数,description为这个请求头的描述,后续spring rest doc会根据这些方法生成对应的表格文件, requestParameters 方法设置了请求体的参数,parameterWithName方法设定了请求参数的具体值, responseFields方法可以理解为设置响应体,fieldWithPath 方法为设置响应体具体的参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package com.test;import static org.junit.Assert.*;import com.alibaba.fastjson.JSON;import org.junit.Before;import org.junit.Rule;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.http.MediaType;import org.springframework.restdocs.JUnitRestDocumentation;import org.springframework.test.context.junit4.SpringRunner;import org.springframework.test.web.servlet.MockMvc;import static org.springframework.restdocs.mockmvc.MockMvcRestDocumentation.documentationConfiguration;import static org.springframework.restdocs.payload.PayloadDocumentation.*;import static org.springframework.restdocs.payload.PayloadDocumentation.fieldWithPath;import static org.springframework.restdocs.request.RequestDocumentation.requestParameters;import org.springframework.test.web.servlet.setup.MockMvcBuilders;import org.springframework.web.context.WebApplicationContext;import static org.hamcrest.Matchers.*;import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.post;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.jsonPath;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;import static org.springframework.restdocs.mockmvc.MockMvcRestDocumentation.document;import static org.springframework.restdocs.headers.HeaderDocumentation.*;import static org.springframework.restdocs.request.RequestDocumentation.*;/** * @author Liush * @description * @date 2020/8/19 21:08 **/@RunWith(SpringRunner.class)@SpringBootTestpublic class Test &#123; @Autowired private WebApplicationContext webApplicationContext; @Rule public JUnitRestDocumentation restDocumentation = new JUnitRestDocumentation(&quot;target/generated-snippets&quot;); private MockMvc mockMvc; @Before public void setUp()&#123; mockMvc=MockMvcBuilders.webAppContextSetup(webApplicationContext).apply(documentationConfiguration(restDocumentation)).build(); &#125; /** * requestFields 可以理解为添加的示例数据入&#123;&quot;id&quot;:&quot;222&quot;,&quot;name&quot;:&quot;Liush&quot;&#125; * responseFields 同理 * requestParameters 为入参数,使用此方法添加后会生成入场表格文件 */ @org.junit.Test public void addUserTest()throws Exception&#123; mockMvc.perform(post(&quot;/addUser&quot;).accept(MediaType.APPLICATION_JSON).param(&quot;id&quot;,&quot;1&quot;). param(&quot;name&quot;,&quot;liush&quot;).header(&quot;token&quot;,&quot;token&quot;) ).andExpect(jsonPath(&quot;$.id&quot;,is(&quot;1&quot;))).andExpect(jsonPath(&quot;$.name&quot;,is(&quot;liush&quot;))). andExpect(status().isOk()).andDo(document(&quot;addUser&quot;, requestHeaders(headerWithName(&quot;token&quot;).description(&quot;校验token&quot;)), requestParameters(parameterWithName(&quot;id&quot;).description(&quot;用户id&quot;), parameterWithName(&quot;name&quot;).description(&quot;用户名&quot;) ), responseFields(fieldWithPath(&quot;id&quot;).description(&quot;用户id&quot;), fieldWithPath(&quot;name&quot;).description(&quot;用户名&quot;) ) )); &#125; @org.junit.Test public void updateUser() throws Exception &#123; User user=new User(&quot;222&quot;,&quot;Liush&quot;); mockMvc.perform(post(&quot;/updateUser&quot;).accept(MediaType.APPLICATION_JSON).contentType(MediaType.APPLICATION_JSON).content(JSON.toJSONString(user))) .andExpect(jsonPath(&quot;$.id&quot;,is(&quot;222&quot;))).andExpect(status().isOk()). andDo(document(&quot;updateUser&quot;, requestFields(fieldWithPath(&quot;id&quot;).description(&quot;用户id&quot;), fieldWithPath(&quot;name&quot;).description(&quot;用户名&quot;) ), responseFields(fieldWithPath(&quot;id&quot;).description(&quot;用户id&quot;),fieldWithPath(&quot;name&quot;).description(&quot;用户名&quot;)) )) ; &#125;&#125; 看到这里你也许会有点懵,不过没关系,下面我们执行 mvn clean package命令查看具体目录结构后你就会一目了然vn 执行完该命令后,进入到target目录,下面会生成generated-snippets的目录,其有生成了一个addUser的目录 目录名字之前我们在document方法中指定了,其下又有9个文件,如果你对AsciiDoc有一些 了解你就会知道这些事AsciiDoc的文件 123456789curl-request.adochttp-request.adochttp-response.adochttpie-request.adocrequest-body.adocrequest-headers.adocrequest-parameters.adocresponse-body.adocresponse-fields.adoc 打开request-parameters.adoc文件,发现其已经将我们的请求体参数自动生成了表格 12345678910|===|Parameter|Description|`+id+`|用户id|`+name+`|用户名|=== 生成html文档 上面我们已经生成了AsciiDoc文件,现在我们就要将这些文件转换成html文档,首先我们需要在maven main 目录下新建一个asciidoc目录,里面新建一个index.adoc的文件,该文件名可以随意取, 我们编辑该文件,我们采用AsciiDoc语法写入一个文档,如果不熟悉AsciiDoc的语法可以 自行百度一下,很简单,我们重点关注 include命令,这里执行的就是将我们之前采用Spring rest doc生成的asccidoc文件引入到主文档来 我们再执行mvn clean package,我们就会再target目录下的 classes下的static下的docs下发现一个index.html 的html文档,然后我们访问该页面就能得到一个和Spring官方文档一样清爽的文档了. 1234567891011121314151617181920212223242526272829= 接口文档:author: liush:email: 442549007@qq.com:revnumber: v1.0:toc: left:toc-title: 接口文档== 用户接口=== 新增用户*curl 示例*include::&#123;snippets&#125;\addUser\curl-request.adoc[]*请求头头*include::&#123;snippets&#125;\addUser\request-headers.adoc[]*入参*include::&#123;snippets&#125;\addUser\request-parameters.adoc[]*出参*include::&#123;snippets&#125;\addUser\response-fields.adoc[]=== 修改用户*curl 示例*include::&#123;snippets&#125;\updateUser\curl-request.adoc[]*入参*include::&#123;snippets&#125;\updateUser\request-fields.adoc[]*入参示例*include::&#123;snippets&#125;\updateUser\request-body.adoc[]*出参*include::&#123;snippets&#125;\updateUser\response-fields.adoc[]*出参示例*include::&#123;snippets&#125;\updateUser\response-body.adoc[]]]></content>
      <categories>
        <category>文档</category>
      </categories>
      <tags>
        <tag>AsciiDoc</tag>
        <tag>SpringRestDoc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cas单点退出和自定义验证登录成功后返回的信息]]></title>
    <url>%2F2020%2F07%2F24%2Fcas%E5%8D%95%E7%82%B9%E9%80%80%E5%87%BA%E5%92%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E9%AA%8C%E8%AF%81ST%E8%BF%94%E5%9B%9E%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[简介项目中使用的CAS后续需要外部系统的接入，这里需要解决两个问题，1：单点登出问题，之前的文章中提到各个接入cas的应用在验证st时会获取到用户信息，然后将用户信息做缓存，下次再次访问这个子应用时就不需要再向cas去获取是否登录，那么这就存在一个问题，CAS已经退出登录，但是各个子应用仍然保存着登录状态，这就导致了用户仍然可以访问子应用。第二个问题，由于在验证st时，cas会返回用户信息，但是cas默认返回的信息有并不能满足项目需求，有些是多余的，还有一些自定义的用户信息并没有返回，这里也需要对信息做重新定制. 单点登出根据官网文档 https://apereo.github.io/cas/5.1.x/installation/Logout-Single-Signout.html slo退出分为2种，Back Channel 和Front Channel，我这里使用的是Back Channel，其原理也很简单就是在每个service下配置一个回调地址，当触发退出时，如果这个服务验证过st，那么系统就会认为其已经保存了登录信息，那么在触发单点登出时，调用配置的退出地址。 配置service 我这里没有使用静态json配置service的方法，在resource/services 下添加你要接入cas的配置文件,文件名为localhost-10000003.json，其中这里的localhost必须和下面配置文件的name对上，相应的10000003也必须和下面配置文件中的id对上，evaluationOrder为配置优先级，当一个接入的url同事满足多个配置文件时，值越小，优先级越高，还有一个配置单点登出的重要参数logoutUrl，这个就是触发登出时系统要去调用的子应用的回调地址，但实践当中我们的回调地址往往都需要带上一些凭证信息如用户id，所以用户id是动态生成的，CAS默认提供的逻辑只是静态的去调用配置的回调接口，我们要的是自定义登出逻辑，在配置的回调地址中加上参数，这里是加上用户id 1234567891011 &#123; &quot;@class&quot; : &quot;org.apereo.cas.services.RegexRegisteredService&quot;, &quot;serviceId&quot; : &quot;http://127.0.0.1.*&quot;, &quot;name&quot; : &quot;localhost&quot;, &quot;id&quot; : 10000003, &quot;description&quot; : &quot;localhost&quot;, &quot;evaluationOrder&quot; : 1, &quot;theme&quot;:&quot;theme_default&quot;, &quot;logoutUrl&quot;:&quot;http://127.0.0.1:11202/logout&quot;&#125; 定制单点登出回调逻辑 官网并没有对如何实现单点登出给出更多的文档，因为cas是通过webflow来实现的，通过跟踪具体的webflow配置信息就可以看出他的逻辑 DefaultLogoutWebflowConfigurer这个类是单点退出的webflow配置入口,在这个类中,可以找到以下代码，其中terminateSessionAction就是处理单点退出所在的类1ActionState actionState = this.createActionState(flow, &quot;terminateSession&quot;, &quot;terminateSessionAction&quot;); 我们进入TerminateSessionAction 这个类 在terminate方法下有一行，根据方法名我们可以知道这里执行的是销毁TGT凭证的地方 1List&lt;LogoutRequest&gt; logoutRequests = this.centralAuthenticationService.destroyTicketGrantingTicket(tgtId); 我们找到CentralAuthenticationService 这个接口，发现其默认只有一个实现类DefaultCentralAuthenticationService,在其的destroyTicketGrantingTicket方法中我们可以看到，如下代码，通过查看源码，发现this.logoutManager.performLogout(ticket)中执行的就是单点退出的逻辑。 123456789101112131415public List&lt;LogoutRequest&gt; destroyTicketGrantingTicket(String ticketGrantingTicketId) &#123; try &#123; LOGGER.debug(&quot;Removing ticket [&#123;&#125;] from registry...&quot;, ticketGrantingTicketId); TicketGrantingTicket ticket = (TicketGrantingTicket)this.getTicket(ticketGrantingTicketId, TicketGrantingTicket.class); LOGGER.debug(&quot;Ticket found. Processing logout requests and then deleting the ticket...&quot;); AuthenticationCredentialsThreadLocalBinder.bindCurrent(ticket.getAuthentication()); List&lt;LogoutRequest&gt; logoutRequests = this.logoutManager.performLogout(ticket); this.deleteTicket(ticketGrantingTicketId); this.doPublishEvent(new CasTicketGrantingTicketDestroyedEvent(this, ticket)); return logoutRequests; &#125; catch (InvalidTicketException var4) &#123; LOGGER.debug(&quot;TicketGrantingTicket [&#123;&#125;] cannot be found in the ticket registry.&quot;, ticketGrantingTicketId); return new ArrayList(0); &#125; &#125; 我们进入其唯一实现类DefaultLogoutManager，找到 performLogout方法,下面我做注释，注释的地方就是执行单点登出的地方 12345678910111213141516public List&lt;LogoutRequest&gt; performLogout(TicketGrantingTicket ticket) &#123; LOGGER.info(&quot;Performing logout operations for [&#123;&#125;]&quot;, ticket.getId()); if (this.singleLogoutCallbacksDisabled) &#123; LOGGER.info(&quot;Single logout callbacks are disabled&quot;); return new ArrayList(0); &#125; else &#123; //执行单点退出逻辑 List&lt;LogoutRequest&gt; logoutRequests = this.performLogoutForTicket(ticket); this.logoutExecutionPlan.getLogoutHandlers().forEach((h) -&gt; &#123; LOGGER.debug(&quot;Invoking logout handler [&#123;&#125;] to process ticket [&#123;&#125;]&quot;, h.getClass().getSimpleName(), ticket.getId()); h.handle(ticket); &#125;); LOGGER.info(&quot;[&#123;&#125;] logout requests were processed&quot;, logoutRequests.size()); return logoutRequests; &#125; &#125; 现在我们再进入performLogoutForTicket 方法,下面注释出已经标出了执行单点退出的地址 1234567891011private List&lt;LogoutRequest&gt; performLogoutForTicket(TicketGrantingTicket ticketToBeLoggedOut) &#123; Stream&lt;Map&lt;String, Service&gt;&gt; streamServices = Stream.concat(Stream.of(ticketToBeLoggedOut.getServices()), Stream.of(ticketToBeLoggedOut.getProxyGrantingTickets())); return (List)streamServices.map(Map::entrySet).flatMap(Collection::stream).filter((entry) -&gt; &#123; return entry.getValue() instanceof WebApplicationService; &#125;).map((entry) -&gt; &#123; WebApplicationService service = (WebApplicationService)entry.getValue(); LOGGER.debug(&quot;Handling single logout callback for [&#123;&#125;]&quot;, service); //具体执行单点退出的地方 return this.singleLogoutServiceMessageHandler.handle(service, (String)entry.getKey()); &#125;).flatMap(Collection::stream).filter(Objects::nonNull).collect(Collectors.toList()); &#125; 现在我们思路就很明确了，实现自己的SingleLogoutServiceMessageHandler，并注入到DefaultLogoutManager中 单点登出实践 重写SingleLogoutServiceMessageHandler 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class LogoutHandler implements SingleLogoutServiceMessageHandler &#123; private HttpClient httpClient; private ServicesManager servicesManager; private TicketRegistry ticketRegistry; public LogoutHandler(HttpClient httpClient, ServicesManager servicesManager, TicketRegistry ticketRegistry) &#123; this.httpClient = httpClient; this.servicesManager = servicesManager; this.ticketRegistry = ticketRegistry; &#125; @Override public Collection&lt;LogoutRequest&gt; handle(WebApplicationService singleLogoutService, String ticketId) &#123; //根据ticketId获取到ST ServiceTicket serviceTicket =(ServiceTicket)ticketRegistry.getTicket(ticketId); //根据ST获取到TGT TicketGrantingTicket ticketGrantingTicket=serviceTicket.getTicketGrantingTicket(); //用TGT获取用户id String userId=ticketGrantingTicket.getAuthentication().getPrincipal().getId(); Collection&lt;LogoutRequest&gt; logoutRequests=new ArrayList&lt;&gt;(); //获取当前有多少服务使用TGT去生成ST,因为单点的统一凭证就是TGT，一次登录使用的都是同一个TGT，所以可以使用TGT发现有多少个自服务登录过系统 for(Map.Entry&lt;String, Service&gt; entry: ticketGrantingTicket.getServices().entrySet())&#123; //查询对应系统配置的信息 RegisteredService registeredService = servicesManager.findServiceBy(entry.getValue()); //获取到前面配置的service的回调地址并且加上userId作为参数 String url=registeredService.getLogoutUrl()+&quot;?userId=&quot;+userId; try &#123; //发送消息 HttpMessage message =httpClient.sendMessageToEndPoint(new URL(url)); DefaultLogoutRequest defaultLogoutRequest=new DefaultLogoutRequest(ticketId,singleLogoutService,new URL(url)); logoutRequests.add(defaultLogoutRequest); &#125; catch (MalformedURLException e) &#123; e.printStackTrace(); &#125; &#125; return logoutRequests; &#125;&#125; 在Srping的LogoutManager中注入的LogoutHandler 1234567891011121314151617181920212223 @Autowired private LogoutMessageCreator logoutBuilder; @Autowired @Qualifier(&quot;noRedirectHttpClient&quot;) private HttpClient httpClient; @Autowired @Qualifier(&quot;servicesManager&quot;) private ServicesManager servicesManager; @Autowired @Qualifier(&quot;ticketRegistry&quot;) private ObjectProvider&lt;TicketRegistry&gt; ticketRegistry;@Autowired @Bean public LogoutManager logoutManager(@Qualifier(&quot;logoutExecutionPlan&quot;) final LogoutExecutionPlan logoutExecutionPlan) &#123; return new DefaultLogoutManager(logoutBuilder, new LogoutHandler(httpClient,servicesManager,ticketRegistry.getIfAvailable()), false , logoutExecutionPlan); &#125; 自定义登录成功后的返回信息在cas中用户登录信息是用过验证st时返回，但是默认返回的信息包含很多我们不需要的信息，在第三方接入时难免体验很差，所以我这边对返回的用户信息进行了改造 找到入口之前的的文章中就已经找到验证st的接口地址是/p3/serviceValidate,我们在源码中搜索此地址找到验证st的入口 V3ServiceValidateController 123456@GetMapping( path = &#123;&quot;/p3/serviceValidate&quot;&#125; ) protected ModelAndView handle(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; return super.handleRequestInternal(request, response); &#125; 我第一步想找到的是，接口的参数是如何渲染出来的，使用idea一步步进入方法，发现其生成参数的地方是在其父类 AbstractServiceValidateController的 getModelAndView方法下,我们可以看到根据传参的不同可以生成json格式的view和xml模式的view,而successView是通过构造方法注入到这个类的，那我们只需要在源码去全局搜索AbstractServiceValidateController的注入的successView到底是什么 12345678910111213private ModelAndView getModelAndView(HttpServletRequest request, boolean isSuccess, WebApplicationService service) &#123; ValidationResponseType type = service != null ? service.getFormat() : ValidationResponseType.XML; String format = request.getParameter(&quot;format&quot;); if (!StringUtils.isEmpty(format)) &#123; try &#123; type = ValidationResponseType.valueOf(format.toUpperCase()); &#125; catch (Exception var7) &#123; LOGGER.warn(var7.getMessage(), var7); &#125; &#125; return type == ValidationResponseType.JSON ? new ModelAndView(this.jsonView) : new ModelAndView(isSuccess ? this.successView : this.failureView); &#125; 在源码中我发现其配置类在CasValidationConfiguration下 1234567891011121314151617181920@Bean @ConditionalOnMissingBean(name = &quot;v3ServiceValidateController&quot;) public V3ServiceValidateController v3ServiceValidateController() &#123; return new V3ServiceValidateController( cas20WithoutProxyProtocolValidationSpecification, authenticationSystemSupport.getIfAvailable(), servicesManager, centralAuthenticationService, proxy20Handler.getIfAvailable(), argumentExtractor.getIfAvailable(), multifactorTriggerSelectionStrategy, authenticationContextValidator, cas3ServiceJsonView(), cas3ServiceSuccessView(), cas3ServiceFailureView, casProperties.getAuthn().getMfa().getAuthenticationContextAttribute(), serviceValidationAuthorizers, casProperties.getSso().isRenewAuthnEnabled() ); &#125; 我们进一步查看cas3ServiceSuccessView()这个方法,又发现其是Cas30ResponseView，其中我们关注下面这个参数cas3SuccessView 123456789101112131415@Bean @ConditionalOnMissingBean(name = &quot;cas3ServiceSuccessView&quot;) public View cas3ServiceSuccessView() &#123; final String authenticationContextAttribute = casProperties.getAuthn().getMfa().getAuthenticationContextAttribute(); final boolean isReleaseProtocolAttributes = casProperties.getAuthn().isReleaseProtocolAttributes(); return new Cas30ResponseView(true, protocolAttributeEncoder, servicesManager, authenticationContextAttribute, cas3SuccessView, isReleaseProtocolAttributes, authenticationAttributeReleasePolicy, authenticationServiceSelectionPlan.getIfAvailable(), cas3ProtocolAttributesRenderer()); &#125; 我们找到了 cas3SuccessView这个类 123456@Bean@Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE)public CasProtocolView cas3SuccessView() &#123; return new CasProtocolView(casProperties.getView().getCas3().getSuccess(), applicationContext, springTemplateEngine, thymeleafProperties);&#125; Cas30ViewProperties 我们一步步进去查看发现重要信息protocol/3.0/casServiceValidationSuccess 123456public class Cas30ViewProperties implements Serializable &#123; private static final long serialVersionUID = 2345062034300650858L; private String success = &quot;protocol/3.0/casServiceValidationSuccess&quot;; private String failure = &quot;protocol/3.0/casServiceValidationFailure&quot;; ... &#125; 我们进入源码目录下找到此目录下的文件,我们发现其实cas是使用thymeleaf将xml渲染出来而已 1234567891011121314&lt;cas:serviceResponse xmlns:cas=&apos;http://www.yale.edu/tp/cas&apos;&gt; &lt;cas:authenticationSuccess&gt; &lt;cas:user th:text=&quot;$&#123;principal.id&#125;&quot;/&gt; &lt;cas:proxyGrantingTicket th:if=&quot;$&#123;pgtIou&#125;&quot; th:text=&quot;$&#123;pgtIou&#125;&quot;/&gt; &lt;cas:proxies th:if=&quot;$&#123;not #lists.isEmpty(chainedAuthentications)&#125;&quot;&gt; &lt;cas:proxy th:each=&quot;proxy : $&#123;chainedAuthentications&#125;&quot; th:text=&quot;$&#123;proxy.principal.id&#125;&quot;/&gt; &lt;/cas:proxies&gt; &lt;cas:attributes th:if=&quot;$&#123;not #lists.isEmpty(formattedAttributes)&#125;&quot;&gt; &lt;div th:each=&quot;attr : $&#123;formattedAttributes&#125;&quot; th:remove=&quot;tag&quot;&gt; &lt;div th:utext=&quot;$&#123;attr&#125;&quot; th:remove=&quot;tag&quot;/&gt; &lt;/div&gt; &lt;/cas:attributes&gt; &lt;/cas:authenticationSuccess&gt;&lt;/cas:serviceResponse&gt; 定制参数现在我们知道了参数是如何渲染出来的下面我们就要开支定制参数了同样在AbstractServiceValidateController类中发现generateSuccessView方法，使用过SpringMVC的一定都能看懂以下代码，那么我们现在寻找绑定modal的Assertion 参数是如何生成的 1234567891011121314151617181920212223private ModelAndView generateSuccessView(Assertion assertion, String proxyIou, WebApplicationService service, HttpServletRequest request, Optional&lt;MultifactorAuthenticationProvider&gt; contextProvider, TicketGrantingTicket proxyGrantingTicket) &#123; ModelAndView modelAndView = this.getModelAndView(request, true, service); //将数据绑定到modal中 modelAndView.addObject(&quot;assertion&quot;, assertion); modelAndView.addObject(&quot;service&quot;, service); if (StringUtils.hasText(proxyIou)) &#123; modelAndView.addObject(&quot;pgtIou&quot;, proxyIou); &#125; if (proxyGrantingTicket != null) &#123; modelAndView.addObject(&quot;proxyGrantingTicket&quot;, proxyGrantingTicket.getId()); &#125; contextProvider.ifPresent((provider) -&gt; &#123; modelAndView.addObject(this.authnContextAttribute, provider.getId()); &#125;); Map&lt;String, ?&gt; augmentedModelObjects = this.augmentSuccessViewModelObjects(assertion); if (augmentedModelObjects != null) &#123; modelAndView.addAllObjects(augmentedModelObjects); &#125; return modelAndView; &#125; 我们在generateSuccessView的调用者handleTicketValidation发现了以下方法，这里生成了Assertion 1Assertion assertion = this.validateServiceTicket(service, serviceTicketId); 我们再进入validateServiceTicket方法,发现我们的类其实是由CentralAuthenticationService生成的 123protected Assertion validateServiceTicket(WebApplicationService service, String serviceTicketId) &#123; return this.centralAuthenticationService.validateServiceTicket(serviceTicketId, service); &#125; 我们再进入其默认实现类DefaultCentralAuthenticationService的validateServiceTicket方法，这里我们看到主要逻辑是这边的代码会获取原来的Principal，然后将其的attributes重新生成了一次，这里就是为什么我之前在自定义认证时生成的Principal中的attributes丢失的原因，那么我们这里解决办法也很明了了，重新CentralAuthenticationService的方法将我们需要的参数放到新的Principal的attributes中即可 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public Assertion validateServiceTicket(String serviceTicketId, Service service) throws AbstractTicketException &#123; if (!this.isTicketAuthenticityVerified(serviceTicketId)) &#123; LOGGER.info(&quot;Service ticket [&#123;&#125;] is not a valid ticket issued by CAS.&quot;, serviceTicketId); throw new InvalidTicketException(serviceTicketId); &#125; else &#123; ServiceTicket serviceTicket = (ServiceTicket)this.ticketRegistry.getTicket(serviceTicketId, ServiceTicket.class); if (serviceTicket == null) &#123; LOGGER.warn(&quot;Service ticket [&#123;&#125;] does not exist.&quot;, serviceTicketId); throw new InvalidTicketException(serviceTicketId); &#125; else &#123; Assertion var18; try &#123; synchronized(serviceTicket) &#123; if (serviceTicket.isExpired()) &#123; LOGGER.info(&quot;ServiceTicket [&#123;&#125;] has expired.&quot;, serviceTicketId); throw new InvalidTicketException(serviceTicketId); &#125; if (!serviceTicket.isValidFor(service)) &#123; LOGGER.error(&quot;Service ticket [&#123;&#125;] with service [&#123;&#125;] does not match supplied service [&#123;&#125;]&quot;, new Object[]&#123;serviceTicketId, serviceTicket.getService().getId(), service&#125;); throw new UnrecognizableServiceForServiceTicketValidationException(serviceTicket.getService()); &#125; &#125; Service selectedService = this.resolveServiceFromAuthenticationRequest(serviceTicket.getService()); LOGGER.debug(&quot;Resolved service [&#123;&#125;] from the authentication request&quot;, selectedService); RegisteredService registeredService = this.servicesManager.findServiceBy(selectedService); LOGGER.debug(&quot;Located registered service definition [&#123;&#125;] from [&#123;&#125;] to handle validation request&quot;, registeredService, selectedService); RegisteredServiceAccessStrategyUtils.ensureServiceAccessIsAllowed(selectedService, registeredService); TicketGrantingTicket root = serviceTicket.getTicketGrantingTicket().getRoot(); Authentication authentication = this.getAuthenticationSatisfiedByPolicy(root.getAuthentication(), new ServiceContext(selectedService, registeredService)); //获取旧的Principal Principal principal = authentication.getPrincipal(); RegisteredServiceAttributeReleasePolicy attributePolicy = registeredService.getAttributeReleasePolicy(); LOGGER.debug(&quot;Attribute policy [&#123;&#125;] is associated with service [&#123;&#125;]&quot;, attributePolicy, registeredService); //生成新的attributesToRelease Map&lt;String, Object&gt; attributesToRelease = attributePolicy != null ? attributePolicy.getAttributes(principal, selectedService, registeredService) : new HashMap(); LOGGER.debug(&quot;Calculated attributes for release per the release policy are [&#123;&#125;]&quot;, ((Map)attributesToRelease).keySet()); String principalId = registeredService.getUsernameAttributeProvider().resolveUsername(principal, selectedService, registeredService); //生成新的Principal类 Principal modifiedPrincipal = this.principalFactory.createPrincipal(principalId, (Map)attributesToRelease); AuthenticationBuilder builder = DefaultAuthenticationBuilder.newInstance(authentication); builder.setPrincipal(modifiedPrincipal); LOGGER.debug(&quot;Principal determined for release to [&#123;&#125;] is [&#123;&#125;]&quot;, registeredService.getServiceId(), principalId); Authentication finalAuthentication = builder.build(); AuditableContext audit = AuditableContext.builder().service(selectedService).authentication(finalAuthentication).registeredService(registeredService).retrievePrincipalAttributesFromReleasePolicy(Boolean.FALSE).build(); AuditableExecutionResult accessResult = this.registeredServiceAccessStrategyEnforcer.execute(audit); accessResult.throwExceptionIfNeeded(); AuthenticationCredentialsThreadLocalBinder.bindCurrent(finalAuthentication); Assertion assertion = (new DefaultAssertionBuilder(finalAuthentication)).with(selectedService).with(serviceTicket.getTicketGrantingTicket().getChainedAuthentications()).with(serviceTicket.isFromNewLogin()).build(); this.doPublishEvent(new CasServiceTicketValidatedEvent(this, serviceTicket, assertion)); var18 = assertion; &#125; finally &#123; if (serviceTicket.isExpired()) &#123; this.deleteTicket(serviceTicketId); &#125; else &#123; this.ticketRegistry.updateTicket(serviceTicket); &#125; &#125; return var18; &#125; &#125; &#125; 具体实践1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class RestCentralAuthenticationService extends DefaultCentralAuthenticationService&#123; public RestCentralAuthenticationService(ApplicationEventPublisher applicationEventPublisher, TicketRegistry ticketRegistry, ServicesManager servicesManager, LogoutManager logoutManager, TicketFactory ticketFactory, AuthenticationServiceSelectionPlan authenticationRequestServiceSelectionStrategies, ContextualAuthenticationPolicyFactory&lt;ServiceContext&gt; serviceContextAuthenticationPolicyFactory, PrincipalFactory principalFactory, CipherExecutor&lt;String, String&gt; cipherExecutor, AuditableExecution registeredServiceAccessStrategyEnforcer) &#123; super(applicationEventPublisher, ticketRegistry, servicesManager, logoutManager, ticketFactory, authenticationRequestServiceSelectionStrategies, serviceContextAuthenticationPolicyFactory, principalFactory, cipherExecutor, registeredServiceAccessStrategyEnforcer); &#125; public Assertion validateServiceTicket(String serviceTicketId, Service service) throws AbstractTicketException &#123; if (!this.isTicketAuthenticityVerified(serviceTicketId)) &#123; throw new InvalidTicketException(serviceTicketId); &#125; else &#123; ServiceTicket serviceTicket = (ServiceTicket)this.ticketRegistry.getTicket(serviceTicketId, ServiceTicket.class); if (serviceTicket == null) &#123; throw new InvalidTicketException(serviceTicketId); &#125; else &#123; Assertion var18; try &#123; synchronized(serviceTicket) &#123; if (serviceTicket.isExpired()) &#123; throw new InvalidTicketException(serviceTicketId); &#125; if (!serviceTicket.isValidFor(service)) &#123; throw new UnrecognizableServiceForServiceTicketValidationException(serviceTicket.getService()); &#125; &#125; Service selectedService = this.resolveServiceFromAuthenticationRequest(serviceTicket.getService()); RegisteredService registeredService = this.servicesManager.findServiceBy(selectedService); TicketGrantingTicket root = serviceTicket.getTicketGrantingTicket().getRoot(); Authentication authentication = this.getAuthenticationSatisfiedByPolicy(root.getAuthentication(), new ServiceContext(selectedService, registeredService)); Principal principal = authentication.getPrincipal(); RegisteredServiceAttributeReleasePolicy attributePolicy = registeredService.getAttributeReleasePolicy(); Map&lt;String, Object&gt; attributesToRelease = attributePolicy != null ? attributePolicy.getAttributes(principal, selectedService, registeredService) : new HashMap(); //将我们需要回传给用户的信息放入新的attributes中 attributesToRelease.putAll(principal.getAttributes()); attributesToRelease.put(&quot;tgt&quot;,root.getId()); String principalId = registeredService.getUsernameAttributeProvider().resolveUsername(principal, selectedService, registeredService); Principal modifiedPrincipal = this.principalFactory.createPrincipal(principalId, (Map)attributesToRelease); AuthenticationBuilder builder = DefaultAuthenticationBuilder.newInstance(authentication); builder.setPrincipal(modifiedPrincipal); Authentication finalAuthentication = builder.build(); AuditableContext audit = AuditableContext.builder().service(selectedService).authentication(finalAuthentication).registeredService(registeredService).retrievePrincipalAttributesFromReleasePolicy(Boolean.FALSE).build(); AuditableExecutionResult accessResult = this.registeredServiceAccessStrategyEnforcer.execute(audit); accessResult.throwExceptionIfNeeded(); AuthenticationCredentialsThreadLocalBinder.bindCurrent(finalAuthentication); Assertion assertion = (new DefaultAssertionBuilder(finalAuthentication)).with(selectedService).with(serviceTicket.getTicketGrantingTicket().getChainedAuthentications()).with(serviceTicket.isFromNewLogin()).build(); this.doPublishEvent(new CasServiceTicketValidatedEvent(this, serviceTicket, assertion)); var18 = assertion; &#125; finally &#123; if (serviceTicket.isExpired()) &#123; this.deleteTicket(serviceTicketId); &#125; else &#123; this.ticketRegistry.updateTicket(serviceTicket); &#125; &#125; return var18; &#125; &#125; &#125;&#125; 同样将我们重新的CentralAuthenticationService类注入Spring取代默认的CentralAuthenticationService 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Autowired @Qualifier(&quot;ticketRegistry&quot;) private ObjectProvider&lt;TicketRegistry&gt; ticketRegistry; @Autowired @Qualifier(&quot;servicesManager&quot;) private ObjectProvider&lt;ServicesManager&gt; servicesManagers; @Autowired @Qualifier(&quot;logoutManager&quot;) private ObjectProvider&lt;LogoutManager&gt; logoutManager; @Autowired @Qualifier(&quot;defaultTicketFactory&quot;) private ObjectProvider&lt;TicketFactory&gt; ticketFactory; @Autowired private ContextualAuthenticationPolicyFactory&lt;ServiceContext&gt; authenticationPolicyFactory; @Autowired @Qualifier(&quot;principalFactory&quot;) private ObjectProvider&lt;PrincipalFactory&gt; principalFactory; @Autowired @Qualifier(&quot;protocolTicketCipherExecutor&quot;) private ObjectProvider&lt;CipherExecutor&gt; cipherExecutor; @Autowired @Qualifier(&quot;registeredServiceAccessStrategyEnforcer&quot;) private AuditableExecution registeredServiceAccessStrategyEnforcer;@Bean @Autowired public CentralAuthenticationService centralAuthenticationService( @Qualifier(&quot;authenticationServiceSelectionPlan&quot;) final AuthenticationServiceSelectionPlan authenticationServiceSelectionPlan) &#123; return new RestCentralAuthenticationService(applicationEventPublisher, ticketRegistry.getIfAvailable(), servicesManagers.getIfAvailable(), logoutManager.getIfAvailable(), ticketFactory.getIfAvailable(), authenticationServiceSelectionPlan, authenticationPolicyFactory, principalFactory.getIfAvailable(), cipherExecutor.getIfAvailable(), registeredServiceAccessStrategyEnforcer); &#125; 现在我们修改protocol/3.0/casServiceValidationSuccess文件,将我们的attributes作为模板放入xml即可 1234567891011121314151617&lt;response&gt; &lt;id th:text=&quot;$&#123;principal.id&#125;&quot;/&gt; &lt;name th:text=&quot;$&#123;principal.attributes.name&#125;&quot;/&gt; &lt;type th:text=&quot;$&#123;principal.attributes.type&#125;&quot;/&gt; &lt;tgt th:text=&quot;$&#123;principal.attributes.tgt&#125;&quot;/&gt; &lt;token th:if=&quot;$&#123;principal.attributes.token!=null&#125;&quot; th:text=&quot;$&#123;principal.attributes.token&#125;&quot;/&gt; &lt;idCard th:if=&quot;$&#123;principal.attributes.idCard!=null&#125;&quot; th:text=&quot;$&#123;principal.attributes.idCard&#125;&quot;/&gt; &lt;jbrName th:if=&quot;$&#123;principal.attributes.jbrName!=null&#125;&quot; th:text=&quot;$&#123;principal.attributes.jbrName&#125;&quot;/&gt; &lt;jbrIdCard th:if=&quot;$&#123;principal.attributes.jbrIdCard!=null&#125;&quot; th:text=&quot;$&#123;principal.attributes.jbrIdCard&#125;&quot;/&gt; &lt;legalpersonCompanyMan th:if=&quot;$&#123;principal.attributes.legalpersonCompanyMan!=null&#125;&quot; th:text=&quot;$&#123;principal.attributes.legalpersonCompanyMan&#125;&quot;/&gt; &lt;legalpersonName th:if=&quot;$&#123;principal.attributes.legalpersonName!=null&#125;&quot; th:text=&quot;$&#123;principal.attributes.legalpersonName&#125;&quot;/&gt; &lt;legalpersonIdCard th:if=&quot;$&#123;principal.attributes.legalpersonIdCard!=null&#125;&quot; th:text=&quot;$&#123;principal.attributes.legalpersonIdCard&#125;&quot;/&gt; &lt;jbrMobile th:if=&quot;$&#123;principal.attributes.jbrMobile!=null&#125;&quot; th:text=&quot;$&#123;principal.attributes.jbrMobile&#125;&quot;/&gt; &lt;code&gt;200&lt;/code&gt;&lt;/response&gt;]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数仓变化维度的建设实践]]></title>
    <url>%2F2020%2F07%2F19%2F%E6%95%B0%E4%BB%93%E5%8F%98%E5%8C%96%E7%BB%B4%E5%BA%A6%E7%9A%84%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[简介之前的文章中概述了如何建设数仓的变化维度，这里对建设变化维度进行实践，本文建设了全国的地市维度，由于地市归属区域有时会变化，这里采用了最常用的类型2来处理，也就是俗称的拉链表. 爬取数据我采用java和selenium 代码https://github.com/liushprofessor/hase_repository/blob/master/create_data/src/main/java/com/liu/City.java将爬取的数据先存入hbase在导入到Phoenix中，关于如何创建hbase表和将hbase数据和Phoenix做关联这里就不做重复描述，可参考之前的文章,Phoenix中的示例数据如下，这里采用的是星型模型,星型模型在数仓中是最常用的维度数据模型，相比于关系型数据库的雪花模型，其存储了冗余数据，来减少连表的查询，在数据仓库中存在大量数据，我们要尽量避免连表来加快数据的分析速度。数据仓库中所有事实表的数据需要拉平(在同一纬度)，这也要求我们的维度表也在在同一维度,比如下面数据中台湾省(台)，并不存在地和县，我们在处理的时候就需要强行将台湾数据拉平，人为给di和xian字段创建台湾，如果不给维度拉平，那么在数据在做group by分析时会导致数据的不准确，应该用日期类型比较合适但是我这里为了方便演示就使用了字符串 ID CODE SHENG DI XIAN BEGIN_DATE END_DATE 1595152366153 1 北京市(京) 北京市 东城区 1999-01-01 2999-01-01 1595152366332 2 北京市(京) 北京市 西城区 1999-01-01 2999-01-01 1595152366393 3 北京市(京) 北京市 朝阳区 1999-01-01 2999-01-01 1595152366921 4 北京市(京) 北京市 丰台区 1999-01-01 2999-01-01 1595152366974 5 北京市(京) 北京市 石景山区 1999-01-01 2999-01-01 1595152367027 6 北京市(京) 北京市 海淀区 1999-01-01 2999-01-01 1595152367081 7 北京市(京) 北京市 门头沟区 1999-01-01 2999-01-01 1595152367356 8 北京市(京) 北京市 房山区 1999-01-01 2999-01-01 1595152367413 9 北京市(京) 北京市 通州区 1999-01-01 2999-01-01 1595152367473 10 北京市(京) 北京市 顺义区 1999-01-01 2999-01-01 1595152367529 11 北京市(京) 北京市 昌平区 1999-01-01 2999-01-01 1595152367591 12 北京市(京) 北京市 大兴区 1999-01-01 2999-01-01 1595152367657 13 北京市(京) 北京市 怀柔区 1999-01-01 2999-01-01 1595152367719 14 北京市(京) 北京市 平谷区 1999-01-01 2999-01-01 1595152367774 15 北京市(京) 北京市 密云区 1999-01-01 2999-01-01 1595152367827 16 北京市(京) 北京市 延庆区 1999-01-01 2999-01-01 1595153354199 2849 台湾省(台) 台湾省(台) 台湾省(台) 1999-01-01 2999-01-01 分析数据这里我建设了一张用户表其数据如下,其模拟了一张用户维度表，其有一个地区维度和我们之前的地区维度做关联 ID NAME AREA_PK 1 mike 1016 2 jake 1016 3 tom 1016 4 liu 1019 连表查询用户地市信息 1select t.*,t1.sheng,t1.di,t1.xian from f_user t inner join d_area t1 on t.area_pk=t1.code; ID NAME AREA_PK T1.SHENG T1.DI T1.XIAN 1 mike 1016 福建省(闽) 福州市 闽侯县 2 jake 1016 福建省(闽) 福州市 闽侯县 3 tom 1016 福建省(闽) 福州市 闽侯县 4 liu 1019 福建省(闽) 福州市 闽清县 5 li 1046 福建省(闽) 泉州市 鲤城区 维度信息上卷查询福州市下的所有用户信息 1select t.*,t1.sheng,t1.di,t1.xian from f_user t inner join d_area t1 on t.area_pk=t1.code where t1.di=&apos;福州市&apos;; ID NAME AREA_PK T1.SHENG T1.DI T1.XIAN 1 mike 1016 福建省(闽) 福州市 闽侯县 2 jake 1016 福建省(闽) 福州市 闽侯县 3 tom 1016 福建省(闽) 福州市 闽侯县 4 liu 1019 福建省(闽) 福州市 闽清县 统计分析福州县下的用户数量 1select t1.xian ,count(*) from f_user t inner join d_area t1 on t.area_pk=t1.code group by t1.xian; T1.XIAN COUNT(1) 闽侯县 3 闽清县 1 鲤城区 1 维度的变化现在我们来模拟维度变化，假设上面的数据今天闽侯县变成了闽侯区，这里我们应用上面创建的拉链表来处理维度的变化 修改原来的数据 ID CODE SHENG DI XIAN BEGIN_DATE END_DATE 1595152702922 1016 福建省(闽) 福州市 闽侯县 1999-01-01 2999-01-01 我们修改end_date字段，将结束日期修改成今天 2020-07-19 ,对应Phoenix为 1upsert into d_area (id,end_date) values(&apos;1595152702922&apos;,&apos;2020-07-19&apos;); 新增数据我们这里新增数据，保存原来的code，但是将begin_date ,和end_date修改成现在的时间 1upsert into d_area(id,code,sheng,di,xian,begin_date,end_date) values(&apos;1595158956&apos;,&apos;1016&apos;,&apos;福建省(闽)&apos;,&apos;福州市&apos;,&apos;闽侯区&apos;,&apos;2020-07-20&apos;,&apos;2999-01-01&apos;); ID CODE SHENG DI XIAN BEGIN_DATE END_DATE 1595152702922 1016 福建省(闽) 福州市 闽侯县 1999-01-01 2020-07-19 1595158956 1016 福建省(闽) 福州市 闽侯区 2020-07-20 2999-01-01 查询分析现在我们我们再次执行上面用户分析地市的查询语句,现在查询出的数据已经是变更后的数据 1select t.*,t1.sheng,t1.di,t1.xian from f_user t inner join d_area t1 on t.area_pk=t1.code where end_date&gt;&apos;2020-07-19&apos; and code=&apos;1016&apos;; ID NAME AREA_PK T1.SHENG T1.DI T1.XIAN 1 mike 1016 福建省(闽) 福州市 闽侯区 2 jake 1016 福建省(闽) 福州市 闽侯区 3 tom 1016 福建省(闽) 福州市 闽侯区 由于我们有了时间字段，我们在日期更改后还能对历史维度进行分析 1select t.*,t1.sheng,t1.di,t1.xian from f_user t inner join d_area t1 on t.area_pk=t1.code where end_date&lt;&apos;2020-07-20&apos; and code=&apos;1016&apos;;]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>维度</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用phoenix和hbase搭建数仓基础知识]]></title>
    <url>%2F2020%2F07%2F14%2F%E4%BD%BF%E7%94%A8phoenix%E5%92%8Chbase%E6%90%AD%E5%BB%BA%E6%95%B0%E4%BB%93%2F</url>
    <content type="text"><![CDATA[简介在之前的项目中采用HDFS和Hive来搭建数据仓库。但是使用HDFS和hive来搭建数据仓库无法做到数据的实时查询,因为hive的本质是mapreduce运算，map和reduce的过程都存储在磁盘，存储在磁盘避免不了磁盘的i/o，随机i/o又是磁盘的主要瓶颈(固态硬盘可从无视)，所以这边对使用hbase搭建数仓库，hbase也是基于hdfs上建设的nosql数据库，之所以它能够做到数据的实时查询是因为它以列去存储数据，并且在数据写入到磁盘时已经将数据排序完成，尽量避免了磁盘的随机i/o而磁盘的顺序读取速度又非常的快，几乎可达到内存的速度，其实我目前除了auto sharding以外，个人比较喜欢hbase可以保留不同版本数据的这个功能，在看过我之前的关于数据建立维度里面就提到，数仓的好坏的难点就是在维度的建设方面，而维度最麻烦的就是处理维度的变化，如果相同的维度数据可以保留多个历史版本，这样就完美解决维度变化这个问题，可是目前我在phoenix并没有看到可以查找到历史数据这个功能，但是在网上查询到有人通过对phoenix修改后达到这个目的。相比关系型数据库其能存储海，这是依托由其auto sharding功能，这使nosql在数据存储扩展方面具有得天独厚的优势，在关系型数据库中对数据进行扩展往往意味着对数据分片或分库的重建，如甚于关系型数据库开发的greenplum就必须在搭建时提前考虑好数据的增长量，如果后序增加节点是非常复杂的事，如果你使用的是诸如mongo或hbase来搭建数据仓库的话就完全不要考虑这方面问题，但Hbase也有自己的缺点其时实查询的功能高度依赖rowkey,并且无法创建索引对列中的具体值进行查找(虽然可从使用api提供的过滤器去查找数据)，所以我们在设计hbase的rowkey时需要尽可能将查询信息都包含在rowkey中。为了解决这个问题，这里尝试使用Phoenix来当作数仓工具来构建数仓，它将传统的Sql语句转换成hbase的api进行查询，并且支持二级索引和联表统计，和自定义函数等功能，hbase相比hive的另一个优势就是可以完美解决小文件的问题，我们都知道hdfs将数据的元数据都存储在namenode的内存中，因此namenode的内存大小限制了文件的数量，因为即使文件再小都要占用固定的元数据大小的空间，所有hdfs的长处是存储大文件，如果我们的数据是许多小文件构成，那么namenode的内存使用效率就地，我们需要定期自己将小文件合并成块，但是hbase就不需要关系这一点，他可以自动的对数据文件进行合并和拆分，然后再存储到hdfs中。 创建我使用的是cdh来搭建hadoop集群，在官网上下载对应cdh hbase的phoenix版本，phoenix是构建在hbase的数仓工具，之所以我这样说是因为真正存储数据分析的地方是hbase，而hbase又依赖hdfs，就好比hive也数仓而是数仓工具一样，hive大多都依赖hdfs存储数据，hive只提供分析等功能，将解压的包中的service包复制到hbase的各台region server的lib下，重启hbase。以下是官网安装简介 download and expand our installation tar copy the phoenix server jar that is compatible with your HBase installation into the lib directory of every region server restart the region servers add the phoenix client jar to the classpath of your HBase client 表操作hive 分为内部表和外部表，内部表是托管hdfs中的数据，你执行命令删除了hive的数据，hdfs的数据也会删除，而外部表则不将数据拖由hive管理，你删除了hive中的数据，hdfs的数据还将保留。相应的phoenix和sql一样也分为表和视图，表就是将数据拖由phoenix报错，视图对应hive的外部表，但是创建完表后新增的数据只能在hive中进行，如果建立了phoenix和hbase关联后，调用hbase的api新增数据，则新增的数据不会在phoenix中查询的到,到底使用表还是视图？我的理解是你需不需要将数据托管给hive来保管，如果你想那么就使用表下面我们将phoenix关联hbase，使用我github中的爬虫爬取淘宝数据，会生成一张hbase taobaoList的表，我创建了一个data列簇，有以下字段 data.sellNum data.title data.url data.shopName data.price 销售量 商品标题 商品连接 店铺名 商品价格 现在我们运行phoenix客户端 ./sqlline.py ip:2181其中ip是hbase所在zookeeper集群的ip地址，端口为对应的端口，默认是2181注意新版本中要在后面加上列的编码不然会导致phoenix列编码和hbase中不一致导致数据查询不出来phoenix中的列一定要和hbase中列大小对应上，phoenix默认全部都是大写，所以我们使用双引号将小写的列引用起来，除了rowkey 对应的主键名可以自己指定外 12create view &quot;taobaoList&quot;(&quot;id&quot; varchar primary key,&quot;data&quot;.&quot;sellNum&quot; varchar,&quot;data&quot;.&quot;title&quot; varchar,&quot;data&quot;.&quot;url&quot; varchar,&quot;data&quot;.&quot;shopName&quot; varchar,&quot;data&quot;.&quot;price&quot; varchar)column_encoded_bytes=0; 执行 以下命令就可以看见表 1! tables 查询数据,注意查询数据的条件(如:where id=’1’)中的条件需要用单引号包裹，查询出的字段(如select “id”)用双引号包裹，如果查询的字段是小写的话 1select * from &quot;taobaoList&quot; limit 1; grop by 1select &quot;shopName&quot; ,count(*) from &quot;taobaoList&quot; group by &quot;shopName&quot;; join 加分页 1select * from &quot;taobaoList&quot; as t1 inner join &quot;taobaoDetailList&quot; t2 on t1.&quot;id&quot;=t2.&quot;productRowKey&quot; limit 1 offset 20; 二级索引二级索引也是将二级索引存入在hbase表中，由于hbase使用的是裂存储，索引和sql一样尽量使用覆盖索引，避免回表首先查看未创建二级索引前的执行计划 123456789explain select * from &quot;taobaoDetailList&quot; where &quot;productRowKey&quot;=&apos;100001594042362234&apos;;+----------------------------------------------------------------------------+-----------------+----------------+--------------+| PLAN | EST_BYTES_READ | EST_ROWS_READ | EST_INFO_TS |+----------------------------------------------------------------------------+-----------------+----------------+--------------+| CLIENT 1-CHUNK PARALLEL 1-WAY ROUND ROBIN FULL SCAN OVER taobaoDetailList | null | null | null || SERVER FILTER BY data.&quot;productRowKey&quot; = &apos;100001594042362234&apos; | null | null | null |+----------------------------------------------------------------------------+-----------------+----------------+--------------+ 执行计划中现实的是全表扫描,现在创建执行计划，创建执行计划前需要添加配置文件,由于我使用的是4.14.0 phoenix版本根据官网，在所有RegionServer 中添加如下配置即可重启即可CDH只需在hbase配置中搜索hbase-site，然后将值填入到RegionServer的配置项中即可,官网链接https://phoenix.apache.org/secondary_indexing.html 1234&lt;property&gt; &lt;name&gt;hbase.regionserver.wal.codec&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec&lt;/value&gt;&lt;/property&gt; 下面创建二级覆盖索引include包含你要覆盖的列，这样查询索引时就不要回表，如果不创建覆盖索引就不要添加include后面的代码 1create index rowkey_index on &quot;taobaoDetailList&quot;(&quot;data&quot;.&quot;productRowKey&quot;) include(&quot;id&quot;); 现在我们再执行上面的执行计划,发现已经走索引了 123456+------------------------------------------------------------------------------------------------+-----------------+----------------+--------------+| PLAN | EST_BYTES_READ | EST_ROWS_READ | EST_INFO_TS |+------------------------------------------------------------------------------------------------+-----------------+----------------+--------------+| CLIENT 1-CHUNK PARALLEL 1-WAY ROUND ROBIN RANGE SCAN OVER ROWKEY_INDEX [&apos;100001594042362234&apos;] | null | null | null || SERVER FILTER BY FIRST KEY ONLY | null | null | null |+------------------------------------------------------------------------------------------------+-----------------+----------------+--------------+ udf自定义函数和hive一样phoenix一样支持自定义函数，下面这个自定义函数就是将taobaoList中的sellNum字段转换成数字，从淘宝上爬取下来的交易笔数都是如 1万笔 800笔这样的，我们需要将其转换成数字首先添加phoenix下bin目录下的hbase-site.xml配置文件中的配置信息 hbase.rootdir改成真实的hbase在hdfs的路径即可，hbase.dynamic.jars.dir为你后续编写的udf函数存放的路径, 12345678910111213141516171819202122232425262728293031&lt;property&gt; &lt;name&gt;phoenix.functions.allowUserDefinedFunctions&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.hdfs.impl&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.DistributedFileSystem&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;$&#123;hbase.tmp.dir&#125;/hbase&lt;/value&gt; &lt;description&gt;The directory shared by region servers and into which HBase persists. The URL should be &apos;fully-qualified&apos; to include the filesystem scheme. For example, to specify the HDFS directory &apos;/hbase&apos; where the HDFS instance&apos;s namenode is running at namenode.example.org on port 9000, set this value to: hdfs://namenode.example.org:9000/hbase. By default, we write to whatever $&#123;hbase.tmp.dir&#125; is set too -- usually /tmp -- so change this configuration or else all data will be lost on machine restart.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.dynamic.jars.dir&lt;/name&gt; &lt;value&gt;$&#123;hbase.rootdir&#125;/lib&lt;/value&gt; &lt;description&gt; The directory from which the custom udf jars can be loaded dynamically by the phoenix client/region server without the need to restart. However, an already loaded udf class would not be un-loaded. See HBASE-1936 for more details. &lt;/description&gt;&lt;/property&gt; 鉴于我都是存放在hdfs下所以我的配置 12345678910111213141516&lt;property&gt; &lt;name&gt;phoenix.functions.allowUserDefinedFunctions&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.hdfs.impl&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.DistributedFileSystem&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://hztnode1:8020/hbase&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.dynamic.jars.dir&lt;/name&gt; &lt;value&gt;hdfs://hztnode1:8020/hbase/lib&lt;/value&gt;&lt;/property&gt; 创建udf代码实现udf类，具体代码说明如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package com.liu;import org.apache.hadoop.hbase.io.ImmutableBytesWritable;import org.apache.phoenix.expression.Expression;import org.apache.phoenix.expression.function.ScalarFunction;import org.apache.phoenix.parse.FunctionParseNode;import org.apache.phoenix.schema.tuple.Tuple;import org.apache.phoenix.schema.types.PBinary;import org.apache.phoenix.schema.types.PDataType;import org.apache.phoenix.schema.types.PInteger;import org.apache.phoenix.schema.types.PVarchar;import java.io.UnsupportedEncodingException;import java.util.List;/** * 功能： TODO(用一句话描述类的功能) * * ────────────────────────────────────────── * version 变更日期 修改人 修改说明 * ------------------------------------------ * V1.0.0 2020/7/9 Liush 初版 * ────────────────────────────────────────── *///指定函数名和参数@FunctionParseNode.BuiltInFunction( name =&quot;F_SELLNUM&quot; , args = &#123; @FunctionParseNode.Argument(allowedTypes = &#123;PVarchar.class&#125;), &#125;)public class SellNumUDF extends ScalarFunction &#123; @Override public String getName() &#123; return &quot;F_SELLNUM&quot;; &#125; public SellNumUDF(List&lt;Expression&gt; children) &#123; super(children); &#125; @Override public boolean evaluate(Tuple tuple, ImmutableBytesWritable immutableBytesWritable) &#123; //获取到参数 Expression arg1 =this.getChildren().get(0); //从表达式中或获取参数 if(arg1.evaluate(tuple,immutableBytesWritable))&#123; if(immutableBytesWritable.getLength()&gt;0)&#123; //得到参数字节码 byte[] valueByte=immutableBytesWritable.copyBytes(); try &#123; String sellNum=new String(valueByte,&quot;UTF-8&quot;); if(sellNum.contains(&quot;万笔&quot;))&#123; String num=sellNum.substring(0,sellNum.indexOf(&quot;万笔&quot;)); int numInt=(int)(Float.valueOf(num)*10000); //将处理后的数据返回，如果执行的是类似sum运算的话返回的必须是数字类型 immutableBytesWritable.set(PInteger.INSTANCE.toBytes(numInt)); return true; &#125; if(sellNum.contains(&quot;笔&quot;))&#123; String num=sellNum.substring(0,sellNum.indexOf(&quot;笔&quot;)); int numInt=Integer.valueOf(num); immutableBytesWritable.set(PInteger.INSTANCE.toBytes(numInt)); return true; &#125; &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return false; &#125; @Override public PDataType getDataType() &#123; return PInteger.INSTANCE; &#125;&#125; 打包我采用maven打包，使用maven打包插件，此打包插件可指定工程的配置文件路径等 12345678910111213141516171819202122232425262728&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- 绑定到package生命周期 --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;!-- 只运行一次 --&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 配置描述符文件 --&gt; &lt;!-- &lt;descriptor&gt;src/main/assembly/assembly.xml&lt;/descriptor&gt;--&gt; &lt;!-- 也可以使用Maven预配置的描述符--&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 最后将打完打jar包放入，之前配置文件中配置的hdfs的路径下，现在我们在shell中执行sql 1select f_sellnum(&quot;sellNum&quot;),&quot;sellNum&quot; from &quot;taobaoList&quot; limit 1; 我们查询到 12345+----------------------------+----------+| F_SELLNUM(data.&quot;sellNum&quot;) | sellNum |+----------------------------+----------+| 39000 | 3.9万笔 |+----------------------------+----------+]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>phoenix</tag>
        <tag>hbase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Appium爬取数据]]></title>
    <url>%2F2020%2F06%2F13%2F%E4%BD%BF%E7%94%A8Appium%E7%88%AC%E5%8F%96%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[简介之前使用Selenium模拟谷歌浏览器爬取网页数据，现在使用Appium来模拟爬取app数据，这里以抖音为例子 步骤 安装 Appium 使用python驱动 Appium-Python-Client 1pip3 install Appium-Python-Client 3.使用Appium启动会话，并且获取要爬取数据的元素id,期间要设置以下参数，其中appPackage和appActivity可通过在windows环境下在dos中运行adb shell dumpsys window |findstr mCurrent命令获取deviceName 通过adb devices -l 中的 model字段获取 123456&#123; &quot;platformName&quot;: &quot;Android&quot;, &quot;deviceName&quot;: &quot;vivo_X21UD_A&quot;, &quot;appPackage&quot;: &quot;com.ss.android.ugc.aweme&quot;, &quot;appActivity&quot;: &quot;com.ss.android.ugc.aweme.splash.SplashActivity&quot;&#125; 设置完参数启动session后下面获取要爬取的元素id即可 Appium可以通过界面上的时间自动生成代码，我这里使用python来驱动,以下代码模拟滑动操作并且爬取了点赞数据，和用户名,注意一下几点 Appium每次打开app都会默认删除app并且重新安装，我们在参数中设置”noReset”: True来禁止每次都重新安装软件 Appium每次打开app都会重新安装apk，我们通过“skipServerInstallation”: True,“skipDeviceInitialization”: True这两个参数来禁止每次安装apk，但是至少要进行一次安装 appium.webdriver import webdriver 一定要导入appium包下的webdriver模块，不然无法选择元素 123456789101112131415161718192021222324252627282930313233343536373839import timefrom appium import webdriverfrom selenium.webdriver.common.by import Byoption = &#123; &quot;platformName&quot;: &quot;Android&quot;, &quot;deviceName&quot;: &quot;vivo_X21UD_A&quot;, &quot;appPackage&quot;: &quot;com.ss.android.ugc.aweme&quot;, &quot;appActivity&quot;: &quot;com.ss.android.ugc.aweme.splash.SplashActivity&quot;, #不需要每次都重新安装软件 &quot;noReset&quot;: True, #不要每次都安装apk &quot;skipServerInstallation&quot;: True, &quot;skipDeviceInitialization&quot;: True&#125;driver = webdriver.Remote(&apos;http://localhost:4723/wd/hub&apos;, option)def getData(): like=driver.find_element(By.ID,&apos;com.ss.android.ugc.aweme:id/aqg&apos;).text print(&apos;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&apos;) print(like) title =driver.find_element(By.ID,&apos;com.ss.android.ugc.aweme:id/title&apos;).text print(&apos;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&apos;) print(title) driver.swipe(100, 1700, 100, 100, 1000)time.sleep(10)try: while True: getData() print(&apos;=====================================&apos;)except: print(&apos;----------------------------------&apos;)]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>Appium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python和Selenium爬取淘宝数据]]></title>
    <url>%2F2020%2F06%2F11%2F%E4%BD%BF%E7%94%A8python%E5%92%8CSelenium%E7%88%AC%E5%8F%96%E6%B7%98%E5%AE%9D%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[简介之前使用python爬取了速卖通的数据，这里使用Selenium爬取淘宝数据，总体的实现逻辑没有太大区别，但是用Selenium打开淘宝页面，并且会有一个拖拽式的验证码，我们同样使用Selenium来模拟这些动作 遇到的问题 登陆：淘宝会强制我们进行登录，不然无法访问具体商品列表，我这里的实现思路，是获取登录页的title，如果获取的网页title和登录页的title我们自行登录逻辑 验证码：实践中淘宝采用了拖拽式验证码，我们使用Selenium模拟拖拽即可，但是在实际中如果一次性将拖拽条拖完，则无法通过验证，我这里模拟了拖拽，在拖拽到固定长度后停留0.1秒，然后再将进度条拖拽完成，模拟人拖拽的过程 爬取详情中由于各个商场的风格页面不一样，有可能有些元素无法获取，所以要对获取不到元素时进行异常处理（其实所有定位元素都需要异常处理，因为爬虫异常总是会发生） 后台限制：由于太快的请求可能会遭遇封IP等操作，我这边每个操作都设置了一个延时，尽量避免过快操作 Chrome浏览器现在已经支持headless模式，即不打开浏览器UI的情况下进行爬取数据123chrome_options = Options()chrome_options.add_argument(&apos;--headless&apos;)driver = webdriver.Chrome(chrome_options=chrome_options) 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091import timefrom selenium import webdriverfrom selenium.common.exceptions import NoSuchElementExceptionfrom selenium.webdriver import ActionChainsfrom selenium.webdriver.common.by import Bybrowser = webdriver.Chrome()browser.get(&apos;https://s.taobao.com/search?q=ipad&apos;)def roll(height=800): time.sleep(1) for i in range(15): script = &quot;window.scrollBy(0,&quot; + str(height) + &quot;)&quot; time.sleep(2) browser.execute_script(script) browser.execute_script(&quot;window.scrollBy(0,&quot; + str(-height) + &quot;)&quot;) time.sleep(1)title = browser.titletitle_after_strip = title.strip();#如果title和登录页匹配则登录账号密码if title_after_strip == &apos;淘宝网 - 淘！我喜欢&apos;: actions = ActionChains(browser) username = browser.find_element_by_id(&apos;fm-login-id&apos;) password = browser.find_element_by_id(&apos;fm-login-password&apos;) username.send_keys(&apos;账号&apos;) time.sleep(3) password.send_keys(&apos;密码&apos;) bt = browser.find_element_by_xpath(&quot;//div[@class=&apos;fm-btn&apos;]/button&quot;) bt.click() time.sleep(1) #选中拖拽验证码 source = browser.find_element_by_xpath(&quot;//div[@id=&apos;nocaptcha-password&apos;]//span[@id=&apos;nc_1_n1z&apos;]&quot;) time.sleep(0.3) actions.click_and_hold(source).perform() actions.move_by_offset(108, 0) #拖拽中停止0.1秒模拟人拖拽过程 time.sleep(0.1) actions.move_by_offset(150, 0) actions.release().perform() time.sleep(2) bt = browser.find_element_by_xpath(&quot;//div[@class=&apos;fm-btn&apos;]/button&quot;) bt.click()print(&apos;-------------&apos;)time.sleep(20)#获取数据def getData(): itemList = browser.find_element_by_class_name(&apos;m-itemlist&apos;) items = itemList.find_element_by_class_name(&apos;items&apos;) div = items.find_elements_by_xpath(&apos;./div&apos;) for k in div: price = k.find_element_by_xpath(&apos;.//strong&apos;) print(price.get_attribute(&quot;outerHTML&quot;)) pic = k.find_element_by_xpath(&quot;.//div[@class=&apos;pic&apos;]&quot;) #点击链接进入商品详情 a = pic.find_element_by_xpath(&apos;./a&apos;) #获取商品详情 getProductDetail(a) page = browser.find_element_by_id(&apos;mainsrp-pager&apos;) nextPage = page.find_element_by_css_selector(&quot;[class=&apos;J_Ajax num icon-tag&apos;]&quot;) nextPage.click()#获取商品详情def getProductDetail(a): a.click() time.sleep(1) #获取浏览器各个窗口的句柄 handles = browser.window_handles #由于点击详情会新开一个页面，切换到详情页面 browser.switch_to_window(handles[2]) time.sleep(5) try: product = browser.find_element_by_xpath(&quot;//div[@id=&apos;detail&apos;]//div[@class=&apos;tb-detail-hd&apos;]/h1/a&quot;) print(product.get_attribute(&quot;innerHTML&quot;)) except NoSuchElementException: print(&apos;爬取失败&apos;) #关闭当前浏览器窗口 browser.close() #切换到商品列表窗口 browser.switch_to_window(handles[0])for i in range(50): print(str(i)+&quot;---------------------------------------------------&quot;) getData() time.sleep(10)]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>Selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python和Selenium爬取网页]]></title>
    <url>%2F2020%2F06%2F10%2F%E4%BD%BF%E7%94%A8python%E5%92%8CSelenium%E7%88%AC%E5%8F%96%E7%BD%91%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[简介最近使用八爪鱼爬虫软件在网上爬取了一部分数据，也想尝试一下实现一个简单的爬虫，这里是使用python的一次实践,我们要首先安装python和Selenium，Selenium就是一个软件可以驱动浏览器进行自动化测试的软件，安装方法很简单，可以自行百度. 爬虫原理其实爬虫原理在我理解来看无非2种 使用接口进行爬取：在我们日常开发网站中经常使用js和ajax请求来渲染页面，那如果我们能猜出请求的规律，那么我们可以直接发起http请求去请求这部分接口获取数据 解析html页面：由于接口有可能加密，或者采用后端模板方式生成的html，那么我们这时只能通过解析html来爬取数据，又由于请求页面的时候，很多数据其实是页面加载完成后再去发起ajax请求获取数据再交由js去生成html，所以一般来说我们会使用Selenium或者PhantomJS来模拟浏览器来请求接口，等页面生成后再进行爬取 爬虫难点其实爬虫难点并不是在于爬取数据，而是怎么绕过反爬机制，最常用的是验证码 普通字符串验证码，通常验证码中除了有验证码外，还包含很多干扰信息来阻止机器识别验证码，验证码可以通过opencv处理完图像(如，转变成灰度图像，二值图像(需要设置好阈值),滤波)，将验证码过滤掉多余的干扰信息后再交由ORC去识别图像，来提高验证码的识别率，常用的OCR类库为为tesseract 拖拽式验证码，这部分可以使用Selenium来控制浏览器来拖拽滑动验证码,但是很多拖拽验证码都加入了机器识别功能，比如你使用机器匀速拖拽验证码时其会判定不通过 点击试验证码，这部分是最难攻克的一部分，类似12306，很多验证码人眼都无法识别。。。这部分验证码的一个解决思路是爬取出所有验证码的图片，然后做归档，比如出现点击漏斗的图片，就去本地爬取漏斗的验证码中和网页上出现的漏斗验证码进行比对，比对一致点击(当然这种适用于验证码选择可能较少的情况),或者直接使用第三方服务服务端的反扒机制 IP限制,比如同一ip过多则不让操作 代理限制:为了解决IP限制通常我们会使用代理，轮流切换IP进行爬取，但是服务端会监测你是否开启代理或者VPN，例如淘宝我在开启VPN时，淘宝会拒绝我的访问 环境监测，有些服务器会监测本地环境，比如是否使用Selenium等 登录监测: 站点要求用户登录，或者用户一次操作有次数限制，一般站点都会将用户一些登录凭据存在cookie中，因此我们可以使用本地cookie池来模拟多用户目前总体来说爬取APP的数据会比web容易，这就是为什么我之前看到的群控软件或者爬虫都会基于app端来做 实践在本人第一次实践中，我试着爬取速卖通的商品数据(这个代码只展示了主要逻辑，还有很多异常重试等功能没有实现)，至于为什么选择速卖通网站进行第一次练手，是因为比较好爬。。。。虽然同为阿里系，但是好像阿里并没有严格限制速卖通的爬取，如下代码并没有什么复杂逻辑，因为现在很多网站商品列表很长，它们可能会采用懒加载机制，在滚动条滚动到对应商品时才会进行加载，所以我们这里用selenium模拟了浏览器的滚动，让其加载数据，然后我们后续要做的就是选取要爬取的数据的元素节点(常用的选取是XPATH，或者id，class等，解析html的模块有很多，如lxml，Beautiful Soup或者是可以应用jquery语法来解析xml的pyquery)，我这里使用的是selenium自带的解析html方法,在爬取完当前页面后，点击下一页，然后就是循环爬取页面了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import timefrom selenium import webdriverfrom selenium.common.exceptions import NoSuchElementExceptionfrom selenium.webdriver.common.keys import Keysbrowser = webdriver.Chrome()browser.get(&apos;https://www.aliexpress.com/premium/ipad.html&apos;)size = browser.get_window_size();height = size[&apos;height&apos;]#滚动下拉框def roll(): time.sleep(1) for i in range(15): script = &quot;window.scrollBy(0,&quot; + str(height) + &quot;)&quot; time.sleep(1) browser.execute_script(script) browser.execute_script(&quot;window.scrollBy(0,&quot; + str(-height) + &quot;)&quot;) time.sleep(1)# 获取数据def getData(): time.sleep(1) lis = browser.find_elements_by_xpath(&quot;//ul[@class=&apos;list-items&apos;]/li&quot;) for li in lis: try: a = li.find_element_by_xpath(&quot;.//a[@class=&apos;item-title&apos;]&quot;) print(a.get_attribute(&apos;title&apos;)) except NoSuchElementException: continue print(&apos;----------------------------&apos;) time.sleep(1)#翻页def nextPage(): next = browser.find_element_by_css_selector( &quot;[class=&apos;next-btn next-medium next-btn-normal next-pagination-item next-next&apos;]&quot;) # next.click() 出现异常无法点击元素 next.send_keys(Keys.ENTER)#获取页数，做循环翻页使用def getTotalPage(): totalPageSpan = browser.find_element_by_class_name(&quot;total-page&quot;).get_attribute(&apos;innerHTML&apos;) pageTextArray = str(totalPageSpan).split(&quot; &quot;) totalPageNum = pageTextArray[1] return totalPageNumroll()getData()pageNum = getTotalPage()for i in range(int(pageNum)): nextPage() roll() getData() 实践中遇到的问题 页面懒加载问题:上文说过此问题，我们采用模拟浏览器滚动的方式来加载所有数据 元素点击:在实践中我使用Selenium的click方法点击元素进行翻页时，会出现无法点击元素的异常（Message: element click intercepted）,这是由于元素点击到了其它元素上去了，经过谷歌后发现可以使用send_keys(Keys.ENTER)方法来触发点击事件 异常:真正使用代码爬取数据，需要处理好异常，因为Selenium获取不到页面元素就会抛出异常，而在爬取数据中由于网络等种种原因，爬取总是会失败的，要做好异常处理和重试机制，和后续数据去除。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>Selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty概念和使用netty搭建WebSocket]]></title>
    <url>%2F2020%2F05%2F13%2Fnetty%E6%A6%82%E5%BF%B5%E5%92%8C%E4%BD%BF%E7%94%A8netty%E6%90%AD%E5%BB%BAWebSocket%2F</url>
    <content type="text"><![CDATA[简介netty是java网络编程框架，其架构抽象出的概念很容易使我们针对不同的需求来定制不同的处理器,本文将简介netty的概念和一些网络知识，最后并使用netty来编写一个webScoket聊天室服务器. netty基本概念线程模型阻塞与非阻塞 阻塞与非阻塞是描述进程在访问某个资源时，数据是否准备就绪的的一种处理方式。当数据没有准备就绪时： 阻塞：线程持续等待资源中数据准备完成，直到返回响应结果。 非阻塞：线程直接返回结果，不会持续等待资源准备数据结束后才响应结果。 同步与异步 同步与异步是指访问数据的机制，同步一般指主动请求并等待IO操作完成的方式。 异步则指主动请求数据后便可以继续处理其它任务，随后等待IO操作完毕的通知。 用经典的烧开水理论来解释为 1、普通水壶煮水，站在旁边，主动的看水开了没有？同步的阻塞 2、普通水壶煮水，去干点别的事，每过一段时间去看看水开了没有，水没开就走人。 同步非阻塞 3、响水壶煮水，站在旁边，不会每过一段时间主动看水开了没有。如果水开了，水壶自动通知他。 异步阻塞 4、响水壶煮水，去干点别的事，如果水开了，水壶自动通知他。异步非阻塞 为什么使用异步线程模型？本质上是由于CPU和I/O执行效率的不对等，CPU执行速度很快，而I/0执行的较慢，如果用阻塞去处理，那么就会导致cpu在I/0阻塞时一直在等待I/0的结果，这样导致CPU的浪费 netty使用Reactor线程模型Reactor是为同步I/O设计的线程模式其分为三种, 分别为 单线程模型 (单Reactor单线程) 多线程模型 (单Reactor多线程) 主从多线程模型 (多Reactor多线程) channel:通道，目前可以把channel看做是入站或者出站数据的载体，因此它可以被打开或者关闭—-摘抄自netty实战 Reactor中一个定义了4个事件分表为Accept(接受), Read(读取), Write(写)，Connect(连接)，各个Channel通过这些事件往Reactor中注册信息，来告诉Reactor，他们下一步想要执行什么事件 单线程模型 根据Doug Lea 在 《Scalable IO in Java 》中单线程模型中的代码http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf顾名思义就是已一个线程去控制所有I/O的流转，从代码中我们可以看出其只用了一个线程就能控制所有的I/O，其原理是在Reactor抽象出一个Selector，所有的Channel当状态发生变化时中往Selector中注册事件),由Selector循环去调用select()方法去获取这些发生状态变化的事件，然后根据这些事件绑定的执行器如图中的(acceptor，和handler(read，decode….send))一个个去执行这些事件，这样就使用一个线程就能控制多个I/O的执行 缺点:当处理读写任务的线程负载过高后，处理速度下降，事件会堆积，严重的会超时，可能导致客户端重新发送请求，性能越来越差 多线程模型如图，多线程和单线程模型的区别就是将之前的handler换成一个线程池去处理，来解决单线程的问题，因为在网络编程中，花的时间较多的是handler，因为要负责解码，处理逻辑，最后在编发发送给客户端，因此有用线程池去处理，而acceptor只是单纯的做一个监测端口然后并注册selector中注册的作用，所以没用用到线程池,一般我们使用netty时只监测一个端口，所以这个模型是netty大量使用的模型 主从多线程模型和多线程的区别就是acceptor也使用线程池去处理 主要接口和概念 channel:通道，目前可以把channel看做是入站或者出站数据的载体，因此它可以被打开或者关闭 ChannelHandler：Netty使用不同的事件来通知我们状态的改变或者是操作的状态;这使我们能够基于已经发生的事件来触发适当的动作，举处理心跳的IdleStateHandler为例,在这个类初始化时会初始化一个定时器，如果在一段时间内没有触发消失这会在定时器中触发事件1234567891011121314151617181920212223private void initialize(ChannelHandlerContext ctx) &#123; switch(this.state) &#123; case 1: case 2: return; default: this.state = 1; this.initOutputChanged(ctx); this.lastReadTime = this.lastWriteTime = this.ticksInNanos(); if (this.readerIdleTimeNanos &gt; 0L) &#123; this.readerIdleTimeout = this.schedule(ctx, new IdleStateHandler.ReaderIdleTimeoutTask(ctx), this.readerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (this.writerIdleTimeNanos &gt; 0L) &#123; this.writerIdleTimeout = this.schedule(ctx, new IdleStateHandler.WriterIdleTimeoutTask(ctx), this.writerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (this.allIdleTimeNanos &gt; 0L) &#123; this.allIdleTimeout = this.schedule(ctx, new IdleStateHandler.AllIdleTimeoutTask(ctx), this.allIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; &#125; &#125; 以下是定时任务的代码，在IdleStateHandler.this.channelIdle(ctx, event);中netty发出了事件 12345678910111213141516171819202122232425262728private final class ReaderIdleTimeoutTask extends IdleStateHandler.AbstractIdleTask &#123; ReaderIdleTimeoutTask(ChannelHandlerContext ctx) &#123; super(ctx); &#125; protected void run(ChannelHandlerContext ctx) &#123; long nextDelay = IdleStateHandler.this.readerIdleTimeNanos; if (!IdleStateHandler.this.reading) &#123; nextDelay -= IdleStateHandler.this.ticksInNanos() - IdleStateHandler.this.lastReadTime; &#125; if (nextDelay &lt;= 0L) &#123; IdleStateHandler.this.readerIdleTimeout = IdleStateHandler.this.schedule(ctx, this, IdleStateHandler.this.readerIdleTimeNanos, TimeUnit.NANOSECONDS); boolean first = IdleStateHandler.this.firstReaderIdleEvent; IdleStateHandler.this.firstReaderIdleEvent = false; try &#123; IdleStateEvent event = IdleStateHandler.this.newIdleStateEvent(IdleState.READER_IDLE, first); IdleStateHandler.this.channelIdle(ctx, event); &#125; catch (Throwable var6) &#123; ctx.fireExceptionCaught(var6); &#125; &#125; else &#123; IdleStateHandler.this.readerIdleTimeout = IdleStateHandler.this.schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS); &#125; &#125; &#125; 发出事件，由后续由我们自行实现的channel在userEventTriggered方法中捕获这个事件并做处理 123protected void channelIdle(ChannelHandlerContext ctx, IdleStateEvent evt) throws Exception &#123; ctx.fireUserEventTriggered(evt); &#125; ChannelHandler:分为入站和出站分别对应其的两个子接口ChannelInboundHandler,ChannelOutboundHandler,入站事件主要处理读事件，这里做一个类比，Http服务器主要做的是处理读事件，在客户单连接到服务器后，服务器需要对接受到的信息进行解码，http协议的解释，最后再进行逻辑的处理，最后将请求返回回去这就是读请求，而客户端需要处理写的请求，将对象序列化，并以一定的协议传输出去，这是写请求。 EventLoopGroup为netty封装的线程池模型 服务端代码服务端代码如下，代码中做了注释 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class ServiceMain &#123; public static void main(String[] args)throws Exception &#123; //编写一个acceptor线程池,主要监测端口和分发连接，因为我们只监测一个端口所以采用的是Reactor的多线程模型(只用一个线程去处理连接) EventLoopGroup bossGroup = new NioEventLoopGroup(1); //定义一个出来ChannelHandler的线程池,不指定参数线程池数量为cpu数*2 EventLoopGroup workerGroup = new NioEventLoopGroup(); //定义一个保存所有channel连接的容器 ChannelGroup group=new DefaultChannelGroup(ImmediateEventExecutor.INSTANCE); try &#123; ServiceMain serviceMain=new ServiceMain(); ServerBootstrap serverBootstrap=new ServerBootstrap(); //绑定Reactor线程池和ChannelHandler线程池 Channel channel =serverBootstrap.group(bossGroup,workerGroup) .channel(NioServerSocketChannel.class).childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline=socketChannel.pipeline(); //添加http协议的解码器和编译器 pipeline.addLast(new HttpServerCodec()); //添加http聚合器，因为在tcp传输中tcp协议会根据发送包的大小对数据进行分包，所以这里要将分的包组合成一个完成的http请求 pipeline.addLast(new HttpObjectAggregator(65536)); //webscoket对应的处理器，用户处理webscoket的握手和协议升级 pipeline.addLast(new WebSocketServerProtocolHandler(&quot;/ws&quot;)); //主要处理websocket发送的消息 pipeline.addLast( serviceMain.new TextHandler(group)); &#125; &#125;) .bind(new InetSocketAddress(9000)).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture channelFuture) throws Exception &#123; System.out.println(channelFuture.isSuccess()); &#125; &#125;).sync().channel(); channel.closeFuture().sync(); &#125;finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; //将用户进入聊天室发起的消息进行分发 private class TextHandler extends SimpleChannelInboundHandler&lt;TextWebSocketFrame&gt;&#123; private ChannelGroup group; public TextHandler(ChannelGroup group) &#123; this.group = group; &#125; //如果触发了webscoket握手信息则往聊天室类发消息通知用户进入聊天室 @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if(evt==WebSocketServerProtocolHandler.ServerHandshakeStateEvent.HANDSHAKE_COMPLETE)&#123; group.writeAndFlush(&quot;新用户加入房间&quot;); group.add(ctx.channel()); &#125; super.userEventTriggered(ctx, evt); &#125; //用户号发送消息时将消息在聊天室内广播 @Override protected void channelRead0(ChannelHandlerContext channelHandlerContext, TextWebSocketFrame textWebSocketFrame) throws Exception &#123; group.writeAndFlush(textWebSocketFrame.retain()); &#125; &#125;&#125; 网页端代码用h5发送消息 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;meta charset=&quot;utf-8&quot; /&gt;&lt;title&gt;WebSocket Test&lt;/title&gt;&lt;script language=&quot;javascript&quot;type=&quot;text/javascript&quot;&gt; alert(2222) var ws = new WebSocket(&quot;ws://127.0.0.1:9000/ws&quot;); ws.onopen = function(evt) &#123; console.log(&quot;Connection open ...&quot;); ws.send(&quot;Hello WebSockets!&quot;); &#125;; ws.onmessage = function(evt) &#123; console.log( &quot;Received Message: &quot; + evt.data); &#125;; ws.onclose = function(evt) &#123; console.log(&quot;Connection closed.&quot;); &#125;; function send() &#123; ws.send(&quot;message.................&quot;) &#125;&lt;/script&gt;&lt;input type=&quot;button&quot; value=&quot;send&quot; onclick=&quot;send()&quot;&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于钉钉在外网故障情况下仍然能发送消息的思考]]></title>
    <url>%2F2020%2F05%2F06%2F%E5%85%B3%E4%BA%8E%E9%92%89%E9%92%89%E5%9C%A8%E5%A4%96%E7%BD%91%E6%95%85%E9%9A%9C%E6%83%85%E5%86%B5%E4%B8%8B%E4%BB%8D%E7%84%B6%E8%83%BD%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[简介前段时间公司外网发生故障，外网无法访问，但是钉钉发送消息却不受影响，却仍然可以收发，当时感觉不可思议，结合最近学习的网络知识，这里做一下分析和总结 必要知识公有地址和私有地址如果我们运行ipconfig查看本机的ip地址我们会发现ip地址大多数都是已192.168.x.x开头的，但是如果我们去百度查找我们的ip地址却和我们ipconfig查找的ip地址不一样,这时因为公网使用的公有地址，而内网使用的是私有地址,为什么地址分为公有地址和私有地址?原因是ip的资源是有限的,但是通讯的时候每个主机都必须存在全球唯一的ip地址，不然就无法将消息发送到指定的主机，但是现在计算机那么多，如果全部都分配一个公有地址明显ip资源是不够用的,所以ip协议中将ip分为4种类型分别为A,B,C三种类型，每一种类型对应着不同的网段，且规划中这四种类型的IP中哪些段是公有地址，哪些段是私有地址，在局域网中私有地址使用NAT技术公用一个公有ip地址从而实现对外通信(这就是为什么我们使用ipconfig查看到的地址多是以192.168.X.X开头的原因，其使用C类型的ip类型),而各种类型的ip又用子网掩码来来告诉计算机ip的网络分段，且如果我们向路由器发出私有段的ip地址，则路由器不会进行转发,以下是知乎搜索的关于公有地址和私有地址的信息 1IPv4地址分为A、B、C、D、E五类，出去特殊作用的D、E两类，剩下的A、B、C三类地址是我们常见的IP地址段。A类地址的容量最大，可以容纳16777214个主机，B类地址可以容纳65534个主机，C类地址可以容纳254个主机。在这三类地址中，绝大多数的IP地址都是公有地址，需要向国际互联网信息中心申请注册。但是在IPv4地址协议中预留了3个IP地址段，作为私有地址，供组织机构内部使用。这三个地址段分别位于A、B、C三类地址内：A类地址：10.0.0.0--10.255.255.255B类地址：172.16.0.0--172.31.255.255 C类地址：192.168.0.0--192.168.255.255所以局域网在选取使用私有地址时，一般会按照实际需要容纳的主机数来选择私有地址段。常见的局域网由于容量小，一般选择C类的192.168.0.0作为地址段使用，一些大型企业就需要使用B类甚至A类地址段作为内部网络的地址段。最后需要补充说明的是，由于NAT和子网掩码的存在，实际在使用中，一个C类大小的局域网也可以选择A类的10.0.0.0网段作为自己的IP地址段。大多数局域网之所以仍然选择192.168.0.0/24或者192.168.1.0/24作为自己的IP地址段，更多的是因为约定成俗或者说网管个人习惯的关系。 IP和MAC地址IP是位于七层结构中的网络层,而MAC位于七层中的第二层数据链路层,其都是为了解决计算机通讯问题而设计的，其都是计算机通讯中的唯一标识(如果不唯一就无法通讯,实际情况下IP有可能会重复如使用了NAT技术),通常在局域网中公司使用的是交换机,由于一般的交换机是两层交换机(数据链路层),所以在内网中计算机通讯实际只使用到了MAC地址就可完成通讯,但是数据在不同链路中或者不同网段中通讯(如互联网和局域网)则需要使用到路由器进行通讯,而路由器位于七层中的第三层网络层,路由器将第二层传入的信息封装成以IP协议的包分发给互联网，由IP地址进行寻址来找到通讯的主机,那么为什么MAC和IP都能进行通讯，为什么还要划分出这两个概念呢?因为IP是有层级关系的如(192.168.1.1),在路由表中可以向查看192.X.X.X的主机在哪个路由中从而走对应的接口发送数据，这样更方便数据在网络中找到对应的主机,而MAC地址没有这种层级关系，因此在互联网中不适用MAC进行寻址. 网络通信中的三张表这三张表分别为 路由表 MAC地址表 ARP缓存表 路由表存在于路由器中,路由器中存在一张表，里面存在每个IP端的路由关系，数据到达路由器时根据IP协议中头部的IP信息来对照路由表中信息进行路由寻址 MAC地址表存在于交换器中，交换机中每一个端口都会记录着端口和所连接的MAC地址的映射关系表,数据经由交换机进行发送时,会将上一层的数据(网络层，如果存在的话),转成数据链路层,解析出发送数据和接受数据的MAC地址信息，再参照MAC地址表发送给对应的端口，这里还设计到交换机自学的过程,有兴趣的可以自行百度 ARP缓存表 其存在于主机，我们知道了对方的ip地址但是我们如何拿到对方的MAC地址?(这里也许大家会有疑问为什么我知道了IP地址还要获取MAC地址，因为在网络七层模型中数据传输是由逐下往上的,举个例子，我们使用netty构建一个IM服务器，在消息的传输中我们首先会定义消息传输的协议,这个协议作用在应用层,比如我规定发送的数据以逗号分隔，那么我在服务端netty中就需要定义一个handler,这个handler的作用就是获取网络中传输的消息，然后获取逗号，如果数据中有逗号则读取数据，并将数据发送给下一个handler，如果没有则等待数据发送完全，这里的逗号分隔就可以认为是我们自己在应用层定义的协议,接下来我们要将数据进行传输就要对数据进行序列化，我们可能采用json的方式对数据进行序列化传输，那么我们在发送消息时就要将上一部我们定义的逗号分隔的数据进行json序列化后进行传输，而这一部位于表示层,同理数据下一步再交给底层去处理，直到数据变成可在传输层传输的信号将数据发送出去)，那么同理在数据接收端我们也要逐层往上转化,将传输的0,1信号转化成我们应用层定义的逗号分隔的数据格式进行展示。,那么同理MAC是在数据链路层，IP是在网络层,数据要进行传输必须逐级往上或者往下传输 ,所以我们需要将IP转成MAC地址或者将MAC转成IP地址才能进行网络传输)答案是ARP协议，其实简单来说就是往IP主机发送一个消息，对应IP地址的返回MAC地址信息即可, 有关这三张表的解释https://blog.51cto.com/dengqi/1223132 钉钉在无外面下仍然可以使用的原因有了以上的基础知识，我这边做一个猜想，钉钉首先在聊天时会获取会话人的IP地址，后续直接使用这个ip地址发送消息，如果发送IP地址不成功或者接收端账号信息不匹配会去服务器拉取接收端的最新登录IP,那么在无外网的情况下由于之前会话就已经获得了接受端的IP，那么发送的消息直接会经由此IP发送出去,而消息经过路由器时，发现此IP已经存在于路由表中(因为公司使用的是内网,接收端和发送端都是同一个IP，就不会把消息发送到外网进行路由)，从而使用NAT技术将数据分发给对应的交换机端口，来接受数据,以上是本人猜想，如有错误欢迎拍砖]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下链接oralce报SQLRecoverableException: I/O Exception: Connection reset]]></title>
    <url>%2F2020%2F04%2F26%2Flinux%E4%B8%8B%E9%93%BE%E6%8E%A5oralce%E6%8A%A5SQLRecoverableException-I-O-Exception-Connection-reset%2F</url>
    <content type="text"><![CDATA[简介今天在正式环境部署应用时，使用jdbc连接数据库发现启动应用非常的忙，等待启动后查看日志发现SQLRecoverableException: I/O Exception: Connection reset’错误,在stackoverflow中发现有可能是linux随机数的问题,一下是网上摘抄的 123/dev/random和/dev/urandom是Linux系统中提供的随机伪设备，这两个设备的任务，是提供永不为空的随机字节数据流。很多解密程序与安全应用程序（如SSH Keys,SSL Keys等）需要它们提供的随机数据流。 这两个设备的差异在于：/dev/random的random pool依赖于系统中断，因此在系统的中断数不足时，/dev/random设备会一直封锁，尝试读取的进程就会进入等待状态，直到系统的中断数充分够用, /dev/random设备可以保证数据的随机性。/dev/urandom不依赖系统的中断，也就不会造成进程忙等待，但是数据的随机性也不高。 所以在启动应用时也有可能很慢也有可能是此问题解决方案 1234567对于jdk而言，需要的是把配置文件中$JAVA_HOME/jre/lib/security/java.security中的securerandom.source=file:/dev/random改为securerandom.source=file:/dev/urandom]]></content>
      <categories>
        <category>oralce</category>
      </categories>
      <tags>
        <tag>oralce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二次开发CAS服务端登录流程]]></title>
    <url>%2F2020%2F04%2F10%2F%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91CAS%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%99%BB%E5%BD%95%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[简介CAS 服务端登录提供了默认的登录流程并采用WebFlow进行实现,但是再实际项目中需要对接外部的登录系统，如果外部账号之前没有在本系统登录过,那么就要在内部账号进行一次二次注册,这需要对原有的登录流程进行修改,如果外部账号验证通过则进行判断该账号时候在本系统注册过,如果没有跳转到二次注册页面进行注册,我这里使用的版本是5.3.X 强制条件CAS 服务端采用Spring WebFlow进行流程编排，需要对WebFlow有个大概的了解才能进行开发https://blog.csdn.net/u013040472/article/details/71375058 修改切入点通过CAS官网得知 登录流程Webflow的默认实现类为DefaultLoginWebflowConfigurer，通过检索源码发现，该类会在工程开启时自动在Spring容器中注册,那么我们对流程的二次开发就已经明了，我们继承该类，加入自己的逻辑并在Spring容器中注册即可 12345678910@ConditionalOnMissingBean(name = &quot;defaultWebflowConfigurer&quot;) @Bean @Order(0) @RefreshScope public CasWebflowConfigurer defaultWebflowConfigurer() &#123; final DefaultLoginWebflowConfigurer c = new DefaultLoginWebflowConfigurer(builder(), loginFlowRegistry(), applicationContext, casProperties); c.setLogoutFlowDefinitionRegistry(logoutFlowRegistry()); c.setOrder(Ordered.HIGHEST_PRECEDENCE); return c; &#125; WebFlow 定义入口，在resources/webflow/login 创建了一个名为loginwebflow,以下的代码都是对这个webflow做扩展 123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;flow xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://www.springframework.org/schema/webflow&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/webflow http://www.springframework.org/schema/webflow/spring-webflow.xsd&quot;&gt; &lt;action-state id=&quot;initializeLoginForm&quot;&gt; &lt;evaluate expression=&quot;initializeLoginAction&quot; /&gt; &lt;transition on=&quot;success&quot; to=&quot;viewLoginForm&quot;/&gt; &lt;/action-state&gt; &lt;view-state id=&quot;viewLoginForm&quot; view=&quot;casLoginView&quot; model=&quot;credential&quot;&gt; &lt;binder&gt; &lt;binding property=&quot;username&quot; required=&quot;true&quot;/&gt; &lt;binding property=&quot;password&quot; required=&quot;true&quot;/&gt; &lt;binding property=&quot;code&quot;/&gt; &lt;binding property=&quot;type&quot; required=&quot;true&quot;/&gt; &lt;/binder&gt; &lt;transition on=&quot;submit&quot; bind=&quot;true&quot; validate=&quot;true&quot; to=&quot;realSubmit&quot; history=&quot;invalidate&quot;/&gt; &lt;/view-state&gt; &lt;action-state id=&quot;realSubmit&quot;&gt; &lt;evaluate expression=&quot;authenticationViaFormAction&quot;/&gt; &lt;transition on=&quot;warn&quot; to=&quot;warn&quot;/&gt; &lt;transition on=&quot;success&quot; to=&quot;createTicketGrantingTicket&quot;/&gt; &lt;transition on=&quot;successWithWarnings&quot; to=&quot;showAuthenticationWarningMessages&quot;/&gt; &lt;transition on=&quot;authenticationFailure&quot; to=&quot;handleAuthenticationFailure&quot;/&gt; &lt;transition on=&quot;error&quot; to=&quot;initializeLoginForm&quot;/&gt; &lt;/action-state&gt;&lt;/flow&gt; CAS默认登录流程通过查看DefaultLoginWebflowConfigurer，绘制了CAS流程登录时候的默认流程图,流程图中省略了一些非主要的逻辑 经过二次开发后的流程我在生成st 的流程下(generateServiceTicket)添加了一个自定义流程checkUserExister,来判断用户是否进行过二次注册，如果注册过就就跳转，如果没有注册过就跳转到二次注册页面,同样我在checkUserExister下也添加了checkUserExister来对用户是否进行过二次注册进行判断 部分代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class MyLoginWebflowConfiger extends DefaultLoginWebflowConfigurer &#123; public MyLoginWebflowConfiger(FlowBuilderServices flowBuilderServices, FlowDefinitionRegistry flowDefinitionRegistry, ApplicationContext applicationContext, CasConfigurationProperties casProperties) &#123; super(flowBuilderServices, flowDefinitionRegistry, applicationContext, casProperties); &#125;//登录页面属性和后端绑定 @Override protected void createRememberMeAuthnWebflowConfig(Flow flow)&#123; if (this.casProperties.getTicket().getTgt().getRememberMe().isEnabled()) &#123; this.createFlowVariable(flow, &quot;credential&quot;, RememberMeUsernamePasswordCredential.class); ViewState state = (ViewState)this.getState(flow, &quot;viewLoginForm&quot;, ViewState.class); BinderConfiguration cfg = this.getViewStateBinderConfiguration(state); cfg.addBinding(new BinderConfiguration.Binding(&quot;rememberMe&quot;, (String)null, false)); &#125; else &#123; this.createFlowVariable(flow, &quot;credential&quot;, LoginUsernamePasswordCredential.class); &#125; &#125;//generateServiceTicket后加入验证用户是否进行过二次注册checkUserExist @Override protected void createGenerateServiceTicketAction(Flow flow) &#123; ActionState handler = this.createActionState(flow, &quot;generateServiceTicket&quot;, this.createEvaluateAction(&quot;generateServiceTicketAction&quot;)); this.createTransitionForState(handler, &quot;success&quot;, &quot;checkUserExist&quot;); this.createTransitionForState(handler, &quot;warn&quot;, &quot;warn&quot;); this.createTransitionForState(handler, &quot;authenticationFailure&quot;, &quot;handleAuthenticationFailure&quot;); this.createTransitionForState(handler, &quot;error&quot;, &quot;initializeLoginForm&quot;); this.createTransitionForState(handler, &quot;gateway&quot;, &quot;gatewayServicesManagementCheck&quot;); createCheckUserExist(flow); &#125;//hasServiceCheck后加入验证用户是否进行过二次注册checkUserExist @Override protected void createHasServiceCheckDecisionState(Flow flow) &#123; this.createDecisionState(flow, &quot;hasServiceCheck&quot;, &quot;flowScope.service != null&quot;, &quot;renewRequestCheck&quot;, &quot;checkUserExist&quot;); &#125;//serviceCheck后加入验证用户是否进行过二次注册checkUserExist @Override protected void createServiceCheckDecisionState(Flow flow) &#123; this.createDecisionState(flow, &quot;serviceCheck&quot;, &quot;flowScope.service != null&quot;, &quot;generateServiceTicket&quot;, &quot;checkUserExist&quot;); &#125;//创建serviceCheck action private void createCheckUserExist(Flow flow)&#123; ActionState handler = this.createActionState(flow, &quot;checkUserExist&quot;, this.createEvaluateAction(&quot;checkUserExistAction&quot;)); //没有注册添加到注册页面 this.createTransitionForState(handler, &quot;noRegister&quot;, &quot;addUser&quot;); //注册过跳转到判断是否有service回调地址 this.createTransitionForState(handler, &quot;register&quot;, &quot;checkServiceDecisionState&quot;); createAddUserView(flow); createRegisteredUserView(flow); createCheckServiceDecisionState(flow); &#125;//如果有回调地址service则重定向,如果么有则跳转到默认页面 private void createCheckServiceDecisionState(Flow flow)&#123; this.createDecisionState(flow, &quot;checkServiceDecisionState&quot;, &quot;flowScope.service != null&quot;, &quot;redirect&quot;, &quot;registeredUser&quot;); &#125; private void createAddUserView(Flow flow)&#123; EndState state = this.createEndState(flow, &quot;addUser&quot;, &quot;addUser&quot;); &#125; private void createRegisteredUserView(Flow flow)&#123; EndState state = this.createEndState(flow, &quot;registeredUser&quot;, &quot;registeredUser&quot;); &#125;&#125; CheckUserExistAction 代码requestContext.getFlowScope().put(“redirect_service”,service);方法可以在flow域中传入参数，这样在页面中就可通过themeleaf模板方法 获取之前传入的值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class CheckUserExistAction extends AbstractAction &#123; private CentralAuthenticationService centralAuthenticationService; private ServiceConfig serviceConfig; public CheckUserExistAction(CentralAuthenticationService centralAuthenticationService,ServiceConfig serviceConfig) &#123; this.centralAuthenticationService = centralAuthenticationService; this.serviceConfig=serviceConfig; &#125; @Override protected Event doExecute(RequestContext requestContext) throws IOException, URISyntaxException &#123; String tgt = WebUtils.getTicketGrantingTicketId(requestContext); TicketGrantingTicket ticketGrantingTicket = this.centralAuthenticationService.getTicket(tgt, TicketGrantingTicket.class); Principal principal =ticketGrantingTicket.getAuthentication().getPrincipal(); String userJson=principal.getId(); User user=JSON.toJavaObject(JSON.parseObject(userJson), User.class); String idCard=user.getIdCard(); Map&lt;String,String&gt; params=new HashMap&lt;&gt;(); params.put(&quot;userIdcard&quot;,idCard); String response=HttpClientUtil.get(serviceConfig.find_useridcard_url,params); validateResponse(response); requestContext.getFlowScope().put(&quot;user_info&quot;,JSON.toJavaObject(JSON.parseObject(principal.getId()),User.class)); WebApplicationService webApplicationService=WebUtils.getService(requestContext); String service=webApplicationService==null?null:webApplicationService.getOriginalUrl(); requestContext.getFlowScope().put(&quot;redirect_service&quot;,service); if(noRegisterAndCompany(response))&#123; return this.getEventFactorySupport().event(this,&quot;noRegister&quot;); &#125;else &#123; return this.getEventFactorySupport().event(this,&quot;register&quot;); &#125; &#125; private void validateResponse(String response)&#123; Object code=JSON.parseObject(response).get(&quot;code&quot;); if(code==null || !&quot;1&quot;.equals(code.toString()))&#123; throw new RuntimeException(&quot;根据信用代码查询用户信息错误&quot;); &#125; &#125; private boolean noRegisterAndCompany(String response) &#123; Object data=JSON.parseObject(response).get(&quot;data&quot;); return data==null?true: !&quot;2d0f4e4b-4a7f-463c-abb1-20d33ea14f1a&quot;.equals(JSON.parseObject(data.toString()).get(&quot;type&quot;)) ; &#125;&#125;]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx反向代理静态资源404问题]]></title>
    <url>%2F2020%2F04%2F10%2Fnginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90404%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[简介在前后端分离的项目中通过nginx映射前端的html静态资源出现404，是由于配置静态路径有两种方式 方式112345Sets the root directory for requests. For example, with the following configurationlocation /i/ &#123; root /data/w3;&#125;The /data/w3/i/top.gif file will be sent in response to the “/i/top.gif” request 当访问/i/top.gif时，root是去/data/w3/i/top.gif请求文件 方式212345Defines a replacement for the specified location. For example, with the following configurationlocation /i/ &#123; alias /data/w3/images/;&#125;on request of “/i/top.gif”, the file /data/w3/images/top.gif will be sent. alias是去/data/w3/images/top.gif获取文件 总结由于采用方式1来配置静态资源导致实际映射的目录和访问的目录对不上导致404,后改制方式2后解决问题]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于大流量下防止超卖的思考]]></title>
    <url>%2F2020%2F03%2F29%2F%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%B5%81%E9%87%8F%E4%B8%8B%E9%98%B2%E6%AD%A2%E8%B6%85%E5%8D%96%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[简介最近在思考如何在大流量下防止超卖的问题,其实在并发下防止超卖或者其它一些并发问题，本质上绕不开锁的问题，因为如果没有锁无法保证数据同步的问题(至少是目前还没想到其它方法)，这边进行了一次尝试. 悲观锁一般悲观锁都由数据库等底层组件时间,比如在mysql的命令行中我们可以开启一个事务，然后再执行select * from table for update,然后再执行其它增删改操作，最后再提交事务即可,悲观锁就是你在select * from table for update时直接锁定这条数据，其它任何操作都要等到锁的释放才能进行操作（这里是事务的提交），在查找网上资料后悲观锁好像在代码中并没有什么比较好的实践方案所以放弃. 乐观锁其本质就是在数据库字段的最后加一个版本号或者更新时间的字段，在操作时先查询库存和版本信息，如果大于1则只需update操作并且在where中带上版本号或者更新日期，如果版本号和更新日期和之前获取的时候不匹配则更新失败,这样对数据变相的加锁，保证一次只能一个请求操作数据保证并发安全，在并发情况下我们可以做一些优化，比如将请求写入到队列中,由消费者去消费,消费者由于乐观锁操作失败时加入一定的重试次数等 redisredis的一些操作中保证了数据的原子性操作如list 的push和pop,那么我们可以应用redis的这些特性来实现此功能，在list中初始化你要卖货物的数量，然后再一个个pop出来直到list不为空为止。如果将所有库存信息都放在一个list中卖大量货物时会导致消费过慢,因此我们可以将库存信息存放在多个list中,一个list中只保存相对量的库存比如1000个,但是这样做还需要加入额外的代码逻辑,比如一个list过早的消费网，那么他就要去其它list中获取库存信息 代码乐观锁123456789101112131415161718@RequestMapping(&quot;sell&quot;) public String sell() &#123; //获取库存信息，你们保存库存量和最后更新时间 Stock stock = stockMapper.findNum(&quot;1&quot;); //如果没有库存 if(stock.getNum()&lt;1)&#123; return &quot;out&quot;; &#125; //如果由于乐观锁导致无法更新成功,重试20次 for (int i = 0; i &lt; 20; i++) &#123; //将版本信息，id，和当前时间传入数据库更新库存 int result = stockMapper.changeStock(&quot;1&quot;, stock.getNum() - 1, new Date(), stock.getUpdate()); if (result == 1) &#123; return &quot;success&quot;; &#125; &#125; return &quot;fail&quot;; &#125; redis123456789101112//初始化redis信息@RequestMapping(&quot;initStock&quot;) public void initStock(int num)&#123; List&lt;String&gt; cargoes=new ArrayList&lt;&gt;(); for(int i=0;i&lt;num;i++)&#123; cargoes.add(&quot;cargo_____&quot;+i); &#125; redisUtil.pushAll(cargoes); &#125; 1234567891011//销售货物@RequestMapping(&quot;sell&quot;) public void sell()&#123; String cargo=redisUtil.sell(); if(cargo!=null)&#123; //这里并没有加入任何锁 stockMapper.sell(&quot;1&quot;); &#125; &#125; 123456789101112131415//redis 代码//初始化库存public void pushAll(List&lt;String&gt; cargoes)&#123; redisTemplate.opsForList().leftPushAll(&quot;stock_num&quot;,cargoes); &#125;//销售商品 public String sell()&#123; Object object= redisTemplate.opsForList().leftPop(&quot;stock_num&quot;); return object!=null?object.toString():null; &#125; 测试实际中我将库存设置为1000，再使用Jmeter测试工程开启100个线程,每个线程循环200次去重复调用http接口，均能保证不超卖]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>超卖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS 解决前后端分离静态页面地址无法验证,无法登录的问题]]></title>
    <url>%2F2020%2F03%2F26%2FCAS-%E8%A7%A3%E5%86%B3%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E5%9C%B0%E5%9D%80%E6%97%A0%E6%B3%95%E9%AA%8C%E8%AF%81-%E6%97%A0%E6%B3%95%E7%99%BB%E5%BD%95%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[简介现有项目采用前后端分离分开部署的策略，根据前文CAS客户端和Gateway集成的文章中提到的CAS的验证流程,我们可得知在用户调用接口时如果发现本地项目没有缓存用户登录信息，就跳转到CAS服务端去验证,登录完成后再跳转到原页面,并在url中带上ticket参数再去验证本次请求的合法性,在采用前后端分离的项目中会有一下问题,以下是解决方案. 验证ticket参数无法获取因为是前后端分离项目,在调用接口时发现本地没有缓存登录信息,将跳转到统一登录页面，登录完成后再调回到原有页面的地址，并在url中加入ticket参数,由于我们采用的是前后端分离的策略，此时回调的地址是一个静态页面,那么后端无法自动对ticket参数进行验证，所以我这里采取了一个策略，在调用接口发现本地没有缓存用户信息的时候,不是直接跳转到cas登录页，而是跳转到一个已经集成了cas客户端第三方的应用(我这里是网关),由网关将需要跳转的链接组装好（将cas登录后跳转的地址改到网关）,在登录完成后跳转到网关进行ticket合法调用的验证(因为网关已经集成客户端)并且缓存下登录信息,在ticket验证成功后再从新跳转到静态页面。注意我们在获取原有静态访问页面地址的时候不是直接获取url,而是优先获取请求头中的Referer中的地址，如果没有Referer再去获取调用接口的rul地址,因为前端中经常使用异步去调用接口，如果直接获取请求接口的url中的地址,我们得到的地址是接口的地址如以下代码，而Referer地址则是反应了请求时从哪里跳转过来的,具体可自行百度Referer 获取登录成功后跳转回原有页面的地址 12StringUtils.isEmpty(request.getHeaders().getFirst(&quot;Referer&quot;)) ? serviceUrl : request.getHeaders().getFirst(&quot;Referer&quot;), 在gateway拦截器中,如果没有登录成功则返回对象告诉页面跳转的地址 123456789101112//这里直接返回对象，这里个返回时放在认证拦截器中,如果没有登录返回301和跳转地址供前端跳转，urlToRedirect的格式举例为//http://localhost.com/cas/login?service=192.168.1.1/gateway/validateTicket&amp;redirectUrl=192.168.1.2/redirect//在原有的service参数后又自定义一个redirectUrl参数，供在ticket验证完成后跳转到访问静态页面 public static Mono&lt;Void&gt; createResponse(ServerWebExchange exchange ,String urlToRedirect)&#123; ServerHttpResponse response = exchange.getResponse(); JSONObject responseJson = new JSONObject(); responseJson.put(&quot;code&quot;,&quot;301&quot;); responseJson.put(&quot;urlToRedirect&quot;,urlToRedirect); byte[] bits = responseJson.toJSONString().getBytes(StandardCharsets.UTF_8); DataBuffer buffer = response.bufferFactory().wrap(bits); return response.writeWith(Mono.just(buffer)); &#125; gateway中重定向的拦截器 1234567891011121314151617181920public class RedirectFilter implements GlobalFilter, Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; ServerHttpRequest request =exchange.getRequest(); String uri=exchange.getRequest().getURI().toString(); if(uri.contains(&quot;/redirect&quot;) &amp;&amp; uri.contains(&quot;redirectUrl=&quot;))&#123; //如果是重定向的话 String redirectUrl=request.getQueryParams().getFirst(&quot;redirectUrl&quot;); return GatewayCommonUtils.redirect(exchange, redirectUrl); &#125;else &#123;//如果不是重定向url的话跳过拦截器 return chain.filter(exchange); &#125; &#125; @Override public int getOrder() &#123; return 10000; &#125;&#125; 异步调用问题采取前后端分离，前端调用接口必然大量存在异步调用,而最开始时我采用的是后端发起301重定向,由浏览器去自动完成跳转,但是在异步情况下，浏览器无法对后端发起的30X请求发起定向，于是这我采用如上代码,直接返回对象和跳转url给前端,由前端去跳转，而不是再由后端发起重定向. 跨域保存cookie的问题在登录成功后需要在本地项目中保存登录信息,由于我们项目使用的是gateway作为网关接入客户单，gateway中并没有session的概念，于是我采用cookie来保存登录的凭证，再用登录凭证去redis中查找登录的信息来判断用户是否已经登录过,但是这样存在一个问题，用户信息是在网关中验证的,我在网关中设置的cookie写入路径path为 / ，但是采用前后端分离的情况静态页面有着单独的http地址，并没有和网关在同一个域,这样导致了我在网关写入的cookie信息无法在前端的那个域中调用的接口中获取到,我这里采用的方法是统一有nginx反向代理网关域名和http静态页面的域名,强制让网关和静态页面在同一个域下,解决跨域无法读取cookie的问题]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置反向代理后，接入nginx的应用无法获取正确的访问路径和端口问题]]></title>
    <url>%2F2020%2F03%2F19%2Fnginx%E9%85%8D%E7%BD%AE%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%90%8E%EF%BC%8C%E6%8E%A5%E5%85%A5nginx%E7%9A%84%E5%BA%94%E7%94%A8%E6%97%A0%E6%B3%95%E8%8E%B7%E5%8F%96%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%AE%BF%E9%97%AE%E8%B7%AF%E5%BE%84%E5%92%8C%E7%AB%AF%E5%8F%A3%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[简介在实际项目中需要用到ngnix做反向代理，但是做完反向代理后发现子应用无法获取正确的url和端口。比如访问nginx的url为 192.168.1.1/test ,那么现在将/test反向代理到 192.168.1.2:8080/test 这个url下，那么我在 192.168.1.2:8080/test 下就获取端口一直会是80，获取的url不会是访问nginx时的192.168.1.1/test ，这里我们需要对ngnix的配置文件的请求头进行修改加入proxy_set_header HOST $host;属性如下$host代表你访问nginx的访问路径，在路径后加入应用的端口，那么在子应用中就能获取到正确的端口了 123456789101112131415161718192021222324252627upstream gateway &#123; server 192.168.171.42:30000; # server 192.168.171.43:30000; # server 192.168.171.45:30000; &#125;server &#123; listen 8080; server_name location; location /cas &#123; proxy_pass http://192.168.171.44:8089/cas; proxy_set_header HOST $host:8089; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; location / &#123; proxy_pass http://gateway; proxy_set_header HOST $host:8080; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS客户端和Gateway集成]]></title>
    <url>%2F2020%2F03%2F04%2FCAS%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8CGateway%E9%9B%86%E6%88%90%2F</url>
    <content type="text"><![CDATA[简介CAS提供的客户端是基于Servlet写的，也就是说我们如果使用非Servlet应用，那么客户端是无法继承的，项目中使用没有使用Zuul来作为网关，而是使用Gateway，所以我们需要将原有的逻辑迁移到Gateway上 实现思路根据查询原有客户端我们可以发现，客户端本质是一些Servlet拦截器，在拦截器中对登录和验证进行各种逻辑，而Gateway也提供了拦截器GlobalFilter，所以我们只要实现GlobalFilter将原有的逻辑迁移到GlobalFilter中并在Spring中注册将其作用到Gateway即可,并且将代码封装成starter实现开箱即用。 Cas客户单总体流程图我们在Servelt应用中集成CAS客户端主要使用的是Cas30ProxyReceivingTicketValidationFilter和AuthenticationFilter两个拦截器，通过查看源码我们可以发现Cas30ProxyReceivingTicketValidationFilter的主要作用是验证Ticket，就是登陆完成后服务端会下发给一个临时的Ticket来验证请求的正确性，用ST来表示，这个类主要用来验证ST和在处理代理模式下的逻辑(代理模式：两个应用同时集成了cas客户单，现在A应用要通过http协议直接调用B应用的接口，类似于Nginx，如果是这这类请求走的验证Ticket逻辑是不一样的，CAS会生成PGT和PGTIOU，通过PGTIOU作为键来对应PGT来验证代理服务器时候之前已经认证过，代理这部分放在以后再说明),下面是根据官网的流程图和结合客户端代码绘制的总体的CAS验证流程图 核心源码分析Cas30ProxyReceivingTicketValidationFilter上文说到Cas30ProxyReceivingTicketValidationFilter的核心作用是验证Ticket，而具体的验证逻辑由TicketValidator类来控制，我们可以在Cas30ProxyReceivingTicketValidationFilter的父类Cas20ProxyReceivingTicketValidationFilter中的getTicketValidator方法中查看初始化TicketValidator的逻辑，总体分为2总一种是初始化代理端的TicketValidator，另一种是初始化被代理端的TicketValidator，下面的注释已经说明，而getTicketValidator方法又会在初始化Cas30ProxyReceivingTicketValidationFilter时被调用。通过源码我们可以发现根据逻辑的不同其初始化了Cas20ServiceTicketValidator或者Cas20ProxyTicketValidator的ticket验证器，前者是作为代理端的ticket验证器(类似nginx)如果不设置代理用这个ticket验证器即可，后者是被代理端的验证器，处理被代理端的ticket验证逻辑 12345678910111213141516171819202122232425262728293031323334353637383940414243protected final TicketValidator getTicketValidator(final FilterConfig filterConfig) &#123; final boolean allowAnyProxy = getBoolean(ConfigurationKeys.ACCEPT_ANY_PROXY); final String allowedProxyChains = getString(ConfigurationKeys.ALLOWED_PROXY_CHAINS); final String casServerUrlPrefix = getString(ConfigurationKeys.CAS_SERVER_URL_PREFIX); final Class&lt;? extends Cas20ServiceTicketValidator&gt; ticketValidatorClass = getClass(ConfigurationKeys.TICKET_VALIDATOR_CLASS); final Cas20ServiceTicketValidator validator; //根据servlet拦截器的初始化参数来判断，如果是被代理端（被调用的应用） if (allowAnyProxy || CommonUtils.isNotBlank(allowedProxyChains)) &#123; final Cas20ProxyTicketValidator v = createNewTicketValidator(ticketValidatorClass, casServerUrlPrefix, this.defaultProxyTicketValidatorClass); v.setAcceptAnyProxy(allowAnyProxy); v.setAllowedProxyChains(CommonUtils.createProxyList(allowedProxyChains)); validator = v; &#125; else &#123; //如果是代理端(类似nginx) validator = createNewTicketValidator(ticketValidatorClass, casServerUrlPrefix, this.defaultServiceTicketValidatorClass); &#125; validator.setProxyCallbackUrl(getString(ConfigurationKeys.PROXY_CALLBACK_URL)); validator.setProxyGrantingTicketStorage(this.proxyGrantingTicketStorage); final HttpURLConnectionFactory factory = new HttpsURLConnectionFactory(getHostnameVerifier(), getSSLConfig()); validator.setURLConnectionFactory(factory); validator.setProxyRetriever(new Cas20ProxyRetriever(casServerUrlPrefix, getString(ConfigurationKeys.ENCODING), factory)); validator.setRenew(getBoolean(ConfigurationKeys.RENEW)); validator.setEncoding(getString(ConfigurationKeys.ENCODING)); final Map&lt;String, String&gt; additionalParameters = new HashMap&lt;String, String&gt;(); final List&lt;String&gt; params = Arrays.asList(RESERVED_INIT_PARAMS); for (final Enumeration&lt;?&gt; e = filterConfig.getInitParameterNames(); e.hasMoreElements(); ) &#123; final String s = (String) e.nextElement(); if (!params.contains(s)) &#123; additionalParameters.put(s, filterConfig.getInitParameter(s)); &#125; &#125; validator.setCustomParameters(additionalParameters); return validator; &#125; 调用TicketValidator我们查看Cas30ProxyReceivingTicketValidationFilter的父类AbstractTicketValidationFilter的doFilter方法，主要逻辑已经在下面代码中做出注释，那么现在我们要做的主要事情已经清晰，重写拦截器中根据不同的功能配置不同协议的TicketValidator（我采用的是CAS3协议对应的是Cas30ServiceTicketValidator和Cas30ProxyTicketValidator,前者作为代理服务端验证ticket的逻辑,后者作为验证被代理端的ticket逻辑）每种不同协议的实现类会调用Cas Service的对应协议的URL具体可以查看各个协议实现的TicketValidator的getUrlSuffix()方法,然后验证成功后再将信息存在缓存中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public final void doFilter(final ServletRequest servletRequest, final ServletResponse servletResponse, final FilterChain filterChain) throws IOException, ServletException &#123; if (!preFilter(servletRequest, servletResponse, filterChain)) &#123; return; &#125; final HttpServletRequest request = (HttpServletRequest) servletRequest; final HttpServletResponse response = (HttpServletResponse) servletResponse; final String ticket = retrieveTicketFromRequest(request); if (CommonUtils.isNotBlank(ticket)) &#123; logger.debug(&quot;Attempting to validate ticket: &#123;&#125;&quot;, ticket); try &#123; //验证ticket的有效性 final Assertion assertion = this.ticketValidator.validate(ticket, constructServiceUrl(request, response)); logger.debug(&quot;Successfully authenticated user: &#123;&#125;&quot;, assertion.getPrincipal().getName()); request.setAttribute(CONST_CAS_ASSERTION, assertion); //验证成功存入Session if (this.useSession) &#123; request.getSession().setAttribute(CONST_CAS_ASSERTION, assertion); &#125; onSuccessfulValidation(request, response, assertion); //验证成功重定向到原来访问的链接 if (this.redirectAfterValidation) &#123; logger.debug(&quot;Redirecting after successful ticket validation.&quot;); response.sendRedirect(constructServiceUrl(request, response)); return; &#125; &#125; catch (final TicketValidationException e) &#123; logger.debug(e.getMessage(), e); onFailedValidation(request, response); if (this.exceptionOnValidationFailure) &#123; throw new ServletException(e); &#125; response.sendError(HttpServletResponse.SC_FORBIDDEN, e.getMessage()); return; &#125; &#125; filterChain.doFilter(request, response); &#125; 功能补充sessionserlvet客户单中采用缓存在session中的方式来缓存用户信息，在gateway中没有session的概念，因此我用cookie来解决用户标识的问题，在用户完成验证后会往cookie中写入信息，在请求时带上cooike信息然后再redis中判断用户是否登录过来模拟实现session 单点登出上面提到我是使用redis来当做分布式session来使用，那么单点登出实现的逻辑是在gateway中提供统一的单点退出接口，用户调用此接口后清除redies中缓存的信息，并且重定向到CAS Service 调用/logout方法，并且在url中带上service参数后面跟上退出成功后cas重定向到的地址，这样在清除掉本地缓存的时又清楚了CAS Service中缓存的TGT信息实现单点退出. 代码地址https://github.com/liushprofessor/cas_demo]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS登录成功跳转]]></title>
    <url>%2F2020%2F02%2F17%2FCAS%E7%99%BB%E5%BD%95%E6%88%90%E5%8A%9F%E8%B7%B3%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[简介项目需求中其中有一个就是根据不同的登录方式，跳转到不同的首页，现实中登录后跳转根据url后的service来做回调，但是在需求中，用户会直接进入到登录页面进行登录，登录页面有不同的登录方式，每一种登录方式成功后都会跳转到不同的页面，如果在访问的时候url中没有带上service参数的回调地址，那么cas会跳转到cas默认的登录页面，并且将登录的一些参数带在url后返回到登录页面，那么要实现这个需求我们只需要改造默认的登录成功页面，根据待在回调url后的参数即可知道是哪一种方式登录的，并根据回调后的参数进行页面跳转 改造默认登录页CAS 默认的登录成功页是在templates目录下的casGenericSuccessView.html我们对其进行改造，我们改造原有的页面，将自己的逻辑加进去，如下面的逻辑是在登录成功后首先会获取登录时上传的type参数，根据type类型的不同进行不同页面的跳转 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;/&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;/&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;!--&lt;title th:text=&quot;#&#123;screen.success.header&#125;&quot;&gt;Generic Success View&lt;/title&gt;--&gt; &lt;!--&lt;link href=&quot;../../static/css/cas.css&quot; rel=&quot;stylesheet&quot; th:remove=&quot;tag&quot; /&gt;--&gt;&lt;/head&gt;&lt;body&gt;&lt;!--此页面是登录完成如果url中没有带service参数的话进入到此页面--&gt;&lt;/body&gt;&lt;script&gt; $(function () &#123; //type为登录时自定义的参数，在登录成功后会将登录的参数待在url后面并且跳转回回调url var type = getQueryString(&quot;type&quot;); if (type == 1) &#123; //这里做了nginx反向代理，换成实际的回调url location.href = &quot;http://192.168.171.46/client3/welcome1&quot;; &#125; else if (type == 2) &#123; //这里做了nginx反向代理，换成实际的回调url location.href = &quot;http://192.168.171.46/client3/welcome2&quot;; &#125; else &#123; alert(&quot;不存在type参数无法跳转&quot;) &#125; &#125;); function getQueryString(name) &#123; var reg = new RegExp(&quot;(^|&amp;)&quot; + name + &quot;=([^&amp;]*)(&amp;|$)&quot;); //构造一个含有目标参数的正则表达式对象 var r = window.location.search.substr(1).match(reg); //匹配目标参数 if (r != null) return decodeURI(r[2]); return null; &#125;&lt;/script&gt;&lt;/html&gt; 覆盖CAS的casGenericSuccessView.html页面12345678910111213141516171819202122232425262728293031&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;warName&gt;cas&lt;/warName&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;recompressZippedFiles&gt;false&lt;/recompressZippedFiles&gt; &lt;archive&gt; &lt;compress&gt;false&lt;/compress&gt; &lt;manifestFile&gt;$&#123;manifestFileToUse&#125;&lt;/manifestFile&gt; &lt;/archive&gt; &lt;overlays&gt; &lt;overlay&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp$&#123;app.server&#125;&lt;/artifactId&gt; &lt;!--原有的服务不再初始化进去--&gt; &lt;excludes&gt; &lt;exclude&gt;WEB-INF/classes/services/*&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/application.*&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/log4j2.*&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/webflow/login/*.xml&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/templates/fragments/loginform.html&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/templates/casLoginView.html&lt;/exclude&gt; &lt;!--将默认的登录成功页面替换成我们自带的页面 --&gt; &lt;exclude&gt;WEB-INF/classes/templates/casGenericSuccessView.html&lt;/exclude&gt; &lt;/excludes&gt; &lt;/overlay&gt; &lt;/overlays&gt; &lt;/configuration&gt; &lt;/plugin&gt; 代码https://github.com/liushprofessor/cas_demo]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS教程1--CAS的搭建]]></title>
    <url>%2F2020%2F01%2F21%2FCAS%E6%95%99%E7%A8%8B1-CAS%E7%9A%84%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[下载代码我使用官方提供的 cas-overlay-template 进行CAS Service的搭建，首先从github上下载代码https://github.com/apereo/cas-overlay-template/tree/5.3我使用的是5.3版本 修改 maven 依赖配置 修改 &lt;cas.version&gt; 标签为 5.3.1 版本 如下,之前尝试其它版本下载不下来，这里我使用的是5.3.1 1&lt;cas.version&gt;5.3.1&lt;/cas.version&gt; 找到 pom 文件中的 maven-war-plugin插件，修改成如下配置,将 overlays中的文件排除出去，因为我们这些文件要进行重写 1234567891011121314151617181920212223242526&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;warName&gt;cas&lt;/warName&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;recompressZippedFiles&gt;false&lt;/recompressZippedFiles&gt; &lt;archive&gt; &lt;compress&gt;false&lt;/compress&gt; &lt;manifestFile&gt;$&#123;manifestFileToUse&#125;&lt;/manifestFile&gt; &lt;/archive&gt; &lt;overlays&gt; &lt;overlay&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp$&#123;app.server&#125;&lt;/artifactId&gt; &lt;!--原有的服务不再初始化进去--&gt; &lt;excludes&gt; &lt;exclude&gt;WEB-INF/classes/services/*&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/application.*&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/log4j2.*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/overlay&gt; &lt;/overlays&gt; &lt;/configuration&gt; &lt;/plugin&gt; 工程目录调整删除多余文件打开 overlays 目录如果下面有 org.apereo.cas.cas-server-webapp-tomcat-5.3.14 这个目录将其删掉，因为我们使用的是5.3.1这个版本，只保留 org.apereo.cas.cas-server-webapp-tomcat-5.3.1 这个目录 创建自定义代码目录在根目录下（ overlays 同级目录 ） 新建maven风格的目录,并且在编译器中将java文件夹设置成 Sources Root,将 resources 设置成 Resources Root 1234src |-main |-java |-resources 复制配置文件将 org.apereo.cas.cas-server-webapp-tomcat-5.3.1/WEB-INF/classes 下的 services 文件夹，application.properties ,log4j2.xml复制到我们上一步定义的resources 目录下 注意如果我们之前在 POM 文件中 的maven-war-plugin 排除了这三个文件，编译器中可能会无法显示这三个文件，我们可以先将其注释，等复制完后再排除这三个文件 修改配置文件 修改services下的 客户端接入文件这个目录下存放的是哪些客户端可以接入CAS 的配置文件， 在CAS中我们可以选择动态的添加客户端，和静态的添加客户端，其中静态添加客户端就是以在services下以json的形式添加，其中json的文件命名是有规定的，json文件名字规则为${name}-${id}.json, id必须为json文件内容id一致，我这里删除了原有services目录下的所有文件,新建一个localhost-10000001.json 的文件，内容如下,这里设置了所有以http,https,imaps开头的都能接入，proxyPolicy 是为了设置代理模式支持http协议而设置的，关于代理模式以后再介绍 123456789101112&#123; &quot;@class&quot; : &quot;org.apereo.cas.services.RegexRegisteredService&quot;, &quot;serviceId&quot; : &quot;^(https|http|imaps)://.*&quot;, &quot;name&quot; : &quot;HTTPS and HTTP and IMAPS&quot;, &quot;id&quot; : 10000001, &quot;description&quot; : &quot;This service definition authorizes all application urls that support HTTPS and HTTP and IMAPS protocols.&quot;, &quot;evaluationOrder&quot; : 10000, &quot;proxyPolicy&quot;: &#123; &quot;@class&quot;: &quot;org.apereo.cas.services.RegexMatchingRegisteredServiceProxyPolicy&quot;, &quot;pattern&quot;: &quot;^(https|http)?://.*&quot; &#125;&#125; 关于json配置文件的简要介绍 1234567json文件解释：@class：必须为org.apereo.cas.services.RegisteredService的实现类，对其他属性进行一个json反射对象，常用的有RegexRegisteredService，匹配策略为id的正则表达式serviceId：唯一的服务idname： 服务名称，会显示在默认登录页id：全局唯一标志description：服务描述，会显示在默认登录页evaluationOrder：确定已注册服务的相对评估顺序。当两个服务URL表达式覆盖相同的服务时，此标志尤其重要;评估顺序决定首先评估哪个注册，并作为内部排序因素。 （越小越优先） 修改 application.properties在配置文件末尾加入,因为我在内网中，所以关闭https，CAS推荐使用https，如果不使用https协议的话会导致跨域登录或者代理等功能无法使用，所以我们都需要手动关闭这些配置让应用支持http 12345678910# 开启json服务注册cas.serviceRegistry.initFromJson=true# 登出后允许跳转到指定页面cas.logout.followServiceRedirects=true# 设置接入端json文件路径cas.serviceRegistry.json.location=classpath:/services#关闭httpsserver.ssl.enabled=falsecas.tgc.secure=falsecas.warningCookie.secure=false 修改log4j2.xml修改日志配置文件，这里没什么好说的，修改输出路径即可 123&lt;Properties&gt; &lt;Property name=&quot;baseDir&quot;&gt;/home/syd/sso/&lt;/Property&gt; &lt;/Properties&gt; 接下来直接将应用打包放入tomcat或者直接在idea中接入tomcat运行即可访问CAS 地址(根据自己的端口和项目名自行修改url)http://localhost:8080/cas/login 客户端的接入创建Spring Web工程导入maven 依赖 12345678910111213141516&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--cas的客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.jasig.cas.client&lt;/groupId&gt; &lt;artifactId&gt;cas-client-core&lt;/artifactId&gt; &lt;version&gt;3.5.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 创建客户端拦截器CAS 客户端的API本质就是一些Servlet 的拦截器，我们将其继承到我们的WEB工程即可,定义拦截器,注意一点filterValidationRegistration过滤器的执行顺序一定要在 filterAuthenticationRegistration之前，具体可以看之前介绍CAS 认证的文章 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156package com.liu;import org.jasig.cas.client.authentication.AuthenticationFilter;import org.jasig.cas.client.session.SingleSignOutFilter;import org.jasig.cas.client.session.SingleSignOutHttpSessionListener;import org.jasig.cas.client.util.AssertionThreadLocalFilter;import org.jasig.cas.client.util.HttpServletRequestWrapperFilter;import org.jasig.cas.client.validation.Cas30ProxyReceivingTicketValidationFilter;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.boot.web.servlet.ServletListenerRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.EventListener;import java.util.HashMap;import java.util.Map;/** * 功能： TODO(用一句话描述类的功能) * * ────────────────────────────────────────── * version 变更日期 修改人 修改说明 * ------------------------------------------ * V1.0.0 2020/1/21 Liush 初版 * ────────────────────────────────────────── */@Configurationpublic class CASConfig &#123; /************************************* SSO配置-开始 ************************************************/ /** * SingleSignOutFilter 登出过滤器 * 该过滤器用于实现单点登出功能，可选配置 * * @return */ @Bean public FilterRegistrationBean filterSingleRegistration() &#123; FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new SingleSignOutFilter()); // 设定匹配的路径 registration.addUrlPatterns(&quot;/*&quot;); Map&lt;String, String&gt; initParameters = new HashMap(); initParameters.put(&quot;casServerUrlPrefix&quot;, URLConfig.CAS_SERVER_LOGIN_PATH); registration.setInitParameters(initParameters); // 设定加载的顺序 registration.setOrder(1); return registration; &#125; /** * SingleSignOutHttpSessionListener 添加监听器 * 用于单点退出，该过滤器用于实现单点登出功能，可选配置 * * @return */ @Bean public ServletListenerRegistrationBean&lt;EventListener&gt; singleSignOutListenerRegistration() &#123; ServletListenerRegistrationBean&lt;EventListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;EventListener&gt;(); registrationBean.setListener(new SingleSignOutHttpSessionListener()); registrationBean.setOrder(1); return registrationBean; &#125; /** * Cas30ProxyReceivingTicketValidationFilter 验证过滤器 * 该过滤器负责对Ticket的校验工作，必须启用它 * * @return */ @Bean public FilterRegistrationBean filterValidationRegistration() &#123; FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new Cas30ProxyReceivingTicketValidationFilter()); // 设定匹配的路径 registration.addUrlPatterns(&quot;/*&quot;); Map&lt;String, String&gt; initParameters = new HashMap(); initParameters.put(&quot;casServerUrlPrefix&quot;, URLConfig.CAS_SERVER_PATH); initParameters.put(&quot;serverName&quot;, URLConfig.SERVER_NAME); // 是否对serviceUrl进行编码，默认true：设置false可以在302对URL跳转时取消显示;jsessionid=xxx的字符串 // 观察CommonUtils.constructServiceUrl方法可以看到 initParameters.put(&quot;encodeServiceUrl&quot;, &quot;false&quot;); registration.setInitParameters(initParameters); // 设定加载的顺序 registration.setOrder(1); return registration; &#125; /** * AuthenticationFilter 认证过滤器 * * @return */ @Bean public FilterRegistrationBean filterAuthenticationRegistration() &#123; FilterRegistrationBean registration = new FilterRegistrationBean(); Map&lt;String, String&gt; initParameters = new HashMap(); registration.setFilter(new AuthenticationFilter()); registration.addUrlPatterns(&quot;/*&quot;); initParameters.put(&quot;casServerLoginUrl&quot;, URLConfig.CAS_SERVER_LOGIN_PATH); initParameters.put(&quot;serverName&quot;, URLConfig.SERVER_NAME); // 不拦截的请求 .* 有后缀的文件 initParameters.put(&quot;ignorePattern&quot;, &quot;.*&quot;); // 表示过滤所有 initParameters.put(&quot;ignoreUrlPatternType&quot;, &quot;com.liu.SimpleUrlPatternMatcherStrategy&quot;); registration.setInitParameters(initParameters); // 设定加载的顺序 registration.setOrder(2); return registration; &#125; /** * AssertionThreadLocalFilter * * 该过滤器使得开发者可以通过org.jasig.cas.client.util.AssertionHolder来获取用户的登录名。 * 比如AssertionHolder.getAssertion().getPrincipal().getName()。 * * @return */ @Bean public FilterRegistrationBean filterAssertionThreadLocalRegistration() &#123; FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new AssertionThreadLocalFilter()); // 设定匹配的路径 registration.addUrlPatterns(&quot;/*&quot;); // 设定加载的顺序 registration.setOrder(1); return registration; &#125; /* * HttpServletRequestWrapperFilter wraper过滤器 * 该过滤器负责实现HttpServletRequest请求的包裹， * 比如允许开发者通过HttpServletRequest的getRemoteUser()方法获得SSO登录用户的登录名，可选配置。 * * @return */ @Bean public FilterRegistrationBean filterWrapperRegistration() &#123; FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new HttpServletRequestWrapperFilter()); // 设定匹配的路径 registration.addUrlPatterns(&quot;/*&quot;); // 设定加载的顺序 registration.setOrder(1); return registration; &#125;&#125; 接着创建拦截器要用到的白名单URL过滤器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.liu;import org.jasig.cas.client.authentication.UrlPatternMatcherStrategy;import java.util.Arrays;import java.util.List;/** * 机能概要:过滤掉一些不需要授权登录的URL */public class SimpleUrlPatternMatcherStrategy implements UrlPatternMatcherStrategy &#123; /** * 机能概要: 判断是否匹配这个字符串 * * @param url 用户请求的连接 * @return true : 不拦截 * false :必须得登录了 */ @Override public boolean matches(String url) &#123; if(url.contains(&quot;/logout&quot;))&#123; return true; &#125; List&lt;String&gt; list = Arrays.asList( &quot;/&quot;, &quot;/index&quot;, &quot;/favicon.ico&quot; ); String name = url.substring(url.lastIndexOf(&quot;/&quot;)); if (name.indexOf(&quot;?&quot;) != -1) &#123; name = name.substring(0, name.indexOf(&quot;?&quot;)); &#125; System.out.println(&quot;name：&quot; + name); boolean result = list.contains(name); if (!result) &#123; System.out.println(&quot;拦截URL：&quot; + url); &#125; return result; &#125; /** * 正则表达式的规则，这个地方可以是web传递过来的 */ @Override public void setPattern(String pattern) &#123; &#125;&#125; 一些拦截器用到的URL常量 123456789101112131415161718192021222324252627282930package com.liu;/** * Cas 的一些配置项 */public class URLConfig &#123; /** * 当前应用程序的baseUrl（注意最后面的斜线） */ public static String SERVER_NAME = &quot;http://localhost:8181/&quot;; /** * App1 登出成功url */ public static String APP_LOGOUT_PATH = SERVER_NAME + &quot;logoutSuccess&quot;; /** * CAS服务器地址 */ public static String CAS_SERVER_PATH = &quot;http://localhost:8080/cas&quot;; /** * CAS登陆服务器地址 */ public static String CAS_SERVER_LOGIN_PATH = &quot;http://localhost:8080/cas/login&quot;; /** * CAS登出服务器地址 */ public static String CAS_SERVER_LOGOUT_PATH = &quot;http://localhost:8080/cas/logout&quot;;&#125; 编写Http 接口这里需要注意一下，单点登出，CAS 客户端在第一次完成认证后会把信息缓存在Sesion中，所以这边编写了一个退出的url叫logout,这边会清除当前服务器的session，并且调用CAS的退出服务，CAS 再将所有的服务器的登录信息清除，完成单点退出,接下来我们访问这个接口就会跳转到CAS 认证服务器，输入完账号密码后又会跳转回来完成单点登录，同样也可以调用接口进行单点登出功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.liu;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.bind.annotation.RestController;import javax.servlet.http.HttpServletRequest;/** * 功能： TODO(用一句话描述类的功能) * * ────────────────────────────────────────── * version 变更日期 修改人 修改说明 * ------------------------------------------ * V1.0.0 2020/1/21 Liush 初版 * ────────────────────────────────────────── */@Controllerpublic class TestController &#123; @RequestMapping(&quot;test&quot;) @ResponseBody public String test(HttpServletRequest request)&#123; //可以在request中获取登录账号信息 String id=request.getRemoteUser(); System.out.println(id); return &quot;test&quot;; &#125; //退出登录，先失效session再调用CAS Service @RequestMapping(&quot;/logout&quot;) public String logout(HttpServletRequest request) &#123; // session失效 request.getSession().invalidate(); return &quot;redirect:&quot; + URLConfig.CAS_SERVER_LOGOUT_PATH + &quot;?service=&quot;+URLConfig.APP_LOGOUT_PATH; &#125; //重定向到退出登录接口，给成功提示语 @RequestMapping(&quot;/logoutSuccess&quot;) @ResponseBody public String logoutSuccess()&#123; return &quot;loginSuccess&quot;; &#125;&#125; 源码地址https://github.com/liushprofessor/cas_demo]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS教程2-自定义登录]]></title>
    <url>%2F2020%2F01%2F20%2FCAS-%E8%87%AA%E5%AE%9A%E4%B9%89%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"><![CDATA[简介CAS提供了单点登录服务功能，但是默认只使用账号密码登录，在现实项目中往往需要添加各种验证因子比如短信和验证码等，通过对源码的跟踪和分析这边简介一下CAS登录验证逻辑的大致流程和如何定制登录代码. 前置学习条件CAS 是使用 Spring Web Flow 和 Thymeleaf来实现登录页面的 Thymeleaf 是一个模板渲染引擎，这部分和jsp有一点点类似，只要接触过 MVC 架构这一块就没有太大问题，在跟踪代码问题中主要问题在 Spring Web Flow 需要对Spring Web Flow的基础概念有一定的了解才能大致了解源码的运行流畅和自定义登录代码，Spring Web Flow的基础概念，只要了解了基础概念定制 CAS 的登录就不会有太大问题：一下是之前写的关于 Spring Web Flow 的基础概念的文档https://liushaohuang.cn/2020/01/17/Spring-Web-flow-%E6%A6%82%E5%BF%B5%E7%AE%80%E4%BB%8B/ 找到入口Flow 入口 我使用CAS 官方提供的 overlays 项目来构建 CAS Servicehttps://github.com/apereo/cas-overlay-template/tree/5.3 在代码编译起来后在 overlays/org.apereo.cas.cas-server-webapp-tomcat-5.3.1/WEB-INF/webflow/login/ 目录下我们可以找到login-webflow.xml 这个文件就是配置登录的 Flow的地方 login-webflow.xml的初始代码如下:这里我们可以看见这里定义了一个flow 里面包含两个 action-state 和 一个 view-state 他们之间根据Flow执行的状态相互跳转 initializeLoginForm : 进入这个 state 后会调用一个注入到Spring容器中的 initializeLoginAction 对象如果它返回的Event是 success的话就跳转到 viewLoginForm state viewLoginForm : 进入这个 state 后会自动跳转到 WEB-INF/templates 目录下的 casLoginView 这个页面，这里我们可以看到这个页面还绑定了一个credential 对象，字段名分别为username，password，具体在哪里绑定的看到这里我们还不懂，这部分后面再看，然后还有一个submit的事件，触发后跳转到 realSubmit state realSubmit : 这部分和 initializeLoginForm 没有太大区别，就是进入这个state后调用 authenticationViaFormAction 然后根据返回值跳转到不同的地方，但是跳转的除了 initializeLoginForm，其它的跳转在xml中一概没有标识看，这部分我们后面再看。 1234567891011121314151617181920212223242526272829&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;flow xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://www.springframework.org/schema/webflow&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/webflow http://www.springframework.org/schema/webflow/spring-webflow.xsd&quot;&gt; &lt;action-state id=&quot;initializeLoginForm&quot;&gt; &lt;evaluate expression=&quot;initializeLoginAction&quot; /&gt; &lt;transition on=&quot;success&quot; to=&quot;viewLoginForm&quot;/&gt; &lt;/action-state&gt; &lt;view-state id=&quot;viewLoginForm&quot; view=&quot;casLoginView&quot; model=&quot;credential&quot;&gt; &lt;binder&gt; &lt;binding property=&quot;username&quot; required=&quot;true&quot;/&gt; &lt;binding property=&quot;password&quot; required=&quot;true&quot;/&gt; &lt;/binder&gt; &lt;transition on=&quot;submit&quot; bind=&quot;true&quot; validate=&quot;true&quot; to=&quot;realSubmit&quot; history=&quot;invalidate&quot;/&gt; &lt;/view-state&gt; &lt;action-state id=&quot;realSubmit&quot;&gt; &lt;evaluate expression=&quot;authenticationViaFormAction&quot;/&gt; &lt;transition on=&quot;warn&quot; to=&quot;warn&quot;/&gt; &lt;transition on=&quot;success&quot; to=&quot;createTicketGrantingTicket&quot;/&gt; &lt;transition on=&quot;successWithWarnings&quot; to=&quot;showAuthenticationWarningMessages&quot;/&gt; &lt;transition on=&quot;authenticationFailure&quot; to=&quot;handleAuthenticationFailure&quot;/&gt; &lt;transition on=&quot;error&quot; to=&quot;initializeLoginForm&quot;/&gt; &lt;/action-state&gt;&lt;/flow&gt; CAS M和V的绑定CAS 使用 Spring Web Flow 完成 MVC 的 M 和 V 的绑定我们首先在官网上找到如何配置自定义的Flow的方法 https://apereo.github.io/cas/5.3.x/installation/Webflow-Customization-Extensions.html 我们通过在网上找到的其它文档发现 CAS 实现登录逻辑是在 DefaultLoginWebflowConfigurer类下，部分源码如下,我们根据方法名可以看到其在初始化时,好像配置了一系列的东西，比如createDefaultActionStates 方法，我们可以猜想到其又在 xml 的基础上用java代码的方式创建了很多 action state，这就解释了为什么上一步中我们在 realSubmit 下配置的跳转信息在xml中没有 123456789101112131415161718public class DefaultLoginWebflowConfigurer extends AbstractCasWebflowConfigurer &#123; protected void doInitialize() &#123; Flow flow = this.getLoginFlow(); if (flow != null) &#123; this.createInitialFlowActions(flow); this.createDefaultGlobalExceptionHandlers(flow); this.createDefaultEndStates(flow); this.createDefaultDecisionStates(flow); this.createDefaultActionStates(flow); this.createDefaultViewStates(flow); this.createRememberMeAuthnWebflowConfig(flow); this.setStartState(flow, &quot;initialAuthenticationRequestValidationCheck&quot;); &#125; &#125; &#125; 我们这里先不管具体的逻辑，我们主要找到入口，在源码中全局搜索 DefaultLoginWebflowConfigurer 我们会找到一个 CasWebflowContextConfiguration的配置类,部分源码如下，我只复制了我感兴趣的代码 123456789101112131415161718192021222324252627282930313233343536373839404142@Configuration(&quot;casWebflowContextConfiguration&quot;)@EnableConfigurationProperties(CasConfigurationProperties.class)@Slf4jpublic class CasWebflowContextConfiguration &#123; @Bean public FlowDefinitionRegistry loginFlowRegistry() &#123; final FlowDefinitionRegistryBuilder builder = new FlowDefinitionRegistryBuilder(this.applicationContext, builder()); builder.setBasePath(BASE_CLASSPATH_WEBFLOW); builder.addFlowLocationPattern(&quot;/login/*-webflow.xml&quot;); return builder.build(); &#125; @ConditionalOnMissingBean(name = &quot;defaultWebflowConfigurer&quot;) @Bean @Order(0) @RefreshScope public CasWebflowConfigurer defaultWebflowConfigurer() &#123; final DefaultLoginWebflowConfigurer c = new DefaultLoginWebflowConfigurer(builder(), loginFlowRegistry(), applicationContext, casProperties); c.setLogoutFlowDefinitionRegistry(logoutFlowRegistry()); c.setOrder(Ordered.HIGHEST_PRECEDENCE); return c; &#125; @ConditionalOnMissingBean(name = &quot;casDefaultWebflowExecutionPlanConfigurer&quot;) @Bean public CasWebflowExecutionPlanConfigurer casDefaultWebflowExecutionPlanConfigurer() &#123; return new CasWebflowExecutionPlanConfigurer() &#123; @Override public void configureWebflowExecutionPlan(final CasWebflowExecutionPlan plan) &#123; plan.registerWebflowConfigurer(defaultWebflowConfigurer()); plan.registerWebflowConfigurer(defaultLogoutWebflowConfigurer()); plan.registerWebflowConfigurer(groovyWebflowConfigurer()); &#125; &#125;; &#125;&#125; loginFlowRegistry() 之前关于 Spring Web Flow 的文章中提过 Flow 是通过Registry去管理的，CAS 对 Spring Web Flow进行了二次封装，这里在 Spring 中注册了Registry，并且将 /login 下的xml注册到 Registry中，进入 builder.build() 方法 12345678public FlowDefinitionRegistry build() &#123; DefaultFlowRegistry flowRegistry = new DefaultFlowRegistry(); flowRegistry.setParent(this.parent); this.registerFlowLocations(flowRegistry); this.registerFlowLocationPatterns(flowRegistry); this.registerFlowBuilders(flowRegistry); return flowRegistry; &#125; 我们再进入this.registerFlowLocations(flowRegistry); 这里注意一点this.flowResourceFactory.createResource(path, attributes, id); 方法将flow 的xml的路径当做id保存在 FlowDefinitionResource中（如 WEB-INF/webflow/login/login-webflow.xml 的id为login），这个id将会被当做 Flow 的id在 flowRegistry中注册 1234567891011121314private void registerFlowLocations(DefaultFlowRegistry flowRegistry) &#123; Iterator var2 = this.flowLocations.iterator(); while(var2.hasNext()) &#123; FlowDefinitionRegistryBuilder.FlowLocation location = (FlowDefinitionRegistryBuilder.FlowLocation)var2.next(); String path = location.getPath(); String id = location.getId(); AttributeMap&lt;Object&gt; attributes = location.getAttributes(); this.updateFlowAttributes(attributes); FlowDefinitionResource resource = this.flowResourceFactory.createResource(path, attributes, id); this.registerFlow(resource, flowRegistry); &#125; &#125; 我们发现 this.registerFlow(resource, flowRegistry); 很有可能是注册逻辑的代码，进入查看,发现 flowRegistry.getFlowModelRegistry().registerFlowModel(resource.getId(), flowModelHolder);这一行代码中将resource的id当做flow的id在flowRegistry中注册，至此我们在overlays下定义的 login-webflow.xml 就已经完成注册 123456789101112131415private void registerFlow(FlowDefinitionResource resource, DefaultFlowRegistry flowRegistry) &#123; if (resource.getPath().getFilename().endsWith(&quot;.xml&quot;)) &#123; FlowModelBuilder flowModelBuilder = new XmlFlowModelBuilder(resource.getPath(), flowRegistry.getFlowModelRegistry()); DefaultFlowModelHolder flowModelHolder = new DefaultFlowModelHolder(flowModelBuilder); FlowModelFlowBuilder flowBuilder = new FlowModelFlowBuilder(flowModelHolder); FlowBuilderContextImpl builderContext = new FlowBuilderContextImpl(resource.getId(), resource.getAttributes(), flowRegistry, this.flowBuilderServices); FlowAssembler assembler = new FlowAssembler(flowBuilder, builderContext); DefaultFlowHolder flowHolder = new DefaultFlowHolder(assembler); flowRegistry.getFlowModelRegistry().registerFlowModel(resource.getId(), flowModelHolder); flowRegistry.registerFlowDefinition(flowHolder); &#125; else &#123; throw new IllegalArgumentException(resource + &quot; is not a supported resource type; supported types are [.xml]&quot;); &#125; &#125; defaultWebflowConfigurer() 这个方法是对之前我们在 xml 中编写的 login-webflow.xml flow做扩展，上面有一个注解@ConditionalOnMissingBean(name = “defaultWebflowConfigurer”) 代表代码执行到这里时，Spring 容器你没有 defaultWebflowConfigurer 对象的话才进行装配，而@Order(0)注解又指定了这个类装配的优先级，那么我们到这里就有思路了要实现登录的主要逻辑，我们可以在这个类进行装配前，自己实现一个defaultWebflowConfigurer，里面包含我们自己的登录逻辑,我们进入 DefaultLoginWebflowConfigurer 查看一下具体的逻辑 123456789101112131415161718 public class DefaultLoginWebflowConfigurer extends AbstractCasWebflowConfigurer &#123; protected void doInitialize() &#123; Flow flow = this.getLoginFlow(); if (flow != null) &#123; this.createInitialFlowActions(flow); this.createDefaultGlobalExceptionHandlers(flow); this.createDefaultEndStates(flow); this.createDefaultDecisionStates(flow); this.createDefaultActionStates(flow); this.createDefaultViewStates(flow); this.createRememberMeAuthnWebflowConfig(flow); this.setStartState(flow, &quot;initialAuthenticationRequestValidationCheck&quot;); &#125; &#125;&#125; this.getLoginFlow(); 方法是从我们上一步FlowRegistry中注册的 login-webflow.xml 中取出 Flow,然后之后对这个 Flow 用代码调用API的方式手动增加了许多 state，这里就解释了我们最早看到的 login-webflow.xml 中很多跳转并没有配置 state，原因就在这里，那些跳转的 state 全部都在这里完成写入，我们重点注意一下 this.createRememberMeAuthnWebflowConfig(flow); 和 this.setStartState(flow, “initialAuthenticationRequestValidationCheck”);方法 this.createRememberMeAuthnWebflowConfig(flow); 我们重点看下 else 中的逻辑，这里在 flow 中创建了一个 credential 变量并和 UsernamePasswordCredential.class 对象做绑定，我们可以重新查看一下 login-webflow.xml ，发现 viewLoginForm 标签中有一个 modal 参数就是和 credential做绑定的，这里和UsernamePasswordCredential.class对象做了绑定，而 UsernamePasswordCredential 又是实现了 Credential 接口，那么这里思路就很明确了，我们 继承 DefaultLoginWebflowConfigurer 重写 createRememberMeAuthnWebflowConfig 方法将我们自定义的 Credential对象和 login-webflow.xml 中的 credential 做绑定 ，这样我们就完成了 MVC 中的 M 和 V 的绑定 1234567891011protected void createRememberMeAuthnWebflowConfig(Flow flow) &#123; if (this.casProperties.getTicket().getTgt().getRememberMe().isEnabled()) &#123; this.createFlowVariable(flow, &quot;credential&quot;, RememberMeUsernamePasswordCredential.class); ViewState state = (ViewState)this.getState(flow, &quot;viewLoginForm&quot;, ViewState.class); BinderConfiguration cfg = this.getViewStateBinderConfiguration(state); cfg.addBinding(new Binding(&quot;rememberMe&quot;, (String)null, false)); &#125; else &#123; this.createFlowVariable(flow, &quot;credential&quot;, UsernamePasswordCredential.class); &#125; &#125; this.setStartState(flow, “initialAuthenticationRequestValidationCheck”) 这个方法给 login Flow 设置了一个 on-start 标签。之前我手动尝试在 login-webflow.xml 中配置一个 on-start 标签，但是发现无论怎么也无法执行，后来查看源码发现这里重新设置了 on-start 标签的内容，这里关联到 initialAuthenticationRequestValidationCheck 标签，initialAuthenticationRequestValidationCheck标签是前面 this.createDefaultActionStates(flow); 中创建的，如果有兴趣可以根据代码中的每一个Action 会发现最后其会关联到我们在 login-webflow.xml 中定义的initializeLoginForm 标签，官网文档中有提到，不要轻易手动修改 login-webflow.xml 中的标签，除非你知道他干什么，看到这里就已经基本明白了，xml定义的标签都是会和这里新增的 state 做关联的。 自定义 CAS M和V的绑定 自定义Credential 根据上一节的思路，我们自定义绑定 M 和 V,首先我们要实现一个 Credential 对象，这个对象是用来 M 和 V 做绑定的参数，类似我们 Spring MVC Controller 层的参数,我们这里选择直接继承 UsernamePasswordCredential，因为 UsernamePasswordCredential 实现了 Credential我们在其中扩展了一个code字段.注意必须添加一个空的构造，不然绑定会发生错误 12345678910111213141516171819202122public class MyUsernamePasswordCredential extends UsernamePasswordCredential &#123; public MyUsernamePasswordCredential(String username, String password, String code) &#123; super(username, password); this.code = code; &#125; //必须添加空参构造，不然Web Flow无法注入 public MyUsernamePasswordCredential() &#123; &#125; private String code; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125;&#125; 自定义 CasWebflowConfigurer 我们这里直接继承 DefaultLoginWebflowConfigurer 重写 createRememberMeAuthnWebflowConfig 方法即可,我们将credential变量绑定给了我们自定义的 MyUsernamePasswordCredential 对象 123456789101112131415161718 public class MyLoginWebflowConfiger extends DefaultLoginWebflowConfigurer &#123; public MyLoginWebflowConfiger(FlowBuilderServices flowBuilderServices, FlowDefinitionRegistry flowDefinitionRegistry, ApplicationContext applicationContext, CasConfigurationProperties casProperties) &#123; super(flowBuilderServices, flowDefinitionRegistry, applicationContext, casProperties); &#125; @Override protected void createRememberMeAuthnWebflowConfig(Flow flow)&#123; if (this.casProperties.getTicket().getTgt().getRememberMe().isEnabled()) &#123; this.createFlowVariable(flow, &quot;credential&quot;, RememberMeUsernamePasswordCredential.class); ViewState state = (ViewState)this.getState(flow, &quot;viewLoginForm&quot;, ViewState.class); BinderConfiguration cfg = this.getViewStateBinderConfiguration(state); cfg.addBinding(new BinderConfiguration.Binding(&quot;rememberMe&quot;, (String)null, false)); &#125; else &#123; this.createFlowVariable(flow, &quot;credential&quot;, MyUsernamePasswordCredential.class); &#125; &#125;&#125; 注册自定义 CasWebflowConfigurer 我们模仿CasWebflowContextConfiguration 将我们自定义的 MyLoginWebflowConfiger注入到Spring中,注意一下我们使用@Order(-1)注解来标识我们的defaultWebflowConfigurer() 对象 在默认 的 defaultWebflowConfigurer() 对象之前注入到 Spring 中 12345678910111213141516171819202122232425262728293031@EnableConfigurationProperties(&#123;CasConfigurationProperties.class&#125;)public class CASWebFlowConfig implements CasWebflowExecutionPlanConfigurer&#123; @Autowired private FlowBuilderServices flowBuilderServices; @Autowired @Qualifier(&quot;loginFlowRegistry&quot;) private FlowDefinitionRegistry loginFlowRegistry; @Autowired @Qualifier(&quot;logoutFlowRegistry&quot;) FlowDefinitionRegistry logoutFlowRegistry; @Autowired private ApplicationContext applicationContext; @Autowired private CasConfigurationProperties casProperties; @Autowired private ServicesManager servicesManager; @Bean @Order(-1) public CasWebflowConfigurer defaultWebflowConfigurer() &#123; MyLoginWebflowConfiger c = new MyLoginWebflowConfiger(flowBuilderServices,loginFlowRegistry , this.applicationContext, this.casProperties); c.setLogoutFlowDefinitionRegistry(logoutFlowRegistry); return c; &#125;&#125; 接下来是编写配置文件，使用Spring 的SPI机制将 CASWebFlowConfig注入到Spring中，因为我们编写的类并没有在 CAS工程的 Spring 的扫描路径下，所以我们使用 Spring 的 SPI 机制 来配置，在 resources 下新建 META-INF 文件夹,新建文件 spring.factories,配置注册的类全路径，将我们刚才编写的注册类 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.sunnada.cas.Config,com.sunnada.cas.CASWebFlowConfig 自定义View在定制界面和webflow时候，我们需要将我们重写的资源放到我们自定义的maven resources 对应的目录下(比如我们需要重写webflow/login/login-webflow.xml 那我们就要在我们的 resources 目录下新建webflow/login/login-webflow.xml，然后再修改自己的文件内容)，然后再maven中排除overlays中的文件,详细配置请看注意一节 CAS 是用 Thymeleaf 模板来实现页面渲染的，我们在 login-webflow.xml 中找到 viewLoginForm 标签发现其重定向到 casLoginView 页面,我们在 bind下新增 code 属性 这边绑定的model credential 已经在我们上面改成了 MyUsernamePasswordCredential 对象，里面有个 code 字段 12345678&lt;view-state id=&quot;viewLoginForm&quot; view=&quot;casLoginView&quot; model=&quot;credential&quot;&gt; &lt;binder&gt; &lt;binding property=&quot;username&quot; required=&quot;true&quot;/&gt; &lt;binding property=&quot;password&quot; required=&quot;true&quot;/&gt; &lt;binding property=&quot;code&quot; required=&quot;true&quot;/&gt; &lt;/binder&gt; &lt;transition on=&quot;submit&quot; bind=&quot;true&quot; validate=&quot;true&quot; to=&quot;realSubmit&quot; history=&quot;invalidate&quot;/&gt; &lt;/view-state&gt; 我们在 resources/templates 目录下找到 casLoginView.html,这是一个普通的 Thymeleaf 模板 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!DOCTYPE html&gt;&lt;html xmlns:layout=&quot;http://www.ultraq.net.nz/thymeleaf/layout&quot; layout:decorate=&quot;~&#123;layout&#125;&quot;&gt;&lt;head&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;/&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;/&gt; &lt;title th:text=&quot;#&#123;cas.login.pagetitle&#125;&quot;&gt;CAS Acceptable Use Policy View&lt;/title&gt; &lt;link href=&quot;../../static/css/cas.css&quot; rel=&quot;stylesheet&quot; th:remove=&quot;tag&quot; /&gt;&lt;/head&gt;&lt;body class=&quot;login&quot;&gt;&lt;main role=&quot;main&quot; class=&quot;container mt-3 mb-3&quot;&gt; &lt;div layout:fragment=&quot;content&quot; class=&quot;row&quot;&gt; &lt;div class=&quot;col-md&quot;&gt; &lt;!-- 表单部分代码 --&gt; &lt;div th:replace=&quot;fragments/loginform :: loginform&quot;&gt;&lt;a href=&quot;fragments/loginform.html&quot;&gt;Login Form goes here&lt;/a&gt;&lt;/div&gt; &lt;/div&gt; &lt;div id=&quot;notices&quot; class=&quot;col-md mt-3 mt-md-0&quot;&gt; &lt;div th:replace=&quot;fragments/insecure :: insecure&quot;&gt;&lt;a href=&quot;fragments/insecure.html&quot;&gt;insecure alert goes here&lt;/a&gt;&lt;/div&gt; &lt;div th:replace=&quot;fragments/defaultauthn :: staticAuthentication&quot;&gt; &lt;a href=&quot;fragments/defaultauthn.html&quot;&gt;defaultAuthn&lt;/a&gt; fragment &lt;/div&gt; &lt;div th:replace=&quot;fragments/cookies :: cookiesDisabled&quot;&gt;&lt;a href=&quot;fragments/cookies.html&quot;&gt;cookies&lt;/a&gt; fragment &lt;/div&gt; &lt;div th:replace=&quot;fragments/serviceui :: serviceUI&quot;&gt;&lt;a href=&quot;fragments/serviceui.html&quot;&gt;service ui&lt;/a&gt; fragment&lt;/div&gt; &lt;div th:replace=&quot;fragments/loginProviders :: loginProviders&quot;&gt;&lt;a href=&quot;fragments/loginProviders.html&quot;&gt;loginProviders&lt;/a&gt; fragment &lt;/div&gt; &lt;div th:replace=&quot;fragments/cas-resources-list :: cas-resource-list&quot;&gt; &lt;a href=&quot;fragments/cas-resources-list.html&quot;&gt;cas-resource&lt;/a&gt; list fragment &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/main&gt;&lt;/body&gt;&lt;/html&gt; 代码中得知，表单部分在在 fragments/loginform目录下，我们查看那部分代码，并在下面添加一个input框 其name属性为code 用于绑定我们自定义的 MyUsernamePasswordCredential 对象,添加部分已经注释出来 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;/&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;/&gt; &lt;title&gt;Login Form Fragment&lt;/title&gt; &lt;link href=&quot;../../static/css/cas.css&quot; rel=&quot;stylesheet&quot; th:remove=&quot;tag&quot; /&gt;&lt;/head&gt;&lt;body&gt;&lt;main role=&quot;main&quot; class=&quot;container mt-3 mb-3&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md&quot;&gt; &lt;!-- Login form template begins here --&gt; &lt;div th:fragment=&quot;loginform&quot; class=&quot;card&quot;&gt; &lt;div class=&quot;card-header text-center&quot;&gt; &lt;h2 th:text=&quot;#&#123;cas.login.pagetitle&#125;&quot;&gt;Login&lt;/h2&gt; &lt;span class=&quot;fa-stack fa-2x hidden-xs&quot;&gt; &lt;i class=&quot;fa fa-circle fa-stack-2x&quot;&gt;&lt;/i&gt; &lt;i class=&quot;fa fa-lock fa-stack-1x fa-inverse&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;/div&gt; &lt;div class=&quot;card-body&quot;&gt; &lt;form method=&quot;post&quot; id=&quot;fm1&quot; th:object=&quot;$&#123;credential&#125;&quot; action=&quot;login&quot;&gt; &lt;div class=&quot;alert alert-danger&quot; th:if=&quot;$&#123;#fields.hasErrors(&apos;*&apos;)&#125;&quot;&gt; &lt;span th:each=&quot;err : $&#123;#fields.errors(&apos;*&apos;)&#125;&quot; th:utext=&quot;$&#123;err&#125;&quot;&gt;Example error&lt;/span&gt; &lt;/div&gt; &lt;h3 th:utext=&quot;#&#123;screen.welcome.instructions&#125;&quot;&gt;Enter your Username and Password&lt;/h3&gt; &lt;section class=&quot;form-group&quot;&gt; &lt;label for=&quot;username&quot; th:utext=&quot;#&#123;screen.welcome.label.netid&#125;&quot;&gt;Username&lt;/label&gt; &lt;div th:if=&quot;$&#123;openIdLocalId&#125;&quot;&gt; &lt;strong&gt; &lt;span th:utext=&quot;$&#123;openIdLocalId&#125;&quot;/&gt; &lt;/strong&gt; &lt;input type=&quot;hidden&quot; id=&quot;username&quot; name=&quot;username&quot; th:value=&quot;$&#123;openIdLocalId&#125;&quot;/&gt; &lt;/div&gt; &lt;div th:unless=&quot;$&#123;openIdLocalId&#125;&quot;&gt; &lt;input class=&quot;form-control required&quot; id=&quot;username&quot; size=&quot;25&quot; tabindex=&quot;1&quot; type=&quot;text&quot; th:disabled=&quot;$&#123;guaEnabled&#125;&quot; th:field=&quot;*&#123;username&#125;&quot; th:accesskey=&quot;#&#123;screen.welcome.label.netid.accesskey&#125;&quot; autocomplete=&quot;off&quot;/&gt; &lt;/div&gt; &lt;/section&gt; &lt;section class=&quot;form-group&quot;&gt; &lt;label for=&quot;password&quot; th:utext=&quot;#&#123;screen.welcome.label.password&#125;&quot;&gt;Password&lt;/label&gt; &lt;div&gt; &lt;input class=&quot;form-control required&quot; type=&quot;password&quot; id=&quot;password&quot; size=&quot;25&quot; tabindex=&quot;2&quot; th:accesskey=&quot;#&#123;screen.welcome.label.password.accesskey&#125;&quot; th:field=&quot;*&#123;password&#125;&quot; autocomplete=&quot;off&quot;/&gt; &lt;span id=&quot;capslock-on&quot; style=&quot;display:none;&quot;&gt; &lt;p&gt; &lt;i class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/i&gt; &lt;span th:utext=&quot;#&#123;screen.capslock.on&#125;&quot;/&gt; &lt;/p&gt; &lt;/span&gt; &lt;/div&gt; &lt;/section&gt; &lt;!-- 新增code 表单代码 --&gt; &lt;section class=&quot;form-group&quot;&gt; &lt;label for=&quot;code&quot;&gt;code...&lt;/label&gt; &lt;div&gt; &lt;input class=&quot;form-control required&quot; type=&quot;text&quot; id=&quot;code&quot; size=&quot;25&quot; name=&quot;code&quot; tabindex=&quot;2&quot; th:accesskey=&quot;#&#123;screen.welcome.label.password.accesskey&#125;&quot; autocomplete=&quot;off&quot;/&gt; &lt;span id=&quot;capslock-on&quot; style=&quot;display:none;&quot;&gt; &lt;p&gt; &lt;i class=&quot;fa fa-exclamation-circle&quot;&gt;&lt;/i&gt; &lt;span th:utext=&quot;#&#123;screen.capslock.on&#125;&quot;/&gt; &lt;/p&gt; &lt;/span&gt; &lt;/div&gt; &lt;/section&gt; &lt;section class=&quot;form-check&quot; th:if=&quot;$&#123;passwordManagementEnabled &amp;&amp; param.doChangePassword != null&#125;&quot;&gt; &lt;p&gt; &lt;input type=&quot;checkbox&quot; name=&quot;doChangePassword&quot; id=&quot;doChangePassword&quot; value=&quot;true&quot; th:checked=&quot;$&#123;param.doChangePassword != null&#125;&quot; tabindex=&quot;4&quot;/&gt; &lt;label for=&quot;doChangePassword&quot; th:text=&quot;#&#123;screen.button.changePassword&#125;&quot;&gt;Change Password&lt;/label&gt; &lt;/p&gt; &lt;/section&gt; &lt;section class=&quot;form-check&quot; th:if=&quot;$&#123;rememberMeAuthenticationEnabled&#125;&quot;&gt; &lt;p&gt; &lt;input type=&quot;checkbox&quot; name=&quot;rememberMe&quot; id=&quot;rememberMe&quot; value=&quot;true&quot; tabindex=&quot;5&quot;/&gt; &lt;label for=&quot;rememberMe&quot; th:text=&quot;#&#123;screen.rememberme.checkbox.title&#125;&quot;&gt;Remember Me&lt;/label&gt; &lt;/p&gt; &lt;/section&gt; &lt;section class=&quot;row&quot; th:if=&quot;$&#123;recaptchaSiteKey != null AND recaptchaInvisible != null AND recaptchaSiteKey AND !recaptchaInvisible&#125;&quot;&gt; &lt;div class=&quot;g-recaptcha&quot; th:attr=&quot;data-sitekey=$&#123;recaptchaSiteKey&#125;&quot;/&gt; &lt;/section&gt; &lt;input type=&quot;hidden&quot; name=&quot;execution&quot; th:value=&quot;$&#123;flowExecutionKey&#125;&quot;/&gt; &lt;input type=&quot;hidden&quot; name=&quot;_eventId&quot; value=&quot;submit&quot;/&gt; &lt;input type=&quot;hidden&quot; name=&quot;geolocation&quot;/&gt; &lt;input class=&quot;btn btn-block btn-submit&quot; th:unless=&quot;$&#123;recaptchaSiteKey != null AND recaptchaInvisible != null AND recaptchaSiteKey AND recaptchaInvisible&#125;&quot; name=&quot;submit&quot; accesskey=&quot;l&quot; th:value=&quot;#&#123;screen.welcome.button.login&#125;&quot; tabindex=&quot;6&quot; type=&quot;submit&quot; value=&quot;Login3&quot; /&gt; &lt;button class=&quot;btn btn-block btn-submit g-recaptcha&quot; th:if=&quot;$&#123;recaptchaSiteKey != null AND recaptchaInvisible != null AND recaptchaSiteKey AND recaptchaInvisible&#125;&quot; th:attr=&quot;data-sitekey=$&#123;recaptchaSiteKey&#125;, data-badge=$&#123;recaptchaPosition&#125;&quot; data-callback=&quot;onSubmit&quot; name=&quot;submitBtn&quot; accesskey=&quot;l&quot; th:text=&quot;#&#123;screen.welcome.button.login&#125;&quot; tabindex=&quot;6&quot; /&gt; &lt;/form&gt; &lt;form th:if=&quot;$&#123;passwordManagementEnabled&#125;&quot; method=&quot;post&quot; id=&quot;passwordManagementForm&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;execution&quot; th:value=&quot;$&#123;flowExecutionKey&#125;&quot;/&gt; &lt;input type=&quot;hidden&quot; name=&quot;_eventId&quot; value=&quot;resetPassword&quot;/&gt; &lt;span class=&quot;fa fa-unlock&quot;&gt;&lt;/span&gt; &lt;a th:utext=&quot;#&#123;screen.pm.button.resetPassword&#125;&quot; href=&quot;javascript:void(0)&quot; onclick=&quot;$(&apos;#passwordManagementForm&apos;).submit();&quot;/&gt; &lt;p/&gt; &lt;/form&gt; &lt;div th:unless=&quot;$&#123;passwordManagementEnabled&#125;&quot;&gt; &lt;span class=&quot;fa fa-question-circle&quot;&gt;&lt;/span&gt; &lt;span th:utext=&quot;#&#123;screen.pm.button.forgotpwd&#125;&quot;&gt;Forgot your password?&lt;/span&gt; &lt;p/&gt; &lt;/div&gt; &lt;script type=&quot;text/javascript&quot; th:inline=&quot;javascript&quot;&gt; var i = [[#&#123;screen.welcome.button.loginwip&#125;]] $( document ).ready(function() &#123; $(&quot;#fm1&quot;).submit(function () &#123; $(&quot;:submit&quot;).attr(&quot;disabled&quot;, true); $(&quot;:submit&quot;).attr(&quot;value&quot;, i); console.log(i); return true; &#125;); &#125;); &lt;/script&gt; &lt;div th:replace=&quot;fragments/loginsidebar :: loginsidebar&quot; /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/main&gt;&lt;/body&gt;&lt;/html&gt; 现在我们运行CAS Service 进入登录页已经可以看见页面增加了一个code 字段，我们也完成了M和V的绑定，前端的表单对象会绑定我们后端配置的MyUsernamePasswordCredential 对象,后续我们要做的就是完成自定义认证 自定义认证以上部分我们只是完成了 M 和 V的绑定，现在我们实现自定义认证，这边我采用 mybatis 来当做持久层来从数据库中查询数据 mybtais配置由于刚开始实践时我直接继承 mybatis-stater 来完成mybatis，但是发现无论怎么尝试，CAS 都无法完成对 Mybtais-stater中的配置文件完成自动配置，于是我采用手动配置的方法完成mybatis的集成 POM文件配置加上 mybatis-spring 和 mybatis的包 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; 配置mybatis数据源mybatis 的核心是SqlSessionFactory 类而其有依赖DataSource 类所以我们进行如下配置即可，如果需要使用连接池，修改DataSource中的配置即可，现在我们就可以正常使用 mybatis 的功能了 12345678910111213141516171819202122232425262728293031public class DataSourceConfig &#123; //配置数据源 @Bean public DataSource dataSource()&#123; DriverManagerDataSource dataSource= new DriverManagerDataSource(&quot;jdbc:mysql://192.168.169.94:3306/mysql?serverTimezone=CTT&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true&amp;useSSL=false&quot;,&quot;root&quot;,&quot;root&quot;); dataSource.setDriverClassName(&quot;com.mysql.cj.jdbc.Driver&quot;); return dataSource; &#125; //配置 mybatis自动扫描 Mapper @Bean public MapperScannerConfigurer mapperScannerConfigurer()&#123; MapperScannerConfigurer mapperScannerConfigurer=new MapperScannerConfigurer(); mapperScannerConfigurer.setSqlSessionFactoryBeanName(&quot;sqlSessionFactory&quot;); mapperScannerConfigurer.setBasePackage(&quot;com.sunnada&quot;); return mapperScannerConfigurer; &#125; @Bean public SqlSessionFactory sqlSessionFactory() throws Exception &#123; SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); factoryBean.setMapperLocations(); factoryBean.setDataSource(dataSource()); ResourcePatternResolver resourcePatternResolver=new PathMatchingResourcePatternResolver(); //配置扫描对应路径的xml resourcePatternResolver.getResources(&quot;classpath*:mapper/*.xml&quot;); factoryBean.setMapperLocations(resourcePatternResolver.getResources(&quot;classpath*:mapper/*.xml&quot;)); return factoryBean.getObject(); &#125;&#125; 自定义 CAS 认证CAS 认证扩展类为 AuthenticationHandler 我们实现其抽象类 AbstractPreAndPostProcessingAuthenticationHandler即可 12345678910111213141516171819202122232425262728293031323334353637383940public class CustomUsernamePasswordAuthentication extends AbstractPreAndPostProcessingAuthenticationHandler &#123; private UserMapper userMapper; //UserMapper 为mybatis的 mapper 接口，在构造方法中手动赋值 public CustomUsernamePasswordAuthentication(String name, ServicesManager servicesManager, PrincipalFactory principalFactory, Integer order,UserMapper userMapper) &#123; super(name, servicesManager, principalFactory, order); this.userMapper=userMapper; &#125; //设置只支持验证 MyUsernamePasswordCredential 类型的 Credential @Override public boolean supports(Credential credential)&#123; return credential instanceof MyUsernamePasswordCredential ; &#125; @Override protected AuthenticationHandlerExecutionResult doAuthentication(Credential credential) throws GeneralSecurityException, PreventedException &#123; MyUsernamePasswordCredential myUsernamePasswordCredential=(MyUsernamePasswordCredential)credential; //如果从数据库中根据用户和密码查出的用户id不为空则用户存在 String userId=userMapper.findUserName(myUsernamePasswordCredential.getUsername() ,myUsernamePasswordCredential.getPassword()); //验证code时候正确 if(userId!= null &amp;&amp; &quot;code&quot;.equals(((MyUsernamePasswordCredential) credential).getCode()) )&#123; List&lt;MessageDescriptor&gt; list = new ArrayList&lt;&gt;(); return createHandlerResult(credential,this.principalFactory.createPrincipal(credential.getId()),list); &#125; //登录失败抛出异常 throw new FailedLoginException(&quot;登录失败 &quot;); &#125;&#125; 在CAS 中注册 AuthenticationHandler 1234567891011121314151617181920212223public class Config implements AuthenticationEventExecutionPlanConfigurer &#123; @Autowired @Qualifier(&quot;servicesManager&quot;) private ServicesManager servicesManager; @Autowired private UserMapper userMapper; //AuthenticationHandler依赖 &quot;dataSource&quot;,&quot;mapperScannerConfigurer&quot;,&quot;sqlSessionFactory&quot; 这三个bean @Bean @DependsOn(&#123;&quot;dataSource&quot;,&quot;mapperScannerConfigurer&quot;,&quot;sqlSessionFactory&quot;&#125;) public AuthenticationHandler authenticationHandler()&#123; return new CustomUsernamePasswordAuthentication(CustomUsernamePasswordAuthentication.class.getName(), servicesManager, new DefaultPrincipalFactory(), 1,userMapper); &#125; @Override public void configureAuthenticationExecutionPlan(AuthenticationEventExecutionPlan plan) &#123; plan.registerAuthenticationHandler(authenticationHandler()); &#125;&#125; 在 spring.factories 文件 中注册你需要在Spring中的配置类 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.sunnada.cas.DataSourceConfig,\com.sunnada.cas.Config,com.sunnada.cas.CASWebFlowConfig 到此为止自定义登录就已经完成 注意点我们在基于CAS overlay做扩展的时候，有一些jar包已经集成在war中，但是我们编写扩展类的时候也需要这部分代码，我们可以将这部分pox文件引入并设置作用域为provided,特别注意在设置 maven-war-plugin 插件时需要将 overlays中重复的配置文件排除出去如本人依赖如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd &quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-overlay&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp$&#123;app.server&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--json服务注册--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-json-service-registry&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-core-authentication&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-core-authentication-api&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter --&gt; &lt;!--引入Spring SPI机制 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-core-configuration&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-rest&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-core-webflow-api&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-core-webflow&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apereo.cas/cas-server-support-actions --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-actions&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.12.6&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.rimerosolutions.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;wrapper-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.0.5&lt;/version&gt; &lt;configuration&gt; &lt;verifyDownload&gt;true&lt;/verifyDownload&gt; &lt;checksumAlgorithm&gt;MD5&lt;/checksumAlgorithm&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;springboot.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;mainClass&gt;$&#123;mainClassName&#125;&lt;/mainClass&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;executable&gt;$&#123;isExecutable&#125;&lt;/executable&gt; &lt;layout&gt;WAR&lt;/layout&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;warName&gt;cas&lt;/warName&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;recompressZippedFiles&gt;false&lt;/recompressZippedFiles&gt; &lt;archive&gt; &lt;compress&gt;false&lt;/compress&gt; &lt;manifestFile&gt;$&#123;manifestFileToUse&#125;&lt;/manifestFile&gt; &lt;/archive&gt; &lt;overlays&gt; &lt;overlay&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp$&#123;app.server&#125;&lt;/artifactId&gt; &lt;!--原有的服务不再初始化进去--&gt; &lt;excludes&gt; &lt;exclude&gt;WEB-INF/classes/services/*&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/application.*&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/log4j2.*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/overlay&gt; &lt;/overlays&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;finalName&gt;cas&lt;/finalName&gt; &lt;/build&gt; &lt;properties&gt; &lt;cas.version&gt;5.3.1&lt;/cas.version&gt; &lt;springboot.version&gt;1.5.18.RELEASE&lt;/springboot.version&gt; &lt;!-- app.server could be -jetty, -undertow, -tomcat, or blank if you plan to provide appserver --&gt; &lt;app.server&gt;-tomcat&lt;/app.server&gt; &lt;mainClassName&gt;org.springframework.boot.loader.WarLauncher&lt;/mainClassName&gt; &lt;isExecutable&gt;false&lt;/isExecutable&gt; &lt;manifestFileToUse&gt;$&#123;project.build.directory&#125;/war/work/org.apereo.cas/cas-server-webapp$&#123;app.server&#125;/META-INF/MANIFEST.MF&lt;/manifestFileToUse&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;sonatype-releases&lt;/id&gt; &lt;url&gt;http://oss.sonatype.org/content/repositories/releases/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-snapshots&lt;/id&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;shibboleth-releases&lt;/id&gt; &lt;url&gt;https://build.shibboleth.net/nexus/content/repositories/releases&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;id&gt;default&lt;/id&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp$&#123;app.server&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- ...Additional dependencies may be placed here... --&gt; &lt;/dependencies&gt; &lt;/profile&gt; &lt;profile&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;id&gt;exec&lt;/id&gt; &lt;properties&gt; &lt;mainClassName&gt;org.apereo.cas.web.CasWebApplication&lt;/mainClassName&gt; &lt;isExecutable&gt;true&lt;/isExecutable&gt; &lt;manifestFileToUse&gt;&lt;/manifestFileToUse&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.soebes.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;echo-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.3.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;echo&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;echos&gt; &lt;echo&gt;Executable profile to make the generated CAS web application executable.&lt;/echo&gt; &lt;/echos&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;profile&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;id&gt;bootiful&lt;/id&gt; &lt;properties&gt; &lt;app.server&gt;-tomcat&lt;/app.server&gt; &lt;isExecutable&gt;false&lt;/isExecutable&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp$&#123;app.server&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt; 排除依赖在定制界面和webflow时候，我们需要将我们重写的资源放到我们自定义的maven resources 对应的目录下(比如我们需要重写webflow/login/login-webflow.xml 那我们就要在我们的 resources 目录下新建webflow/login/login-webflow.xml，然后再修改自己的文件内容)，然后再maven中排除overlays中的文件 1234567891011121314151617181920212223242526272829&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;warName&gt;cas&lt;/warName&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;recompressZippedFiles&gt;false&lt;/recompressZippedFiles&gt; &lt;archive&gt; &lt;compress&gt;false&lt;/compress&gt; &lt;manifestFile&gt;$&#123;manifestFileToUse&#125;&lt;/manifestFile&gt; &lt;/archive&gt; &lt;overlays&gt; &lt;overlay&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp$&#123;app.server&#125;&lt;/artifactId&gt; &lt;!--原有的服务不再初始化进去--&gt; &lt;excludes&gt; &lt;exclude&gt;WEB-INF/classes/services/*&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/application.*&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/log4j2.*&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/webflow/login/*.xml&lt;/exclude&gt; &lt;exclude&gt;WEB-INF/classes/templates/fragments/loginform.html&lt;/exclude&gt; &lt;/excludes&gt; &lt;/overlay&gt; &lt;/overlays&gt; &lt;/configuration&gt; &lt;/plugin&gt;]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Web flow 概念简介]]></title>
    <url>%2F2020%2F01%2F17%2FSpring-Web-flow-%E6%A6%82%E5%BF%B5%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[简介最近在搭建CAS单点登录，CAS中使用了Spring Web Flow来构建MVC 应用，需要对Web Flow的基本概念有一定的了解才能进行CAS登录的改造。 什么是Spring Web FlowFlow字面上的意思为工作流，意思就是将一系列的操作进行编排，使用户较为直观的了解整个业务流程，比如OA系统中的工作流，IT管理人员在OA系统中编辑了一个请假的工作流，那么在员工在OA上提出请假单时，就可以直观的查看请假的流程是什么，现在流程进行到哪一步,Spring Web Flow对Spring MVC进行了再一次封装，使之前在Controller的页面和动作跳转已工作流的这种形式直观的体现出来，可以在xml中配置和查看某个业务具体的流程跳转(Spring Web Flow是基于SpringMVC的基础上开发的，允许web应用对flows实现。一个Flow封装了一些列的操作步骤，引导用户执行某些业务任务。Flows可以包含多个HTTP的请求，她有状态、能处理事务的数据，是可重用的，本质上是可以动态的长时间运行). Spring Web Flow 的基本配置每个Flow可以包含多个如下的配置： Actions: 一个可执行任务和有返回结果的组件 Transitions: 把Flow从一个状态转到另外一个状态；转换可能对整个FLow有全局影响。 Views: 把表示层展现到客户端显示的组件 Decisions: 路由到其他的Flow，可以有逻辑的判定组件 Flow 可看作是客户端与服务器的一次对话（ conversation ）。 Flow 的完成要由分多个步骤来实现，在 Spring Web Flow 的语义中，步骤指的就是 state 。 Spring Web Flow 提供了五种 state ，分别是 Action State 、 View State 、 Subflow State 、 Decision State 、 End State ，这些 state 可用于定义 flow 执行过程中的各个步骤。除了 End State 外，其他 state 都可以转换到别的 state ，一般通过在 state 中定义 transition 来实现到其他 state 的转换，转换的发生一般由事件（ event ）来触发 Spring Web Flow的核心类 FlowRegistry FlowRegistry 是存放 flow 的仓库，每个定义 flow 的 XML 文档被解析后，都会被分配一个唯一的 id ，并以 FlowDefinition 对象的形式存放在 FlowResigtry 中。 FlowExecutor FlowExecutor 是 Spring Web Flow 的一个核心接口，启动某个 flow ，都要通过这个接口来进行 FlowBuilder Services flow-builder-services 属性的配置指明了在这个 flow-registry “仓库”里的 flow 的一些基本特性，例如，是用 Unified EL 还是 OGNL， model （模型）对象中的数据在显示之前是否需要先作转换，等等。比如我们需要在 flow-builder-services 属性中指明 Spring Web Flow 中所用到的 view ，由 Spring Web MVC 的“ View Resolver ”来查找，由 Spring Web MVC 的“ View Class”来解析，最后呈现给客户。 Flow 的xml配置下面是CAS 的login-webflow.xmlw配置文件 12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;flow xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://www.springframework.org/schema/webflow&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/webflow http://www.springframework.org/schema/webflow/spring-webflow.xsd&quot;&gt; &lt;action-state id=&quot;initializeLoginForm&quot;&gt; &lt;evaluate expression=&quot;initializeLoginAction&quot; /&gt; &lt;transition on=&quot;success&quot; to=&quot;viewLoginForm&quot;/&gt; &lt;/action-state&gt; &lt;view-state id=&quot;viewLoginForm&quot; view=&quot;casLoginView&quot; model=&quot;credential&quot;&gt; &lt;binder&gt; &lt;binding property=&quot;username&quot; required=&quot;true&quot;/&gt; &lt;binding property=&quot;password&quot; required=&quot;true&quot;/&gt; &lt;/binder&gt; &lt;transition on=&quot;submit&quot; bind=&quot;true&quot; validate=&quot;true&quot; to=&quot;realSubmit&quot; history=&quot;invalidate&quot;/&gt; &lt;/view-state&gt; &lt;action-state id=&quot;realSubmit&quot;&gt; &lt;evaluate expression=&quot;authenticationViaFormAction&quot;/&gt; &lt;transition on=&quot;warn&quot; to=&quot;warn&quot;/&gt; &lt;transition on=&quot;success&quot; to=&quot;createTicketGrantingTicket&quot;/&gt; &lt;transition on=&quot;successWithWarnings&quot; to=&quot;showAuthenticationWarningMessages&quot;/&gt; &lt;transition on=&quot;authenticationFailure&quot; to=&quot;handleAuthenticationFailure&quot;/&gt; &lt;transition on=&quot;error&quot; to=&quot;initializeLoginForm&quot;/&gt; &lt;/action-state&gt;&lt;/flow&gt; CAS中对Spring Web Flow的代码进行了二次封装，主体的逻辑是在程序开启时将login这个url和上述的web flow做绑定,当访问后缀为login的地址时会自动跳转到这个flow中，将配置的casLoginView这个页面展示出去，当casLoginView页面中触发submit动作时候又会跳转到realSubmit这个action，接着运行配置的authenticationViaFormAction代码，最后flow完成调用 Spring Web Flow 基础详细说明和实例https://www.ibm.com/developerworks/cn/education/java/j-spring-webflow/index.html 总结Spring Web Flow总体来说就是对传统的MVC C到V和V到C做了一层中间层，使这部分的业务更加抽象更能体现出业务流程，并实现在Requset和Session中多加了一种状态Flow作用域，在Flow的调用中这部分的调用都是共享状态的(类似session，在多次请求中session可以获取相同的变量，flow的作用域比request大但是却小于session)，但是大大加大了配置的代码]]></content>
      <categories>
        <category>Web Flow</category>
      </categories>
      <tags>
        <tag>CAS</tag>
        <tag>Web Flow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS详细认证流程和部分客户端源码解析]]></title>
    <url>%2F2020%2F01%2F07%2FCAS%E8%AF%A6%E7%BB%86%E8%AE%A4%E8%AF%81%E6%B5%81%E7%A8%8B%E5%92%8C%E9%83%A8%E5%88%86%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介CAS解决了单点登录的问题，网上有很多关于CAS是如何实现单点的文章，但是很少有对详细认证流程做解释，这里做一下梳理。 核心概念 TGC：Ticket Granting CookieCAS 会将生成的 TGT 放在 session(默认，实际项目放在redis中这里只是举例) 中，而 TGC 就是这个 session 的唯一标识(sessionId)，可以认为是 TGT 的key，为 TGT 就是 TGC 的 value，TGC 以 cookie 的形式保存在浏览器中，每次访问单点域名都会尝试携带 TGC。（每个服务都会在 session 和 cookie 中保存对应的 TGT 和 TGC） TGT：Ticket Granting TicketTGT 是CAS 为用户签发的登录 ticket，也是用于验证用户登录成功的唯一方式。 TGT 封装了用户信息，CAS 通过 Cookie 值（TGC）为 key 查询缓存中有无 TGT（TGC:TGT（key:value）），如果有的话就说明用户已经登录成。 ST：Service TicketST 是当用户访问某一服务时提供的 ticket。用户在访问其他服务时，发现没有 登录 ，那么就会302到 CAS 服务器获取 ST。然后会携带着 ST 302 回来，本地应用根据ST去CAS获取登录的用户信息，并且保存在本地应用中。 环境准备我们这里准备了3台节点来测试,1和2服务分别对应接入单点的2个系统，我们开启这3个服务 序号 域名 作用 1 app1.com 应用1 2 app2.com 应用2 3 localhost/cas CAS单点登录服务器 第一次访问app1我们访问app1下的接口http://app1.com:8181/book/books ，由于此时浏览器第一次访问app1，之前并没登录，在CAS的client中会做一次跳转，将我们访问的地址重新定向到cas单点登录服务器,我们可以看到此时浏览器一共做了2次操作，第一次如下图，服务器返回302，在respone中返回Location:来标明接下来要重定向的地址，在url中带了一个service的参数，这个参数用来标明在Cas认证完成后，要调转回原来服务的地址接下来浏览器根据上一步浏览器返回的地址进行跳转，跳转到CAS服务器，进行账号密码认证 第一次认证接上上一步，我们在CAS中输入账号和密码，我们可以看到浏览器进行了如下操作提交账号密码并返回302进行重定向，我们可以注意一下在重定向的Location:中返回了一个临时票据ST，并且我们注意到当前在CAS服务器的这个域名下存入了cookieTGC,这里是跨域完成单点登录最重要的一步，因为传统模式下cookie是不能跨域的，但是我们单点登录不同系统往往是跨域名的，如果只将cookie存在当前系统下的不行的，因为不同域不能访问不同的cookie，于是CAS投机取巧的把cookie存放在了CAS所在的域名下，所有子系统在浏览器第一次访问时都要跳转的CAS服务器，那么这时候CAS就可以获取CAS服务端下的cookie，那么这时候CAS服务器只要查看本域名下时候有cookie就知道用户是否已经登陆过，如果登陆了再把信息存入到各个系统的session中，这样就不要每次访问都经过cas服务器，具体原理我们在下面查看 访问重定向的地址，其中地址中带上ST临时票据来进行安全认证，并且返回302，重新定向到我们最开始访问的地址 最后访问我们最开始要访问的地址 这时我们发现请求中已经没有带上任何cookie的信息了，那么CAS是如何知道我们已经完成过登录验证了呢？因为我们使用的CAS提供的client包已经将SESSION_ID存入服务器的SESSION，这里的原理就和我们使用SESSION来做登录原理一样了。我们来查看一下具体源码来证实一下我们的想法CAS客户端主要是由Servlet拦截器去实现的，我们在上一篇提到的博文中在客户端中注册了Cas30ProxyReceivingTicketValidationFilter拦截器和AuthenticationFilter拦截器，而且规定Cas30ProxyReceivingTicketValidationFilter拦截器必须要在AuthenticationFilter的前面，这是为什么呢？因为前者是负责验证ticket的或者是用来做认证的(没有登录的话跳转到CAS服务器)，前者认证完ticket会把验证对象放入到session中，如果AuthenticationFilter发现session中存在验证对象则跳过拦截器。我们查看一下Cas30ProxyReceivingTicketValidationFilter拦截器的父类AbstractTicketValidationFilter，其中的doFilter方法实现了拦截器的主体逻辑，下面我的注释已经写出最主要的逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445public abstract class AbstractTicketValidationFilter extends AbstractCasFilter &#123; public final void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; //此方法验证拦截器的前置条件在Cas30ProxyReceivingTicketValidationFilter中实现的是代理前置过滤，如果拦截器设置了代理地址则不进入拦截器 if (this.preFilter(servletRequest, servletResponse, filterChain)) &#123; HttpServletRequest request = (HttpServletRequest)servletRequest; HttpServletResponse response = (HttpServletResponse)servletResponse; String ticket = this.retrieveTicketFromRequest(request); if (CommonUtils.isNotBlank(ticket)) &#123; this.logger.debug(&quot;Attempting to validate ticket: &#123;&#125;&quot;, ticket); try &#123; //此部分为远程调用CAS服务端接口来验证ticket是否合法，如果合法生成Assertion验证对象 Assertion assertion = this.ticketValidator.validate(ticket, this.constructServiceUrl(request, response)); this.logger.debug(&quot;Successfully authenticated user: &#123;&#125;&quot;, assertion.getPrincipal().getName()); request.setAttribute(&quot;_const_cas_assertion_&quot;, assertion); //将验证对象存入session if (this.useSession) &#123; request.getSession().setAttribute(&quot;_const_cas_assertion_&quot;, assertion); &#125; this.onSuccessfulValidation(request, response, assertion); if (this.redirectAfterValidation) &#123; this.logger.debug(&quot;Redirecting after successful ticket validation.&quot;); response.sendRedirect(this.constructServiceUrl(request, response)); return; &#125; &#125; catch (TicketValidationException var8) &#123; this.logger.debug(var8.getMessage(), var8); this.onFailedValidation(request, response); if (this.exceptionOnValidationFailure) &#123; throw new ServletException(var8); &#125; response.sendError(403, var8.getMessage()); return; &#125; &#125; filterChain.doFilter(request, response); &#125;&#125;&#125; 上面我们说到Cas30ProxyReceivingTicketValidationFilter必须要在AuthenticationFilter拦截器之前，我们现在看下AuthenticationFilter拦截器又做了什么最主要的逻辑就是从session中获取验证过滤器中放入的Assertion对象，如果存在则认为已经登陆过，没有则跳转到CAS服务器去登陆 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class AuthenticationFilter extends AbstractCasFilter &#123; public final void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest)servletRequest; HttpServletResponse response = (HttpServletResponse)servletResponse; //如果跳过验证，白名单 if (this.isRequestUrlExcluded(request)) &#123; this.logger.debug(&quot;Request is ignored.&quot;); filterChain.doFilter(request, response); &#125; else &#123; HttpSession session = request.getSession(false); Assertion assertion = session != null ? (Assertion)session.getAttribute(&quot;_const_cas_assertion_&quot;) : null; //如果session中存在值则跳出拦截器，认为此次访问已经登陆过 if (assertion != null) &#123; filterChain.doFilter(request, response); &#125; else &#123; //如果session中没有值重定向到CAS服务器去登陆 String serviceUrl = this.constructServiceUrl(request, response); String ticket = this.retrieveTicketFromRequest(request); boolean wasGatewayed = this.gateway &amp;&amp; this.gatewayStorage.hasGatewayedAlready(request, serviceUrl); if (!CommonUtils.isNotBlank(ticket) &amp;&amp; !wasGatewayed) &#123; this.logger.debug(&quot;no ticket and no assertion found&quot;); String modifiedServiceUrl; if (this.gateway) &#123; this.logger.debug(&quot;setting gateway attribute in session&quot;); modifiedServiceUrl = this.gatewayStorage.storeGatewayInformation(request, serviceUrl); &#125; else &#123; modifiedServiceUrl = serviceUrl; &#125; this.logger.debug(&quot;Constructed service url: &#123;&#125;&quot;, modifiedServiceUrl); String urlToRedirectTo = CommonUtils.constructRedirectUrl(this.casServerLoginUrl, this.getProtocol().getServiceParameterName(), modifiedServiceUrl, this.renew, this.gateway); this.logger.debug(&quot;redirecting to \&quot;&#123;&#125;\&quot;&quot;, urlToRedirectTo); this.authenticationRedirectStrategy.redirect(request, response, urlToRedirectTo); &#125; else &#123; filterChain.doFilter(request, response); &#125; &#125; &#125; &#125;&#125; 接下来我们第一次访问APP2应用来证实我们上面所说的流程在我们已经登陆过app1的情况下我们访问app2 http://app2.com:8282/book/books ，我们看到服务器发出302请求跳转到CAS服务端 接下来浏览器自动跳转到CAS服务器的域名，这里我们看到这里带上了CAS域名localhost下的cookie 这时CAS就用这个cookie从服务端中查找，发现已经登陆过了，继续发出302请求，并且在Location: 跳转地址中在url中下发st 接下来又下发302请求要求浏览器使用st去验证时候是本人发起的访问，如果验证成功在respone中重新定向到我们之前要访问的地址 最后完成访问，这时候session_id已经存入到app2的session中，所以后续的访问不会再经过上面的逻辑，直接从App2服务端中获取session中就知道应用时候已经登陆 ticket时效总结由上述论证我们可以得到ticket时效，如果ticket（TGT）在CAS服务端中过期，但是应用中session没有过期，仍然有效的话，那么应用仍然可以登录，如果应用中session时效的话，CAS的ticket(TGT)未过期，那么应用仍然可以通过上述方式重新生成session，只有在CAS中的ticket和应用中的session同时失效的情况下，才需要重新登录]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS教程]]></title>
    <url>%2F2020%2F01%2F06%2FCAS%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[参考博文地址https://github.com/X-rapido/CAS_SSO_Recordhttps://www.jianshu.com/nb/36971803 实践中的问题版本本人使用的是5.3.1版本 配置静态json客户单service问题本人使用的版本是5.3.1，在simple-sso包下实践简单SSO登录在CAS服务端application.properties中静态配置service客户端时比没有设置静态json service的路径，网上查找到如果不配置默认在resources/services下，但是如果不配置此参数在5.3.1版本中无法识别到客户端json配置，所以需要手动加上以下配置cas.serviceRegistry.json.location=classpath:/services博文中–Service 配置介绍中(http://www.ibloger.net/article/3122.html)给定的配置如下，但是将配置配成下面时，CAS 服务端无法开启 #cas.serviceRegistry.config.location=classpath:/services 如果不使用https的情况下在CAS服务端application.properties中关闭SSL，如果不关闭会导致无法跨域单点登录1234server.ssl.enabled=false#解决http下登录状态不互通，无法跨域问题cas.tgc.secure=falsecas.warningCookie.secure=false 解决http下代理模式无法回调成功在http模式下代理模式调用代理端回调函数时会报 1org.jasig.cas.client.validation.TicketValidationException: 所提供的代理回调网址&apos;https://xxxx&apos;不能提供认证。 这是因为CAS默认代理回调函数只支持https我们需要在CAS服务端中的service注册json文件中添加proxyPolicy属性来增加对http的支持 123456789101112&#123; &quot;@class&quot; : &quot;org.apereo.cas.services.RegexRegisteredService&quot;, &quot;serviceId&quot; : &quot;^(https|http|imaps)://.*&quot;, &quot;name&quot; : &quot;HTTPS and HTTP and IMAPS&quot;, &quot;id&quot; : 10000001, &quot;description&quot; : &quot;This service definition authorizes all application urls that support HTTPS and HTTP and IMAPS protocols.&quot;, &quot;evaluationOrder&quot; : 10000, &quot;proxyPolicy&quot;: &#123; &quot;@class&quot;: &quot;org.apereo.cas.services.RegexMatchingRegisteredServiceProxyPolicy&quot;, &quot;pattern&quot;: &quot;^(https|http)?://.*&quot; &#125;&#125;]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring @Import和@Enable*注解和Spring的SPI完成二方包的注入]]></title>
    <url>%2F2019%2F12%2F30%2FSpring-Import%E5%92%8C-Enable-%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[简介最近在写一些基于SpringBoot的jar供其它工程调用，学习了一些开源和了解了Spring的自动配置后做了以下总结，在最开始接触Spring时当时网上说Spring基于xml的控制反转和依赖注入可以很好的将代码解耦，当时并不理解，明明依赖还是存在为什么能很好的解耦？直到接触了多模块后才渐渐理解它的含义，在多模块中代码供应商提供统一的接口，犹如一些插件，软件商提供主要接口，接入商负责实现，接入商的又有很多，那么如何做到可插拔开箱即用而各个接入商之间又不互相影响呢？这是依赖注入就很好的解决了这个问题，开发商和接入商不再进行强耦合，而是依赖类似与中间件一样的组件，将实现都由中间去管理，如果我想替换掉某个接入商的实现就在中间中更换接口的实现即可，对供应商的代码无任何影响，这就是Spring做的事。 将二方包注入到调用者的Spring容器中我们都知道SpringBoot工程的入口需要有一个@SpringBootApplication注解，然后SpringBoot会自动扫描这个类同级或者子包的Spring注解然后注入到Spring容器中，但是我们编写的二方包往往和调用者有者不同的目录结构，如何才能将我们提供的二方包注入到调用者的容器中呢？这里有3中方法。 保持相同的目录结构简单粗暴的方法就是调用者和被调用者有着相同的目录结构，使二方包中的配置类在调用者启动类如果的同级包或者子包下，那么这样SpringBoot在扫描时就会扫描到二方包中的Spring配置自动注入到容器中。 我们创建一个二方包工程,POM文件如下,只引入Spring的容器模块 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_core2&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;!--&lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;配置程序入口如果有的话&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt;--&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;!-- &lt;goal&gt;assembly&lt;/goal&gt; --&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--use commend: mvn assembly:assembly -DskipTests --&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 编写二方包接口 12345678910111213package com.liu.app1;/** * @author Liush * @description * @date 2019/12/30 17:35 **/public interface ServiceI &#123; String getServiceName();&#125; 接口实现类 12345678910111213package com.liu.app1;/** * @author Liush * @description * @date 2019/12/30 17:35 **/public class ServiceImpl implements ServiceI &#123; @Override public String getServiceName() &#123; return &quot;core2...........&quot;; &#125;&#125; Spring配置类 1234567891011121314151617181920package com.liu.app1;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author Liush * @description * @date 2019/12/30 17:36 **/@Configurationpublic class Config &#123; @Bean public ServiceI createService()&#123; return new ServiceImpl(); &#125;&#125; 执行mvn install将二方包打入本地仓库 创建调用工程 我们创建调用者POM文件,创建一个web工程 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--引入自定义二方包 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_core2&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 接着我们编写入口和一个Rest接口 123456789101112131415161718192021222324252627package com.liu.app1;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author Liush * @description * @date 2019/12/30 17:26 **/@RestControllerpublic class Rest &#123; @Autowired private ServiceI serviceI; @RequestMapping(&quot;/getName&quot;) public String getName()&#123; return serviceI.getServiceName(); &#125;&#125; 编写调用包的启动类 1234567891011121314151617181920212223package com.liu.app1;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Import;/** * @author Liush * @description * @date 2019/12/30 16:51 **/@SpringBootApplicationpublic class APP &#123; public static void main(String[] args) &#123; SpringApplication.run(APP.class,args); &#125;&#125; 接着我们访问http://localhost:8080/getName输出 core2……….. 总结这种方法需要调用者和二方包有相同的目录接口才能使调用方扫描到二方包的Spring配置，这种在实际中可行性较低 使用@Import注解 第一种方法在项目中可行性很低于是我们可以采用这种方法来编写二方包 创建工程POM文件,注意这里和第一种方法的POM文件没有什么不同除了我们将 改成了enable_core 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_core&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;!--&lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;配置程序入口如果有的话&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt;--&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;!-- &lt;goal&gt;assembly&lt;/goal&gt; --&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--use commend: mvn assembly:assembly -DskipTests --&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 这次我们在和调用方不同的路径下编写代码,总体和第一步都相同，主要就是包的路径不同,首先编写接口 123456789101112package com.sunnada;/** * @author Liush * @description * @date 2019/12/30 17:05 **/public interface ServiceI &#123; String getServiceName();&#125; 编写实现类 12345678package com.sunnada;public class ServiceImpl implements ServiceI &#123; @Override public String getServiceName() &#123; return &quot;core包中的服务实现&quot;; &#125;&#125; 编写配置文件 123456789101112131415161718192021package com.sunnada;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author Liush * @description * @date 2019/12/30 17:01 **/@Configurationpublic class CoreConfig &#123; @Bean public ServiceI createService()&#123; return new ServiceImpl(); &#125;&#125; 执行mvn clean install将代码打入仓库 调用方代码 创建POM文件，引入二方包 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_core&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 编写Rest接口 12345678910111213141516171819202122232425262728package com.liu.app1;import com.sunnada.ServiceI;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author Liush * @description * @date 2019/12/30 17:26 **/@RestControllerpublic class Rest &#123; @Autowired private ServiceI serviceI; @RequestMapping(&quot;/getName&quot;) public String getName()&#123; return serviceI.getServiceName(); &#125;&#125; 编写调用包的启动类,注意我们这里使用了@Import注解将我们二方包的配置文件导入 1234567891011121314151617181920212223package com.liu.app1;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Import;/** * @author Liush * @description * @date 2019/12/30 16:51 **/@SpringBootApplication@Import(&#123;com.sunnada.CoreConfig.class&#125;)public class APP &#123; public static void main(String[] args) &#123; SpringApplication.run(APP.class,args); &#125;&#125; 访问接口输出 core包中的服务实现 总结我们使用@Import在调用方中的启动类中手动指定需要注入的配置类，完成二方包的注入 更进一步我们在调用开源工程的时候经常引入一些二方包，这些包中我们并不需要使用@Import注解，而是在启动类中使用@Enable* 注解即可完成二方包的注入，我们可以查看@EnableScheduling中的源码,发现其本质也是使用@Import注解完成二方包的注入 1234567891011121314151617181920//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package org.springframework.scheduling.annotation;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import org.springframework.context.annotation.Import;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Import(&#123;SchedulingConfiguration.class&#125;)@Documentedpublic @interface EnableScheduling &#123;&#125; 基于Spring的SPI机制新建配置文件由于我们用maven构建工程，我们在resources下新建目录/META-INF/spring.factories文件,在配置文件中加入以下代码 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.liu.Config 我们注意配置文件等号左边的部分是Spring自动配置提供的类，右边是我们需要注入的类的全路径，到此我们会疑问SpringBoot是如何使用这个方法自动注入的呢？下面我们进入org.springframework.boot.autoconfigure.EnableAutoConfiguration查看源码 12345678910111213141516171819202122232425262728//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package org.springframework.boot.autoconfigure;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Inherited;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import org.springframework.context.annotation.Import;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(&#123;AutoConfigurationImportSelector.class&#125;)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; 我们注意最重要的部分@Import({AutoConfigurationImportSelector.class})，我们进入类中查看,发现其实现DeferredImportSelector接口，而DeferredImportSelector又实现ImportSelector 12345678public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123;...&#125; 那ImportSelector接口的作用又是什么呢？其有只有一个方法 1234567package org.springframework.context.annotation;import org.springframework.core.type.AnnotationMetadata;public interface ImportSelector &#123; String[] selectImports(AnnotationMetadata var1);&#125; 我们通过查找官方API,得知这个接口是决定哪些类可以导入Spring容器，也就是说我们可以通过实现这个接口来通过编码和配置文件的方式注入类到Spring的容器中 1Interface to be implemented by types that determine which @Configuration class(es) should be imported based on a given selection criteria, usually one or more annotation attributes. 接着我们查看AutoConfigurationImportSelector的selectImports方法实现，查看到底在AutoConfigurationImportSelector中做了什么 123456789public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!this.isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; else &#123; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader); AutoConfigurationImportSelector.AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations()); &#125; &#125; 这里我们看的一头雾水，但是我们可以根据方法名来猜测loadMetadata方法大概是加载什么元数据之类的,getAutoConfigurationEntry方法是获取配置实体之类的我们进入该方法查看一下 123456789101112131415protected AutoConfigurationImportSelector.AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; if (!this.isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; else &#123; AnnotationAttributes attributes = this.getAttributes(annotationMetadata); List&lt;String&gt; configurations = this.getCandidateConfigurations(annotationMetadata, attributes); configurations = this.removeDuplicates(configurations); Set&lt;String&gt; exclusions = this.getExclusions(annotationMetadata, attributes); this.checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = this.filter(configurations, autoConfigurationMetadata); this.fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationImportSelector.AutoConfigurationEntry(configurations, exclusions); &#125; &#125; 这里我们根据方法名大概可以知道这里做的就是获取配置文件中的信息，然后做了去重，过滤等一系列查找然后将属性封装出去 12345protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(this.getSpringFactoriesLoaderFactoryClass(), this.getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you are using a custom packaging, make sure that file is correct.&quot;); return configurations; &#125; 这里我们进入getSpringFactoriesLoaderFactoryClass方法看一下发现其返回的是一个EnableAutoConfiguration对象，也就是我们配置文件中配置的org.springframework.boot.autoconfigure.EnableAutoConfiguration类，这里也就是解释了为什么我们需要在配置文件中在org.springframework.boot.autoconfigure.EnableAutoConfiguration类下配置类才能完成自动注入 123protected Class&lt;?&gt; getSpringFactoriesLoaderFactoryClass() &#123; return EnableAutoConfiguration.class; &#125; 现在再根据方法名我们发现this.getCandidateConfigurations方法可能使获取配置类发生的地方我们进入该方法查看一下这里我们发现了SpringFactoriesLoader类的身影，熟悉Spring spi的知道spring spi就是通过这个类来加载配置文件中的类来达成自动配置的目的的，我们在进入SpringFactoriesLoader查看一下,发现其中又一个属性为FACTORIES_RESOURCE_LOCATION ，这里就说明了我们建配置文件为什么必须目录为META-INF/spring.factories 123456public final class SpringFactoriesLoader &#123; public static final String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;;.... &#125; 那么这里逻辑就已经清晰我们在META-INF/spring.factories中配置SpringBoot需要自动注入的类，org.springframework.boot.autoconfigure.EnableAutoConfiguration是Spring帮我们封装好的一个注解我们在其后配置我们需要自动注入的类，那么SpringBoot就会使用AutoConfigurationImportSelector来帮助我们将我们配置的类一个个注入到Spring中]]></content>
      <categories>
        <category>SPI</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SPI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA_SPI机制]]></title>
    <url>%2F2019%2F12%2F27%2FJAVA-SPI%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[简介在编写SpringBoot stater时我们会在项目的resources目录下新建META-INF文件夹并且在该目录下新建spring.factories文件,该文件中配置了在SpringBoot开启时需要加载和配置的类，那为什么只要配置了这个文件Spring就能自动去加载这个类呢？这个是因为用到了java的SPI机制 SPI想象一下现在有两个项目A,B。他们之间存在依赖关系B依赖于项目A,也就是说B在A项目的上层，通常反映在我们需要在B的maven POM.xml文件中配置了A的依赖。那么现在处在下层的A工厂有一个抽象接口需要由下层应用去实现，（举个例子A工程是快递公司，B工程是一个电商客户，那么快递公司只要留一个统一的收快递的电话给电商客户，由电商客户去打电话叫快递公司去寄快递即可，对于快递公司它并不关心电商公司是寄送什么货物，快递公司只负责寄送即可，那么具体寄送什么货物的实现就由电商公司自行去实现），想象一下这个系统你会怎么写？我们只要实现快递公司提供的寄送货物的接口，然后再由电商公司调用寄送货物的接口即可，简单暴力完成解耦。那么现在有一个问题，由于快递公司和这家电商公司关系恶化，那么快递公司想把这家公司开除，然后和另外一家快递公司合作，那么我们要怎么做？是不是要修改代码，去掉这家被开除的电商公司的实现，然后加入新的电商公司的实现？有没有一个方法我们不需要修改代码只要修改一下配置文件即可？于是这里就延伸除了SPI机制,其实控制反转的实现依赖注入就是一个变相的SPI实现，我们只要配置Spring的xml文件就能完成替换我们不同的类的实现，这样我们就不要更改我们核心的代码，只要修改我们的配置类即可，这样大大降低了出错的可能和完成了解耦 JDK自带 SPI简单的代码实现定义一个接口我们定义一个父类汽车,他有一个方法获取汽车名 123456789101112package com.liu;/** * @author Liush * @description * @date 2019/12/27 10:36 **/public interface CarI &#123; String getName();&#125; 定义2个实现类分别为奔驰和宝马1234567891011121314package com.liu;/** * @author Liush * @description * @date 2019/12/27 10:43 **/public class BenZ implements CarI &#123; @Override public String getName() &#123; return &quot;我是奔驰&quot;; &#125;&#125; 12345678910111213package com.liu;/** * @author Liush * @description * @date 2019/12/27 10:37 **/public class BMW implements CarI &#123; @Override public String getName() &#123; return &quot;我是宝马&quot;; &#125;&#125; 新建配置文件因为我使用的是maven工程所以我在resources目录下新建services目录注意services目录时固定的，这个在jdk的代码中只识别这个目录，在services目录下新建配置文件，文件名为父接口的全路径名称，比如这里是com.liu.CarI,然后再文件中添加我们想要注入的实现类这里配置如下,我们将宝马和奔驰都注入 12com.liu.BMWcom.liu.BenZ 调用新建main函数，使用ServiceLoader去调用方法，我们会发现系统输入了我是宝马和我是奔驰，那么一个简单的SPI实现完成，这样就完成了代码的配置和代码的实现解耦 1234567891011121314151617181920212223242526package com.liu;import java.sql.Driver;import java.util.Iterator;import java.util.ServiceLoader;/** * @author Liush * @description * @date 2019/12/27 10:39 **/public class MainTest &#123; public static void main(String[] args) &#123; ServiceLoader&lt;CarI&gt; serviceLoader=ServiceLoader.load(CarI.class); Iterator&lt;CarI&gt; carIterator=serviceLoader.iterator(); while (carIterator.hasNext())&#123; System.out.println(carIterator.next().getName()); &#125; &#125;&#125;]]></content>
      <categories>
        <category>SPI</category>
      </categories>
      <tags>
        <tag>SPI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计原本-杂记]]></title>
    <url>%2F2019%2F12%2F12%2F%E8%AE%BE%E8%AE%A1%E5%8E%9F%E6%9C%AC-%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第二章，理性模型工程师对于设计过程有一个清晰但通常来说也是隐含的模型，这个隐含的模型是在项目设计开始时根据目标，必要条件，约束等设计出来的，我们可以在开始设计时将条件设计出一个决策树，将各种暂时能想到的决策用树的形式展示出来，正如本章开篇所说因为设计的理念是普通的搜索理论即巨大的组合空间搜索，我是这样理解这句话，设计就是各个模块的各种可能选择最优解的组合，在项目开始设计时，将我们能想到的各种解用决策树的形式展示出来，并给每个节点（每种设计可能）一个权重，从而取出目前的最优设计.而有了这个决策树的理性模型，就更方便的和项目组中的其它成员分析项目的设计.注意：理性模型不是设计决策，而是暂定的设计方案。 第三章，理性模型的缺陷理性模型不是设计决策，而是暂定的设计方案，我们在项目开发中，刚开始我们并不知道项目树的样子，只有一边设计一般探索才能完善这颗树，而且约束等外部条件也在持续变化。这是一种设计过程的模型，设计过程的模型会影响设计的本身，因为当我们有了这个理性模型后，我们后续的工作都会围绕理性模型开展 第四章，需求软件设计不能在一开始就提出所有的需求，在开始时提出所有的需求必将导致项目的失败，因为在项目开始时我们并不能很好的考虑到每一点，我们应该提出概念模型和主要的需求和约束来进行开发，在根据主要模型和主要约束完成第一个版本后再对这些主要需求进行延伸，而且必须严格控制在开发一个版本进行过程中的需求蠕动(根据原有需求在一个版本未完成时对需求进行更改或者延伸) 第六章，协作设计在多人协作设计一个项目时，必须要有一个人主导设计，概念模型必须要由一个人提出，但是只有两个人的团队除外，因为两个人比多人能更快的达成一致，且沟通更加高效，且可以互相监督和提出意见，这样效率比单人设计效率和质量更高. ####第九章，模型设计:宁错勿淆,错误可以让我们很快接近真理，而混乱却不能设计前应该将对用户的认识和使用系统的目的详细列出，如果面向的是不同的用户，则计算出不同用户的各自权重，根据权重来设计一个折中的设计，在设计时，团队必须对模型定义出通用语言(领域驱动设计)，对一个模型要进行详细的说明，这样才能对由其引发的细节进行更深层的思考(我们在设计原型和开发时，进程随着开发和设计的深入，对原有的流程有了更深的思考，会发现原有的流程并不合理)，另外随着思考的深入，产生的细节和问题也会越来越不明确，这时可以大胆的去假设，因为宁错勿淆,错误可以让我们很快接近真理，而混乱却不能]]></content>
      <categories>
        <category>设计原本</category>
      </categories>
      <tags>
        <tag>设计原本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring security的认证和鉴权]]></title>
    <url>%2F2019%2F12%2F09%2FSpring-security%E7%9A%84%E8%AE%A4%E8%AF%81%E5%92%8C%E9%89%B4%E6%9D%83%2F</url>
    <content type="text"><![CDATA[简介Spring security 总体分为认证和鉴权两部分，认证我们可以理解为对账号密码的验证，鉴权为用户能不能访问资源，我们可以通过实现Spring security的接口来实现自定义的认证和鉴权。Spring security的本质是一连串的拦截器，我们可以拦截器链中加入自定义的拦截器来实现自己的逻辑. 认证部分下面介绍认证的核心接口和概念 Authentication此接口负者存储要认证的具体信息，主要是将认证的账号密码还有权限等信息存放在其中,比如前端传入账号和密码给后端验证，那么需要将账号和密码封装进实现Authentication接口的认证类中，然后将认证信息传给Spring security拦截器链，由Spring security调用认证和鉴权方法,代码如下 12345678910111213141516171819public interface Authentication extends Principal, Serializable &#123; //此账号具有哪些角色或者权限 Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); //认证信息，可以理解为密码 Object getCredentials(); Object getDetails(); //认证主体，如账号 Object getPrincipal(); //这个Authentication是否已经认证过 boolean isAuthenticated(); //设置Authentication是否已经认证过 void setAuthenticated(boolean var1) throws IllegalArgumentException;&#125; AuthenticationManager在框架中AuthenticationManager负责认证，一般我们使用Spring security自带实现类ProviderManager 1234public interface AuthenticationManager &#123; Authentication authenticate(Authentication var1) throws AuthenticationException;&#125; ProviderManager的authenticate(Authentication var1)方法的实现，我们可以看到起主要逻辑是循环调用List providers 中的AuthenticationProvider下的authenticate(Authentication authentication)方法，如果其中有一个AuthenticationProvider认证成功则返回，那么这里认证的逻辑就已经大概清晰，Spring Security 依托ProviderManager的实现去完成认证，而ProviderManager的主要实现类是ProviderManager，ProviderManager中又有一个AuthenticationProvider对象的集合，其负责具体的验证逻辑，如果有一个认证通过，则之前存在Authentication中的信息就认证成功，我们要做的就是实现自己的AuthenticationProvider认证，将其加入到ProviderManager的认证集合List providers中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172private List&lt;AuthenticationProvider&gt; providers;//...省略其余代码public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Class&lt;? extends Authentication&gt; toTest = authentication.getClass(); AuthenticationException lastException = null; AuthenticationException parentException = null; Authentication result = null; Authentication parentResult = null; boolean debug = logger.isDebugEnabled(); Iterator var8 = this.getProviders().iterator(); while(var8.hasNext()) &#123; AuthenticationProvider provider = (AuthenticationProvider)var8.next(); if (provider.supports(toTest)) &#123; if (debug) &#123; logger.debug(&quot;Authentication attempt using &quot; + provider.getClass().getName()); &#125; try &#123; result = provider.authenticate(authentication); if (result != null) &#123; this.copyDetails(authentication, result); break; &#125; &#125; catch (AccountStatusException var13) &#123; this.prepareException(var13, authentication); throw var13; &#125; catch (InternalAuthenticationServiceException var14) &#123; this.prepareException(var14, authentication); throw var14; &#125; catch (AuthenticationException var15) &#123; lastException = var15; &#125; &#125; &#125; if (result == null &amp;&amp; this.parent != null) &#123; try &#123; result = parentResult = this.parent.authenticate(authentication); &#125; catch (ProviderNotFoundException var11) &#123; ; &#125; catch (AuthenticationException var12) &#123; parentException = var12; lastException = var12; &#125; &#125; if (result != null) &#123; if (this.eraseCredentialsAfterAuthentication &amp;&amp; result instanceof CredentialsContainer) &#123; ((CredentialsContainer)result).eraseCredentials(); &#125; if (parentResult == null) &#123; this.eventPublisher.publishAuthenticationSuccess(result); &#125; return result; &#125; else &#123; if (lastException == null) &#123; lastException = new ProviderNotFoundException(this.messages.getMessage(&quot;ProviderManager.providerNotFound&quot;, new Object[]&#123;toTest.getName()&#125;, &quot;No AuthenticationProvider found for &#123;0&#125;&quot;)); &#125; if (parentException == null) &#123; this.prepareException((AuthenticationException)lastException, authentication); &#125; throw lastException; &#125; &#125; AuthenticationProvider上文提到了AuthenticationProvider是负责具体认证的地方，它的代码如下authenticate方法负责接收一个Authentication类，如果认证成功则返回一个Authentication对象，supports(Class&lt;?&gt; var1)负责判定这个AuthenticationProvider可以鉴定什么类型的Authentication，我们可以实现自己的Authentication，和AuthenticationProvider，从而使我们自定义的AuthenticationProvider只去鉴定特定的Authentication 12345public interface AuthenticationProvider &#123; Authentication authenticate(Authentication var1) throws AuthenticationException; boolean supports(Class&lt;?&gt; var1);&#125; UserDetailsServiceUserDetailsService是Spring security抽象的接口其方法如下，其作用是根据参数获取一个用户属性UserDetails，UserDetails为Spring secur为用户做的一个抽象。 123public interface UserDetailsService &#123; UserDetails loadUserByUsername(String var1) throws UsernameNotFoundException;&#125; 在网上我们看到的很多教程叫我们只要自定义实现自己的 UserDetailsService就可以完成认证，这是因为Spring security默认使用的Authentication 是UsernamePasswordAuthenticationToken，而默认对UsernamePasswordAuthenticationToken进行认证的又是AuthenticationProvider 是DaoAuthenticationProvider,下面我们查看DaoAuthenticationProvider源码发现以下代码，其中this.getUserDetailsService().loadUserByUsername就是调用UserDetailsService去获取UserDetailsService对象 12345678910111213141516171819protected final UserDetails retrieveUser(String username, UsernamePasswordAuthenticationToken authentication) throws AuthenticationException &#123; this.prepareTimingAttackProtection(); try &#123; UserDetails loadedUser = this.getUserDetailsService().loadUserByUsername(username); if (loadedUser == null) &#123; throw new InternalAuthenticationServiceException(&quot;UserDetailsService returned null, which is an interface contract violation&quot;); &#125; else &#123; return loadedUser; &#125; &#125; catch (UsernameNotFoundException var4) &#123; this.mitigateAgainstTimingAttack(authentication); throw var4; &#125; catch (InternalAuthenticationServiceException var5) &#123; throw var5; &#125; catch (Exception var6) &#123; throw new InternalAuthenticationServiceException(var6.getMessage(), var6); &#125; &#125; 那retrieveUser又具体做了什么呢，我们查看DaoAuthenticationProvider父类AbstractUserDetailsAuthenticationProvider中的代码,其中以下最重要的一段代码this.additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken)authentication);这段代码的实现在DaoAuthenticationProvider中，且public boolean supports(Class&lt;?&gt; authentication) 表明了其只验证实现了UsernamePasswordAuthenticationToken的Authentication 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Assert.isInstanceOf(UsernamePasswordAuthenticationToken.class, authentication, () -&gt; &#123; return this.messages.getMessage(&quot;AbstractUserDetailsAuthenticationProvider.onlySupports&quot;, &quot;Only UsernamePasswordAuthenticationToken is supported&quot;); &#125;); String username = authentication.getPrincipal() == null ? &quot;NONE_PROVIDED&quot; : authentication.getName(); boolean cacheWasUsed = true; UserDetails user = this.userCache.getUserFromCache(username); if (user == null) &#123; cacheWasUsed = false; try &#123; user = this.retrieveUser(username, (UsernamePasswordAuthenticationToken)authentication); &#125; catch (UsernameNotFoundException var6) &#123; this.logger.debug(&quot;User &apos;&quot; + username + &quot;&apos; not found&quot;); if (this.hideUserNotFoundExceptions) &#123; throw new BadCredentialsException(this.messages.getMessage(&quot;AbstractUserDetailsAuthenticationProvider.badCredentials&quot;, &quot;Bad credentials&quot;)); &#125; throw var6; &#125; Assert.notNull(user, &quot;retrieveUser returned null - a violation of the interface contract&quot;); &#125; try &#123; this.preAuthenticationChecks.check(user); this.additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken)authentication); &#125; catch (AuthenticationException var7) &#123; if (!cacheWasUsed) &#123; throw var7; &#125; cacheWasUsed = false; user = this.retrieveUser(username, (UsernamePasswordAuthenticationToken)authentication); this.preAuthenticationChecks.check(user); this.additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken)authentication); &#125; this.postAuthenticationChecks.check(user); if (!cacheWasUsed) &#123; this.userCache.putUserInCache(user); &#125; Object principalToReturn = user; if (this.forcePrincipalAsString) &#123; principalToReturn = user.getUsername(); &#125; return this.createSuccessAuthentication(principalToReturn, authentication, user); &#125; public boolean supports(Class&lt;?&gt; authentication) &#123; return UsernamePasswordAuthenticationToken.class.isAssignableFrom(authentication); &#125; DaoAuthenticationProvider中我们找到additionalAuthenticationChecks方法,这里的逻辑就很清晰了，将UserDetails中的值和authentication中的值做比对，如果不匹配抛出AuthenticationException异常由spring security去处理异常 123456789101112protected void additionalAuthenticationChecks(UserDetails userDetails, UsernamePasswordAuthenticationToken authentication) throws AuthenticationException &#123; if (authentication.getCredentials() == null) &#123; this.logger.debug(&quot;Authentication failed: no credentials provided&quot;); throw new BadCredentialsException(this.messages.getMessage(&quot;AbstractUserDetailsAuthenticationProvider.badCredentials&quot;, &quot;Bad credentials&quot;)); &#125; else &#123; String presentedPassword = authentication.getCredentials().toString(); if (!this.passwordEncoder.matches(presentedPassword, userDetails.getPassword())) &#123; this.logger.debug(&quot;Authentication failed: password does not match stored value&quot;); throw new BadCredentialsException(this.messages.getMessage(&quot;AbstractUserDetailsAuthenticationProvider.badCredentials&quot;, &quot;Bad credentials&quot;)); &#125; &#125; &#125; 拦截器上文提到我们登陆的时候需要把我们登陆的信息封装成Authentication对象，再由Spring security框架去认证，前文还说到Spring Security的本质就是一连串的拦截器，那我们实现的思路就是这样，我们自定义一个拦截器，拦截登陆的信息，将账号密码组成Authentication对象，再交由Spring security对象去认证即可,之后以我们可以不自定义上述的类就可以使用是因为Spring security中默认加入了一个UsernamePasswordAuthenticationFilter拦截器，且提供了默认实现的DaoAuthenticationProvider.我们查看UsernamePasswordAuthenticationFilter的源码,发现其只是将前传送进来的账号密码组成一个UsernamePasswordAuthenticationToken ，我们注意到this.getAuthenticationManager().authenticate(authRequest)这段代码，这段代码就是调用ProviderManager去完成对Authentication的认证 1234567891011121314151617181920public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; if (this.postOnly &amp;&amp; !request.getMethod().equals(&quot;POST&quot;)) &#123; throw new AuthenticationServiceException(&quot;Authentication method not supported: &quot; + request.getMethod()); &#125; else &#123; String username = this.obtainUsername(request); String password = this.obtainPassword(request); if (username == null) &#123; username = &quot;&quot;; &#125; if (password == null) &#123; password = &quot;&quot;; &#125; username = username.trim(); UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(username, password); this.setDetails(request, authRequest); return this.getAuthenticationManager().authenticate(authRequest); &#125; &#125; 下面我们再查看UsernamePasswordAuthenticationToken的父类AbstractAuthenticationProcessingFilter,发现其调用了UsernamePasswordAuthenticationToken的attemptAuthentication方法，并且将UsernamePasswordAuthenticationToken放入SecurityContextHolder中的SecurityContext里 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest)req; HttpServletResponse response = (HttpServletResponse)res; if (!this.requiresAuthentication(request, response)) &#123; chain.doFilter(request, response); &#125; else &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Request is to process authentication&quot;); &#125; Authentication authResult; try &#123; authResult = this.attemptAuthentication(request, response); if (authResult == null) &#123; return; &#125; this.sessionStrategy.onAuthentication(authResult, request, response); &#125; catch (InternalAuthenticationServiceException var8) &#123; this.logger.error(&quot;An internal error occurred while trying to authenticate the user.&quot;, var8); this.unsuccessfulAuthentication(request, response, var8); return; &#125; catch (AuthenticationException var9) &#123; this.unsuccessfulAuthentication(request, response, var9); return; &#125; if (this.continueChainBeforeSuccessfulAuthentication) &#123; chain.doFilter(request, response); &#125; this.successfulAuthentication(request, response, chain, authResult); &#125; &#125; protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, Authentication authResult) throws IOException, ServletException &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Authentication success. Updating SecurityContextHolder to contain: &quot; + authResult); &#125; SecurityContextHolder.getContext().setAuthentication(authResult); this.rememberMeServices.loginSuccess(request, response, authResult); if (this.eventPublisher != null) &#123; this.eventPublisher.publishEvent(new InteractiveAuthenticationSuccessEvent(authResult, this.getClass())); &#125; this.successHandler.onAuthenticationSuccess(request, response, authResult); &#125; 默认的SecurityContext是由ThredLocal生成,也就是说在同一个线程下我们都可以通过SecurityContextHolder.getContext().getAuthentication()获取到Authentication或者通过 SecurityContextHolder.getContext().setAuthentication()设置Authentication 1234567891011121314151617181920212223242526272829final class ThreadLocalSecurityContextHolderStrategy implements SecurityContextHolderStrategy &#123; private static final ThreadLocal&lt;SecurityContext&gt; contextHolder = new ThreadLocal(); ThreadLocalSecurityContextHolderStrategy() &#123; &#125; public void clearContext() &#123; contextHolder.remove(); &#125; public SecurityContext getContext() &#123; SecurityContext ctx = (SecurityContext)contextHolder.get(); if (ctx == null) &#123; ctx = this.createEmptyContext(); contextHolder.set(ctx); &#125; return ctx; &#125; public void setContext(SecurityContext context) &#123; Assert.notNull(context, &quot;Only non-null SecurityContext instances are permitted&quot;); contextHolder.set(context); &#125; public SecurityContext createEmptyContext() &#123; return new SecurityContextImpl(); &#125;&#125; 在本人的自行实现的拦截器中并没有调用this.getAuthenticationManager().authenticate(authRequest)方法,因为本人只实现了OncePerRequestFilter类，并没有实现Spring security提供的AbstractAuthenticationProcessingFilter抽象类，但是仍然可以实现认证，因为在后面的鉴权拦截器中我实现了AbstractSecurityInterceptor类该中有一段代码Authentication authenticated = this.authenticateIfRequired(); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162protected InterceptorStatusToken beforeInvocation(Object object) &#123; Assert.notNull(object, &quot;Object was null&quot;); boolean debug = this.logger.isDebugEnabled(); if (!this.getSecureObjectClass().isAssignableFrom(object.getClass())) &#123; throw new IllegalArgumentException(&quot;Security invocation attempted for object &quot; + object.getClass().getName() + &quot; but AbstractSecurityInterceptor only configured to support secure objects of type: &quot; + this.getSecureObjectClass()); &#125; else &#123; Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource().getAttributes(object); if (attributes != null &amp;&amp; !attributes.isEmpty()) &#123; if (debug) &#123; this.logger.debug(&quot;Secure object: &quot; + object + &quot;; Attributes: &quot; + attributes); &#125; if (SecurityContextHolder.getContext().getAuthentication() == null) &#123; this.credentialsNotFound(this.messages.getMessage(&quot;AbstractSecurityInterceptor.authenticationNotFound&quot;, &quot;An Authentication object was not found in the SecurityContext&quot;), object, attributes); &#125; Authentication authenticated = this.authenticateIfRequired(); try &#123; this.accessDecisionManager.decide(authenticated, object, attributes); &#125; catch (AccessDeniedException var7) &#123; this.publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated, var7)); throw var7; &#125; if (debug) &#123; this.logger.debug(&quot;Authorization successful&quot;); &#125; if (this.publishAuthorizationSuccess) &#123; this.publishEvent(new AuthorizedEvent(object, attributes, authenticated)); &#125; Authentication runAs = this.runAsManager.buildRunAs(authenticated, object, attributes); if (runAs == null) &#123; if (debug) &#123; this.logger.debug(&quot;RunAsManager did not change Authentication object&quot;); &#125; return new InterceptorStatusToken(SecurityContextHolder.getContext(), false, attributes, object); &#125; else &#123; if (debug) &#123; this.logger.debug(&quot;Switching to RunAs Authentication: &quot; + runAs); &#125; SecurityContext origCtx = SecurityContextHolder.getContext(); SecurityContextHolder.setContext(SecurityContextHolder.createEmptyContext()); SecurityContextHolder.getContext().setAuthentication(runAs); return new InterceptorStatusToken(origCtx, true, attributes, object); &#125; &#125; else if (this.rejectPublicInvocations) &#123; throw new IllegalArgumentException(&quot;Secure object invocation &quot; + object + &quot; was denied as public invocations are not allowed via this interceptor. This indicates a configuration error because the rejectPublicInvocations property is set to &apos;true&apos;&quot;); &#125; else &#123; if (debug) &#123; this.logger.debug(&quot;Public object - authentication not attempted&quot;); &#125; this.publishEvent(new PublicInvocationEvent(object)); return null; &#125; &#125; &#125; 进入 this.authenticateIfRequired();我们发现Authentication的isAuthenticated状态时false时在这里将会完成再次认证,所以我们自定义认证完Authentication后必须将Authentication的isAuthenticated的状态设置为true，避免后续拦截器再次去认证 123456789101112131415161718private Authentication authenticateIfRequired() &#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authentication.isAuthenticated() &amp;&amp; !this.alwaysReauthenticate) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Previously Authenticated: &quot; + authentication); &#125; return authentication; &#125; else &#123; authentication = this.authenticationManager.authenticate(authentication); if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Successfully Authenticated: &quot; + authentication); &#125; SecurityContextHolder.getContext().setAuthentication(authentication); return authentication; &#125; &#125; 认证异常处理在认证过程中出现认证失败，不管是我们自定义的认证类和Spring security 自带的实现类都抛出AuthenticationException异常，这个异常可以统一由Spring security捕获，从而处理认证异常 认证配置以下配置中关于认证的我们只需要注意几点 public void configure(AuthenticationManagerBuilder authenticationManagerBuilder)此方法下往ProviderManager中配置了AuthenticationProvider认证器，并且设置了UserDetailService类和设置了认证时密码不加密 public void configure(HttpSecurity http)此方法配置了认证的具体逻辑，http.addFilterBefore(validateFilter, UsernamePasswordAuthenticationFilter.class)将我们自定义实现的拦截器加入到UsernamePasswordAuthenticationFilter之前，UsernamePasswordAuthenticationFilter是Spring security中默认最后一个负责认证的拦截器，加入的拦截器负责组装前台提交的账号和密码，将其转换成Authentication。.exceptionHandling().authenticationEntryPoint负责配置认证异常，所有认证抛出的AuthenticationException及其实现都会在这里配置的AuthenticationEntryPointd 的实现类中处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115/** * @author Liush * @description * @date 2019/11/12 16:06 **/@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired private CustomLoginSuccessHandler customLoginSuccessHandler; @Autowired private CustomLoginFailHandler customLoginFailHandler; @Autowired private CustomLogoutSuccessHandler customLogoutSuccessHandler; @Autowired private JWTUtil jwtUtil; @Autowired private SecurityProperties securityProperties; @Autowired private DbUserDetailsService dbUserDetailsService; @Autowired private PasswordProvider passwordProvider; @Autowired private TokenProvider tokenProvider; @Autowired private CustomEntryPointHandler customEntryPointHandler; @Autowired private IdentityUserServiceI identityUserService; @Autowired private RoleAccessDeniedHandler roleAccessDeniedHandler; @Autowired public void configure(AuthenticationManagerBuilder authenticationManagerBuilder) throws Exception &#123; authenticationManagerBuilder.userDetailsService(dbUserDetailsService). passwordEncoder(NoOpPasswordEncoder.getInstance()); authenticationManagerBuilder.authenticationProvider(passwordProvider); authenticationManagerBuilder.authenticationProvider(tokenProvider); &#125; @Bean public RoleAccessSecurityInterceptor roleAccessSecurityInterceptor()&#123; List&lt;AccessDecisionVoter&lt;? extends Object&gt;&gt; voters=new ArrayList&lt;&gt;(); voters.add(new RoleAccessDecisionVoter()); AccessDecisionManager accessDecisionManager=new RoleDecisionManager(voters); RoleMetadataSource roleMetadataSource=new RoleMetadataSource(jwtUtil,identityUserService); return new RoleAccessSecurityInterceptor(securityProperties.getWhiteUrls(),accessDecisionManager,roleMetadataSource); &#125; @Override public void configure(HttpSecurity http) throws Exception &#123; ValidateFilter validateFilter = new ValidateFilter(securityProperties.getLogin_url(),securityProperties.getWhiteUrls(), jwtUtil, customEntryPointHandler); http.addFilterBefore(validateFilter, UsernamePasswordAuthenticationFilter.class) //设置认证异常处理器 .exceptionHandling().authenticationEntryPoint(customEntryPointHandler) //设置鉴权异常处理器 .accessDeniedHandler(roleAccessDeniedHandler) .and() .cors() .and() .csrf().disable(); whiteUrlConfig(http); //设置鉴权拦截器 http.addFilterAfter(roleAccessSecurityInterceptor(),FilterSecurityInterceptor.class); &#125; /** * 白名单配置,调用permitAll方法，此url下的连接可以进入security拦截器，但是不鉴权 */ private void whiteUrlConfig(HttpSecurity http) throws Exception &#123; List&lt;String&gt; whiteUrls= WhiteUrlUtil.createWhiteUrls(securityProperties.getWhiteUrls()); for (String url:whiteUrls)&#123; http.authorizeRequests().antMatchers(url).permitAll(); &#125; http.authorizeRequests().anyRequest().authenticated(); &#125; /* @Override public void configure(HttpSecurity http) throws Exception&#123; http.authorizeRequests().anyRequest().permitAll(); &#125;*/&#125; 鉴权部分鉴权就是对用户可以做什么进行判断 FilterInvocationAPI中给的解释是Holds objects associated with a HTTP filter.意思就是其是保存HTTP过滤器的地方,我们必须在鉴权拦截器中生成FilterInvocation对象，并将FilterInvocation对象传入拦截器链，从而获取http中的信息，因为鉴权很多是和url做关联的，比如什么角色能访问什么url SecurityMetadataSourceAPI中的解释是：提供ConfigAttribute的类实现。 1234567public interface SecurityMetadataSource extends AopInfrastructureBean &#123; Collection&lt;ConfigAttribute&gt; getAttributes(Object var1) throws IllegalArgumentException; Collection&lt;ConfigAttribute&gt; getAllConfigAttributes(); boolean supports(Class&lt;?&gt; var1);&#125; 下面是本人对于这个方法的实现,入参Object var1，是一个FilterInvocation，通过拿到request中的信息，查询到该次请求需要哪些权限（一般是直接获取请求的url，然后去查询这次url访问需要哪些权限），将查询到的需要的权限封装成Collection ，供后续代用 12345678910111213141516@Override public Collection&lt;ConfigAttribute&gt; getAttributes(Object object) throws IllegalArgumentException &#123; HttpServletRequest request = ((FilterInvocation) object).getRequest(); String powerId=request.getHeader(&quot;powerId&quot;); //查询powerId下需要的角色 List&lt;RoleDTO&gt; roles=identityUserService.findRoleByPowerId(powerId); if(roles==null || roles.isEmpty())&#123; throw new AccessDeniedException(&quot;该权限id不存在&quot;); &#125; List&lt;ConfigAttribute&gt; configAttributes=new ArrayList&lt;&gt;(); for(RoleDTO role:roles)&#123; configAttributes.add(new RoleConfigAttribute(role.getAuthority())); &#125; return configAttributes; &#125; ConfigAttributeAPI中的解释:存储与安全系统相关的配置属性 123public interface ConfigAttribute extends Serializable &#123; String getAttribute();&#125; AccessDecisionManagerAPI中的解释:做出最终访问控制（授权）决定。 1234567public interface AccessDecisionManager &#123; void decide(Authentication var1, Object var2, Collection&lt;ConfigAttribute&gt; var3) throws AccessDeniedException, InsufficientAuthenticationException; //判断决策管理器时候支持此属性的验证,关于这两个类的实现可参考Spiring security的默认实现 boolean supports(ConfigAttribute var1); boolean supports(Class&lt;?&gt; var1);&#125; 本人实现,获取AbstractAccessDecisionManager中AccessDecisionVoter，进行投票如果有一个AccessDecisionVoter投票为1说明有权限，如果鉴权失败抛出AccessDeniedException异常，由SpringSecurity统一处理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class RoleDecisionManager extends AbstractAccessDecisionManager &#123; protected RoleDecisionManager(List&lt;AccessDecisionVoter&lt;?&gt;&gt; decisionVoters) &#123; super(decisionVoters); &#125; @Override public void decide(Authentication authentication, Object object, Collection&lt;ConfigAttribute&gt; configAttributes) throws AccessDeniedException, InsufficientAuthenticationException &#123; int deny = -1; //如果等于-1验证失败，如果等于1验证成功 for (AccessDecisionVoter voter : getDecisionVoters()) &#123; int result = voter.vote(authentication, object, configAttributes); switch (result) &#123; //通过验证 case AccessDecisionVoter.ACCESS_GRANTED:&#123; deny=1; break; &#125; //验证失败 case AccessDecisionVoter.ACCESS_DENIED: continue; default: &#125; &#125; if (deny !=1) &#123; throw new AccessDeniedException(&quot;没有权限调用此功能&quot;); &#125; // 如果所有投票者都弃权的话 //checkAllowIfAllAbstainDecisions(); &#125; /** * 被AbstractSecurityInterceptor调用，遍历ConfigAttribute集合，筛选出不支持的attribute */ @Override public boolean supports(ConfigAttribute attribute) &#123; return true; &#125; /** * 被AbstractSecurityInterceptor调用，验证AccessDecisionManager是否支持这个安全对象的类型。 */ @Override public boolean supports(Class&lt;?&gt; clazz) &#123; return true; &#125;&#125; AccessDecisionVoterAPI中的解释:负责对授权决策进行投票 ,int vote(Authentication var1, S var2, Collection var3)如果有权限返回1，没有权限返回-1 1234567891011public interface AccessDecisionVoter&lt;S&gt; &#123; int ACCESS_GRANTED = 1; int ACCESS_ABSTAIN = 0; int ACCESS_DENIED = -1; boolean supports(ConfigAttribute var1); boolean supports(Class&lt;?&gt; var1); int vote(Authentication var1, S var2, Collection&lt;ConfigAttribute&gt; var3);&#125; AbstractSecurityInterceptorAPI中的解释:为安全对象实现安全拦截的抽象类 整体认证逻辑首先我们实现自己的AbstractSecurityInterceptor,在拦截器中生成FilterInvocation对象，调用AbstractSecurityInterceptor的super.beforeInvocation(roleFilterInvocation)完成鉴权 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * @author Liush * @description 鉴权拦截器 * @date 2019/11/17 19:39 **/public class RoleAccessSecurityInterceptor extends AbstractSecurityInterceptor implements Filter &#123; private String whiteUrls; private FilterInvocationSecurityMetadataSource securityMetadataSource; public RoleAccessSecurityInterceptor(String whiteUrls, AccessDecisionManager decisionManager,FilterInvocationSecurityMetadataSource securityMetadataSource) &#123; if(StringUtils.isEmpty(whiteUrls))&#123; whiteUrls= &quot;&quot;; &#125; this.whiteUrls = whiteUrls; super.setAccessDecisionManager(decisionManager); this.securityMetadataSource=securityMetadataSource; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; //查看是否白名单，如果是的话不认证 if(WhiteUrlUtil.isWhite((HttpServletRequest) servletRequest,whiteUrls))&#123; filterChain.doFilter(servletRequest,servletResponse); return; &#125; FilterInvocation roleFilterInvocation=new FilterInvocation(servletRequest,servletResponse,filterChain); InterceptorStatusToken token=super.beforeInvocation(roleFilterInvocation); try&#123; roleFilterInvocation.getChain().doFilter(servletRequest,servletResponse); &#125;finally &#123; super.afterInvocation(token,null); &#125; &#125; @Override public Class&lt;?&gt; getSecureObjectClass() &#123; return FilterInvocation.class; &#125; @Override public SecurityMetadataSource obtainSecurityMetadataSource() &#123; return securityMetadataSource; &#125;&#125; 我们进入super.beforeInvocation(roleFilterInvocation)方法,Collection attributes = this.obtainSecurityMetadataSource().getAttributes(object);此方法调用SecurityMetadataSource来获取，该次调用需要获取什么权限this.authenticateIfRequired()上面文章提到如果之前如果Authenticate的isAuthenticated为false的话会在这里再次鉴权this.accessDecisionManager.decide(authenticated, object, attributes);调用AccessDecisionManager进行鉴权投票,如果没有抛出AccessDeniedException异常则鉴权成功 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162protected InterceptorStatusToken beforeInvocation(Object object) &#123; Assert.notNull(object, &quot;Object was null&quot;); boolean debug = this.logger.isDebugEnabled(); if (!this.getSecureObjectClass().isAssignableFrom(object.getClass())) &#123; throw new IllegalArgumentException(&quot;Security invocation attempted for object &quot; + object.getClass().getName() + &quot; but AbstractSecurityInterceptor only configured to support secure objects of type: &quot; + this.getSecureObjectClass()); &#125; else &#123; Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource().getAttributes(object); if (attributes != null &amp;&amp; !attributes.isEmpty()) &#123; if (debug) &#123; this.logger.debug(&quot;Secure object: &quot; + object + &quot;; Attributes: &quot; + attributes); &#125; if (SecurityContextHolder.getContext().getAuthentication() == null) &#123; this.credentialsNotFound(this.messages.getMessage(&quot;AbstractSecurityInterceptor.authenticationNotFound&quot;, &quot;An Authentication object was not found in the SecurityContext&quot;), object, attributes); &#125; Authentication authenticated = this.authenticateIfRequired(); try &#123; this.accessDecisionManager.decide(authenticated, object, attributes); &#125; catch (AccessDeniedException var7) &#123; this.publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated, var7)); throw var7; &#125; if (debug) &#123; this.logger.debug(&quot;Authorization successful&quot;); &#125; if (this.publishAuthorizationSuccess) &#123; this.publishEvent(new AuthorizedEvent(object, attributes, authenticated)); &#125; Authentication runAs = this.runAsManager.buildRunAs(authenticated, object, attributes); if (runAs == null) &#123; if (debug) &#123; this.logger.debug(&quot;RunAsManager did not change Authentication object&quot;); &#125; return new InterceptorStatusToken(SecurityContextHolder.getContext(), false, attributes, object); &#125; else &#123; if (debug) &#123; this.logger.debug(&quot;Switching to RunAs Authentication: &quot; + runAs); &#125; SecurityContext origCtx = SecurityContextHolder.getContext(); SecurityContextHolder.setContext(SecurityContextHolder.createEmptyContext()); SecurityContextHolder.getContext().setAuthentication(runAs); return new InterceptorStatusToken(origCtx, true, attributes, object); &#125; &#125; else if (this.rejectPublicInvocations) &#123; throw new IllegalArgumentException(&quot;Secure object invocation &quot; + object + &quot; was denied as public invocations are not allowed via this interceptor. This indicates a configuration error because the rejectPublicInvocations property is set to &apos;true&apos;&quot;); &#125; else &#123; if (debug) &#123; this.logger.debug(&quot;Public object - authentication not attempted&quot;); &#125; this.publishEvent(new PublicInvocationEvent(object)); return null; &#125; &#125; &#125; 注意在WebSecurityConfigurerAdapter配置类下配置的白名单http.authorizeRequests().antMatchers(url).permitAll(),这里配置的url仍然会进入拦截器，所以我在进入拦截器前先会去查找白名单，如果是白名单直接跳过拦截器]]></content>
      <categories>
        <category>Spring security</category>
      </categories>
      <tags>
        <tag>Spring security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用mysqlbinlog和mysql日志恢复数据]]></title>
    <url>%2F2019%2F11%2F07%2F%E4%BD%BF%E7%94%A8mysqlbinlog%E5%92%8Cmysql%E6%97%A5%E5%BF%97%E6%81%A2%E5%A4%8D%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[简介有时候我们会误删mysql中的数据，如果有开启binlog日志，那么我们可以通过mysql提供的mysqlbinlog工具来读取出操作日志，并且重新执行操作日志达到恢复数据的效果 备份我们通常会在数据达到一个节点去备份一次数据库使用mysqldump工具可以完成备份,以下输出的备份中会包含当前备份所指向的日志文件和日志position，这个是我们恢复日志的关键 1/usr/bin/mysqldump --single-transaction --master-data=2 -u root -p -A&gt;/mysql/qwe.sql 查看日志事件执行以下语句，把对应的日志换成自己mysql的日志文件的名字，可以查看到该文件的日志详情，其中Pos字段表示执行语句的开始positon，end_log_position表示改语句执行结束时的position，如果是从备份中恢复数据，那么这里要对应上备份sql文件中的position，找到需要恢复数据的日志positon 1show BINLOG EVENTS in &apos;mysql-bin.000004&apos; 回放日志内容以下语句将需要回放日志的开始position和结束position输入，并且传入对应的日志文件，并将结果输出到一个文件中 1mysqlbinlog --start-position 1487 --stop-position 2207 /var/lib/mysql/mysql-bin.000004&gt; /liu/mysql/ppp.sql 重新执行语句恢复数据将上一步导出的日志操作步骤导入mysql中重新执行，即可完成数据恢复 1mysql -u root -p&lt;/liu/mysql/ppp.sql]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysqlbinlog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql不停机主备复制]]></title>
    <url>%2F2019%2F11%2F06%2Fmysql%E4%B8%8D%E5%81%9C%E6%9C%BA%E4%B8%BB%E5%A4%87%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[简介之前在网上找到的关于主备节点的同步数据大多是要在主节点停机或者限制写入，然后将数据拷贝到从节点，然后再进行主从节点的日志同步，其实mysql下提供了mysqldump工具可以在不停机下进行主从数据的同步，将主节点的数据复制到从节点，即使这时候主节点仍在写入数据，将数据导入到从节点后，再将从节点的binlog日志节点指向拷贝主节点数据时的binlog日志位置，最后再由系统追上主节点的数据进度。 搭建主备如何搭建主备参考hive分类下的—hive mysql元数据表单的主从备份这篇文章 导出主库数据 single-transaction保证在innodb引擎下导出数据的一致性 master-data=2表示在导出的文件中现实binlog的名字和position，后续在从节点中根据这里的参数指向主节点的binlog日志 -A表示导出所有数据库，一般导出所有数据库。1/usr/bin/mysqldump --single-transaction --master-data=2 -u root -p -A&gt;/mysql/qwe.sql 关于mysqldump的用法参考 https://www.centos.bz/2018/02/mysqldump-%E5%8F%82%E6%95%B0%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D/ 模拟主从不一致我们需要手动同步主备数据往往就是因为数据库出现异常，导致主从节点数据不一样，这里我们模型主从数据库不一致的情况，然后将主库数据导入到备库中 停止从库 1stop SLAVE 将主库数据导入到从库，qwe.sql是之前主库中导出的数据 1mysql -u root -p&lt;qwe.sql 导入成功后主从的数据已经一致 我们在主库中随意插入几条数据，由于未开启同步，从库中并没有同步新插入的数据，这里模拟了主从数据不同步的问题，在线数据迁移中往往会出现这个问题，在备份过程中，又有新的数据插入到数据库中 开启从节点同步 首先查看我们之前导出的sql数据的binlog的位置和postion 1head -n 30 qwe.sql 查看到如下数据 1-- CHANGE MASTER TO MASTER_LOG_FILE=&apos;mysql-bin.000004&apos;, MASTER_LOG_POS=785; 查看主节点的binlog 1show master status 发现其binlog位置已经和导出数据时发生了改变 1mysql-bin.000004 1410 将从节点的binlog指向主节点 注意我们在这里使用的是导出数据时候的binlog，也就是导出sql里显示的binlog 12change master to master_host=&apos;192.168.1.10&apos;, master_user=&apos;slave&apos;, master_password=&apos;mysql&apos;, master_log_file=&apos;mysql-bin.000004&apos;, master_log_pos=785; 开启从节点同步 1start slave; 执行以下语句，发现现在主从的binlog已经同步，查询从库数据发现已经存在之前插入的数据 1show slave status; 问题 最好保证主从数据库版本的一致，至少主库的数据库版本要大于从库的版本]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>主从备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[平衡内存和磁盘资源]]></title>
    <url>%2F2019%2F11%2F04%2F%E5%B9%B3%E8%A1%A1%E5%86%85%E5%AD%98%E5%92%8C%E7%A3%81%E7%9B%98%E8%B5%84%E6%BA%90%2F</url>
    <content type="text"><![CDATA[简介在项目中往往应用内存来做缓存，这样做是为了避免磁盘I/O，特别是随机磁盘I/O，这里梳理了磁盘的基础知识，和mysql 如何避免磁盘随机I/O 磁盘的物理结构硬盘内部主要部件为磁盘盘片、传动手臂、读写磁头和主轴马达。实际数据都是写在盘片上，读写主要是通过传动手臂上的读写磁头来完成。实际运行时，主轴让磁盘盘片转动，然后传动手臂可伸展让读取头在盘片上进行读写操作。磁盘物理结构如下图所示：、 由于单一盘片容量有限，一般硬盘都有两张以上的盘片，每个盘片有两面，都可记录信息，所以一张盘片对应着两个磁头。盘片被分为许多扇形的区域，每个区域叫一个扇区，硬盘中每个扇区的大小固定为512字节。盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用。磁盘盘片垂直视角如下图所示： 影响硬盘性能的因素寻道时间Tseek是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在3-15ms。 旋转延迟Trotation是指盘片旋转将请求数据所在的扇区移动到读写磁盘下方所需要的时间。旋转延迟取决于磁盘转速，通常用磁盘旋转一周所需时间的1/2表示。比如：7200rpm的磁盘平均旋转延迟大约为60*1000/7200/2 = 4.17ms，而转速为15000rpm的磁盘其平均旋转延迟为2ms。 数据传输时间Ttransfer是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。目前IDE/ATA能达到133MB/s，SATA II可达到300MB/s的接口数据传输率，数据传输时间通常远小于前两部分消耗时间。简单计算时可忽略。 衡量性能的指标机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是IOPS和吞吐量。 IOPSIOPS（Input/Output Per Second）即每秒的输入输出量（或读写次数），即指每秒内系统能处理的I/O请求数量。随机读写频繁的应用，如小文件存储等，关注随机读写性能，IOPS是关键衡量指标。可以推算出磁盘的IOPS = 1000ms / (Tseek + Trotation + Transfer)，如果忽略数据传输时间，理论上可以计算出随机读写最大的IOPS。常见磁盘的随机读写最大IOPS为： 7200rpm的磁盘 IOPS = 76 IOPS 10000rpm的磁盘IOPS = 111 IOPS 15000rpm的磁盘IOPS = 166 IOPS 吞吐量吞吐量（Throughput），指单位时间内可以成功传输的数据数量。顺序读写频繁的应用，如视频点播，关注连续读写性能、数据吞吐量是关键衡量指标。它主要取决于磁盘阵列的架构，通道的大小以及磁盘的个数。不同的磁盘阵列存在不同的架构，但他们都有自己的内部带宽，一般情况下，内部带宽都设计足够充足，不会存在瓶颈。磁盘阵列与服务器之间的数据通道对吞吐量影响很大，比如一个2Gbps的光纤通道，其所能支撑的最大流量仅为250MB/s。最后，当前面的瓶颈都不再存在时，硬盘越多的情况下吞吐量越大。 平和内存和磁盘资源配置大量内存最大的原因其实不是因为可以在内存中保存大量数据:最终目的是避免磁盘I/O，因为磁盘I/O比在内存中访问数据要慢的多，计算机包含一个金字塔型的缓存体系，更小，更快更昂贵的缓存在顶端，如图 在这个高速缓存层次中，最好是利用各级缓存来存放热点数据，以获取更快的访问速度，通常使用一些启发式的方法，如最近被使用的数据很可能会很快的再次使用，以及相邻的数据可能很快需要使用。设计良好的数据库缓存（如innoDB缓冲池），其效率通常超过操作系统的缓存，因为操作系统的缓存是为通用任务设计的，数据库缓存更了解数据库存储的需求，它包含特殊的用途和逻辑(例如写入顺序)一帮助满足这些需求。 随机I/O和顺序I/O数据库服务器同事使用顺序I/O和随机I/O，随机I/O从缓存中受益最多,因为缓存这些数据将有助于避免昂贵的磁盘寻道，相反顺序读取一般只需要扫描一次数据，所以缓存对它是没用的，除非能完全放在内存中缓存起来。 顺序读取不能从缓中受益另一个原因是它们比随机读取快，有以下两个原因： 顺序I/O比随机I/O快 顺序操作的执行速度比随机操作快，无论是在内存还是在磁盘上。假设磁盘每秒可以做100个随机I/O操作，并且可以完成每秒50M的顺序读取（在大概是消费级磁盘现在能达到的水平）。如果每行100字节，随机读取可以每秒读取100行，相比之下顺序读取可以读取每秒500000行这个是随机读取的5000倍，或几个数量级的差异，因此这种情况下随机I/O可以从缓冲中获得很多好处。（注：因为随机读取受到IOPS的限制—100个随机I/O，而顺序读取受到吞吐量的限制—这里是每秒50M） 顺序访问内存行的数据也快于随机访问。现在的内存芯片通常每秒可以随机访问约250000次100字节的行，或者每秒500万次的顺序访问。请注意，内存随机访问速度比磁盘随机访问快了2500倍，而内存中顺序访问通常只有磁盘的10倍的数据。 存储引擎执行顺序读取比随机快 一个随机读取一般意味着存储引擎必须执行索引操作，通常需要通过B树的数据结构查找，并且和其它值比较（innoDB中如果不是覆盖索引则需要回表查询主键索引的B树查询全部数据）。相反，连续读取一般需要遍历一个简单的数据结构，如链表。这样就少了很多工作，反复这样操作，连续读取的速度就比随机读取要快了。 最后随机读取通常只要查找特定的行，但不仅仅只读取一样–而是要读取一整页的数据(因为页数数据再磁盘中存储的最小单位，innodbDB中也可以配置相应的最小页的大小)，其中大部分都是不需要的，这浪费了很多工作。另一方方面，顺序读取数据，通常发生在想要的页面上的所有行，所以更符合成本效益。 缓存，读和写 如果有足够的内存，就完全可以避免磁盘读取请求，如果所有数据文件都可以放在内存中，一旦服务器缓存热起来，所有读取都可以在缓存中命中，虽然有逻辑读取，但是物理读取就没有了。但是写入是不同的问题，写入可以像读一样在内存中完成，但是迟早要写入到磁盘中，所以它需要持久化，换一句话说，缓存可以延迟写入，但是不能像消除读取一样消除写入。 主要通过以下两个方法解决 多次写入，一次刷新 一片数据可以在内存中改变很多次，而不需要吧所有新值写到磁盘，当数据最终被刷新到磁盘后，最后一次物理写入之前发生的所有修改都被持久化了，例如许多语句可以更新内存中的计数器，如果计数器递增100次，然后写入磁盘，100次修改就被合并成一次写入。 I/O合并 许多不同部分的数据可以在内存中修改，并且这些修改可以合并在一起，通过一次磁盘操作完成物理写入。 这就是为什么许多交易系统使用预写日志(WAL)策略。预写日志采用在内存中变更页面，而不是马上刷新到磁盘上的策略，因为刷新磁盘通常需要随机I/O，这非常慢。相反，如果吧变化记录写到一个连续的日志文件中，这就很快了。后台线程可以稍后把修改的页面刷新到磁盘，并且在刷新过程中优化写操作，写入操作从缓冲中受益很大，因为它把随机I/O更多的转换到连续I/O.（注：innodb的事务日志就是这样做的，innodb用日志把随机I/O变为顺序I/O，每次事务的变化将其顺序的写入到日志文件中，后续再由后台进程将数据写入到数据文件中）。 参考资料 高性能Mysql https://tech.meituan.com/2017/05/19/about-desk-io.html]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>磁盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[innoDB的缓冲池和事务日志(为什么innoDB无法存储大数据)]]></title>
    <url>%2F2019%2F10%2F21%2FinnoDB%E7%9A%84%E7%BC%93%E5%86%B2%E6%B1%A0%E5%92%8C%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[简介mysql的innoDB存储引擎提供了缓冲池innodb_buffer_pool_size来设置缓冲池的大小，其可以缓存索引，行数据，自适应哈希索引，插入缓冲等数据，InnoDB还使用缓冲池来帮助延迟写入，这样就能合并多个写入操作，然后一起顺序地回写。之前与另一个配置query_cache_size混淆，query_cache_size在8.0中已经废除，因为如果查询缓存中使用了很大的内存，缓存失效操作会成为一个严重的问题瓶颈导致系统僵死一会(更新表中的数据会导致该表的缓存失效)，因为这个操作是靠一个全局锁保护的，所有需要该操作的查询都要等待这个锁，而且无论是检测是否命中缓存，还是缓存失效检测都需要等待这个全局锁。以下是网上找的对于这两个缓存的定义. Qcacche缓存的是SQL语句及对应的结果集，缓存在内存，最简单的情况是SQL一直不重复，那Qcache的命令率肯定是0 buffer pool中缓存的是整张表中的数据，缓存在内存，SQL再变只要数据都在内存，那么命中率就是100%。 事务日志事务修改的数据和索引通常会映射到表空间的随机位置，这导致大量随机I/O，对机械硬盘来说，随机I/O伴随着磁盘大量寻址操作。InnoDB使用日志把随机I/O变成顺序I/O，一旦日志安全写到磁盘，事务就持久化了，即使变更的数据还没写入到数据文件，一旦系统发生崩溃，InnoDB可以重放日志并且恢复已经提交的事务，当然InnoDB最后必须把日志里的变更数据写入到数据文件当中，因为日志有固定大小。可以通过innodb_log_file_size来设置日志文件大小，在8.0中默认是48M，对于高性能工作来说这太小，至少需要几百M，还有一种说法是能存储1-2个小时的时间. innodb_buffer_pool_size的大小设置缓冲池一般设置为服务器内存的75%-80%(前提是该服务器只部署mysql，如果还部署其它应用需扣除其它应用使用的内存) 大innodb_log_file_size和innodb_buffer_pool_size导致的问题数据大小和访问模式也将影响恢复时间。假设有一个1TB的数据和16G的缓冲池，并且日志大小是128M，如果缓冲池里有很多脏页(例如数据写入了日志文件，但是没有写入数据文件),并且这些数据均匀的分布在1TB数据中，系统崩溃后恢复将需要相当长的一段时间，InnoDB必须从头到尾扫描日志，检查数据文件，并且将事务日志中的数据写到数据文件当中。 日志缓冲刷新到持久化系统（innodb_flush_log_at_trx_commit）当InnoDB变更任何数据时，会写入一条变更记录到内存的日志缓冲区，在缓冲满的时候，或者每一秒中，或者事务提交时—-无论上述三个条件哪个先到，日志缓冲区默认1M，通过innodb_log_buffer_size配置，如果有大事务，将其配置大一些可以帮助减少磁盘I/O，通常不需要设置的很大1M-9M即可。 innodb_flush_log_at_trx_commit有3个值 0：把日志缓冲写到日志文件，并且每秒刷新一次 1: 将日志缓冲写到日志文件，并且每次事务提交都刷新到持久化系统，这是默认的，并且是最安全的，该设置保证不会丢失任何已经提交的事务，除非磁盘或者系统是伪刷新。 2：每次提交时把日志缓冲写到日志文件，但是不刷新，InnoDB每秒刷新一次。0和2的区别是如果mysql挂了，2不会丢失任何事务，因为2会自动刷新缓存到日志文件在事务提交的时候，但是如果整个服务挂了，则还是可能会丢失一部分事务。这个很好理解，如果我提交了事务，数据已经写入了日志文件所以不会丢失，但是缓存区里未提交的事务，且时间还没到1秒，则会丢失这一秒的数据 因此如果设置0或者2另一个以mysql崩溃或者断电会导致最多丢失一秒的数据。 (innodb怎样打开和刷新日志文件和数据文件)innodb_flush_method这个配置既影响日志文件，也影响数据文件 将innodb_flush_method设置为O_DIRECT以避免双重缓冲.唯一一种情况你不应该使用O_DIRECT是当你操作系统不支持时。但如果你运行的是Linux，使用O_DIRECT来激活直接IO。不用直接IO，双重缓冲将会发生，因为所有的数据库更改首先会写入到OS缓存然后才同步到硬盘 – 所以InnoDB缓冲池和OS缓存会同时持有一份相同的数据。特别是如果你的缓冲池限制为总内存的50%，那意味着在写密集的环境中你可能会浪费高达50%的内存。如果没有限制为50%，服务器可能由于OS缓存的高压力会使用到swap。简单地说，设置为innodb_flush_method=O_DIRECT。 以下是InnoDB的缓存和文件的流程图 Buffer pool中将变更写入Log Buffer，Log Buffer将数据写入事务日志文件，InnoDB使用一个后台线程智能的刷新这些变更到数据文件，实际上，事务日志把数据文件的随机I/O转换成为几乎顺序的日志文件和数据文件I/O。把刷新操作转移到后台使查询可以更快完成,并且缓和查询高峰时I/O系统的压力，这个也很好理解，数据更新后将数据存放在Buffer pool中为了保证数据不丢失，并且降低I/O损耗采用日志顺序I/O记录这些变更，在系统崩溃时采用日志恢复，并且后台定时将日志文件刷新到数据文件，查询缓存直接查询Buffer pool中的数据即可。 为什么innoDB无法存储大数据量说白了主要就是innodb_buffer_pool_size缓存不够引起的原因 缓存池可以被认为一条长LRU链表，该链表又分为2个子链表，一个子链表存放old pages(里面存放的是长时间未被访问的数据页)，另一个子链接存放new pages（里面存放的是最近被访问的数据页面）。old pages 默认占整个列表大小的37%（这个值对应my.conf 的 innoDB_old_blocks_pct 参数的默认值为37，取值范围是5~95），其余为new pages占用。 如图下图所示。靠近LRU链表头部的数据页表示最近被访问，靠近LRU链表尾部的数据页表示长时间未被访问，而这两个部分交汇处成为midpoint。 当系统查询数据时当innodb_buffer_pool_size已满时会将排在old pages中的数据挤出缓存，导致innodb_buffer_pool中找不到查询数据，导致磁盘的I/O操作。 另外请参考https://www.cnblogs.com/leefreeman/p/8315844.html 参考资料高性能Mysql https://www.centos.bz/2016/11/mysql-performance-tuning-15-config-item/ http://xiaorui.cc/2016/12/08/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%BB%BA%E8%AE%AEinnodb%E4%BD%BF%E7%94%A8%E4%BA%BF%E7%BA%A7%E5%A4%A7%E8%A1%A8/ https://www.cnblogs.com/leefreeman/p/8315844.html]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>innoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务简介]]></title>
    <url>%2F2019%2F10%2F17%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[简介数据库事务需要满足ACID（原子性、一致性、隔离性、持久性）四个特性。 原子性（Atomicity）指事务作为整体来执行，要么全部执行，要么全不执行。 一致性（Consistency）指事务应确保数据从一个一致的状态转变为另一个一致的状态。 隔离性（Isolation）指多个事务并发执行时，一个事务的执行不应影响其他事务的执行。 持久性（Durability）指已提交的事务修改数据会被持久保存。 在单一数据节点中，事务仅限于对单一数据库资源的访问控制，称之为本地事务。几乎所有的成熟的关系型数据库都提供了对本地事务的原生支持。 但是在基于微服务的分布式应用环境下，越来越多的应用场景要求对多个服务的访问及其相对应的多个数据库资源能纳入到同一个事务当中，分布式事务应运而生。 关系型数据库虽然对本地事务提供了完美的ACID原生支持。 但在分布式的场景下，它却成为系统性能的桎梏。如何让数据库在分布式场景下满足ACID的特性或找寻相应的替代方案，是分布式事务的重点工作。 本地事务在不开启任何分布式事务管理器的前提下，让每个数据节点各自管理自己的事务。 它们之间没有协调以及通信的能力，也并不互相知晓其他数据节点事务的成功与否。 本地事务在性能方面无任何损耗，但在强一致性以及最终一致性方面则力不从心。 现在模拟一个业务场景，游戏的道具交易系统，系统分为金币洗系统和道具系统两个部分，购买道具时先需要扣除金币，然后才能获取道具，采用单数据库的本地事务的流程如下图,所有的事务都在单库中进行，不设计分布式事务，由数据库自身提供的事务功能去保证数据的一致性 分布式事务XAX/Open 组织（即现在的 Open Group ）定义了分布式事务处理模型。 X/Open DTP 模型（ 1994 ）包括应用程序（ AP ）、事务管理器（ TM ）、资源管理器（ RM ）、通信资源管理器（ CRM ）四部分。一般，常见的事务管理器（ TM ）是交易中间件，常见的资源管理器（ RM ）是数据库，常见的通信资源管理器（ CRM ）是消息中间件。 通常把一个数据库内部的事务处理，如对多个表的操作，作为本地事务看待。数据库的事务处理对象是本地事务，而分布式事务处理的对象是全局事务。 所谓全局事务，是指分布式事务处理环境中，多个数据库可能需要共同完成一个工作，这个工作即是一个全局事务，例如，一个事务中可能更新几个不同的数据库。对数据库的操作发生在系统的各处但必须全部被提交或回滚。此时一个数据库对自己内部所做操作的提交不仅依赖本身操作是否成功，还要依赖与全局事务相关的其它数据库的操作是否成功，如果任一数据库的任一操作失败，则参与此事务的所有数据库所做的所有操作都必须回滚。 一般情况下，某一数据库无法知道其它数据库在做什么，因此，在一个 DTP 环境中，交易中间件是必需的，由它通知和协调相关数据库的提交或回滚。而一个数据库只将其自己所做的操作（可恢复）影射到全局事务中。 XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。 二阶提交协议和三阶提交协议就是根据这一思想衍生出来的。可以说二阶段提交其实就是实现XA分布式事务的关键(确切地说：两阶段提交主要保证了分布式事务的原子性：即所有结点要么全做要么全不做) XA的刚性实现二阶段提交是XA的标准实现。它将分布式事务的提交拆分为2个阶段：prepare和commit/rollback。 开启XA全局事务后，所有子事务会按照本地默认的隔离级别锁定资源，并记录undo和redo日志，然后由TM发起prepare投票，询问所有的子事务是否可以进行提交：当所有子事务反馈的结果为“yes”时，TM再发起commit；若其中任何一个子事务反馈的结果为“no”，TM则发起rollback；如果在prepare阶段的反馈结果为yes，而commit的过程中出现宕机等异常时，则在节点服务重启后，可根据XA recover再次进行commit补偿，以保证数据的一致性。 2PC模型中，在prepare阶段需要等待所有参与子事务的反馈，因此可能造成数据库资源锁定时间过长，不适合并发高以及子事务生命周长较长的业务场景。 Sharding-Sphere支持基于XA的强一致性事务解决方案，可以通过SPI注入不同的第三方组件作为事务管理器实现XA协议，如Atomikos和Narayana。 XA 协议它依赖的是数据库层面来保障事务的一致性，也即是说 XA 的各个分支事务是在数据库层面上驱动的，由于 XA 的各个分支事务需要有 XA 的驱动程序，一方面会导致数据库与 XA 驱动耦合，另一方面它会导致各个分支的事务资源锁定周期长，这也是它没有在互联网公司流行的重要因素。 XA的柔性实现柔性实现牺牲了数据的一致性，在刚性实现中，所有节点在完成提交确认时都需要锁定数据库资源，这样在网络不稳定，或者节点故障时很容易发生死锁，或者等待锁资源过长，因此柔性实现中，采用最终一致性原则，先提交，并将执行数据写入日志，如果发现其它节点发生故障，则根据日志回滚数据即可。 2PC二阶段提交(Two-phaseCommit)是指，在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提交也被称为是一种协议(Protocol))。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。 准备阶段 事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。 可以进一步将准备阶段分为以下三个步骤： 协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作 各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。 提交阶段如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源) 接下来分两种情况分别讨论提交阶段的过程。 当协调者节点从所有参与者节点获得的相应消息都为”同意”时: 协调者节点向所有参与者节点发出”正式提交(commit)”的请求。 参与者节点正式完成操作，并释放在整个事务期间内占用的资源。 参与者节点向协调者节点发送”完成”消息。 协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。 如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时： 协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求。 参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。 参与者节点向协调者节点发送”回滚完成”消息。 协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务。 二阶段提交看起来确实能够提供原子性的操作，但是不幸的事，二阶段提交还是有几个缺点的： 同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。 单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题） 数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。 二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。 3pc由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷，所以，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。 三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。 与两阶段提交不同的是，三阶段提交有两个改动点。 引入超时机制。同时在协调者和参与者中都引入超时机制。 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。 也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。 CanCommit阶段 3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。 事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。 响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No PreCommit阶段 协调者根据参与者的反应情况来决定是否可以继续事务的PreCommit操作。根据响应情况，有以下两种可能。 假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。 发送预提交请求 协调者向参与者发送PreCommit请求，并进入Prepared阶段。 事务预提交 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。 响应反馈 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。 假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。 发送中断请求 协调者向所有参与者发送abort请求。 中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。 doCommit阶段该阶段进行真正的事务提交，也可以分为以下两种情况。 执行提交 发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。 事务提交 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。 响应反馈 事务提交完之后，向协调者发送Ack响应。 完成事务 协调者接收到所有参与者的ack响应之后，完成事务。 中断事务 协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。 发送中断请求 协调者向所有参与者发送abort请求 事务回滚 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。 反馈结果 参与者完成事务回滚之后，向协调者发送ACK消息 中断事务 协调者接收到参与者反馈的ACK消息之后，执行事务的中断。 在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。 ） 2PC与3PC的区别相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。 柔性事务的理论基础-BASE理论柔性事务是对XA协议的妥协和补偿，它通过对强一致性要求的降低，已达到降低数据库资源锁定时间的效果。 BASE是对CAP中一致性和可用性权衡的结果，其核心思想是即使无法做到强一致性，但每个应用都可以根据自身的业务特点，采用适当的方法来使系统达到最终一致性。 基本可用（Basically Available） 基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性 响应时间上的损失：正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加到了1-2秒。功能上的损失：在一个电子商务网站上进行购物，消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 软状态（Soft state） 软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 最终一致性（Eventually consistent） 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 柔性事务的实现 补偿型 TCC（Try/Confirm/Cancel）型事务。在一个长事务中，一个由两台服务器一起参与的事务，服务器A发起事务，服务器B参与事务，B的事务需要人工参与，所以处理时间可能很长。如果按照ACID的原则，要保持事务的隔离性、一致性，服务器A中发起的事务中使用到的事务资源将会被锁定，不允许其他应用访问到事务过程中的中间结果，直到整个事务被提交或者回滚。这就造成事务A中的资源被长时间锁定，系统的可用性将不可接受。WS-BusinessActivity提供了一种基于补偿的long-running的事务处理模型。还是上面的例子，服务器A的事务如果执行顺利，那么事务A就先行提交，如果事务B也执行顺利，则事务B也提交，整个事务就算完成。但是如果事务B执行失败，事务B本身回滚，这时事务A已经被提交，所以需要执行一个补偿操作，将已经提交的事务A执行的操作作反操作，恢复到未执行前事务A的状态。这样的SAGA事务模型，是牺牲了一定的隔离性和一致性的，但是提高了long-running事务的可用性。 异步确保型 将一些同步阻塞的事务操作变为异步的操作，避免对数据库事务的争用。比如热点资源的批量更新、异步更新的处理,比如上述交易系统，先扣除金币后往队列中道具系统发送增加道具通知。 最大努力型 通过通知服务器（消息通知）进行，允许失败，有补偿机制（或重发机制）。 参考资料https://shardingsphere.apache.org/document/current/cn/features/transaction/concept/2pc-xa-transaction/ http://www.hollischuang.com/archives/681 https://www.jianshu.com/p/d70df89665b9]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>分布式事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的缓慢日志]]></title>
    <url>%2F2019%2F10%2F15%2Fmysql%E7%9A%84%E7%BC%93%E6%85%A2%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[简介mysql有4种日志，分别为错误日志，一般查询日志，慢查询日志，二进制日志 错误日志错误日志是最重要的日志之一，它记录了MySQL服务启动和停止正确和错误的信息，还记录了mysqld实例运行过程中发生的错误事件信息，mysql默认开启，在my.cnf中log-error=/var/log/mysqld.log 配置对应错误日志的位置。 一般查询日志一般查询日志，记录所有操作记录都记录在日志中，默认不开启，一般也不建议开启，这样会造成I/O等资源的浪费，对于查询分析我们开源开启慢查询日志。 二进制日志二进制日志包含了引起或可能引起数据库改变(如delete语句但没有匹配行)的事件信息，但绝不会包括select和show这样的查询语句。语句以”事件”的形式保存，所以包含了时间、事件开始和结束位置等信息。mysql中主从同步采用二进制日志来进行同步，由my.cnflog-bin来控制,具体配置可查看hive分类中的hive主从配置这篇文章 慢查询日志查询超出变量 long_query_time 指定时间值的为慢查询。但是查询获取锁(包括锁等待)的时间不计入查询时间内。mysql记录慢查询日志是在查询执行完毕且已经完全释放锁之后才记录的，因此慢查询日志记录的顺序和执行的SQL查询语句顺序可能会不一致(例如语句1先执行，查询速度慢，语句2后执行，但查询速度快，则语句2先记录) 慢查询日志配置 在my.cnf中 12345678#是否启用慢日志slow_query_log=ON#慢日志文件的路径slow_query_log_file=/var/log/mysql-slow.log#指定慢查询超时时长(默认10秒)，超出此时长的属于慢查询long_query_time=0.5#没有使用索引时候记录慢日志log_queries_not_using_indexes=OFF 慢语句分析当初的慢日志文件如下,记录着查询时间，锁时间，和执行的记录 123456789101112131415/usr/sbin/mysqld, Version: 8.0.17 (MySQL Community Server - GPL). started with:Tcp port: 0 Unix socket: /var/lib/mysql/mysql.sockTime Id Command Argument# Time: 2019-10-15T03:47:35.922001Z# User@Host: root[root] @ [192.168.169.58] Id: 8# Query_time: 2.061037 Lock_time: 0.000320 Rows_sent: 712182 Rows_examined: 712182use test;SET timestamp=1571111253;SELECT * FROM d_area;# Time: 2019-10-15T03:48:16.302963Z# User@Host: root[root] @ [192.168.169.58] Id: 8# Query_time: 1.250141 Lock_time: 0.000096 Rows_sent: 712182 Rows_examined: 712182SET timestamp=1571111295;SELECT * FROM d_area; 这样查询日志很不直观，mysql提供了mysqldumpslow来查看缓慢日志,用法如下 1234567891011121314151617181920mysqldumpslow -s [Parameter] -t [Parameter] 缓慢日志路径参数-s : 排序方式c：query执行的次数t：sql执行的时间l：lock锁表的时间r：sql返回的行数-t： top，返回前n条数据-g： 正则匹配，大小写不敏感返回执行时间最长的前两个querymysqldumpslow -s t -t 2 /var/log/mysql-slow.log显示执行次数最多的前两个querymysqldumpslow -s c -t 2 /var/log/mysql-slow.log返回按照时间排序的前10条里面含有左连接的查询语句mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/log/mysql-slow.log 执行 1mysqldumpslow -s t -t 2 /var/log/mysql-slow.log 结果如下 123456Reading mysql slow query log from /var/log/mysql-slow.logCount: 2 Time=1.66s (3s) Lock=0.00s (0s) Rows=712182.0 (1424364), root[root]@[192.168.169.58] SELECT * FROM d_areaCount: 2 Time=0.64s (1s) Lock=0.00s (0s) Rows=61757.5 (123515), root[root]@[192.168.169.58] SELECT * FROM d_area where province_ like &apos;S&apos; or town_ like &apos;S&apos; 注意配置的slow_query_log_file（慢日志路径）的文件，mysql账号需要有读写权限执行 1chown mysql:mysql /路径 否则查询 ,语句状态一直未on 1show variables like &apos;%slow_query_log%&apos;; 设置会话基本缓慢日志以上设置的缓慢日志，或者当缓慢日志过大清理时，需要重启数据库，但是在生产环境中是不允许这样做的，所以我们采用SET变量的方法去设置缓慢日志。 关闭缓慢日志服务 1set global slow_query_log=OFF; 查看缓慢日志时候关闭 1show variables like &apos;%slow%&apos;; 迁移缓慢日志 1直接用linux mv命令或者其它方法迁移缓慢日志 重新设置缓慢日志路径 1set global slow_query_log_file=&apos;/路径&apos;; 重新开启缓慢日志 1set global slow_query_log=ON; 实际操作方案实际生产环境中可以采用上述方案，每天编写脚本完成缓慢日志迁移.]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql缓慢日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式唯一id(数据库主键):snowflake算法]]></title>
    <url>%2F2019%2F10%2F14%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%94%AF%E4%B8%80id-snowflake%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[简介项目中大家喜欢用java自带的UUID工具类去生成唯一的数据库主键，这样做的原因是简单。但mysql的innodb存储引擎的主键是聚簇索引（一种索引类型，数据与索引数据放在一起），既然数据和索引数据放在一起，那么在数据插入或者更新的时候，那么在数据插入或者更新的时候，我们需要找到要插入的位置，再把数据写到特定的位置上，这就产生了随机的 IO，而innodb存储引擎采用的是B+树的结果存储索引，一旦发生了页分裂，就不可避免会做数据的移动，也会极大地损耗写入性能,但是如果使用mysql的自增，则在分库分表下无法保证主键id的唯一性，因此我们采用twitter的snowflake算法来生成分布式的唯一id。 snowflake算法snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。41为的时间戳大概可以生成69年((2^41)/1000/60/60/24/365),10bit的工作机器id可以支持1024(2^10)台机器，序列号支持1毫秒产生4096(2^12)个自增序列id 算法java实现Twitter在github上提供了scala的实现版本,以下版本是根据scala转换成java的版本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package com.liu;public class IdWorker&#123; private long workerId; private long datacenterId; private long sequence; //开始时间,比如我想从2000-1-1开始生成日期就填入2000-1-1的时间 private long twepoch = 1288834974657L; /** * * @param workerId 机器id(占用5比特，最大为31) * @param datacenterId 机房id（占用5比特） * @param sequence (12位序列号起始编号) * long twepoch 参数开始时间,比如我想从2000-1-1开始生成日期就填入2000-1-1的时间 */ public IdWorker(long workerId, long datacenterId, long sequence)&#123; // sanity check for workerId if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;worker Id can&apos;t be greater than %d or less than 0&quot;,maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;datacenter Id can&apos;t be greater than %d or less than 0&quot;,maxDatacenterId)); &#125; System.out.printf(&quot;worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d&quot;, timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId); this.workerId = workerId; this.datacenterId = datacenterId; this.sequence = sequence; &#125; private long workerIdBits = 5L; private long datacenterIdBits = 5L; private long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); private long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); private long sequenceBits = 12L; private long workerIdShift = sequenceBits; private long datacenterIdShift = sequenceBits + workerIdBits; private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; private long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); private long lastTimestamp = -1L; public long getWorkerId()&#123; return workerId; &#125; public long getDatacenterId()&#123; return datacenterId; &#125; public long getTimestamp()&#123; return System.currentTimeMillis(); &#125; public synchronized long nextId() &#123; long timestamp = timeGen(); if (timestamp &lt; lastTimestamp) &#123; System.err.printf(&quot;clock is moving backwards. Rejecting requests until %d.&quot;, lastTimestamp); throw new RuntimeException(String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp)); &#125; if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; if (sequence == 0) &#123; timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123; sequence = 0; &#125; lastTimestamp = timestamp; return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift) | (workerId &lt;&lt; workerIdShift) | sequence; &#125; private long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; private long timeGen()&#123; return System.currentTimeMillis(); &#125; //---------------测试--------------- public static void main(String[] args) &#123; IdWorker worker = new IdWorker(3,1,1); for (int i = 0; i &lt; 30; i++) &#123; System.out.println(worker.nextId()); &#125; &#125;&#125;]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>snowflake</tag>
        <tag>唯一id</tag>
        <tag>数据库主键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用sharding-jdbc实现mysql的分库分表并主从读写分离]]></title>
    <url>%2F2019%2F10%2F14%2F%E4%BD%BF%E7%94%A8sharding-jdbc%E5%AE%9E%E7%8E%B0mysql%E7%9A%84%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%B9%B6%E4%B8%BB%E4%BB%8E%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[简介之前的文章中提到了使用sharding-jdbc进行读写分离和分库分表，本文将使用sharding-jdbc并且使用-《使用sharding-jdbc实现mysql的分库分表》这篇文章中的代码，将分库分表和读写分离结结合起来。 配置mysql从库具体步骤依照《hive mysql元数据表单的主从备份》一文配置好主备,举例一下是主库配置,复制主库的test,user_1,user_2数据库到 123456server-id=1log-bin=mysql-binbinlog-do-db=testbinlog-do-db=user_1binlog-do-db=user_2log-slave-updates=1 从库配置,复制主库的test,user_1,user_2数据库 12345server-id=2#read_only=1replicate-do-db=testreplicate-do-db=user_1replicate-do-db=user_2 修改application.properties配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889spring.shardingsphere.datasource.names=master0,master1,master0slave0,master1slave0spring.shardingsphere.datasource.master0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.master0.jdbc-url=jdbc:mysql://192.168.171.76:3306/user_1?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.master0.username=rootspring.shardingsphere.datasource.master0.password=Liush123!@#spring.shardingsphere.datasource.master0.minimum-idle=10spring.shardingsphere.datasource.master0.maximum-pool-size=10spring.shardingsphere.datasource.master0.pool-name=masterHikariCPspring.shardingsphere.datasource.master1.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master1.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.master1.jdbc-url=jdbc:mysql://192.168.171.76:3306/user_2?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.master1.username=rootspring.shardingsphere.datasource.master1.password=Liush123!@#spring.shardingsphere.datasource.master1.minimum-idle=10spring.shardingsphere.datasource.master1.maximum-pool-size=10spring.shardingsphere.datasource.master1.pool-name=masterHikariCP2spring.shardingsphere.datasource.master0slave0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master0slave0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.master0slave0.jdbc-url=jdbc:mysql://192.168.171.77:3306/user_1?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.master0slave0.username=rootspring.shardingsphere.datasource.master0slave0.password=Liush123!@#spring.shardingsphere.datasource.master0slave0.minimum-idle=10spring.shardingsphere.datasource.master0slave0.maximum-pool-size=10spring.shardingsphere.datasource.master0slave0.pool-name=slaveHikariCPspring.shardingsphere.datasource.master1slave0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master1slave0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.master1slave0.jdbc-url=jdbc:mysql://192.168.171.77:3306/user_2?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.master1slave0.username=rootspring.shardingsphere.datasource.master1slave0.password=Liush123!@#spring.shardingsphere.datasource.master1slave0.minimum-idle=10spring.shardingsphere.datasource.master1slave0.maximum-pool-size=10spring.shardingsphere.datasource.master1slave0.pool-name=slaveHikariCP2spring.shardingsphere.sharding.default-database-strategy.inline.sharding-column=user_id_spring.shardingsphere.sharding.default-database-strategy.inline.algorithm-expression=master$-&gt;&#123;user_id_ % 2&#125;#如果不#如果不设置此参数，会产生笛卡尔积查询，使效率大大减慢（表间绑定，比如这里相同的orderID的t_order和t_order_item会划分到同一分片下，这样就不会产生笛卡尔积查询）spring.shardingsphere.sharding.binding-tables=t_order,t_order_itemspring.shardingsphere.sharding.broadcast-tables=t_addressspring.shardingsphere.sharding.tables.t_user.actual-data-nodes=master$-&gt;&#123;0..1&#125;.t_user_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_user.table-strategy.inline.sharding-column=user_id_spring.shardingsphere.sharding.tables.t_user.table-strategy.inline.algorithm-expression=t_user_$-&gt;&#123;user_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_user.key-generator.column=user_id_spring.shardingsphere.sharding.tables.t_user.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_user.key-generator.props.worker.id=123spring.shardingsphere.sharding.tables.t_order.actual-data-nodes=master$-&gt;&#123;0..1&#125;.t_order_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=order_id_spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order_$-&gt;&#123;order_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id_spring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_order.key-generator.props.worker.id=123spring.shardingsphere.sharding.tables.t_order_item.actual-data-nodes=master$-&gt;&#123;0..1&#125;.t_order_item_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.sharding-column=order_id_spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.algorithm-expression=t_order_item_$-&gt;&#123;order_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_order_item.key-generator.column=order_item_id_spring.shardingsphere.sharding.tables.t_order_item.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_order_item.key-generator.props.worker.id=123# 显示执行sqlspring.shardingsphere.props.sql.show=true## 注意这段代码和官方提供的日志不一致，官方提供的配置文件中master0，master1并没有使用，spring.shardingsphere.datasource.names中配置的源，但是实测中不使用spring.shardingsphere.datasource.names中配置的源配置的数据源会报 org.apache.shardingsphere.core.exception.ShardingException: Cannot find data source in sharding rule, invalid actual data nodespring.shardingsphere.sharding.master-slave-rules.master0.master-data-source-name=master0spring.shardingsphere.sharding.master-slave-rules.master0.slave-data-source-names=master0slave0spring.shardingsphere.sharding.master-slave-rules.master1.master-data-source-name=master1spring.shardingsphere.sharding.master-slave-rules.master1.slave-data-source-names=master1slave0 测试方法执行使用sharding-jdbc实现mysql的分库分表中的findOrderItem方法 12@Select(&quot;select item_name_ from t_order t1 inner join t_order_item t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( #&#123;orderId1&#125;,#&#123;orderId2&#125; )&quot;) List&lt;String&gt; findOrderItem(@Param(&quot;orderId1&quot;)long orderId1,@Param(&quot;orderId2&quot;)long orderId2); 查看打印代码,发现所有的读都已经分发到配置的读节点中了 122019-10-14 09:50:04.045 INFO 12276 --- [ main] ShardingSphere-SQL : Actual SQL: master0slave0 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608]2019-10-14 09:50:04.046 INFO 12276 --- [ main] ShardingSphere-SQL : Actual SQL: master1slave0 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608] 事务本地事务在不开启任何分布式事务管理器的前提下，让每个数据节点各自管理自己的事务。 它们之间没有协调以及通信的能力，也并不互相知晓其他数据节点事务的成功与否。 本地事务在性能方面无任何损耗，但在强一致性以及最终一致性方面则力不从心。 完全支持非跨库事务，例如：仅分表，或分库但是路由的结果在单库中。 完全支持因逻辑异常导致的跨库事务。例如：同一事务中，跨两个库更新。更新完毕后，抛出空指针，则两个库的内容都能回滚。 不支持因网络、硬件异常导致的跨库事务。例如：同一事务中，跨两个库更新，更新完毕后、未提交之前，第一个库宕机，则只有第二个库数据提交。 我们查看本地事务提交代码就可看到，如果我们的事务是在commit阶段发生异常，则事务不会生效，如果是发生在预编译PreparedStatement阶段，也就是语句错误，或者业务逻辑异常，这些异常在进入commit方法前就已经跑出则事务生效,所以在不引入分布式事务时，应该保证一次事务提交是在单库中进行的，比如订单，和订单明细都分片到一个库中 1234567891011121314public abstract class AbstractConnectionAdapter extends AbstractUnsupportedOperationConnection &#123; @Override public final void commit() throws SQLException &#123; Collection&lt;SQLException&gt; exceptions = new LinkedList&lt;&gt;(); for (Connection each : cachedConnections.values()) &#123; try &#123; each.commit(); &#125; catch (final SQLException ex) &#123; exceptions.add(ex); &#125; &#125; throwSQLExceptionIfNecessary(exceptions); &#125;&#125;]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>sharding-jdbc</tag>
        <tag>mysql分库分表</tag>
        <tag>mysql读写分离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用sharding-jdbc实现mysql的分库分表]]></title>
    <url>%2F2019%2F10%2F11%2F%E4%BD%BF%E7%94%A8sharding-jdbc%E5%AE%9E%E7%8E%B0mysql%E7%9A%84%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[简介之前提到的用sharding-jdbc对mysql进行读写分离可以很好的处理在读远远大于写的情况下的并发问题，但是无法突破写入大量数据造成性能下降的问题，在数据量达到千万甚至亿级别时，内存可能已经无法缓存全部索引，就要从硬盘中读取索引，这时即便再怎么优化也难免造成性能下降的问题，这时我们需要对数据进行分库分表，mysql中提供了分区功能，但是无法突破单机性能瓶颈,这里我们使用sharding-jdbc来实现分库分表功能。 核心概念简介逻辑表水平拆分的数据库（表）的相同逻辑和数据结构表的总称。例：订单数据根据主键尾数拆分为10张表，分别是t_order_0到t_order_9，他们的逻辑表名为t_order。 真实表在分片的数据库中真实存在的物理表。即上个示例中的t_order_0到t_order_9。 绑定表指分片规则一致的主表和子表。例如：t_order表和t_order_item表，均按照order_id分片，则此两张表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。举例说明，如果SQL为： 1SELECT i.* FROM t_order o JOIN t_order_item i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 在不配置绑定表关系时，假设分片键order_id将数值10路由至第0片，将数值11路由至第1片，那么路由后的SQL应该为4条，它们呈现为笛卡尔积： 1234567SELECT i.* FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11);SELECT i.* FROM t_order_0 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11);SELECT i.* FROM t_order_1 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11);SELECT i.* FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 在配置绑定表关系后，路由的SQL应该为2条： 123SELECT i.* FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11);SELECT i.* FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 其中t_order在FROM的最左侧，ShardingSphere将会以它作为整个绑定表的主表。 所有路由计算将会只使用主表的策略，那么t_order_item表的分片计算将会使用t_order的条件。故绑定表之间的分区键要完全相同。 广播表指所有的分片数据源中都存在的表，表结构和表中的数据在每个数据库中均完全一致。适用于数据量不大且需要与海量数据的表进行关联查询的场景，例如：字典表。 创建数据库在mysql中创建两个数据库user_1和user_2,并且在这两个数据库中分别创建以下测试表 地址表（用于测试广播） 1234CREATE TABLE `t_address` ( `id_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic; 用户表(用于测试分库分区) 12345678910CREATE TABLE `t_user_0` ( `user_id_` bigint(255) NULL DEFAULT NULL, `name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;CREATE TABLE `t_user_1` ( `user_id_` bigint(255) NULL DEFAULT NULL, `name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic; 订单表和订单明细表(用于测试绑定表) 1234567891011121314151617181920212223242526272829303132CREATE TABLE `t_order_0` ( `order_id_` bigint(255) NULL DEFAULT NULL, `order_name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `user_id_` int(255) NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;CREATE TABLE `t_order_1` ( `order_id_` bigint(255) NULL DEFAULT NULL, `order_name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `user_id_` int(255) NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;CREATE TABLE `t_order_item_0` ( `order_item_id_` bigint(255) NULL DEFAULT NULL, `item_name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `user_id_` int(255) NULL DEFAULT NULL, `order_id_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;CREATE TABLE `t_order_item_1` ( `order_item_id_` bigint(255) NULL DEFAULT NULL, `item_name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `user_id_` int(255) NULL DEFAULT NULL, `order_id_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic; 创建maven工程关于sharding-jdbc打包参考之前sharding-jdbc主从分离文章 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;dependencies&gt; &lt;!-- for spring namespace --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-namespace&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 创建application.properties配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263spring.shardingsphere.datasource.names=ds0,ds1#创建数据源spring.shardingsphere.datasource.ds0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.ds0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.ds0.jdbc-url=jdbc:mysql://192.168.171.76:3306/user_1?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.ds0.username=rootspring.shardingsphere.datasource.ds0.password=Liush123!@#spring.shardingsphere.datasource.ds0.minimum-idle=10spring.shardingsphere.datasource.ds0.maximum-pool-size=10spring.shardingsphere.datasource.ds0.pool-name=HikariCP1spring.shardingsphere.datasource.ds1.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.ds1.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.ds1.jdbc-url=jdbc:mysql://192.168.171.76:3306/user_2?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.ds1.username=rootspring.shardingsphere.datasource.ds1.password=Liush123!@#spring.shardingsphere.datasource.ds1.minimum-idle=10spring.shardingsphere.datasource.ds1.maximum-pool-size=10spring.shardingsphere.datasource.ds1.pool-name=HikariCP2# 设置分库键和分库算法spring.shardingsphere.sharding.default-database-strategy.inline.sharding-column=user_id_spring.shardingsphere.sharding.default-database-strategy.inline.algorithm-expression=ds$-&gt;&#123;user_id_ % 2&#125;#设置绑定表规则#如果不#如果不设置此参数，会产生笛卡尔积查询，使效率大大减慢（表间绑定，比如这里相同的orderID的t_order和t_order_item会划分到同一分片下，这样就不会产生笛卡尔积查询）spring.shardingsphere.sharding.binding-tables=t_order,t_order_item#设置广播表spring.shardingsphere.sharding.broadcast-tables=t_address#设置t_user表分片规则，和主键生成规则（主键生成规则采用SNOWFLAKE）spring.shardingsphere.sharding.tables.t_user.actual-data-nodes=ds$-&gt;&#123;0..1&#125;.t_user_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_user.table-strategy.inline.sharding-column=user_id_spring.shardingsphere.sharding.tables.t_user.table-strategy.inline.algorithm-expression=t_user_$-&gt;&#123;user_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_user.key-generator.column=user_id_spring.shardingsphere.sharding.tables.t_user.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_user.key-generator.props.worker.id=123#设置t_order分片规则，和主键生成规则（主键生成规则采用SNOWFLAKE）spring.shardingsphere.sharding.tables.t_order.actual-data-nodes=ds$-&gt;&#123;0..1&#125;.t_order_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=order_id_spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order_$-&gt;&#123;order_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id_spring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_order.key-generator.props.worker.id=123#设置t_order_item分片规则，和主键生成规则（主键生成规则采用SNOWFLAKE）spring.shardingsphere.sharding.tables.t_order_item.actual-data-nodes=ds$-&gt;&#123;0..1&#125;.t_order_item_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.sharding-column=order_id_spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.algorithm-expression=t_order_item_$-&gt;&#123;order_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_order_item.key-generator.column=order_item_id_spring.shardingsphere.sharding.tables.t_order_item.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_order_item.key-generator.props.worker.id=123# 显示执行sqlspring.shardingsphere.props.sql.show=true 编写mybatis测试代码1234567891011121314@Insert(&quot;insert into t_user(name_) values(#&#123;name&#125;)&quot;)void insertUserShardingByName(@Param(&quot;name&quot;)String name);@Insert(&quot;insert t_address(id_,name_) values(#&#123;id&#125;,#&#123;name&#125;)&quot;)void insertAddress(@Param(&quot;id&quot;)String id,@Param(&quot;name&quot;)String name);@Insert(&quot;insert into t_order(order_name_,user_id_) values(#&#123;name&#125;,#&#123;userId&#125;)&quot;)void insertOrder(@Param(&quot;userId&quot;)int userId,@Param(&quot;name&quot;)String name);@Insert(&quot;insert into t_order_item(item_name_,user_id_,order_id_) values(#&#123;name&#125;,#&#123;userId&#125;,#&#123;orderId&#125;)&quot;)void insertItem(@Param(&quot;userId&quot;)int userId,@Param(&quot;name&quot;)String name,@Param(&quot;orderId&quot;) Long orderId);@Select(&quot;select item_name_ from t_order t1 inner join t_order_item t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( #&#123;orderId1&#125;,#&#123;orderId2&#125; )&quot;)List&lt;String&gt; findOrderItem(@Param(&quot;orderId1&quot;)long orderId1,@Param(&quot;orderId2&quot;)long orderId2); 执行结果 insertUserShardingByName执行此代码数据库会自动根据之前配置的SNOWFLAKE的策略生成分布式唯一主键，在对应的库和对应的表中插入数据 insertAddress插入广播数据在所有的库中的t_address表都插入数据，因为是广播表(类似与字典，所以不会分表分区) insertOrder和insertItem在对应设置的库和分表中插入语句 findOrderItem我们重点看一下这个执行结果,这里我们做了一个t_order表和t_order_item的连表查询，这两张表使用oder_id_进行关联，并且在配置文件中配置了这两张表Z为绑定关系(spring.shardingsphere.sharding.binding-tables=t_order,t_order_item),我们执行查询语句在日志中发现一下信息 12Actual SQL: ds0 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? )Actual SQL: ds1 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) 发现其只是在各个分库中对对应的分片进行了连表查询(因为我们传入的order_id_根据我们的分片方式都在分片0上)，并没有进行笛卡尔积查询，现在我们注释掉spring.shardingsphere.sharding.binding-tables=t_order,t_order_item，不设置表间绑定，我们查看日志,发现产生了笛卡尔积查询，所以必须配置spring.shardingsphere.sharding.binding-tables参数，不然查询效率很有可能比单表更慢 12342019-10-12 10:37:19.557 INFO 2632 --- [ main] ShardingSphere-SQL : Actual SQL: ds0 ::: select item_name_ from t_order_0 t1 inner join t_order_item_1 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608]2019-10-12 10:37:19.557 INFO 2632 --- [ main] ShardingSphere-SQL : Actual SQL: ds0 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608]2019-10-12 10:37:19.557 INFO 2632 --- [ main] ShardingSphere-SQL : Actual SQL: ds1 ::: select item_name_ from t_order_0 t1 inner join t_order_item_1 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608]2019-10-12 10:37:19.557 INFO 2632 --- [ main] ShardingSphere-SQL : Actual SQL: ds1 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608] 问题与思考分库分表的瓶颈传统数据库的分库分表很多都是依赖于中间件去实现的，不同于new sql(tidb)，或者nosql(mongo,hdfs)，这些数据库或者组件提供了auto sharding的特性，即系统可以自动对数据进行分区分片并完成数据平衡，当系统扩展后(增加计算节点)，这些系统会自动将数据再平衡，可以实现0维护扩展节点（只需当初的将节点加入集群其余的什么也不用做），传统数据库进行扩展需要重新手动对数据进行迁移，重新设计分片(如上文如果我们根据userId将2个库扩展为3个库那么原来的分库策略就不能使用了，因为运来采用分库策略是对userId和2进行取模运算{user_id_ % 2}，如果改成3个节点那么算法就要改成{user_id_ % 3}，那么需要手动将原来的数据做再平衡，将匹配的数据分配到第三台节点上)，所以使用关系型数据库做分库分片最好一次性就计划好未来的数据量，最好节点的规划.还有一个问题就是分片键的问题，为了查询能准确定位到数据所在的分片，每次查询时都要带上分片键，那么就会产生这么一个问题，如果现在有需求需要根据用户名查询用户数据，那么怎么办？因为数据都是根据userId进行分库分片的，这种情况下我们可以建立一张用户名和userId的映射表，这张表也可以进行分库分表，这张表根据用户名进行hash运算后进行分库分表，这样我们就可以先通过用户名，用户id关系表进行查询到用户id后，再根据用户id获取用户信息。 什么情况下对数据进行分库分表只有在有需要的情况下才对数据进行分库分表，分库分表比单表会带来很多限制，比如数据的join查询等（因为分片的原因需要考虑查询效率）,或者限制要在根据用户id进行分片的数据中对用户名进行模糊查询怎么办？有些时候就要对业务进行一些妥协，或者采用其它方案去解决如NOSQL，同时分表分库也带来了复杂度的提升，维护难度的提升.]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>sharding-jdbc</tag>
        <tag>mysql分库分表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用sharding-jdbc实现mysql的读写分离]]></title>
    <url>%2F2019%2F10%2F10%2F%E4%BD%BF%E7%94%A8sharding-jdbc%E5%AE%9E%E7%8E%B0mysql%E7%9A%84%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[简介在读数据远远大于写数据时，且写数据连在千万级别，为了扩展数据库的可读性可以采用数据库的读写分离结构来减轻读数据的压力。其实现方案就是利用数据库的主备，将读请求分发到各个从库中，来减轻读压力，实现这部分方案往往依赖中间件去屏蔽数据库访问信息(开发者像使用单数据源一样进行开发),而这类中间件又可以分为两部分，一部分为植入应用程序，通常为jar包，如淘宝的 TDDL，在访问数据源时由植入的中间件完成对数据请求的分发，将读请求分发到不同的数据库中，采用这部分中间的优点是简单易用，缺点是不能跨语言去使用。还有一部分中间件为独立部署到服务器中，应用程序去访问这部分服务，然后由服务去完成请求的处理和转发。sharding-jdbc（现在托管给Apache改名为ShardingSphere）兼备了这两种功能，这里我们使用ShardingSphere的sharding-jdbc模块来植入应用程序来实现一个读写分离的应用。 配置mysql主从这部分可以参考之前hive分类下的hive mysql元数据表单的主从备份这篇文章 下载sharding-jdbc源码并编译打包https://shardingsphere.apache.org/document/current/cn/downloads/下载完毕后使用maven在父目录下执行maven clean install将源码打包并安装到本地仓库,在打包过程中会遇到一些问题，可以查看下文问题一节. 在主库中创建测试表这张表中简单的创建了一张用户表包含了一个id字段和一个name字段 12345CREATE TABLE `t_user` ( `id_` int(255) UNSIGNED NOT NULL AUTO_INCREMENT, `name_` varchar(255) , PRIMARY KEY (`id_`)) 创建SpringBoot工程并且引入sharding-jdbc 引入sharding-jdbc-spring,mysql驱动，mybatis依赖 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;!-- for spring namespace --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-namespace&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置application.properties配置文件,配置连接池和数据源设置主从数据源，和配置主从节点 1234567891011121314151617181920212223242526272829303132#配置数据源名字spring.shardingsphere.datasource.names=master,slave0#配置数据源和连接池spring.shardingsphere.datasource.master.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.master.jdbc-url=jdbc:mysql://192.168.171.76:3306/test?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.master.username=rootspring.shardingsphere.datasource.master.password=Liush123!@#spring.shardingsphere.datasource.master.minimum-idle=10spring.shardingsphere.datasource.master.maximum-pool-size=10spring.shardingsphere.datasource.master.pool-name=masterHikariCPspring.shardingsphere.datasource.slave0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.slave0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.slave0.jdbc-url=jdbc:mysql://192.168.171.77:3306/test?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.slave0.username=rootspring.shardingsphere.datasource.slave0.password=Liush123!@#spring.shardingsphere.datasource.slave0.minimum-idle=10spring.shardingsphere.datasource.slave0.maximum-pool-size=10spring.shardingsphere.datasource.slave0.pool-name=slave0HikariCPspring.shardingsphere.masterslave.name=ms# 配置主节点spring.shardingsphere.masterslave.master-data-source-name=master# 多个从节点逗号分隔spring.shardingsphere.masterslave.slave-data-source-names=slave0# 显示执行sqlspring.shardingsphere.props.sql.show=true 编写mybaits测试代码12345678910111213141516171819202122package com.liu;import org.apache.ibatis.annotations.Insert;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Param;import org.apache.ibatis.annotations.Select;/** * @author Liush * @description * @date 2019/10/10 17:20 **/@Mapperpublic interface UserMapper &#123; @Select(&quot;select name_ from t_user where id_=#&#123;id&#125;&quot;) String findUserNameBy(@Param(&quot;id&quot;) String id); @Insert(&quot;insert into t_user(name_) values(#&#123;name&#125;) &quot;) void insertUser(@Param(&quot;name&quot;)String name);&#125; 编写Springboot 测试方法1234567891011121314151617181920212223242526272829303132333435package com.liu;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;/** * @author Liush * @description * @date 2019/10/10 17:22 **/@RunWith(SpringRunner.class)@SpringBootTestpublic class AppTest &#123; @Autowired private UserMapper userMapper; @Test public void findUser()&#123; userMapper.findUserNameBy(&quot;1&quot;); &#125; @Test public void insertUser()&#123; userMapper.insertUser(&quot;liuSH&quot;); &#125;&#125; 执行insertUser方法在控制台打印日志中我们发现插入数据永远都是在主节点中进行 1SQL: insert into t_user(name_) values(?) ::: DataSources: master 执行findUser 查询数据永远都是在从节点中进行*1SQL: select name_ from t_user where id_=? ::: DataSources: slave0 由此可见我们采用中间件实现了数据库的主从读写分离 问题maven打包问题在windows下用maven将ShardingSphere部署到本地仓库执行 install命令时出现 1MavenReportException: Error while generating Javadoc: 这里我们跳过javadoc生成 1mvn clean install -Dmaven.javadoc.skip=true -Dmaven.test.skip=true -Pbpfle 这时候又出现 1Unknown lifecycle phase &quot;.javadoc.skip=true&quot;. You must specify a valid lifecycle phase or a goal in the format &lt;plugin-prefix&gt;:&lt;goal&gt; or &lt;plugin-group-id&gt;:&lt;plugin-artifact-id&gt;[:&lt;plugin-version&gt;]:&lt;goal&gt;. 这是由于在windows下.具有其它含义，我们在点前加入`解决问题 1mvn clean install `-Dmaven`.javadoc`.skip=true `-Dmaven`.test`.skip=true `-Pbpfle]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>sharding-jdbc</tag>
        <tag>mysql读写分离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot中使用HikariCP连接池]]></title>
    <url>%2F2019%2F10%2F09%2FSpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8HikariCP%E8%BF%9E%E6%8E%A5%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[简介数据库连接池是为了规避每次查询时都向数据库建立连接而采用的技术，而向数据库创建连接往往比一次简单的查询所耗费的时间多好几倍，采用连接池在项目中可以有效的提升数据库查询的响应速度，而在SpringBoot中的spring-boot-starter-jdbc模块中又默认集成了HikariCP连接池，使我们很方便的在Springboot中使用数据库连接池.注意一下，由于本人使用的是mybatis持久化框架，HikariCP的依赖包含在spring-boot-starter-jdbc模块中，而mybatis-spring-boot-starter又包含了spring-boot-starter-jdbc，所以只需要引入mybatis-spring-boot-starter即可 引入maven POM依赖12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 本人新建SpringBoot Web项目，也可只创建SpringBoot项目 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置application.properties文件连接池中最重要两个配置，最小连接数和最大连接数 spring.datasource.hikari.minimum-idle 最小空闲连接数量 spring.datasource.hikari.maximum-pool-size 连接池最大连接数 如果当前连接数小于最小连接数，则创建新的连接处理数据库请求 如果连接池中有空闲连接则复用空闲连接； 如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接 如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间（HikariCP中为connectionTimeout）等待旧的连接可用 如果等待超过了这个设定时间则向用户抛出错误。 使用mysql中有一点需要注意，就是mysql中wait_timeout参数控制了一个连接多长时间后将会被回收，所以我们将max-lifetime参数设置的比mysql中的这个参数值稍微小写 connection-test-query,此参数为在应用程序每次获取连接池连接时都会去执行一下语句，如果正常，则使用这个个连接，但是在官网的简介中新版本的jdbc不再推荐使用这个参数，而是自动会调用jdbc4接口中的Connection.isValid()方法去判断连接是否可用，因此我们去除这个参数 1234567891011121314151617181920212223242526spring.datasource.url=jdbc:mysql://127.0.0.1:3306/mytest?serverTimezone=UTCspring.datasource.username=rootspring.datasource.password=rootspring.datasource.driver-class-name=com.mysql.jdbc.Driver## Hikari 连接池配置 ------ 详细配置请访问：https://github.com/brettwooldridge/HikariCP## 最小空闲连接数量spring.datasource.hikari.minimum-idle=10## 空闲连接存活最大时间，默认600000（10分钟）spring.datasource.hikari.idle-timeout=180000## 连接池最大连接数，默认是10spring.datasource.hikari.maximum-pool-size=20## 此属性控制从池返回的连接的默认自动提交行为,默认值：truespring.datasource.hikari.auto-commit=true## 连接池的用户定义名称，主要出现在日志记录和JMX管理控制台中以识别池和池配置spring.datasource.hikari.pool-name=MyHikariCP## 此属性控制池中连接的最长生命周期，值0表示无限生命周期，默认1800000即30分钟,如果是mysql可以将值配置的比mysql中wait_timeout参数稍小些spring.datasource.hikari.max-lifetime=1800000## 数据库连接超时时间,默认30秒，即30000spring.datasource.hikari.connection-timeout=30000## 如果支持驱动jdbc4不要设置#spring.datasource.hikari.connection-test-query=SELECT 1]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>HikariCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么不允许在高并发下使用JDK中的Executors去创建线程池]]></title>
    <url>%2F2019%2F10%2F09%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%85%81%E8%AE%B8%E4%BD%BF%E7%94%A8JDK%E4%B8%AD%E7%9A%84Executors%E5%8E%BB%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[简介Executors 是JDK 1.5中提供的一个创建线程池的建议类，其是对ThreadPoolExecutor进行了一次封装，屏蔽了ThreadPoolExecutor复杂的参数，简单使用且暴力。Executors提供了3种线程池分别为newCachedThreadPool(无固定大小线程池,如果线程空闲时间超过60s则回收),固定线程池newFixedThreadPool,和单一线程池newSingleThreadExecutor(只有一个线程)，相比使用ThreadPoolExecutor，Executors虽然也是使用ThreadPoolExecutor去创建线程池，但是其给ThreadPoolExecutor提供了默认参数，这就使我们在使用Executors时比ThreadPoolExecutor简单的多得多，往往只有传入一个创建线程的个数参数即可，但就是由于其屏蔽了ThreadPoolExecutor的细节导致在使用Executors在处理大量任务时存在OOM的隐患，所以在阿里巴巴编程规范中明确禁止使用Executors去创建线程池，我们可以通过查看api和查看Executors代码可以得知为什么会这样. ThreadPoolExecutorapi中关于ThreadPoolExecutor构造方法的解释1234567891011121314151617public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 参数： corePoolSize - 池中所保存的线程数，包括空闲线程。 maximumPoolSize - 池中允许的最大线程数。 keepAliveTime - 当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间。 unit - keepAliveTime 参数的时间单位。 workQueue - 执行前用于保持任务的队列。此队列仅保持由 execute 方法提交的 Runnable 任务。 threadFactory - 执行程序创建新线程时使用的工厂。 handler - 由于超出线程范围和队列容量而使执行被阻塞时所使用的处理程序。 ThreadPoolExecutor执行流程，当需要线程时调用参数中的ThreadFactory方法去创建线程，JDK中提供了默认的工具类去创建默认的线程工程Executors.defaultThreadFactory(),其有一个newThread方法去创建一个线程，在实际使用中我们可以自行实现线程工程(修改线程名字等)，方便后续日志追踪线程信息 12345678910public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125; 在创建线程时会先去判断当前活动的线程数是否达到corePoolSize设置的数量，如果没有的话则调用ThreadFactory去新建线程，如果当前正在使用执行任务的线程已经达到corePoolSize设置的数量，则将任务存放到构造方法中设置的BlockingQueue workQueue队列中,如果BlockingQueue使用的无解队列如LinkedBlockingDeque的话，那么等待执行的任务就会无限往无界队列中添加，如果使用的是有界队列的话如ArrayBlockingQueue,当任务数达到有界队列的数量后，如果目前执行任务的线程数量小于maximumPoolSize设置的线程数量则继续创建线程执行任务，直到线程数到达设置的maximumPoolSize时，执行拒绝策略RejectedExecutionHandler中实现的方法丢弃任务。 以下是线程执行的流程图 Executors Executors创建3种线程池的构造方法 12345678910111213141516171819202122public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; Executors存在的问题如果你认真查看上文关于，也许你就会发现一些问题 在newCachedThreadPool中maximumPoolSize最大数量为Integer.MAX_VALUE，那么根据上文所说，如果线程有大量任务需要执行，那么会不断的开启新的线程直到线程数达到Integer.MAX_VALUE，但是往往还没达到这个线程数，服务器就OOM了。 编写测试代码 首先编写一个拒绝处理器类RejectedExecutionHandler的实现,其功能为当执行队列已满且执行线程数已经达到设置的最大线程时打印文字 123456789101112131415161718package com.liu;import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadPoolExecutor;/** * @author Liush * @description * @date 2019/10/9 9:46 **/public class MyRejectedExecutionHandler implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; System.out.println(&quot;线程队列已满，且线程数已达最大线程数&quot;); &#125;&#125; 创建线程池，且设置参数,我们设置了一个10个大小的队列，为了方便查看拒绝执行线程时调用RejectedExecutionHandler中的代码我们设置了最小线程数为1，最大线程数为2 123456789101112131415161718192021222324252627282930313233343536package com.liu;import java.util.concurrent.*;/** * @author Liush * @description * @date 2019/10/9 9:40 **/public class ThreadPoolTest &#123; public static void main(String[] args) &#123; BlockingQueue&lt;Runnable&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;(10); ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(1, 2, 5000, TimeUnit.MILLISECONDS, blockingQueue, Executors.defaultThreadFactory(), new MyRejectedExecutionHandler()); for (int i = 0; i &lt; 100; i++) &#123; threadPoolExecutor.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(&quot;阻塞队列中有待执行任务个数&quot; + blockingQueue.size()); Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125;&#125; 执行结果,我们看到了任务出现了大量失败，因为我们将最大线程数设置为2，且队列大小设置为10，所以最多同时处理12个任务(2个任务正在执行，其余10个在队列中)，直到最后当循环快结束时（此时大量任务已经被丢弃），阻塞队列中的任务数量才降低 12345678910111213141516171819202122232425线程队列已满，且线程数已达最大线程数阻塞队列中有待执行任务个数10线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数阻塞队列中有待执行任务个数10线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数...阻塞队列中有待执行任务个数9阻塞队列中有待执行任务个数8阻塞队列中有待执行任务个数6阻塞队列中有待执行任务个数6阻塞队列中有待执行任务个数4阻塞队列中有待执行任务个数4阻塞队列中有待执行任务个数3阻塞队列中有待执行任务个数2阻塞队列中有待执行任务个数1阻塞队列中有待执行任务个数0 SynchronousQueue SynchronousQueue实现了BlockingQueue，BlockingQueue的实现类都是安全线程的 SynchronousQueue是阻塞队列，只能单进单出，也就是说多个线程调用queue的put或者offer方法只能有一个线程往里插入元素，除非消费者take出元素后才能继续插入元素。 BlockingQueue插入元素和移除元素有4种方法，分别对应当队列为空或者队列已满时不同的生产策略和消费策略 操作 抛出异常（当队列已满或者这队列为空） 特殊值（当队列已满或者这队列为空） 阻塞（当队列已满或者这队列为空） 超时（当队列已满或者这队列为空） 插入 add(e) offer(e) put(e) offer(e, time, unit) 移除 remove() poll() take() poll(time, unit) 检查 element() peek() 不可用 不可用 由上文可知我们在Executors中的 newCachedThreadPool中使用的是SynchronousQueue队列，也就是说当多个线程一起往SynchronousQueue调用offer返回时会返回false，从而使线程池开启新的线程，又由于newCachedThreadPool将 maximumPoolSize（池中允许的最大线程数）设置为Integer.MAX_VALUE，从而导致在大规模并发下导致OOM，以下是ThreadPoolExecutor中execute方法的源码，其注释和代码描述上述ThreadPoolExecutor的执行策略 123456789101112131415161718192021222324252627282930313233343536373839public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&apos;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; SynchronousQueue的公平队列,虽然SynchronousQueue只允许只有一个元素，但是其却可以维护一个公平队列，在新建SynchronousQueue实例时在构造方法中传入true即可，这个公平队列的作用就是按照线程玩队列插入元素的先后顺序插入元素，实践代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.liu;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.SynchronousQueue;/** * @author Liush * @description * @date 2019/10/9 14:03 **/public class QueueTest &#123; public static void main(String[] args) throws Exception&#123; //不使用公平队列 SynchronousQueue&lt;String&gt; synchronousQueue=new SynchronousQueue(); //使用公平队列 //SynchronousQueue&lt;String&gt; synchronousQueue=new SynchronousQueue(true); ExecutorService executorService =Executors.newCachedThreadPool(); executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; synchronousQueue.put(&quot;1&quot;); Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); Thread.sleep(1000); executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; synchronousQueue.put(&quot;2&quot;); Thread.sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); Thread.sleep(1000); executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; synchronousQueue.put(&quot;3&quot;); Thread.sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); Thread.sleep(1000); executorService.execute(new Runnable() &#123; @Override public void run() &#123; while (true)&#123; try &#123; System.out.println(synchronousQueue.take() +&quot;消费&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;); &#125;&#125; 上述代码开启了3个生产者，开启期间线程睡眠了1秒，保证其先后调用顺序，以下结果是我们不使用公平队列的情况的生产者输出，我们看到消费者并没有满足先进先出的原则， 1233消费2消费1消费 如果我们使用公平队列，结果如下,满足了队列先进先出的原则 1231消费2消费3消费]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Executors</tag>
        <tag>ThreadPoolExecutor</tag>
        <tag>SynchronousQueue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CDH安装集群教程]]></title>
    <url>%2F2019%2F09%2F26%2FCDH%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[下载地址下载地址]]></content>
      <categories>
        <category>CDH</category>
      </categories>
      <tags>
        <tag>CDH</tag>
        <tag>大数据</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用agentmain进行运行时热部署]]></title>
    <url>%2F2019%2F09%2F26%2F%E4%BD%BF%E7%94%A8agentmain%E8%BF%9B%E8%A1%8C%E8%BF%90%E8%A1%8C%E6%97%B6%E7%83%AD%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[简介在&lt;使用agent和javassist实现基于jvm的aop日志打印系统&gt;一文中，我使用了javaagent完成了一个基于JVM的aop，在main方法运行前动态的修改class文件的字节码，从而达到aop的效果，而java应用代码的编写者却感觉不到我们修改了代码,但是使用javaagent我们在启动java的main方时启动premain方法(虽然inst.addTransformer启动的ClassFileTransformer是永久存在的，也就是说后续用户自定义类加载器，并放弃双亲委派时（因为使用双亲委派模式每次加载的都是同一个class对象）也会调用ClassFileTransformer里的方法)(具体实践可查看使用agent和javassist实现基于jvm的aop日志打印系统 中的更进一步一节),但是这要求我们每次在主代码启动时必须加上javaagent参数去启动主代码包，如果我们转换器ClassFileTransformer需要变动的话那还是要停掉jvm，那么有无一种可以在运行时可以动态修改字节码的方法呢？答案就是JDK1.6提供的agentmain。 1234public static void premain(String agentArgs, Instrumentation inst) &#123; inst.addTransformer(new ClassFileTransformer() //省略实现类...); &#125; 实现思路实例一个分层3个jar包 agentmain代码负责从外部读取class文件，并且加载到虚拟机中 运行的测试工程 jvm加载代码，从本机中查找目标虚拟机，将运行agentmain的jar包插入到目标虚拟机中完成热部署 agentmain代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.liu;import java.io.IOException;import java.lang.instrument.*;import java.net.*;import java.nio.file.Files;import java.nio.file.Path;import java.nio.file.Paths;/** * @author Liush * @description * @date 2019/9/25 14:57 **/public class AgentMain &#123; public static void agentmain(String agentArgs, Instrumentation inst) throws ClassNotFoundException, UnmodifiableClassException, URISyntaxException, IOException &#123; if(agentArgs.trim()==null)&#123; return; &#125; //从参数中截取文件路径和要修改的类 String[] args=agentArgs.split(&quot; &quot;); //查找所有已经加载的类 Class[] classes=inst.getAllLoadedClasses(); for(Class&lt;?&gt; c:classes)&#123; //查找需要重新加载的类 if(!c.getName().endsWith(&quot;.&quot;+args[1]))&#123; continue; &#125; //获取修改后的类的字节码 //格式 file:///C:/Users/Administrator/Desktop/test/Test.class Path path = Paths.get(new URI(args[0])); byte[] classBytes = Files.readAllBytes(path); //重新定义类，完成热部署 inst.redefineClasses(new ClassDefinition(c,classBytes)); &#125; &#125;&#125; 打包,我们需要在MANIFEST.MF 中指定Agent-Class和Can-Redefine-Classes，Can-Retransform-Classes属性，我们采用maven打包方式加入如下插件,并且打成jar包 12345678910111213141516171819202122232425262728293031323334&lt;build&gt; &lt;plugins&gt; &lt;!-- http://maven.apache.org/shared/maven-archiver/index.html#class_manifest --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;index&gt;true&lt;/index&gt; &lt;manifestEntries&gt; &lt;Agent-Class&gt;com.liu.AgentMain&lt;/Agent-Class&gt; &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- 将插件绑定maven的package命令--&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!-- append to the packaging phase. --&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;!-- goals == mojos --&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 测试工程并没有什么特别循环执行Test.test()方法 1234567891011121314151617181920212223242526package com.liu;/** * @author Liush * @description * @date 2019/9/25 16:31 **/public class MainTest &#123; public static void main(String[] args) &#123; while (true)&#123; Test test=new Test(); test.test(); System.out.println(&quot;running........................&quot;); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; Test 类 12345678910111213141516package com.liu;/** * @author Liush * @description * @date 2019/9/25 16:54 **/public class Test &#123; public void test()&#123; System.out.println(&quot;未修改之前的数据..............&quot;); &#125;&#125; jvm加载代码注意VirtualMachine类是在${JAVA_HOME}/lib包下的tool.jar包下，需要在编译器中加入这个jar包,以idea为例点击Files-&gt;Project Structure-&gt;Libraiest 在此节目中添加tool.jar包即可 123456789101112131415161718192021222324252627282930313233343536package com.liu;import com.sun.tools.attach.*;import java.io.IOException;import java.util.List;/** * @author Liush * @description * @date 2019/9/25 15:16 **/public class JVMLoader &#123; public static void main(String[] args) throws IOException, AgentLoadException, AgentInitializationException, AttachNotSupportedException &#123; List&lt;VirtualMachineDescriptor&gt; list=VirtualMachine.list(); for (VirtualMachineDescriptor vmd : list) &#123; //查找MainTest虚拟机 if (vmd.displayName().endsWith(&quot;MainTest&quot;)) &#123; VirtualMachine virtualMachine = VirtualMachine.attach(vmd.id()); //在目标虚拟机中加载agentmainjar包，并且传入修改后的Test.class文件 和要修改的类这里是Test，传入一个字符串参数，这个字符串将在agentmain中进行分割得到对应的参数，比如这里使用&quot; &quot;做区分不同参数 virtualMachine.loadAgent(&quot;C:\\Users\\Administrator\\Desktop\\test\\agentmain-1.0-SNAPSHOT-jar-with-dependencies.jar &quot;, &quot;file:///C:/Users/Administrator/Desktop/test/Test.class Test&quot;); System.out.println(&quot;ok&quot;); virtualMachine.detach(); &#125; &#125; &#125;&#125; 开始执行 将agentmain打成jar包 运行测试工程main方法出现 1234未修改之前的数据..............running........................未修改之前的数据..............running........................ 修改Test文件并且重新编译 1234567891011121314151617package com.liu;/** * @author Liush * @description * @date 2019/9/25 16:54 **/public class Test &#123; public void test()&#123; System.out.println(&quot;Test已经修改完毕..............&quot;); &#125;&#125; 执行jvm加载代码的main方法，在目标虚拟机中执行agentmain方法，在代码中传入agentmain包的路径，重新编译完成的Test文件的路径，和要替换的类（这是是Test类），详情查看jvm加载代码中的注释 结果之前的Test已经完成了热部署，但是我们并没有重启测试工程的JVM 123456未修改之前的数据..............running........................未修改之前的数据..............running........................Test已经修改完毕..............running........................ 使用agentmain的限制通过查看JDK Instrumentation 的redefineClasses说明发现以下限制，也就是用此方法热部署不能更改类的继承关系，类名，方法名，方法参数，而且如果在从新加载类后如果，之前已经存在正在运行的未重从定义的方法，那么运行的仍然是原来的方法 1234567重定义可能会更改方法体、常量池和属性。重定义不得添加、移除、重命名字段或方法；不得更改方法签名、继承关系。在以后的版本中，可能会取消这些限制。在应用转换之前，类文件字节不会被检查、验证和安装。如果结果字节错误，此方法将抛出异常。如果此方法抛出异常，则不会重定义任何类如果重定义的方法有活动的堆栈帧，那么这些活动的帧将继续运行原方法的字节码。将在新的调用上使用此重定义的方法。此方法不会引起任何初始化操作，JVM 惯例语义下发生的初始化除外。换句话说，重定义一个类不会引起其初始化方法的运行。静态变量的值将与调用之前的值一样。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>热部署</tag>
        <tag>instrument</tag>
        <tag>agentmain</tag>
        <tag>maven打包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用agent和javassist实现基于jvm的aop日志打印系统]]></title>
    <url>%2F2019%2F09%2F25%2F%E4%BD%BF%E7%94%A8agent%E5%92%8Cjavassist%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8Ejvm%E7%9A%84aop%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[简介java在JDK1.5中提供了java.lang.Instrument包,该包提供了一些工具帮助开发人员在 Java 程序运行时动态的修改class,此文介绍其中的agent组件来实现基于jvm层面的aop. 命令如果我们在cmd输入java -help就会看到关于javaagent命令的简介 1234567java -help用法: java [-options] class [args...]其中选项包括: -javaagent:&lt;jarpath&gt;[=&lt;选项&gt;] 加载 Java 编程语言代理, 请参阅 java.lang.instrument 实例如下 1java -javaagent:/to/agent.jar -jar /main.jar 其中javaagent参数后的路径就是我们要编写的代码,其可以在要代理运行的jar运行前进行一些class字节的操作,如果在此期间使用犹如javassist,或者asm字节码操作的框架则可以实现在类运行前对要运行的class进行修改. agent简介 参数 javaagent 可以用于指定一个 jar 包，并且对该 java 包有2个要求： 这个jar 包的MANIFEST.MF 文件必须指定 Premain-Class 项。 Premain-Class 指定的那个类必须实现 premain（）方法。关于第一点我们在后续创建工程中使用maven 打包插件maven-assembly-plugin去解决这一点.现在我们解释一下第二点:javaagent程序不需要实现任何接口,只需要创建一个类其中类中必须要有以下方法之一即可 public static void premain(String agentArgs, Instrumentation inst)public static void premain(String agentArgs) 一般我们使用第一个方法 ,参数 agentArgs 时通过命令行传给 Java Agent 的参数，inst 是Java Class 字节码转换的工具，Instrumentation 常用方法如下： void addTransformer(ClassFileTransformer transformer, boolean canRetransform);增加一个Class 文件的转换器，转换器用于改变 Class 二进制流的数据，参数 canRetransform 设置是否允许重新转换我们可以使用ClassFileTransformer对象结合javassist或者asm对class文件进行修改。 void redefineClasses(ClassDefinition… definitions) hrows ClassNotFoundException, UnmodifiableClassException;在类加载之前，重新定义 Class 文件，ClassDefinition 表示对一个类新的定义，如果在类加载之后，需要使用 retransformClasses 方法重新定义。 本文中我们使用addTransformer方法在class文件加载前,我们对class字节码进行处理,添加打印日志代码,此方法接收一个ClassFileTransformer对象,Transformer 类包含了一个 transform 方法，它的签名会接受 ClassLoader、类名、要重定义的类所对应的 Class 对象、定义权限的 ProtectionDomain 以及这个类的原始字节。如果从 transform 方法中返回 null 的话，将会告诉运行时环境我们并没有对这个类进行变更。 123public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; return new byte[0]; &#125; 实现思路简介我们实现的原理很简单,首先我们在运行的主工程中定义个注解,此注解的功能是标识出哪些方法和哪些参数需要打印log,其作用域为在方法上,fields属性为数组,我们将需要打印的参数的角标放入其中如, 123456//打印方法的第一个参数@PrintLog(fields = &#123;&quot;1&quot;&#125;) public void test(String name,String name2)&#123; &#125; 123456789101112131415package com.liu;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface PrintLog &#123; String[] fields();&#125; 然后我们对需要打印日志的方法如上加上注解即可,在运行agent程序的时候我们会在class文件加载前,逐个扫描方法,查看是否有@PrintLog注解,如果有注解我们则应用javassist框架在class文件中加入打印代码,由于在之前文章讲述的类加载器的双亲委派模型,同一个class文件在双亲委派模式下只会加载一次,所以只有在class文件第一次被加载时才会触发此修改class的条件,因此也不必过多担心效率问题. 搭建agent工程创建agent主题类我们新建一个maven工程,首先新建一个类,其只包含上文简介的premain方法,并添加一个日志打印转换器,此方法会在代码里jar文件执行main方法前执行 12345678910111213141516171819202122package com.liu;import java.lang.instrument.Instrumentation;/** * @author Liush * @description 自定义agent在main方法执行前执行 * @date 2019/9/23 15:32 **/public class MyAgent &#123; public static void premain(String agentArgs, Instrumentation inst) &#123; inst.addTransformer(new LogPrintTransformer()); &#125;&#125; 创建ClassFileTransformer转换类上文提到premain方法中有一个Instrumentation对象,其的addTransformer方法可以添加一个创建ClassFileTransformer转换类,其可以在class第一次加载时对class文件进行处理,修改java代码因此我们现在创建一个ClassFileTransformer的实现类,类中主要使用javassist框架扫描加载的类的信息,和方法,查看方法上时候有我们之前标识的@PrintLog注解,如果有的话获取注解中的值,然后最后根据获取的值打印对应的参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package com.liu;import javassist.*;import javassist.bytecode.AnnotationsAttribute;import javassist.bytecode.CodeAttribute;import javassist.bytecode.LocalVariableAttribute;import javassist.bytecode.MethodInfo;import javassist.bytecode.annotation.Annotation;import javassist.bytecode.annotation.ArrayMemberValue;import javassist.bytecode.annotation.MemberValue;import javassist.bytecode.annotation.StringMemberValue;import java.io.IOException;import java.lang.instrument.ClassFileTransformer;import java.lang.instrument.IllegalClassFormatException;import java.security.ProtectionDomain;import java.util.ArrayList;import java.util.Arrays;import java.util.Collections;import java.util.List;/** * @author Liush * @description * @date 2019/9/23 15:41 **/public class LogPrintTransformer implements ClassFileTransformer &#123; /** * 签名会接受 ClassLoader、类名、要重定义的类所对应的 Class 对象、定义权限的 ProtectionDomain 以及这个类的原始字节。 * 如果从 transform 方法中返回 null 的话，将会告诉运行时环境我们并没有对这个类进行变更。 */ @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; try &#123; CtClass ctClass=ClassPool.getDefault().get(className.replaceAll(&quot;/&quot;, &quot;.&quot;)); CtMethod[] ctMethods =ctClass.getDeclaredMethods(); for(CtMethod ctMethod:ctMethods)&#123; if(getAnnotation(ctMethod)!=null) &#123; List&lt;String&gt; value = getParamIndexes(getAnnotation(ctMethod)); ctMethod.insertBefore(createJavaString(className, ctMethod, value)); &#125; &#125; return ctClass.toBytecode(); &#125; catch (NotFoundException e) &#123; e.printStackTrace(); &#125; catch (CannotCompileException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; //在javassist中$1代表方法的第一个参数,$2代表第二个参数以此类推可参考https://www.jianshu.com/p/b9b3ff0e1bf8 private String createJavaString(String className,CtMethod ctMethod,List&lt;String&gt; params)&#123; StringBuilder stringBuilder=new StringBuilder(); for(String index:params)&#123; stringBuilder.append(&quot;System.out.println($&quot;); stringBuilder.append(index); stringBuilder.append(&quot;);&quot;); &#125; return stringBuilder.toString(); &#125; //查找方法注解 public Annotation getAnnotation(CtMethod method) &#123; MethodInfo methodInfo = method.getMethodInfo(); AnnotationsAttribute attInfo = (AnnotationsAttribute) methodInfo .getAttribute(AnnotationsAttribute.visibleTag); if (attInfo != null) &#123; return attInfo.getAnnotation(&quot;com.liu.PrintLog&quot;); &#125; return null; &#125; //获得注解中的属性值 public List&lt;String&gt; getParamIndexes(Annotation annotation) &#123; ArrayMemberValue fields = (ArrayMemberValue) annotation.getMemberValue(&quot;fields&quot;); if (fields != null) &#123; MemberValue[] values = fields.getValue(); List&lt;String&gt; parameterIndexes = new ArrayList&lt;&gt;(); for (MemberValue val : values) &#123; parameterIndexes.add(((StringMemberValue) val).getValue()); &#125; return parameterIndexes; &#125; return Collections.emptyList(); &#125;&#125; 生成MANIFEST.MF文件使用agent必须在MANIFEST.MF中指定Premain-Class表示我们只想的agent的类,设置Can-Redefine-Classes和Can-Retransform-Classes属性为true,我们采用maven插件的方式进行打包,由maven自动生成MANIFEST.MF文件在maven pom依赖中加入 1234567891011121314151617181920212223242526272829303132333435&lt;build&gt; &lt;plugins&gt; &lt;!-- http://maven.apache.org/shared/maven-archiver/index.html#class_manifest --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;index&gt;true&lt;/index&gt; &lt;manifestEntries&gt; &lt;!-- 设置MANIFEST中的属性 --&gt; &lt;Premain-Class&gt;com.liu.MyAgent&lt;/Premain-Class&gt; &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- 将插件绑定maven的package命令--&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!-- append to the packaging phase. --&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;!-- goals == mojos --&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 创建主工程创建打印注解此类为了标识哪些方法的哪些参数需要打印 123456789101112131415package com.liu;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface PrintLog &#123; String[] fields();&#125; 创建一个测试类 12345678910111213141516171819package com.liu;/** * @author Liush * @description * @date 2019/9/23 18:12 **/public class LogTest &#123; @PrintLog(fields = &#123;&quot;1&quot;&#125;) public void test(String name,String name2)&#123; System.out.println(&quot;over...........................&quot;); &#125;&#125; 创建main方法 1234567891011121314151617package com.liu;/** * @author Liush * @description * @date 2019/9/23 18:06 **/public class MainTest &#123; public static void main(String[] args) &#123; LogTest logTest=new LogTest(); logTest.test(&quot;liushaohuang111&quot;,&quot;liushaohuang2222&quot;); &#125;&#125; 同样我是使用maven maven-assembly-plugin插件进行打包,与上面不同的是我们这次不要指定Premain-Class,Can-Redefine-Classes和Can-Retransform-Classes参数我们只需要声明main函数的入口即可 1234567891011121314151617181920212223242526272829303132&lt;build&gt; &lt;plugins&gt; &lt;!-- http://maven.apache.org/shared/maven-archiver/index.html#class_manifest --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;index&gt;true&lt;/index&gt; &lt;manifest&gt; &lt;mainClass&gt;com.liu.MainTest&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- this is used for inheritance merges --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!-- append to the packaging phase. --&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;!-- goals == mojos --&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 打包运行在两个工程目录下执行 1mvn clean package 运行javaagent命令 1java -javaagent:.\agent-1.0-SNAPSHOT-jar-with-dependencies.jar -jar .\main_test-1.0-SNAPSHOT-jar-with-dependencies.jar 在控制台中出现,成功打印出传入的第一个参数,并且在原始方法执行打印overing之前执行打印 12liushaohuang111over........................... 更进一步在实践中本人思考premain 中的Instrumentation 添加的转换器到底什么时候才起作用呢？这里再做一个实践，我们修改premain方法，往里面加入一行打印代码，为了方便在运行的时候发现什么时候触发转化器,其余代码和之前的代码一模一样 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package com.liu;import javassist.*;import javassist.bytecode.AnnotationsAttribute;import javassist.bytecode.CodeAttribute;import javassist.bytecode.LocalVariableAttribute;import javassist.bytecode.MethodInfo;import javassist.bytecode.annotation.Annotation;import javassist.bytecode.annotation.ArrayMemberValue;import javassist.bytecode.annotation.MemberValue;import javassist.bytecode.annotation.StringMemberValue;import java.io.IOException;import java.lang.instrument.ClassFileTransformer;import java.lang.instrument.IllegalClassFormatException;import java.security.ProtectionDomain;import java.util.ArrayList;import java.util.Arrays;import java.util.Collections;import java.util.List;/** * @author Liush * @description * @date 2019/9/23 15:41 **/public class LogPrintTransformer implements ClassFileTransformer &#123; /** * 签名会接受 ClassLoader、类名、要重定义的类所对应的 Class 对象、定义权限的 ProtectionDomain 以及这个类的原始字节。 * 如果从 transform 方法中返回 null 的话，将会告诉运行时环境我们并没有对这个类进行变更。 */ @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; try &#123; System.out.println(&quot;in transform....................&quot;); CtClass ctClass=ClassPool.getDefault().get(className.replaceAll(&quot;/&quot;, &quot;.&quot;)); CtMethod[] ctMethods =ctClass.getDeclaredMethods(); for(CtMethod ctMethod:ctMethods)&#123; if(getAnnotation(ctMethod)!=null) &#123; List&lt;String&gt; value = getParamIndexes(getAnnotation(ctMethod)); ctMethod.insertBefore(createJavaString(className, ctMethod, value)); &#125; &#125; return ctClass.toBytecode(); &#125; catch (NotFoundException e) &#123; e.printStackTrace(); &#125; catch (CannotCompileException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; //在javassist中$1代表方法的第一个参数,$2代表第二个参数以此类推可参考https://www.jianshu.com/p/b9b3ff0e1bf8 private String createJavaString(String className,CtMethod ctMethod,List&lt;String&gt; params)&#123; StringBuilder stringBuilder=new StringBuilder(); for(String index:params)&#123; stringBuilder.append(&quot;System.out.println($&quot;); stringBuilder.append(index); stringBuilder.append(&quot;);&quot;); &#125; return stringBuilder.toString(); &#125; //查找方法注解 public Annotation getAnnotation(CtMethod method) &#123; MethodInfo methodInfo = method.getMethodInfo(); AnnotationsAttribute attInfo = (AnnotationsAttribute) methodInfo .getAttribute(AnnotationsAttribute.visibleTag); if (attInfo != null) &#123; return attInfo.getAnnotation(&quot;com.liu.PrintLog&quot;); &#125; return null; &#125; //获得注解中的属性值 public List&lt;String&gt; getParamIndexes(Annotation annotation) &#123; ArrayMemberValue fields = (ArrayMemberValue) annotation.getMemberValue(&quot;fields&quot;); if (fields != null) &#123; MemberValue[] values = fields.getValue(); List&lt;String&gt; parameterIndexes = new ArrayList&lt;&gt;(); for (MemberValue val : values) &#123; parameterIndexes.add(((StringMemberValue) val).getValue()); &#125; return parameterIndexes; &#125; return Collections.emptyList(); &#125;&#125; 现在我们更改主项目中被代理的main方法代码,里面一共new了4次LogTest对象 第一个是第一次触发class加载(class文件只有被调用时候才会第一次加载到虚拟机)，则会触发premain方法中的转换器 第二个是直接调用堆栈中的class又new一次对象对象，没有触发转化器 第三个我们使用自定义类加载器，并且不突破双亲委派模式(还是调用堆栈中的LogTest)，同样也没有触发转化器 第四个，我们又创建了一个类加载器，并且突破双亲委派模式，重新加载一个LogTest，不再使用之前堆栈中的LogTest对象，最后发现触发了转化器 结论：只有在class重新被加载时才会触发ClassFileTransformer转换器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.liu;import java.io.IOException;import java.io.InputStream;/** * @author Liush * @description * @date 2019/9/23 18:06 **/public class MainTest &#123; public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException &#123; //第一次次加载触发ClassFileTransformer LogTest logTest = new LogTest(); logTest.test(&quot;liushaohuang111&quot;, &quot;liushaohuang2222&quot;); //重新创建对象,不会触发premain中的ClassFileTransformer(类已经加载到堆栈中) LogTest logTest1 = new LogTest(); logTest1.test(&quot;shao111111111111&quot;, &quot;shao22222222222222&quot;); //不突破双亲委派类进行类加载,不会触发premain中的ClassFileTransformer(类已经加载到堆栈中) ClassLoader classLoader = new ClassLoader() &#123; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; return super.loadClass(name); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; e.printStackTrace(); throw new ClassNotFoundException(name); &#125; &#125; &#125;; Class aClass = classLoader.loadClass(&quot;com.liu.LogTest&quot;); LogTest logTest2 = (LogTest)aClass.newInstance(); logTest2.test(&quot;Parents Delegation Model 1&quot;,&quot;Parents Delegation Model 2&quot;); //突破双亲委派模式 ClassLoader classLoader2=new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; return super.loadClass(name); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; e.printStackTrace(); throw new ClassNotFoundException(name); &#125; &#125; &#125;; Class aClass2 = classLoader.loadClass(&quot;com.liu.LogTest&quot;); LogTest logTest3 = (LogTest)aClass.newInstance(); logTest3.test(&quot;No Parents Delegation Model1&quot;,&quot;No Parents Delegation Model 2&quot;); &#125;&#125; 输出结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................liushaohuang111over...........................shao111111111111over...........................Parents Delegation Model 1over...........................in transform....................No Parents Delegation Model1over...........................in transform....................in transform....................]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>instrument</tag>
        <tag>javassist</tag>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql存储过程游标的嵌套和使用(统计局地区维度表的创建)]]></title>
    <url>%2F2019%2F09%2F24%2Fmysql%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E6%B8%B8%E6%A0%87%E7%9A%84%E5%B5%8C%E5%A5%97%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介之前主要使用oracle来实现存储过程,今天在写mysql存储过程时发现mysql并没有类似oracle的for循环语法,因此通过游标方式来实现类似功能,本过程通过正则切割地区id将统计局的全国到村和街道的数据装换成供数据仓库使用的宽表结构 (因为统计局提供的地区层次是通过id来区分的,code字段共有12个字符，第1、2位标识省份，第3、4位标识地市、第5、6位标识县区，第7-9位标识乡镇、第10-12位标识村。其数据来自http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/), 转化后的表结构如下 注意这里多了一列当前正在使用的id,这是为了应对后续存在的地区名字或结构变化,这里本人采用的是维度变化的类型6的变种,如果id和正在使用的id相同则代表当前地区是最新结构,否则通过子查询去寻找当前的正在使用的地区id,因为这张表中目前有70多万条数据,如果重新生成较为耗时,且这是一个通用维度,历史数据还是关联就的地区状态,所以需要保留地区维度表的历史信息,且地区信息是拉平的(数据仓库维度表中数据都是拉平的,以此表来说如果有些数据是关联在福建省下则,需要创建,福建省,福建市,福建县,福建镇,福建乡),因为如果维度不拉平则在统计分析时会漏掉直接关联在福建省下的数据. id 省 市 县 镇 村 当前正在使用的id id 福建 福州 闽清 镇 村 id 代码和注释如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210CREATE DEFINER=`root`@`%` PROCEDURE `F_AREA`()BEGIN declare v_sheng_code VARCHAR(20); declare v_sheng_name VARCHAR(255); declare v_shi_code VARCHAR(20); declare v_shi_name VARCHAR(255); declare v_shi_code_short VARCHAR(20); declare v_xian_code VARCHAR(20); declare v_xian_name VARCHAR(255); declare v_xian_code_short VARCHAR(20); declare v_zhen_code VARCHAR(20); declare v_zhen_name VARCHAR(255); declare v_zhen_code_short VARCHAR(20); declare v_cun_code VARCHAR(20); declare v_cun_name VARCHAR(255); -- 游标变量必须在游标前声明 declare v_done int; declare c_sheng cursor for SELECT code ,name from region_code4stat_2018 where code REGEXP &apos;^[0-9][0-9]$&apos; ; -- 声明市游标 declare c_shi cursor for SELECT code ,name from region_code4stat_2018 where code REGEXP concat(concat(&apos;^(&apos;,v_sheng_code),&apos;)[0-9][0-9]0&#123;8,8&#125;$&apos;) ; -- 声明县游标 declare c_xian cursor for SELECT code ,name from region_code4stat_2018 where code REGEXP concat(concat(concat(&apos;^(&apos;,v_sheng_code),v_shi_code_short),&apos;)[0-9][0-9][0]&#123;6,6&#125;$&apos;) and code!= concat(concat(v_sheng_code,v_shi_code_short),&apos;00000000&apos;); -- 声明镇游标 declare c_zhen cursor for SELECT code ,name from region_code4stat_2018 where code REGEXP concat(concat(concat(concat(&apos;^(&apos;,v_sheng_code),v_shi_code_short),v_xian_code_short),&apos;)[0-9][0-9][0-9][0]&#123;3,3&#125;$&apos;) and code!=concat(concat(concat(v_sheng_code,v_shi_code_short),v_xian_code_short),&apos;000000&apos;); -- 声明村游标 declare c_cun cursor for SELECT code ,name from region_code4stat_2018 where code REGEXP concat(concat(concat(concat(concat(&apos;^(&apos;,v_sheng_code),v_shi_code_short),v_xian_code_short),v_zhen_code_short),&apos;)[0-9]&#123;3,3&#125;$&apos;) and code!=concat(concat(concat(concat(v_sheng_code,v_shi_code_short),v_xian_code_short),v_zhen_code_short),&apos;000&apos;) ; -- 声明游标完成状态必须要在游标声明后 DECLARE CONTINUE HANDLER FOR NOT FOUND SET v_done = 1;-- ------------------------------------------------------------------------------------------------------------ -- 打开省游标 open c_sheng; sheng_loop:LOOP FETCH c_sheng INTO v_sheng_code,v_sheng_name; IF v_done = 1 THEN LEAVE sheng_loop; END IF; -- 省数据拉平(数据仓库维度表中数据都是拉平的,以此表来说如果有些数据是关联在福建省下则,需要创建,福建省,福建市,福建县,福建镇,福建乡) INSERT INTO D_AREA(CODE_,PROVINCE_,CITY_,COUNTRY_,TOWN_,VILLAGE,CURR_CODE_) VALUES(v_sheng_code,v_sheng_name,v_sheng_name,v_sheng_name,v_sheng_name,v_sheng_name, v_sheng_code); -- ----------------------------------------------------------------------------------------------------------- -- 打开市游标 open c_shi; shi_loop:LOOP FETCH c_shi INTO v_shi_code,v_shi_name; IF v_done = 1 THEN LEAVE shi_loop; END IF; -- 市数据拉平 INSERT INTO D_AREA(CODE_,PROVINCE_,CITY_,COUNTRY_,TOWN_,VILLAGE,CURR_CODE_) VALUES(v_shi_code,v_sheng_name,v_shi_name,v_shi_name,v_shi_name,v_shi_name, v_shi_code); set v_shi_code_short=substring(v_shi_code,3,2); -- ------------------------------------------------------------ -- 打开县游标 open c_xian; xian_loop:LOOP FETCH c_xian INTO v_xian_code,v_xian_name; IF v_done = 1 THEN LEAVE xian_loop; END IF; -- 县数据拉平 INSERT INTO D_AREA(CODE_,PROVINCE_,CITY_,COUNTRY_,TOWN_,VILLAGE,CURR_CODE_) VALUES(v_xian_code,v_sheng_name,v_shi_name,v_xian_name,v_xian_name,v_xian_name, v_xian_code); set v_xian_code_short=substring(v_xian_code,5,2); -- --------------------------------------------- -- 打开镇游标 open c_zhen; zhen_loop:LOOP FETCH c_zhen INTO v_zhen_code,v_zhen_name; IF v_done = 1 THEN LEAVE zhen_loop; END IF; -- 镇数据拉平 INSERT INTO D_AREA(CODE_,PROVINCE_,CITY_,COUNTRY_,TOWN_,VILLAGE,CURR_CODE_) VALUES(v_zhen_code,v_sheng_name,v_shi_name,v_xian_name,v_zhen_name,v_zhen_name, v_zhen_code); set v_zhen_code_short=substring(v_zhen_code,7,3); -- --------------------------------------------------------------------- -- 打开村游标 open c_cun; cun_loop:LOOP FETCH c_cun INTO v_cun_code,v_cun_name; IF v_done = 1 THEN LEAVE cun_loop; END IF; INSERT INTO D_AREA(CODE_,PROVINCE_,CITY_,COUNTRY_,TOWN_,VILLAGE,CURR_CODE_) VALUES(v_cun_code,v_sheng_name,v_shi_name,v_xian_name,v_zhen_name,v_cun_name, v_cun_code); end LOOP cun_loop; CLOSE c_cun; -- 注意这里需要将v_done初始化,不然外层循环也将跳出 SET v_done=0; end LOOP zhen_loop; CLOSE c_zhen; SET v_done=0; end LOOP xian_loop; CLOSE c_xian; SET v_done=0; end LOOP shi_loop; CLOSE c_shi; SET v_done=0; end LOOP sheng_loop; CLOSE c_sheng;END 参考游标嵌套部分参考代码https://www.cnblogs.com/phao123/p/6006780.html]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>存储过程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用类加载器简单实现热部署]]></title>
    <url>%2F2019%2F09%2F19%2F%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0%E7%83%AD%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[用类加载器实现热部署如果你写过jsp,你会发现在修改jsp后并不需要重启服务器就能实现jsp页面的替换,jsp本质也是java代码,那它是如何实现不重启JVM实现热部署的呢?答案是类加载器. 实践在前面博客中已经简介过类加载器和双亲委托加载,当中提及java中的class文件只会加在一次,比如我创建的一个类A,在第一次实例A类时会在JAVA默认提供的AppClassLoader加载器中去加载A类,后续如果需要实例化A对象只需要调用加载器的loadClass方法其会去先调用findLoadedClass查找是否class文件以及被加载过,如果被加载过则直接读取,没有的话则通过调用子类实现的findClass的方法去读取加载class文件,由于我们这里想实现热部署,如果使用双亲委托就会导致我们的类每次都是从AppClassLoader中的findLoadedClass中读取堆中的class信息,这样做事无法实现热部署的,因为你每次变更的class并没有加载到堆中,于是我们需要突破双亲委派 1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); //子类负责实现findClass方法 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 突破双亲委派实现自己的类加载器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.liu;import java.io.IOException;import java.io.InputStream;/** * @author Liush * @description * @date 2019/9/18 11:07 **/public class Test &#123; public static void main(String[] args) throws Exception &#123; while (true) &#123; ClassLoader classLoader = new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; return super.loadClass(name); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; e.printStackTrace(); throw new ClassNotFoundException(name); &#125; &#125; &#125;; Class aClass = classLoader.loadClass(&quot;com.liu.A&quot;); Object o = aClass.newInstance(); Object o2 = new A(); //输出false System.out.println(o.getClass().isInstance(o2)); //输出AppClassLoader System.out.println(o.getClass().getClassLoader().getParent()); //调用test方法 o.getClass().getMethod(&quot;test&quot;).invoke(o); //如果不休眠会提示java.lang.ClassFormatError: Truncated class file(class文件被删除) System.out.println(); Thread.sleep(2000); &#125; &#125;&#125; A类 12345678910111213141516package com.liu;/** * @author Liush * @description * @date 2019/9/19 13:49 **/public class A &#123; public void test()&#123; System.out.println(&quot;old.......&quot;); &#125;&#125; 执行Test中的main方法输出 1234falsecom.liu.Test$1@3f99bd52sun.misc.Launcher$AppClassLoader@18b4aac2old....... 下面我们修改A类为 123456789101112131415package com.liu;/** * @author Liush * @description * @date 2019/9/19 13:49 **/public class A &#123; public void test()&#123; System.out.println(&quot;new.......&quot;); &#125;&#125; 重新编译A类为新的class文件(由于我使用的是IDEA,会自动编译所以这步我就省略了),打开控制台发现已经输出新的代码,但是我们并没有重启JVM,原因就是我们每次都是从新的ClassLoader去加载新的class文件. 123456789falsecom.liu.Test$1@3af49f1csun.misc.Launcher$AppClassLoader@18b4aac2old.......falsecom.liu.Test$1@31befd9fsun.misc.Launcher$AppClassLoader@18b4aac2new.......]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>类加载器</tag>
        <tag>热部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java类加载器]]></title>
    <url>%2F2019%2F09%2F19%2Fjava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[类加载器简介Kotlin,Scala等语言也是运行在JAVA虚拟机的语言,那为什么这些不是java的语言也能够运行在jvm虚拟机上呢?原因就是Class 文件,对虚拟机来说Class文件是一个重要的接口,无论使用何种语言进行软件开发，只要能将源文件编译为正确的 Class 文件，那么这种语言就可以在 Java 虚拟机上运行.可以说，Class 文件就是虚拟机的基石,而加载Class文件又是通过类加载器进行的. 类加载器的工作流程Class 文件通常是以文件的方式存在（任何二进制流都可以是 Class 类型），但只有能被 JVM 加载后才能被使用，才能运行编译后的代码。系统载入 Class 过程可以分为加载，链接和初始化三个步骤。其中，链接也可分为验证，准备和解析3步骤,其中，只有加载过程是程序员能够控制的，后面的几个步骤都是有虚拟机自动运行的。因此，我们的关注点主要放在加载阶段 类加载JVM第一次使用到这个类时需要对，这个类的信息进行加载。一个类只会加载一次，之后这个类的信息放在堆空间，静态属性放在方法区. 什么时候加载类 当创建一个类的实例是，比如使用 new 关键字，或者通过反射，克隆，反序列化。 当调用类的静态方法时，即当使用字节码 invokstatic 指令。 当使用类或接口的静态字段时（final 常量除外），比如，使用 getstatic 或者 pustatic 指令。 当时用 Java.lang.reflect 包中的方法反射类的方法时。 当初始化子类，要求先初始化父类。 作为启动虚拟机，含有 main（）方法的那个类。 类加载器的分类类加载器主要分为以下几类,除了启动类加载器外,其余扩展器都实现了ClassLoader类 启动类加载器（BootStrap ClassLoader），C++ 语言实现，虚拟机自身的一部分 启动类加载器主要加载${JAVA_HOME}/lib 目录中的包,负责加载JDK中的核心类库,如 rt.jar,我们是无法访问这个类加载器的如下代码 1System.out.println(String.class.getClassLoader()); 控制台中打印的是null,因为String为jdk的核心类由BootStrap ClassLoader加载,我们无法访问这个类加载器. 扩展类加载器 扩展类加载器有 sun.misc.Launcher$ExtClassLoader 实现，负责加载 /lib/ext 目录中的。或者被 java.ext.dirs 系统变量所指定的路径中的所有类库。 应用类加载器 sun.misc.Launcher$AppClassLoader 实现，由于这个类是 ClassLoader 中的 getSystemClassLoader 方法的返回值，也称为系统类加载器，负载加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器。一般情况下，这个就是程序中默认的类加载器。 自定义类加载器 自定义类加载器用于加载一些特殊途径的类，一般也是用户程序类。 类加载器的双亲委派模式 JVM为了保证同一个Class只被加载一次采用了双亲委派模式进行控制,因为同一个Class文件如果被不同类加载器加载那么他们就不是相同的一个类(如同一个类由应用类加载器加载,之后又由自定义类加载器加载,这两个类不是同一个类,即使他们的包名编写的代码时相同的,我们可以简单根据此简单的实现热部署,我们后续会介绍),那么什么是双亲委派模式呢?类加载器的层级关系是启动类加载器&gt;扩展类加载器&gt;应用类加载器&gt;自定义加载器,现在我们在程序中new了一个对象,那么它首先会调用findLoadedClass(name)方法去底层查找这个类时候已经加载(底层堆中),如果有就返回,如果没有就委托父类进行加载,如果父类可以加载则加载不行则退回到子类加载.比如我们自定义了一个A对象,在我们第一次调用new A()实例化对象时,它首先会去启动类加载器中寻找,因为启动类加载器只会加载${JAVA_HOME}/lib目录下的类所以无法加载A这个类,接下来由扩展类加载器(ExtClassLoader)进行加载,由于 其只会加载${JAVA_HOME}/lib/ext 目录下的类所以也不会进行加载,最后退回到应用类加载器(AppClassLoader)加载器,由于其加载用户类路径（ClassPath）上所指定的类库,而我们新建的对象在工程目录下,所以由此加载器完成加载 1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; //在启动类加载器(BootStrap ClassLoader)中查找类 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; loadClass（）、findClass（）、defineClass（）区别loadClass 源码如下其会先调用findLoadedClass去查找是否以及加载了class文件如果没有的话再委托双亲加载 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; findClass()这个方法为子类扩展方法,在ClassLoader中并没有对其进行具体的实现,预留出这个接口的我个人理解是,如果你不想突破双亲委派则只需要实现该方法即可,我们可以在loadClass方法中发现,其调用findClass了,如果我们想要使用默认的双亲委派功能去重新编写loadClass代码的话会产生大量冗余代码,所以开放出此接口来实现用户自定义的class加载方式,其通常会在最后调用defineClass去加载class文件,这个方法是父类中已经实现好的加载class文件的方法,至于为什么不突破双亲委派?举个例子:前文提到双亲委派模式加载类的先后顺序是,启动类加载器&gt;扩展类加载器&gt;应用类加载器&gt;自定义加载器,只有当父类加载不了这个类才由子类去实现,比如启动类加载器加载${JAVA_HOME}/lib目录下的类,如果采用双亲模式则这些类就无法通过扩展类加载器去加载,同理,我现在自定义了一个ClassLoader,如果我去实例化这个类的话,那么它会在应用类加载器(AppClassLoader)中去加载这个class文件,因为我编写的java文件路径是在工程目录下的,应用类加载器(AppClassLoader)有权去加载工程目录下的文件,那么我在调用以下代码时得到的是true,因为我调用new 方法去实例对象是使用应用类加载器(AppClassLoader)去构造对象的,而我通过自定义类加载器加载的(classLoader.loadClass(“com.liu.A”))class对象由于使用了双亲加载模式,其委托给了AppClassLoader去加载对象,这两个类都是使用同一个类加载器去生成对象,所以输出true,反之如果我重写loadClass方法,绕过双亲加载模式那么输出的就是false,,因为class虽然是同一个,但是我使用了不同的类加载器去加载class文件,java认定这两个对象不是相同的对象 1234Class aClass = classLoader.loadClass(&quot;com.liu.A&quot;);Object o = aClass.newInstance();Object o2 = new A();System.out.println(o.getClass().isInstance(o2)); 123protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name); &#125; definclass()把字节码转化为Class 我们现在编写代码来测试 12345678910public class Test &#123; public static void main(String[] args) &#123; ClassLoader classLoader=Test.class.getClassLoader(); System.out.println(classLoader);//获取应用类加载器 System.out.println(classLoader.getParent());//获取扩展类加载器 System.out.println(classLoader.getParent().getParent());//我们无法访问启动类加载器，当试图获取启动类加载器的时候，返回 null，因此，如果返回的是 null，并不意味没有类加载器为它服务，而是指哪个类为启动类加载器 System.out.println(String.class.getClassLoader());//证明String类由启动类加载器加载,由此可见无法找到类加载器那么这个类有可能是由启动类加载器完成加载的 &#125;&#125; 控制台打印出的代码为 1234sun.misc.Launcher$AppClassLoader@18b4aac2sun.misc.Launcher$ExtClassLoader@f6f4d33nullnull 注意 同一个类不能加载两次一个class文件(多次调用load方法),不然会报 attempted duplicate class definition for name:,所以如果用类加载器实现热部署需要每次都要创建一个新的类加载器,在热部署章节中会体现 参考资料本文部分内容参考 https://www.jianshu.com/p/85eba062b9c1]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>类加载器</tag>
        <tag>热部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bistoury非入侵式java生产环境诊断工具]]></title>
    <url>%2F2019%2F09%2F18%2Fbistoury%E9%9D%9E%E5%85%A5%E4%BE%B5java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[简介 最近闲来无事逛github时发现bistoury,Bistoury是去哪儿网的java应用生产问题诊断工具，提供了一站式的问题诊断方案,可以在生产环境中实现非入侵式系统信息查看,包括堆栈信息,机器情况,在线调试,应用线程信息等. 下载首先去github中下载编译好的文件https://github.com/qunarcorp/bistoury/releases 准备 需要Linux环境 JDK1.8 本机 9090，9091，9880，9881 端口未被占用，这些端口会被 Bistoury 使用，如果已占用需要进行配置 以下为github中提供的快速开始说明快速开始Bistoury 具有多个模块，并且和公司自身环境有一定的关联，想要合理部署需要进行一些相关的配置。 为了能够快速启动和体验 Bistoury，我们提供快速部署脚本在单机部署整套 Bistoury 服务。 使用快速部署脚本，会在本机部署一整套 Bistoury 服务，其中包括 ui、proxy、agent。 注意，这里提供的快速部署脚本仅适用于快速上手进行单机诊断，想要获得完整的体验，还是需要进行合理的部署。 目前在我们公司内部的使用方式，也是推荐的部署方式为： ui 独立部署，推荐部署在多台机器，并提供独立的域名 proxy 独立部署，推荐部署在多台机器，并提供独立的域名 agent 需要和应用部署在同一台机器上。推荐在测试环境全环境自动部署，线上环境提供单机一键部署，以及应用下所有机器一键部署 独立的应用中心，管理所有功能内部应用和机器信息，这是一个和 Bistoury 相独立的系统，Bistoury 从中拿到不断更新的应用和机器信息 构建获取快速部署包 我们在项目 Release 页面提供了已经构建好的快速部署包，你也可以直接下载。 你也可以下载源码然后自己构建快速启动包，这同样很简单。首先 clone 项目到本地，运行 script/quick_start_build.sh，运行完成后 script 目录下会生成相应的快速部署包，名字格式为 bistoury-quick-start.tar.gz 准备 目前仅支持 Linux 环境，所以需要一个 Linux 环境 本机已安装 jdk1.8+，并且设置了 JAVA_HOME 环境变量，如果没有设置也可以在启动脚本中传递 -j 参数，详情见下文：启动参数 本机 9090，9091，9880，9881 端口未被占用，这些端口会被 Bistoury 使用，如果已占用需要进行配置，详情见下文：当端口冲突了怎么解决 本机已经启动一个待诊断 JAVA 应用，如果是 Spring Web 应用不需要做处理，非 Spring Web 应用需要配置启动脚本的 -c 参数，详情见下文：启动参数 启动首先我们将快速启动包 bistoury-quick-start.tar.gz 拷贝到想要安装的位置。 然后解压启动包： 12tar -zxvf bistoury-quick-start.tar.gzcd bistoury 最后是启动 Bistoury，因为 Bistoury 会用到 jstack 等操作，为了保证所有功能可用，需要使用和待诊断 JAVA 应用相同的用户启动。 假设应用进程 id 为 1024 如果应用以本人用户启动，可以直接运行 1./quick_start.sh -p 1024 start 如果应用以其它帐号启动，比如 tomcat，需要指定一下用户然后运行 1sudo -u tomcat ./quick_start.sh -p 1024 start 停止运行 1./quick_start.sh stop 访问可以通过 http://ip:9091 来对 ui 进行访问，比如部署的机器 ip 为 192.168.1.20，则可以通过 http://192.168.1.20:9091/ 访问，初始化用户名密码均为 admin 具体实施中遇到的问题websocket连接失败原因是本机可能存在多个ip，导致获取的ip不是当前正在使用的ip（获取到的ip可以在各个日志中查看，也可以在应用中心查看），从而出错， 可以通过quick_start.sh脚本中的-i参数指定当前的ip。 例子 : 1./quick_start.sh -i 127.0.0.1 -p 1024 start 提示 not find proxy for agent端口冲突,修改端口即可 端口 作用 1. 9880 agent和proxy通信默认使用9880端口 2. 9881 ui和proxy通信默认使用9881端口 3. 9090 proxy默认使用9090端口 4. 9091 ui默认使用9091端口 5. 9092 h2数据库默认使用9092端口 端口 端口定义的位置 9880 解压缩目录/bistoury-proxy-bin/conf/global.properties中的agent.newport值 9881 解压缩目录/bistoury-proxy-bin/conf/global.properties中的server.port值和quick_start.sh中PROXY_WEBSOCKET_PORT的值 9090 解压缩目录/bistoury-proxy-bin/conf/server.properties中的tomcat.port值和quick_start.sh中PROXY_TOMCAT_PORT的值以及bistoury-agent-bin/bin/bistoury-agent-env.sh中的BISTOURY_PROXY_HOST的值 9091 解压缩目录/bistoury-ui-bin/conf/server.properties中的tomcat.port值 9092 解压缩目录/h2/h2.sh中的H2_PORT值]]></content>
      <categories>
        <category>性能测试和监控</category>
      </categories>
      <tags>
        <tag>bistoury</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java应用在linux中性能和堆栈信息的排查]]></title>
    <url>%2F2019%2F09%2F18%2Fjava%E5%9C%A8linux%E4%B8%AD%E5%8D%A0%E7%94%A8%E8%B5%84%E6%BA%90%E8%BF%87%E5%A4%9A%E7%9A%84%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[####简介在线上环境中有时会遇到cpu等资源占用过多的资源我们可以使用top命令和jstack命令对问题进行排查 编写循环代码下面代码开启两个线程循环打印 1234567891011121314151617181920212223242526272829public class Test &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newFixedThreadPool(2); service.submit(new Runnable() &#123; @Override public void run() &#123; runTest(); &#125; &#125;); service.submit(new Runnable() &#123; @Override public void run() &#123; runTest(); &#125; &#125;); &#125; public static void runTest() &#123; while (true) &#123; System.out.println(1); &#125; &#125;&#125; 将代码发布到linux上并执行开启jar应用 1nohup java -jar test.jar &gt;/dev/null 2&gt;&amp;1 &amp; 使用top命令查看进程情况我们可以从命令中看到pid 19384占用了大量资源 1top 使用top命令查看线程情况从上一步我们得到进程pid,现在我们使用top命令查看进程pid下的线程 1top -Hp 19384 我们可以看到19436 和19437这两个线程占用了大量资源 使用jstack命令进行具体分析根据进程pid进行查询 1jstack -l 19437 我们由上面的top线程查询到19436和19437这两个线程占用了大量资源将其转化成16进制分别为4bec和4bed根据16进制的pid查询对应的nid,如图我们找到了pool-1-thread-2 这个线程名对应的nid为4bed,这个线程就是我们之前开启的一个线程,我们可以查看之中的堆栈信息发现其在runTest方法中持续执行,并且持续在执行io流(打印) 通过thread dump分析线程状态 除了上述的分析，大多数情况下会基于thead dump分析当前各个线程的运行情况，如是否存在死锁、是否存在一个线程长时间持有锁不放等等。在dump中，线程一般存在如下几种状态： RUNNABLE，线程处于执行中 BLOCKED，线程被阻塞 WAITING，线程正在等待 问题在实际调试中这两个线程无法并发执行,始终都是一个线程为RUNNABLE,一个为BLOCKED,但是实际代码并未加锁,根据堆栈打印出的信息线程中是在io流中加了锁 1locked &lt;0x0000000085c3d2e0&gt; (a java.io.OutputStreamWriter) 于是查看System.out.println(“ “)的源代码,可以看出源码中打印代码时加了锁的,所以导致两个线程无法并发 123456public void println(String x) &#123; synchronized (this) &#123; print(x); newLine(); &#125; &#125; 系统资源监控命令 vmstat iostat]]></content>
      <categories>
        <category>性能测试和监控</category>
      </categories>
      <tags>
        <tag>top</tag>
        <tag>jstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C2 CompilerThread1]]></title>
    <url>%2F2019%2F09%2F18%2Fjava-%E5%B8%B8%E8%A7%81%E7%BA%BF%E7%A8%8B%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[C2 CompilerThread1 线程 C2 Compiler 线程 是JVM在server模式下字节码编译器，JVM启动的时候所有代码都处于解释执行模式，当某些代码被执行到一定阈值次数，这些代码(称为热点代码)就会被 C2 Compiler编译成机器码，编译成机器码后执行效率会得到大幅提升。流量进来后，大部分代码成为热点代码，这个过程中C2 Compiler需要频繁占用CPU来运行，当大部分热点代码被编译成机器代码后，C2 Compiler就不再长期占用CPU了，这个过程也可以看作抖动。解决C2 CompilerThread1抖动方法,可以使用Jmeter等压测工具模拟线上访问流量，让C2 Compiler预先将热点代码编译成机器码, 减少对正式环境流量的影响。]]></content>
      <categories>
        <category>性能测试和监控</category>
      </categories>
      <tags>
        <tag>java常见线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见线程说明]]></title>
    <url>%2F2019%2F09%2F18%2F%E5%B8%B8%E8%A7%81%E7%BA%BF%E7%A8%8B%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch单节点安装]]></title>
    <url>%2F2019%2F09%2F11%2Felasticsearch%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[下载下载elasticsearch 6.8.2版本 解压目录tar -xvf 文件路径 开启服务$ ./bin/elasticsearch &amp; max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 问题 1234567#切换到root用户修改vim /etc/security/limits.conf# 在最后面追加下面内容*** hard nofile 65536*** soft nofile 65536*** 是启动ES的用户 root无法启动问题 123root用户无法启动elasticsearch,切换至其他用户并执行chown -R 文件目录 用户修改目录权限 非本机无法访问rest服务 12修改 config/elasticsearch.yml 修改以下标签为值network.host: 0.0.0.0]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小型项目领域驱动设计实践]]></title>
    <url>%2F2019%2F09%2F05%2F%E5%B0%8F%E5%9E%8B%E9%A1%B9%E7%9B%AE%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[前言 前面已经简介过领域驱动的基本概念，前文介绍的COLA框架在大型项目或者微服务架构中目测有较好的实践，但是对于一个中小项目或者小公司来说管理大量依赖包模块简直就是噩梦，或者就是项目达不到那种规模，采用分包模式也是一种浪费，但是采用领域驱动设计在本人实践过程中确实大大提升了代码质量，最主要的改善就是使开发人员不再以数据库驱动开发，而是真正的开始从业务和领域入手，这样开发出的代码往往能更好的实现面向对象，将代码划分出边界，使代码的可读性更强，代码更加健壮。本文结合现实中使用领域驱动设计时遇到的问题进行了总结，如果错误还需海涵。 项目说明 本文代码存放在 https://github.com/liushprofessor/ddd-demo 中 关于领域驱动设计的基础概念可查看本人个人博客中关于领域驱动部分，另外这纯属个人在实践中的总结，如有错误欢迎拍砖指导。 本项目主要有3个大包分别包含3次不同的实践，实践的具体内容如全文所述 user 为第一次实践包含各种模型设计和简介 user2 正对user包下存在的一些问题做了一些优化设计，请查看全文来看具体说明 project 为了针对实际项目中出现的大聚合来做的一些设计，这个包下只建立了模型设计，其余部分如果感兴趣可以自己补充(其实就是本人偷懒) 使用方法如果你使用的是mysql数据库那么修改application.properties中的数据源即可，liquibase会自动将所需要的表建立完毕 分包 和COLA框架采用模块不同，我采用一个项目下分不同的包的模式来区分领域设计的各个模块项目结构如下 demo └─com └─liu └─demo ├─app 客户端服务代码 ├─controller 控制层代码 ├─domain 领域层 │ ├─client 领域层防腐对象 │ └─modal 领域模型 └─infrastructure 基础层 ├─repository 仓库 │ └─mapper mybatis持久包 └─serviceimpl 领域服务包 app包：客户端代码存放的地方，负责组装调用领域模型，仓库，控制事务，对应六边形架构的应用服务层 controller包: 控制层代码，我用SpringMVC实现，对应六边形架构的输入适配器 domain包: 为项目中最核心的领域模型相关类存放的地方，对应六边形架构的领域(domain)层,另外在此根目录下会存放领域服务的接口，该接口由基础设施层去实现，因为领域层是最核心的层，根据六边形架构领域层需要放在最里层，但是领域服务却有需求调用基础设施层(infrastructure)下的仓库(repository),因此在这个层中定义一个接口由infrastructure层去实现，实现依赖倒置。 client包: 我创建此包是为了反腐，为了不使领域模型外泄，有效的控制代码的边界访问而设立，举例在http协议调用中dto对象从controller层到app层，当要进入到领域层（domain）时必须将其转化成领域模型，同样数据持久化在数据库中，从数据库中直接查找到的数据对象和领域对象同样存在差异，因此需要对外创建一个过渡对象提供给基础设施层调用，也许很多人会对这些对象放在domain层有疑问，但是我认为外部数据的访问领域对象数据的范围和权限是由领域模型去控制的，因此我觉得将其放在领域(domain)包中和适合的。 modal此包主要存放实体(Entity)，值对象(VO),生成领域模型的工厂方法,领域对象验证类. infrastructure基础设施层：主要存放基础设施的地方，比如数据库持久化，调用外部服务，队列等 repository仓库，对持久化的抽象，屏蔽数据库对象生成领域对象，领域对象从创建开始就已经开始生命周期，一直到删除才结束，中间会把领域对象存储在数据库中，存储在数据库时领域对象仍然处于生命周期，因此仓库层的作用就是屏蔽持久层，让调用者觉得领域对象一直存在内存中一样. mapper 由于我使用的是mybatis，所以我创建此层建mybatis的类放在此 serviceimpl 领域服务包，同样有很多人可能会有疑问为什么我讲领域服务的实现类放在基础设施层中，这一点我上面提过，为了实现依赖导致，只要是领域服务的接口存放在领域层(domain)那么我们仍然认为领域服务属于领域层，因为接口规定了领域服务的功能和方法。 建模 在这里我们假设我们和业务方沟通需要实现这样的功能,用户可以有自己的基础信息，这些信息包括用户名，email地址，且用户可以根据用户id和密码登录系统，且用户可以单独修改登录密码，也可以修改用户信息,根据需求分析我们可以得出用户有一个唯一型标识用户id，因此我们得出用户是实体，用户名和email这两个属性对用户来说并不需要维护状态的变化，修改时候为了简单将其整个对象替换即可，因此我们将其设计成值对象VO,由于用户可以单独修改密码因此修改密码对应前端一个单独入口，所有我们将密码这个属性放在用户对象中，因此我们得到以下模型,实体对象UserE中有一个修改用户的方法，只有一个构造方法，并且可以进行密码验证和获取用户基础信息，注意这里并没有set方法，而是用了类似changePassword等方法名代替set方法，这是为了使领域模型充血，为了使模型更好的体现业务，如果使用set修改密码的话，那我们怎么和业务人员解释修改密码这个方法？难道说我set了密码？这明显无法表示出领域对象的意图，反之将其命名changePassword修改密码那么就可以很好的表示出领域模型的意图，领域方法名需要表示出领域和业务的意图。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859 public class UserE &#123; private String userId; private String password; private BaseInfoVO baseInfo ; /** * 修改用户密码 */ public void changePassword(String password)&#123; if(password==null)&#123; throw new IllegalArgumentException(&quot;密码不能为空&quot;); &#125; this.password=password; &#125; public UserE(String userId, String password, BaseInfoVO baseInfo) &#123; this.userId = userId; this.password = password; this.baseInfo = baseInfo; &#125; public String getUserId() &#123; return userId; &#125; public String getPassword() &#123; return this.password; &#125; /** * 认证服务，查询传入密码是否匹配 * @param password 需要认证的密码 * @return 认证结果 */ public boolean authentication(String password) &#123; return password != null &amp;&amp; password.equals(this.password); &#125; public BaseInfoVO getBaseInfo() &#123; return baseInfo; &#125; /** * 修改用户基础信息 */ public void changeInfo(BaseInfoVO baseInfoVO)&#123; this.baseInfo=baseInfoVO; &#125;&#125; 下面是BaseInfoVO为用户的基础信息,同样我们也没有暴露set方法,由于它只是一个用户的值对象，因此并没有那么多的领域方法,至此我们的核心领域对象就已经建立完成了 123456789101112131415161718192021222324252627282930/** * @author Liush * @description 用户基础信息 * @date 2019/9/5 9:48 **/public class BaseInfoVO &#123; private String username; private String email; public BaseInfoVO(String username, String email) &#123; if(username==null)&#123; throw new IllegalArgumentException(&quot;用户名不能为空&quot;); &#125; if(email==null)&#123; throw new IllegalArgumentException(&quot;邮箱不能为空&quot;); &#125; this.username = username; this.email = email; &#125; public String getUsername() &#123; return username; &#125; public String getEmail() &#123; return email; &#125;&#125; 现在让我们考虑如何新增一个用户，创建用户对应领域模型就是创建一个用户实体(UserE),那我们如何做到将领域层的模型信息不外泄到其它地方呢?因为新增用户也属于领域（业务的一部分），举个例子我们去银行开个户也要到银行才能办理，我们不能到公安局去开银行账户，所以我们把创建用户对象放在领域层，而创建用户实体(UserE)有两种方法，一种是直接调用其构造，一种是通过工厂类来创建，但是这里又会出现一个问题，用户实体(UserE)需要一个BaseInfoVO（基础信息）来构造，但是按照领域驱动设计的理念来设计BaseInfoVO（基础信息）只能有领域在领域层中才能去创建，因为我们的通用语言是用户创建和修改了基础信息，如果我们将BaseInfoVO（基础信息）放在领域层外创建就好比一句话少了主语。我采用在领域层中使用工厂类去创建用户实体(UserE)，在工厂方法中传入一个DTO来隔离领域层外部的信息，代码如下,其创建了一个用户实体(UserE)并且使用UUID分配了一个默认的用户ID给用户，最后调用用户实体(UserE)的构造方法去创建用户实体对象，执行完这一行代码，一个用户对象就已经进入了生命周期，直到在数据库中删除或者将用户状态改成不可能用这个用户的生命周期才结束。 123456789101112131415161718192021package com.liu.demo.user.domain.modal;import com.liu.demo.user.domain.client.UserDTO;import org.springframework.stereotype.Component;import java.util.UUID;/** * @author Liush * @description 领域工厂类 * @date 2019/9/5 14:10 **/@Componentpublic class UserFactory &#123; public UserE createUser(UserDTO userDTO )&#123; BaseInfoVO baseInfoVO=new BaseInfoVO(userDTO.getUsername(),userDTO.getEmail()); return new UserE(UUID.randomUUID().toString(),userDTO.getPassword(),baseInfoVO); &#125;&#125; 持久化现在是时候考虑用户对象持久化的问题了，毕竟用户对象不能永远存留在内存中，必须在不使用对象时将其持久化到硬盘中基础设施层包infrastructure下的repository就是为了解决这个问题,它的作用是屏蔽数据库持久化的一些代码，让代码看起来更贴近领域设计一些，我们可以从仓库中根据查找条件直接还原出一个用户实体对象，对领域代码来说数据库持久化代码就好像不存在一样，下面是用户仓库代码,这里注意一下一个方法findUsersByName，这是一个查询方法，从数据库中查询出UserPO然后将其转成UserDTO，这里我们看到我们并没有走领域模型，因为查询往往为了效率特别是批量查询我们做了一部分妥协，但是这部分妥协是可以接受的，因为我们并没有执行领域动作(command)的代码，只是返回一个dto对象给前端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.liu.demo.user.infrastructure.repository;import com.liu.demo.user.domain.client.UserDTO;import com.liu.demo.user.domain.client.UserPO;import com.liu.demo.user.domain.modal.UserE;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Repository;import com.liu.demo.user.infrastructure.repository.mapper.UserMapper;import java.util.ArrayList;import java.util.List;/** * @author Liush * @description 用户仓库 * @date 2019/9/5 11:17 **/@Repositorypublic class UserRepository &#123; @Autowired private UserMapper userMapper; @Autowired private UserRepositoryConvert userRepositoryConvert; /** * 根据用户id查找用户 */ public UserE findUser(String userId)&#123; UserPO userPO =userMapper.findUser(userId); return userRepositoryConvert.convertToUserE(userPO); &#125; /** * 添加用户 */ public void addUser(UserE user)&#123; UserPO userPO= userRepositoryConvert.convertToUserPO(user); userMapper.insertUser(userPO); &#125; /** * 修改密码 */ public void changePassword(UserE userE)&#123; userMapper.updateUserPassword(userE.getUserId(),userE.getPassword()); &#125; /** *根据用户姓名批量查询，查询可以不走领域模型 */ public List&lt;UserDTO&gt; findUsersByName(String name)&#123; List&lt;UserPO&gt; userPOs=userMapper.findUsersByName(name); List&lt;UserDTO&gt; userDTOs=new ArrayList&lt;&gt;(); if (userPOs==null)&#123; return userDTOs; &#125; userPOs.forEach(userPO-&gt;userDTOs.add(userRepositoryConvert.convertToUserDTO(userPO))); return userDTOs; &#125;&#125; 领域服务下面考虑一下这个问题，修改密码，我们在修改密码时一般都会调用远程接口，比如获取短信验证码和校验验证码，这部分放在用户实体中是不合适的，但是远程调用短信接口这部分代码又属于基础设施层的内容，但是在提供给app层调用的时候我们又不想把这部分属于业务逻辑暴露给app层，因为由app层去组装的话，那么开发app层的人员就需要知道业务的流程，他必须知道修改密码内部的流程走向（调用短信验证接口），我们想做的就是客户端开发人员只要调用一个修改密码的方法就好了，至于里面执行什么业务逻辑客户端开发人员不要操心，所以我们采用领域服务去封装修改密码的业务，由客户端开发人员去调用领域服务来屏蔽业务的细节，那么现在就会产生这样一个问题，领域层要依赖基础设施层，但是这样是有悖于六边形架构的（领域层应该放在依赖的最内部），于是我们使用依赖倒置技术，在领域层中创建一个领域服务接口，由基础设施去实现，这样就实现了基础设施层依赖领域层，但是领域层又通过接口对基础设施层领域服务可以做什么做了规定和约束。下面是领域层中的领域服务接口的定义，它提供了一个修改密码的接口 123456789101112package com.liu.demo.user.domain;/** * @author Liush * @description 用户领域服务 * @date 2019/9/5 11:07 **/public interface UserServiceI &#123; void changePassword(String userId,String password);&#125; 下面由基础设施层去实现这个接口 123456789101112131415161718192021222324252627package com.liu.demo.user.infrastructure.serviceimpl;import com.liu.demo.user.domain.UserServiceI;import com.liu.demo.user.domain.modal.UserE;import com.liu.demo.user.infrastructure.repository.UserRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/*** @author Liush* @description User领域服务* @date 2019/9/5 11:12**/@Servicepublic class UserServiceImpl implements UserServiceI &#123; @Autowired private UserRepository userRepository; @Override public void changePassword(String userId, String password) &#123; //执行短信验证代码这边省略 UserE user =userRepository.findUser(userId); user.changePassword(password); userRepository.changePassword(user); &#125;&#125; 现在由APP层去调用修改密码 123public void changePassword(String userId,String password)&#123; userServiceI.changePassword(userId,password); &#125; 关于client二方包的思考在我最开始接触领域设计的时候这些二方包我是没有放在领域模型层里的，当时我会创建一个common包，把这些东西放在common包下，当时随着理解的深入，我认为领域驱动最核心的内容之一就是边界的划分，边界的划分就以为着可以由不同开发者去开发不同的模块(比如一个人去开发领域模型，一个人去开发app层负责组装),如果我们把写代码放在common包中，那么app层开发人员就要去建立自己的领域防腐模型(DTO,PO等)，这样一定程度上也将领域模型的内容泄露出去，与其让客户端开发人员去编写防腐代码，比如有领域层开发人员去设计这部分代码，规定领域层的输入和输出，当然还包括一些领域层和防腐层对象的装换比如示例代码中提供的UserConvert对象装换类其实现如下,这样即让领域层代码不外泄，也很好的把控客户端可以访问什么属性。 1234567891011121314151617181920package com.liu.demo.user.domain.client;import com.liu.demo.user.domain.modal.UserE;import org.springframework.stereotype.Component;/** * @author Liush * @description 转换类 * @date 2019/9/5 14:52 **/@Componentpublic class UserConvert &#123; public UserDTO convertToUserDTO(UserE userE)&#123; String username=userE.getBaseInfo().getUsername(); String email=userE.getBaseInfo().getEmail(); return new UserDTO(userE.getUserId(),userE.getPassword(),username,email); &#125;&#125; 更进一步上诉代码在一般小项目中其实也已经够用，但是眼尖的同学可能会发现存在两个问题 用户实体(UserE)中的changePassword方法是暴露给客户端的，客户端人员在APP层可以直接获取UserE对象然后绕过领域服务去修改密码，这样就不要去验证短信服务等接口了，这样做明显是不符合业务逻辑的。 实体的整体验证，上面代码用户实体(UserE)只对单个属性进行验证比如属性是否为空，但是有些实体对象存在整体验证，比如用户实体(UserE)中如果业务规定密码和邮箱都必须以数字开头怎么办？ 这一节将着手解决这个问题，这部分代码在user2包下 首先我们解决第一个问题，我们创建了一个用户抽象类,这个抽象类并没有修改密码的方法，它只暴露了客户端可以调用的代码 123456789101112131415161718192021222324252627282930313233343536package com.liu.demo.user2.domain.modal;import com.liu.demo.user2.common.DoNothingValidateHandler;import com.liu.demo.user2.common.ValidateHandlerI;/** * @author Liush * @description * @date 2019/9/5 15:27 **/public abstract class UserAbstract &#123; protected String userId; protected String password; protected BaseInfoVO baseInfo ; protected ValidateHandlerI validateHandlerI; public UserAbstract(String userId, String password, BaseInfoVO baseInfo) &#123; this.userId = userId; this.password = password; this.baseInfo = baseInfo; this.validateHandlerI=new DoNothingValidateHandler(); &#125; public abstract boolean authentication(String password); public abstract BaseInfoVO getBaseInfo(); public abstract String getUserId();&#125; 然后我们实现这个类，子类中包行了changePassword方法， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.liu.demo.user2.domain.modal;/** * @author Liush * @description 用户实体类 * @date 2019/9/5 9:47 **/public class UserE extends UserAbstract &#123; public void changePassword(String password)&#123; if(password==null)&#123; validateHandlerI.handlerError(&quot;密码不能为空&quot;,new IllegalArgumentException()); &#125; this.password=password; &#125; /** * 构造完实体后对实体进行整体验证 */ public UserE(String userId, String password, BaseInfoVO baseInfo) &#123; super(userId,password,baseInfo); new UserValidate(this).validate(); &#125; public String getUserId() &#123; return super.userId; &#125; public String getPassword() &#123; return super.password; &#125; /** * 认证服务，查询传入密码是否匹配 * @param password 需要认证的密码 * @return 认证结果 */ public boolean authentication(String password) &#123; return password != null &amp;&amp; password.equals(this.password); &#125; public BaseInfoVO getBaseInfo() &#123; return baseInfo; &#125;&#125; 现在我们在所有返回给客户端代码中的返回用户实体对象不再是UserE而是UserAbstract,如repository包下的repository对象，这样客户端就不能直接通过用户实体去修改密码，而不需通过领域服务去修改密码，而在对应的领域层代码或者基础设施代码中完成一次对象的装换即可（将UserE转成UserAbstract） 123456789101112131415161718192021222324252627282930313233343536373839package com.liu.demo.user2.infrastructure.repository;import com.liu.demo.user2.domain.client.UserPO;import com.liu.demo.user2.domain.modal.UserE;import com.liu.demo.user2.domain.modal.UserAbstract;import com.liu.demo.user2.infrastructure.repository.mapper.UserMapper2;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Repository;/** * @author Liush * @description 用户仓库 * @date 2019/9/5 11:17 **/@Repositorypublic class UserRepository2 &#123; @Autowired private UserMapper2 userMapper; @Autowired private UserRepositoryConvert2 userRepositoryConvert; public UserAbstract findUser(String userId)&#123; UserPO userPO =userMapper.findUser(userId); return userRepositoryConvert.convertToUserE(userPO); &#125; public void addUser(UserAbstract user)&#123; UserPO userPO= userRepositoryConvert.convertToUserPO((UserE) user); userMapper.insertUser(userPO); &#125;&#125; 第二个问题解决方法这次我们定义了一个common包下面有两个基类ValidateAbstract（验证抽象类）,此类为实体整体验证的一个基类，其构成方法中需要传入一个验证处理器，这个处理器的作用是为了如过验证类整体验证失败则调用验证处理器完成错误信息处理，这样做的目的是为了可以将验证和异常处理做解耦，同样在没有参数的构造方法中体用了一个默认的验证处理器 1234567891011121314151617181920212223242526package com.liu.demo.user2.common;/** * @author Liush * @description 验证抽象类 * @date 2019/9/5 17:11 **/public abstract class ValidateAbstract &#123; protected ValidateHandlerI validateHandlerI; public ValidateAbstract(ValidateHandlerI validateHandlerI) &#123; this.validateHandlerI = validateHandlerI; &#125; public ValidateAbstract() &#123; this.validateHandlerI=ValidateHandlerFactory.doNothingValidateHandler(); &#125; public abstract void validate(); public void setValidateHandlerI(ValidateHandlerI validateHandlerI) &#123; this.validateHandlerI = validateHandlerI; &#125;&#125; 用户实体整体验证类实现 1234567891011121314151617181920212223242526272829303132333435package com.liu.demo.user2.domain.modal;import com.liu.demo.user2.common.ValidateAbstract;import com.liu.demo.user2.common.ValidateHandlerI;import org.springframework.util.StringUtils;/** * @author Liush * @description * @date 2019/9/5 17:24 **/public class UserValidate extends ValidateAbstract &#123; protected UserE userE; public UserValidate(UserE userE) &#123; super(); this.userE=userE; &#125; public UserValidate(UserE userE,ValidateHandlerI validateHandlerI) &#123; super(validateHandlerI); this.userE=userE; &#125; @Override public void validate() &#123; if(StringUtils.isEmpty(userE.getPassword()) &amp;&amp; StringUtils.isEmpty(userE.getBaseInfo().getUsername()))&#123; super.validateHandlerI.handlerError(&quot;密码和用户名不能同时为空&quot;,new RuntimeException(&quot;UserE对象整体验证失败&quot;)); &#125; &#125;&#125; 验证处理器 123456789101112package com.liu.demo.user2.common;/** * @author Liush * @description 验证错误处理器 * @date 2019/9/5 17:03 **/public interface ValidateHandlerI &#123; void handlerError(String message,Exception e);&#125; 一个默认实现的验证处理器 1234567891011121314151617181920212223package com.liu.demo.user2.common;/** * @author Liush * @description * @date 2019/9/5 17:05 **/public class DoNothingValidateHandler implements ValidateHandlerI &#123; @Override public void handlerError(String message,Exception e) &#123; System.out.println(message); if(e instanceof IllegalArgumentException)&#123; throw new IllegalArgumentException(message); &#125; if(e instanceof RuntimeException)&#123; throw new RuntimeException(message); &#125; &#125;&#125; 下面我们进行代码整合，你会发现现在再用户实体(UserE)的构造中最后多了一行代码 1234567/** * 构造完实体后对实体进行整体验证 */ public UserE(String userId, String password, BaseInfoVO baseInfo) &#123; super(userId,password,baseInfo); new UserValidate(this).validate(); &#125; 在创建用户实体(UserE)时会进行整体验证，如果不通过就抛出异常此处这两个问题解决完毕 大聚合对象在实际实践过程中遇到过一些大聚合对象，什么是大聚合对象？举个例子，现在有这么一个业务，一个软件项目，下面有成败上千的子项目，子项目都必须在父项目中创建，如果我们按照原始的设计那么代码就会变这样,这样做有什么不妥呢？比如我们以后想查看工程的名字或者修改，那么我们就必须加载整个工程的子项目，如果子项目较小，这样设计也是可以接受的，但是如果子项目有成千上万个，那么这样做有些浪费资源，而且我只是单纯的修改工程名，和子项目并没有什么关联 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.liu.demo.project.domain.modal;import java.util.Date;import java.util.List;/** * @author Liush * @description 项目旧模型 * @date 2019/9/6 10:59 **/public class ProjectEOld &#123; //项目ID private String projectId; //项目名 private String name; //项目开始日期 private Date beginDate; //子项目 private List&lt;ItemE&gt; items; public ProjectEOld(String projectId, String name, Date beginDate, List&lt;ItemE&gt; items) &#123; this.projectId = projectId; this.name = name; this.beginDate = beginDate; this.items = items; &#125; //创建子项目 public void createItem(ItemE itemE)&#123; items.add(itemE); &#125; public String getProjectId() &#123; return projectId; &#125; public String getName() &#123; return name; &#125; public Date getBeginDate() &#123; return beginDate; &#125; public List&lt;ItemE&gt; getItems() &#123; return items; &#125;&#125; 于是我们退而求次改建模型,我们现在创建了两个模型ProjectE，ItemE我们现在将这两个实体分开，ProjectE不再包含ItemE集合，在ItemE我们加入了一个属性projectId和父工程做关联，需要注意的是为了凸显领域和我们的模型是对应的我们在ProjectE中有一个createItem的方法，这个方法符合领域描述子项目是在工程中创建的，也许你们有疑问这样在视图展示方法是不是很不方便？（比如我要一次查找工程名字和工程下面所有的子项目列表），这一点我在上文已经说过，在领域设计中查询和命令是可以做分离的，查询设计可以不走领域模型. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.liu.demo.project.domain.modal;import java.util.Date;/** * @author Liush * @description 工程实体 * @date 2019/9/6 10:49 **/public class ProjectE &#123; //项目ID private String projectId; //项目名 private String name; //项目开始日期 private Date beginDate; /** *由于工程子项目属于工程，按照通用语言，工程子项目要由工程去穿件，这样保证了领域和业务模型的统一性 */ public ItemE createItem(String itemId,String name)&#123; return new ItemE(itemId,name); &#125; public ProjectE(String projectId, String name, Date beginDate) &#123; this.projectId = projectId; this.name = name; this.beginDate = beginDate; &#125; public String getProjectId() &#123; return projectId; &#125; public String getName() &#123; return name; &#125; public Date getBeginDate() &#123; return beginDate; &#125;&#125; 子项目模型 1234567891011121314151617181920212223242526272829303132333435package com.liu.demo.project.domain.modal;/** * @author Liush * @description 项目实体 * @date 2019/9/6 10:49 **/public class ItemE &#123; //工程id private String projectId; //项目实体 private String itemId; //项目名 private String name; public ItemE(String itemId, String name) &#123; this.itemId = itemId; this.name = name; &#125; public String getItemId() &#123; return itemId; &#125; public String getName() &#123; return name; &#125; public String getProjectId() &#123; return projectId; &#125;&#125; 总结使用了领域驱动设计是一个长期过程，随着业务的变化原来的模型可能不再适用，或者有一天觉得原来的模型并不合理，这些都是非常常见的现象，领域驱动设计的另一个核心就是不断重构来创造出合适的模型，没有什么所谓银弹，只有不断摸着石头过河才能构建出好的设计。最后说一点在现实生活中肯定会有一些设计和需求的矛盾，比如客户坚持要批量新增而且又要快速响应怎么办？领域设计可能会影响一部分效率，但是什么才是慢？我觉得的在合理时间内就不算是慢，比如采用过程化开发调用一个接口的响应速度是1秒，采用领域驱动设计是1.1秒那我觉得这个慢是可接受的，并不影响用户体验，但是这0.1秒换来的是代码设设计的清晰，我觉得这是一笔稳赚不赔的买卖，最后再次声明，没有所谓的银弹，世界上没有完美的事，代码一样，人生也一样，不要和甲方爸爸过不去，因为他是你的爸爸。]]></content>
      <categories>
        <category>领域驱动设计(DDD)</category>
      </categories>
      <tags>
        <tag>领域驱动设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis的缓存机制]]></title>
    <url>%2F2019%2F09%2F04%2Fmybatis%E7%9A%84%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[缓存简介 一级缓存 会话缓存 mybatis对应sqlsession，对应于一个连接 二级缓存 应用缓存，不同会话也可访问统一缓存 mybatis对应namespace 三级缓存 跨jvm 如redis mybatis缓存实践 spring事务有四个等级，在mysql inndbn内核中默认采用可重复读（两个事务同时处理一条数据 一个事务更新了，在另一个事务中读取到的仍然是旧的值），mybatis中默认开启一级缓存，如果事务等级低于可重复读 那么在两个事务同时操作一条记录中如（@Transactional( isolation =Isolation.READ_COMMITTED )），一个 事务修改另一个事务就会看见该修改，但是mybatis默认会在当前事务中从缓存中读取，需要手动调用sqlSession.clearCache(); 或者在xml select标签中加上 flushCache=”true”读取时刷新缓存，如果采用java编码方式则加上@Options(flushCache =Options.FlushCachePolicy.TRUE )注解读取时刷新mybatis缓存 在Spring中只有同一锁中读取数据才能用到一级缓存，因为同一锁中使用的是sqlSession是同一个实例对象，如果两次调用是获取不同的sqlSession,所以一级缓存无效,同样因为sqlsession不同所以update也无法对一级缓存进行刷新,另外尽量不要对mybatis返回的对象进行操作，因为返回的对象是缓存在一级缓存中的，改变返回对象一级缓存中的对象也会改变 二级缓存是基于namespqce的缓存（xml中 中的namespace）， 所有对于一张表的操作都需要放在一个namespace中，这样保证更新或者insert操作后后二级缓存可以更新，不然会导致 脏读（在另一个namespace中操作后二级缓存没更新，因为没在用一个namespace下），xml开启二级缓存在xml中添加即可， 注解版开启二级缓存在mapper接口上添加@CacheNamespace(blocking = true)]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[COLA-复杂项目领域驱动设计框架源码和架构解析]]></title>
    <url>%2F2019%2F09%2F04%2FCOLA-%E5%A4%8D%E6%9D%82%E9%A1%B9%E7%9B%AE%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%92%8C%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[COLA简介 可自行到github上查看md简介 https://github.com/alibaba/COLA 目录结构分析COAL提供了一个很方便的maven生成模板，按照项目说明我们生成一个web项目，打开目录我们发现如下几个子模块 父项目 └── start 项目启动模块 └── app 项目应用服务模块（可以理解为客户端程序员在此编写代码） └── client 提供给客户端程序员使用的二方包，为应用服务模块提供一下基础类 └── controller 控制层SpringMVC实现 └── domain 领域层 └── infrastructure 基础设施层，包含数据库持久化，一些其它基础设施调用代码放在此，如RPC调用，队列调用等基础设施代码其项目依赖目录如下start依赖controller，controller依赖app，app同时依赖client和infrastructure，infrastructure依赖domain start └── controller └── app ├── client ├── infrastructure └── domain从依赖中我们明显可以看到前文提到的六边形架构的影子，controller为输入端适配器，infrastructure为持久化输出适配器，而核心服务domain领域层作为软件的核心和最稳定的部分放在依赖的最底层 结合领域驱动设计分析目录结构从目录结构当中划分其实这个框架应该分为两部分，app层之下（不包括）为领域部分，这部分由对领域知识理解较好的开发人员去建模，而app层（包括）之上则为客户端代码，可以由对领域知识不那么了解的开发人员去开发，作者之所以引入client模块一方面是提供了一些二方包和接口功能客户端调用，最主要的原因是反腐，为了反腐在client包中引入DTO，为了读写分离（在领域驱动中这点很重要）又有Command和Query两个实现类，以此完成写命令和读命令的区分，因为在写命令中需要完全遵守领域模型去完成，但是在查询中往往为了响应速度等的妥协而放弃领域模型，直接从基础设施层中读取查询对象返回给前端. 应用框架方面提供了一些注解如示例中的@Command注解,其需要作用在CommandExecutorI的实现类下，这部分内容放在app层代码由客户端人员去实现，这样可以将客户端的业务逻辑放在CommandExecutorI接口规定的方法下，客户端逻辑更加清晰，一个@Command代表着一个客户单操作，每个客户端操作的代码又放在不同的CommandExecutorI实现类下，而框架显示的将操作分为查询操作和命令操作来实现读写分离，实现了各个功能模块的解耦。 client包作为约束客户端（APP）层的重要模块，其下面定义了一个CustomerServiceI接口，此结构的实现类由app层去实现，这种依赖反转的方式很好的控制了app端能做什么也简化了开发。 domain包为领域开发人员所使用的包，领域开发人员将设计的领域模型都放在此提供app层和infrastructure层去调用 infrastructure包可以由数据库开发人员去实现，里面包含领域对象持久化内容和一些基础服务，并且其提供了一个SpringBean的配置文件负责整合了框架 核心源码解析在demo app层中我们发现了被@Command注解的实现类 123456789101112@Commandpublic class CustomerListByNameQryExe implements QueryExecutorI&lt;MultiResponse&lt;Customer&gt;, CustomerListByNameQry&gt; &#123; @Override public MultiResponse&lt;Customer&gt; execute(CustomerListByNameQry cmd) &#123; List&lt;Customer&gt; customerList = new ArrayList&lt;&gt;(); Customer customer = new Customer(); customer.setCustomerName(&quot;Frank&quot;); customerList.add(customer); return MultiResponse.ofWithoutTotal(customerList); &#125;&#125; 在app服务类调用中仅仅是将customerListByNameQry对象发送给CommandBusI（CommandBus总线）即完成调用 1234567891011121314151617@Servicepublic class CustomerServiceImpl implements CustomerServiceI &#123; @Autowired private CommandBusI commandBus; @Override public Response addCustomer(CustomerAddCmd customerAddCmd) &#123; return (Response)commandBus.send(customerAddCmd); &#125; @Override public MultiResponse&lt;Customer&gt; listByName(CustomerListByNameQry customerListByNameQry) &#123; return (MultiResponse&lt;Customer&gt;)commandBus.send(customerListByNameQry); &#125;&#125; 我们使用编译器进入CommandBusI实现类发现CommandBusI下对应着一个CommandBus的实现类 123456789101112@Componentpublic class CommandBus implements CommandBusI&#123; @Autowired private CommandHub commandHub; @Override public Response send(Command cmd) &#123; return commandHub.getCommandInvocation(cmd.getClass()).invoke(cmd); &#125;&#125; 我们再进入CommandHub查看getCommandInvocation方法，发现其实CommandInvocation是从一个HashMap中来的，那么HashMap里的值是合适初始化的呢 12345678private Map&lt;Class/*CommandClz*/, CommandInvocation&gt; commandRepository = new HashMap&lt;&gt;();public CommandInvocation getCommandInvocation(Class cmdClass) &#123; CommandInvocation commandInvocation = commandRepository.get(cmdClass); if (commandRepository.get(cmdClass) == null) throw new ColaException(cmdClass + &quot; is not registered in CommandHub, please register first&quot;); return commandInvocation; &#125; 在infrastructure模块下我们发现框架的入口配置类ColaConfig 123456789101112@Configurationpublic class ColaConfig &#123; @Bean(initMethod = &quot;init&quot;) public Bootstrap bootstrap() &#123; Bootstrap bootstrap = new Bootstrap(); List&lt;String&gt; packagesToScan = new ArrayList&lt;&gt;(); packagesToScan.add(&quot;com.liu&quot;); bootstrap.setPackages(packagesToScan); return bootstrap; &#125;&#125; 于是我们定位到框架的入口,顺着初始化代码在源码COLA-master的cola-framework下找到Bootstrap类,找到初始化方法init 1234public void init() &#123; Set&lt;Class&lt;?&gt;&gt; classSet = scanConfiguredPackages(); registerBeans(classSet); &#125; 看到这里我们就已经明白了scanConfiguredPackages（）方法是扫描编译目录下的Class文件，registerBeans是注册bean对象我们进入registerBeans方法,发现其遍历之前扫描的class文件,并且传入在registerFactory 123456789private void registerBeans(Set&lt;Class&lt;?&gt;&gt; classSet) &#123; for (Class&lt;?&gt; targetClz : classSet) &#123; RegisterI register = registerFactory.getRegister(targetClz); if (null != register) &#123; register.doRegistration(targetClz); &#125; &#125; &#125; 进入registerFactory.getRegister(targetClz)方法，发现代码在registerFactory中根据类上的注解返回对应的注册器，之前对应的@Command注解对应的就是为commandRegister注册器 1234567891011121314151617181920212223public RegisterI getRegister(Class&lt;?&gt; targetClz) &#123; PreInterceptor preInterceptorAnn = targetClz.getDeclaredAnnotation(PreInterceptor.class); if (preInterceptorAnn != null) &#123; return preInterceptorRegister; &#125; PostInterceptor postInterceptorAnn = targetClz.getDeclaredAnnotation(PostInterceptor.class); if (postInterceptorAnn != null) &#123; return postInterceptorRegister; &#125; Command commandAnn = targetClz.getDeclaredAnnotation(Command.class); if (commandAnn != null) &#123; return commandRegister; &#125; Extension extensionAnn = targetClz.getDeclaredAnnotation(Extension.class); if (extensionAnn != null) &#123; return extensionRegister; &#125; EventHandler eventHandlerAnn = targetClz.getDeclaredAnnotation(EventHandler.class); if (eventHandlerAnn != null) &#123; return eventRegister; &#125; return null; &#125; 我们再看commandRegister中的doRegistration方法，现在结果一目了然，这里获取Spring容器中的CommandInvocation对象，并且调用commandHub.getCommandRepository().put(commandClz, commandInvocation)将之前被@Command注解的实现类传入commandRepository中也就是之前上面从HashMap中获取CommandInvocation的地方，代码中还提供了自定义AOP功能，但这部分并未开发接口，至此，整个框架的代码流程就已清晰。 123456789@Override public void doRegistration(Class&lt;?&gt; targetClz) &#123; Class&lt;? extends Command&gt; commandClz = getCommandFromExecutor(targetClz); CommandInvocation commandInvocation = ApplicationContextHelper.getBean(CommandInvocation.class); commandInvocation.setCommandExecutor((CommandExecutorI) ApplicationContextHelper.getBean(targetClz)); commandInvocation.setPreInterceptors(collectInterceptors(commandClz, true)); commandInvocation.setPostInterceptors(collectInterceptors(commandClz, false)); commandHub.getCommandRepository().put(commandClz, commandInvocation); &#125;]]></content>
      <categories>
        <category>领域驱动设计(DDD)</category>
      </categories>
      <tags>
        <tag>领域驱动设计</tag>
        <tag>COLA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[领域驱动设计DDD简介]]></title>
    <url>%2F2019%2F09%2F03%2F%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1DDD%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[什么是领域驱动设计 接触领域驱动设计已经有一年多的时间了，其更关注的是解决复杂的软件设计。这期间也拿一些小项目尝试实践过，也看过一些领域驱动的框架如Halo，Cola,在实践过程中发现如果小项目如果采用简化版的领域驱动设计的理念去实践，代码结构也会有明显的改善，在小项目实践过程中更关注的是边界的划分，和不同功能模块代码的解耦，把核心的领域代码和其它代码区分出来，更好的将代码和现实业务结合起来，更好的执行面向对象，在使用领域驱动设计时能让我们从数据库驱动设计的理念中转换出来，在设计时假设计算机内存是无限大，只考虑领域模型，而不考虑数据库模型，从而使代码更贴近业务，我觉得这是领域驱动设计给我带来的感触。就比如架构，架构的本质无非就是把代码的边界区分好，把代码放在该放的地方Eric Evans提出的领域驱动设计是一个很好的解决这部分问题的方法。领域驱动设计，领域代表着行业，你的软件是应用在哪个行业实现什么样的功能，比如你编写了一个财务软件，那么财务行业就是你编写软件的领域，Eric Evans强调软件一定是要由领域专家和领域知识去驱动开发的，因为软件最终是要应用到领域当中，如果绕过这部分内容直接开发软件，那么开发的软件往往无法交付或者无法满足功能，在我认为，软件是现实生活中的映射，在开发第一个版本的时候，可以和领域专家或者领域中的从业人员进行交流业务流程(现实往往只能找到产品经理)，交流一下在没有软件的情况下，线下业务是如何进行的，然后再根据这些流程去建立领域对象，去驱动整体的软件设计。 领域驱动设计的核心概念通用语言 在开发准备之前必须要和领域人员(如果没有，那只能是需求人员)建立好一套通用的开发语言，我曾经在没接触过过领域驱动设计时实现一个功能时并没有和当时对应需求人员建立一套通用的语言，就是产品说的一个名词和你说的名词并不是同一个名词，但是你以为你理解了产品经理的意思，然后就去开发，结果到交付时发现整个理念完全错误，导致最后返工。建立通用语言的过程往往要经过反复沟通后才能得出的，在反复沟通的过程中，抓住一个反复提及的名词，然后确定这个名词代表的含义，反复提及的名词往往就是找到通用语言的关键,在软件建模中也要紧紧围绕这个名词去建模，当你建立完模型后（通常是UML图），把这部分模型拿给领域专家看，因为你这时候的模型就代表着现实的业务，和领域人员确认模型这样设计是否合理。 领域模型贫血型模型 在领域驱动设计中Eric Evans一直不赞成使用贫血型模型，什么是贫血型模型，简单来说就是我们平常建立的java bean对象，只包行一些字段和get，set方法，因为贫血型对象不能很好的展示出领域模型，有一些本该属于领域模型的方法外泄到其它类比如Service类中去了，所有和领域相关的代码都要包含在领域模型中或者领域服务中，举个例子,有一个用户信息模型，一般我们是这样设计和调用的 12345678910111213141516171819202122public class User &#123; private String userId; private String userName; public String getUserId() &#123; return userId; &#125; public void setUserId(String userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125;&#125; 现在我要修改用户的名字那边就要用Service去实现 1234567891011public class UserService &#123; public void changeUserName(String userName,User user)&#123; if(userName!=null)&#123; user.setUserName(userName); &#125; &#125;&#125; 认真考虑一下现实项目中采用上文编写代码所产生的问题 代码不能很好的体现业务changeUserName这个方法应该是属于用户类中的方法，但是现实中该类却放在了调用方的Service中，上文提到了通用语言，在和领域人员沟通时，他们会说到用户修改了用户名，这里作用的主体是用户，只有用户有权利修改自己的用户名，但是体现在代码中却变成了用户把修改用户名的权利交给了调用方，这样的代码并不能很好的反应出业务，也并不是很好的面向对象的模型。 Service上帝类采用上述方法去建模，将会导致service类的代码快速膨胀，久而久之service类负责所有的功能，包括校验，对象持久化，远程调用等待代码，如果在项目开始时还可以接受，但是随着时间的发展，service变成了乱麻，再也没有人能够轻松分清里面的逻辑了。 充血模型 现在我们采用充血模型实现上述代码 12345678910111213public class User &#123; private String userId; private String userName; public void updateUserName(String userName) &#123; if(userName!=null)&#123; this.userName=userName; &#125; &#125;&#125; 现在我们将原本存在Service中的updateUserName方法放到领域模型中，就修改用户名时传入用户名即可完成用户名修改，这完全符合通用语言的用户修改了用户名，并且在修改用户名时候进行了校验，校验本身也是领域对象提供的功能之一，修改用户名的规则应该由领域对象去觉得，而不是由调用方去决定 现在第三方人员修改用户名变的简单了,再也不需要处理本该属于领域对象校验等功能，这样将属于领域的代码和属于调用方的代码很好的分开,代码的层次也更加分明。 12345678public class UserService &#123; public void changeUserName( User user,String userName) &#123; user.changeUserName(userName); &#125; &#125; 实体（Entity） 采用领域驱动设计建模的一个很重要的概念就是实体,书中给的定义是主要由标识定义的对象称为实体(Entity)，现在我们扩展上诉的User对象，在对象里加入一个Address家庭住址对象 12345678 public class User &#123; private String userId; private String userName; private Address address;&#125; 家庭住址对象包含街道名和邮编 123456public class Address &#123; private String street; private String postcode;&#125; 在通用语言中我们会这样描述，我想根据用户id找到对应用户所居住的地址，这里的用户id就是User的标识定义，那么我们认为User它就是一个实体，但是这里的Address并不是实体，它只是一个VO(键值对对象)在用户模型中给地址一个唯一标识定义是没有意义的，因为在用户跟换地址时我直接将整个Address对象替换掉即可，我并不关心地址的状态。 在现实模型中同一个事物可能需要标识为实体，也有可能不需要表示实体，举个例子上述的User为实体，但是换一个场景，订单对象下关联了一个用户对象来表明这个订单是谁买的，在这里我们关注的是订单，把用户作为实体是没有意义的，所以这里订单是实体，User只是一个VO(键值对对象) VO很多对象没有概念上的标识，它们描述了一个事务的某种特性,我们称这些对象为VO 如果将所有对象设计成实体会有什么问题？在书中有一个很好的例子：小孩子总是可以很好的分清楚那副画是自己画的，因为每幅画都有一些标识来区分哪些是自己画的哪些不是，但是如果必须记住哪些线条使用哪只笔画的那情况该有多复杂？上文的User对象的Address就是一个VO，因为我并不关心Address 的状态，它在User对象中只是单纯是键值属性，但是什么情况下地址为实体什么情况下为VO呢？书中举了另外一个例子:在购物系统中需要用地址来标识发货地址，如果室友也从这家店购买了商品，那么意识到他们是否住在同一个地方并不重要（不需要维护地址标识），这里是地址是VO,如果你和舍友同时去申请宽带，那么这里的地址就是实体，因为电信公司需要知道你和你的舍友居住在同一个地方，这样他们只要上门一次即可。 另一个VO的重要特性是VO是可以整个被替换的，其没有包含副作用的方法，举个例子上文User关联的Address对象,将Address对象传给其它人调用里面的方法并不会对User类产生影响，因此可以放心的将VO传给任何人调用，在设计中尽量将对象设计成VO来减少系统的复杂性，大举个例子，上文中User如果修改Address如果Address的话我们直接在User对象中整个替换Address对象即可完成地址的修改，但是如果地址为实体的话，那么我们必须用地址标识还原出Address对象，然后将地址对象的属性做修改 领域服务 在书中是给领域服务这样定义的：在领域中的某个操作过程或转换过程不是实体或者值对象（VO）的职责时，我们应该将操作放在一个单独的接口中，即领域服务，请确保领域服务和通用语言是一致的，并且保证它是无状态的。 在现实代码中我更喜欢把领域当成客户端调用的代码，领域模型由建模人员编写完代码，然后将这部门代码交给客户端人员去调用，领域建模人员必须保证客户端代码的易用性，如果有些方法并不适合在领域模型中，那么可以将其放在领域服务中，这样可以对客户端人员屏蔽领域细节，例如用户登录时可能涉及到鉴权，鉴权部分可能是另一个模型对象，如果我们不使用领域服务将这些工作全部交给客户端人员去做的话，那么客户端的程序员就必须知道业务的逻辑，要知道原来登录要先鉴权，他先去执行鉴权代码再去执行验证用户密码的代码，这样就导致领域信息暴露，更好的做法应该是用领域服务将鉴权和验证用户信息的方法放在领域服务中，然后再对外暴露一个登陆验证的服务，这样就对客户端程序员屏蔽了领域信息，他只需要调用一个登陆的领域服务即可，不用去关心领域里的逻辑,关于领域服务的具体实践和分包我讲在后续小项目领域驱动实践中介绍。 聚合 在日常开发中将实体和VO进行聚合组成聚合对象是非常普遍的，我们将这些对象称之为聚合，聚合对象都有一个主体我们称之为聚合跟，在使用聚合时对客户端程序员暴露的都应该是聚合根，而不是聚合根下的对象，举例 123456789101112 public class User &#123; private String userId; private String userName; private Address address; public void saveAddress(Address address)&#123; this.address=address; &#125;&#125; 上文中的User对象包就是一个聚合它包含了用户的用户名，用户id属性，也包含了一个地址VO，我们在对外提供领域模型给客户端程序员时我们只能建User对象中的方法,比如上文的saveAddress保存地址方法，而不是将一个个调用Address对象中的get set方法。在实际设计过程中有时候由于聚合包含太多的VO和实体导致聚合过于庞大，我们可以将聚合进行拆分，具体的实践方法我讲在后续小项目领域驱动实践的文章中表述。 资源库（Repository） Repository对领域模型屏蔽了持久化的代码，因为现实软件设计中领域对象不可能全部都存留在内存中，当一个领域对象从创建开始我们就认为其已开始其的生命周期，即使后续将这个领域对象存储在数据库等持久化的对象中我们仍然认为其仍处于生命周期内，直到我们在数据库中将其删除我们才认为一个领域对象生命的结束，资源库就是为了在领域对象存储在数据库或者其它一些持久化组件中时将其还原成领域对象而设计的，比如如下代码 1234567891011121314public class UserRepository &#123; public void addUser(User user)&#123; //持久化代码 &#125; public User findUserById(String userId)&#123; //模拟从数据库中生成对象 User user=new User(); return user; &#125;&#125; 在客户端服务调用完领域服务生成领域对象后，客户端将领域对象传入到资源库中将其持久化(addUser)，同样，资源库也可以根据各种条件去还原一个领域对象（findUserById） 架构设计（六边形架构） 在采用领域驱动设计时我采用的是六边形架构如图 下面是我在网上摘抄的对六边形架构的简介 六边形架构还是一种分层架构，如上图所示，它被分为了三层：端口适配器、应用层与领域层。而端口又可以分为输入端口和输出端口。 输入端口用于系统提供服务时暴露API接口，接受外部客户系统的输入，并客户系统的输入转化为程序内部所能理解的输入。系统作为服务提供者是对外的接入层可以看成是输入端口。 输出端口为系统获取外部服务提供支持，如获取持久化状态、对结果进行持久化，或者发布领域状态的变更通知（如领域事件）。系统作为服务的消费者获取服务是对外的接口（数据库、缓存、消息队列、RPC调用）等都可以看成是输入端口。 应用层定义系统可以完成的工作，很薄的一层。它并不处理业务逻辑通过协调领域对象或领域服务完成业务逻辑，并通过输入端口输出结果。也可以在这一层进行事物管理。 领域层负责表示业务概念、规则与状态，属于业务的核心。 应用层与领域层的不变性可以保证核心领域不受外部的干扰，而端口的可替换性可以很方便的对接不用的外部系统 我在这里对以上的解释说明下 输入端口在上图中对应适配器A,B,C,D比如在http服务中其对应的就是Controller层，用Spring的话就是SpringMVC框架，适配器完成了http对应用用程序的转化，因为应用层提供了固定的API来满足各种渠道的调用，比如现在我要增加一个人RPC调用，我只要根据应用层所提供的API写一个转换器将应用层的API转化成RPC调用的方法即可，图中领域模型作为为核心最稳定的内容放在了六边形的中央，其它所有的组件都必须依赖领域模型，这符合了领域驱动的模型。最后是输出端口，我们将持久化的代码放入这里（资源库Repository）下面给出我们架构设计的依赖结构* 输出层 -&gt; 应用程序(APP) -&gt; 资源库（Repository）-&gt; 领域层 实际中领域层中的领域服务有可能会调用到资源库（Repository），但是我们又不能让领域层去依赖资源库层，因为领域层是项目的核心，应该是最稳定的部分，会被大量的组件依赖，而资源库层相对领域层更加不稳定（比如数据库中新增一个字段等），那么我们这里就要用依赖倒置技术使资源库依赖领域层，具体实践放在小项目领域驱动实践中去讲解*]]></content>
      <categories>
        <category>领域驱动设计(DDD)</category>
      </categories>
      <tags>
        <tag>领域驱动设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[greenplum集群安装]]></title>
    <url>%2F2019%2F09%2F02%2Fgreenplum%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Greenplum集群搭建 关闭所有主机防火墙12systemctl stop firewalld.servicesystemctl disable firewalld.service 关闭SELINUX 12vi /etc/selinux/config将属性 SELINUX 改为 disabled 系统设置设置hostname12345vi /etc/hosts添加各个主机的hostname如:192.168.171.75 master192.168.171.76 node1192.168.171.77 node2 设置系统参数至sysctl.conf12345678910111213141516171819202122232425262728vi /etc/sysctl.conf在文件中添加以下代码kernel.shmmax = 500000000kernel.shmmni = 4096kernel.shmall = 4000000000kernel.sem = 500 2048000 200 40960kernel.sysrq = 1kernel.core_uses_pid = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.msgmni = 2048net.ipv4.tcp_syncookies = 1net.ipv4.conf.default.accept_source_route = 0net.ipv4.tcp_max_syn_backlog = 4096net.ipv4.conf.all.arp_filter = 1net.ipv4.ip_local_port_range = 10000 65535net.core.netdev_max_backlog = 10000net.core.rmem_max = 2097152net.core.wmem_max = 2097152vm.overcommit_memory = 2vm.swappiness = 10vm.zone_reclaim_mode = 0vm.dirty_expire_centisecs = 500vm.dirty_writeback_centisecs = 100vm.dirty_background_ratio = 0vm.dirty_ratio = 0vm.dirty_background_bytes = 1610612736vm.dirty_bytes = 4294967296 在/etc/security/limits.conf中修改以下参数123456vi /etc/security/limits.conf修改以下参数* soft nofile 65536* hard nofile 65536* soft nproc 131072* hard nproc 131072 同步集群时间1234567891011在所有主机上安装ntpyum install -y ntp添加如下内容server 127.127.1.0fudge 127.127.1.0 stratum 10保存退出，然后启动ntp 服务并设为开机启动：systemctl start ntpdsystemctl enable ntpd在集群其他节点安装ntp 服务，并将ntp 服务server 指向主节点echo &quot;server &lt;ip&gt; iburst&quot; &gt; /etc/ntp.conf&lt;ip&gt; 替换为主节点ip 地址 免密登录1234567891011121314151617181920用root用户登录所有主机编辑文件 /etc/ssh/sshd_config将以下两行前面的#号去掉，保存RSAAuthentication yesPubkeyAuthentication yes在所有主机上执行以下命令ssh-keygen -t rsa按四下回车得到public key在所有主机上执行以下命令，将所有主机的public key 拷贝到主节点上ssh-copy-id root@&lt;hostname&gt;&lt;hostname&gt;更换为主节点主机的主机名在主节点机器上通过scp 命令将文件 /root/.ssh/authorized_keys 发送到所有其他节点主机的 /root/.ssh/ 目录下：scp /root/.ssh/authorized_keys root@&lt;hostname&gt;:/root/.ssh/重启所有主机的sshd 服务systemctl restart sshd.servicesystemctl enable sshd.service验证免密码登陆 ：ssh &lt;hostname&gt;&lt;hostname&gt; 更换为主机名。 在主节点安准Greenplum123456rpm -Uvh ./greenplum-db-&lt;version&gt;-&lt;platform&gt;.rpm数据库软件安装在/usr/local/greenplum-db-&lt;version&gt;目录下修改目录权限为gpadmin所有chown -R gpadmin /usr/local/greenplum*chgrp -R gpadmin /usr/local/greenplum* 在集群中安装Greenplum1234567891011121314151617181920su -切换至root用户touch hostfile_exkeys创建一个hostfile_exkeys文件将所有主机hostname放入其中（主机包含所有master, standby master,segments）如mdwmdw-1mdw-2smdwsmdw-1smdw-2sdw1sdw1-1sdw1-2sdw2sdw2-1sdw2-2sdw3sdw3-1sdw3-2 12345创建groupadd账号和groupadd组groupadd gpadminuseradd gpadmin -g gpadminpasswd gpadmin 1234567安装Greenplum rpm包rpm -Uvh ./greenplum-db-&lt;version&gt;-&lt;platform&gt;.rpm数据库默认安装在/usr/local/greenplum-db-&lt;version&gt;目录下更改安装目录权限为gpadmin用户所有 chown -R gpadmin /usr/local/greenplum* chgrp -R gpadmin /usr/local/greenplum* 12345678910111213141516171819202122232425262728将安装分发给集群其它主机执行创建一个空文件touch hostfile_exkeys将集群所有hostname写入文件，如: mdw mdw-1 mdw-2 smdw smdw-1 smdw-2 sdw1 sdw1-1 sdw1-2 sdw2 sdw2-1 sdw2-2 sdw3 sdw3-1 sdw3-2执行以下命令在集群中安装数据库gpseginstall -f hostfile_exkeys确认集权是否安装成功su - gpadminsource /usr/local/greenplum-db/greenplum_path.shgpssh -f hostfile_exkeys -e ls -l $GPHOME如果可以看到集群信息则安装成功 创建数据目录12345678在主节点中创建目录，目录地址根据实际情况更改mkdir -p /data/master改变目录所有者chown gpadmin /data/master如果有副主节点，执行以下命令在副主节点中创建相同目录，smdw为副主节点hostnamesource /usr/local/greenplum-db/greenplum_path.shgpssh -h smdw -e &apos;mkdir -p /data/master&apos;gpssh -h smdw -e &apos;chown gpadmin /data/master&apos; 创建段节点（数据节点）目录123456创建空文件touch hostfile_gpssh_segonly将所有段节点（数据节点）的hostname填入如:sdw1sdw2sdw3 用gpssh命令在段节点(数据节点)创建目录和更改其权限1234source /usr/local/greenplum-db/greenplum_path.shgpssh -f hostfile_gpssh_segonly -e &apos;mkdir -p /data/primary&apos;gpssh -f hostfile_gpssh_segonly -e &apos;mkdir -p /data/mirror&apos;gpssh -f hostfile_gpssh_segonly -e &apos;chown -R gpadmin /data/*&apos; 配置数据库123456789101112131415161718192021222324252627282930313233343536切换至gpadminsu - gpadmincp $GPHOME/docs/cli_help/gpconfigs/gpinitsystem_config /home/gpadmin/gpconfigs/gpinitsystem_config备份配置文件到新目录下修改备份文件gpinitsystem_config，修改以下参数DATA_DIRECTORY（将创建主段数据目录的文件系统位置,有几个DATA_DIRECTORY, 每个节点上便会启动几个segments#### 指定Primary Segment的数据目录, DATA_DIRECTORY参数指定每个Segment主机配置多少个Instance。如果#### 在host文件中为每个Segment主机列出了多个网口，这些Instance将平均分布到所有列出的网口上。#### 这里的案例，hosts里有2个segment，sdw1，sdw2俩主机，都是单网卡段的数量划分要根据服务器的cpu，网卡，磁盘因数划分最好达到share nothing的效果，每个段都有独自的处理器，磁盘或者网卡）MASTER_HOSTNAME(主节点hostname)MASTER_DIRECTORY（将创建主数据目录的文件系统位置）MIRROR_DATA_DIRECTORY（建立节点的镜像mirror节点的地址，镜像的数量必须和DATA_DIRECTORY的数量一致）详细参数说明查阅https://gpdb.docs.pivotal.io/5190/utility_guide/admin_utilities/gpinitsystem.html----------------------------------------------------------------ARRAY_NAME=&quot;Greenplum Data Platform&quot;SEG_PREFIX=gpsegPORT_BASE=40000declare -a DATA_DIRECTORY=(/data/primary)MASTER_HOSTNAME=mdwMASTER_DIRECTORY=/data/masterMASTER_PORT=5432TRUSTED SHELL=sshCHECK_POINT_SEGMENTS=8ENCODING=UNICODE...MIRROR_PORT_BASE=7000REPLICATION_PORT_BASE=8000MIRROR_REPLICATION_PORT_BASE=9000declare -a MIRROR_DATA_DIRECTORY=(/data1/mirror /data1/mirror /data1/mirror /data2/mirror /data2/mirror /data2/mirror)----------------------------------------------------------------- 运行初始化脚本1234567891011121314151617181920 创建文件里面所有段节点（数据节点）hostname touch vi hostfile_gpinitsystem 数据如: sdw1-1 sdw1-2 sdw2-1 sdw2-2 sdw3-1 sdw3-2 sdw4-1 sdw4-2执行以下命令，gpconfigs/gpinitsystem_config为上面更改的配置文件，hostfile_gpinitsystem为所有的段节点hostname，standby_master_hostname为副主节点的hostnamecd ~gpinitsystem -c gpconfigs/gpinitsystem_config -h gpconfigs/hostfile_gpinitsystem \ -s standby_master_hostname -S 当出现Continue with Greenplum creation? Yy/Nn时 输入y回车 出现以下提示表示安装成功 Greenplum Database instance successfully created. 在主节点和备份主节点设置环境变量12345678su - gpadminvi ~/.bashrc添加以下内容，MASTER_DATA_DIRECTORY为实际master目录路径source /usr/local/greenplum-db/greenplum_path.shexport MASTER_DATA_DIRECTORY=/data/master/gpseg-1(注意)如果是RHEL 7 or CentOS 7系统，需要在.bashrc文件的末尾添加如下内容:export LD_PRELOAD=/lib64/libz.so.1 ps至此安装完成 设置账号123456789登录master节点运行psql修改管理员密码alter role gpadmin with password &apos;hzt_2019&apos;;输入\q退出客户端设置账号访问权限,路径根据实际路径填写vi /data/master/gpseg-1添加以下代码，设置gpadmin可远程登录host all gpadmin 0.0.0.0/0 trust]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>greenplum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓慢维度的设计和处理]]></title>
    <url>%2F2019%2F09%2F02%2F%E7%BC%93%E6%85%A2%E7%BB%B4%E5%BA%A6%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[关于缓慢维度变化的简介 在数据仓库设计中理想状态下维度是不会变化的，但是事与愿违，大部分业务系统中的维度是会发生变化的，那么如何去处理这些变化的维度就是本文关注的内容，举个例子如下企业组织架构维度表 ID_ 企业名 部门名 组名 1 微软 研发部 开发一组 如果有一天上表中的部门名发生变化怎么办?根据Kimball的数据仓库工具箱，我们把处理缓慢维度的方法分为7种类型，其为类型1至类型7 类型1:重写 顾名思义，就是将维度表中的字段简单的替换，如上表中如果采用类型1的话，如果部门后续由研发部变成技术部，那么维度表将变成下表，部门维度表和部门人数事实表做关联 ID_ 企业名 部门名 组名 1 微软 技术部 开发一组 部门人数事实表 ID_ 部门ID外键 人数 1 1 10 类型1的优劣势 有点是简单易于实现，仅需重写维度表中的属性值而不需要去更改事实表，但是无法保留历史值，如果业务中存在对维度的历史值进行分析，那么就无法采用该类型，举例：采用类型1将部门名改成技术部后，现在需要分析在部门叫研发部时，研发部下有多少人?那么如果采用类型1将无从下手，因为维度表中没有保存历史维度数据,而部门人数事实表中的数据是用部门ID去与其关联的。但是实际中如果采用类似hive无法执行update语句的数据仓库工具去建设的话，那么只能重新全量生成维度表 类型2：增加新行 类型2是最常用的处理缓慢维度的办法,如果采用此设计方式则在部门名变更为技术部时维度表和事实表如下 ID_ 企业名 部门名 组名 行有效日期 行失效日期 是否生效 1 微软 研发部 开发一组 2011-1-1 2019-9-1 no 2 微软 技术部 开发一组 2019-9-2 9999-1-1 yes 部门人数事实表 ID_ 部门ID外键 人数 1 1 10 2 2 100 在事实表中原来旧的数据仍然和研发部关联，但是新增的数据已经和新的维度（技术部）做关联。这样数据就保留了历史变化的信息，如果需求中存在对历史维度进行分析的话可以采用此类型应对维度缓慢维度变化。 类型3：新增新列 采用维度2去处理维度变化时存在一个缺点，如果需求需要将新的属性值和旧的属性值做关联分析，那么采用类型2将很难实现，因为类型2并没有记录维度变化的关联关系，如果存在这方面需求则可以采用类型3处理，事实表通过代理键ID关联维度表(维度表在创建时自己生产的id，不是业务方提供的ID)但实际中类型3不经常使用 如： ID_ 企业名 当前部门名 之前部门名 组名 1 微软 技术部 研发部 开发一组 部门人数事实表 ID_ 部门ID外键 人数 1 1 10 类型4：微型维度 其解决问题的场景为应对维度表中存在大量数据（几百万），且一些属性快速变化。因为当维度表中存在大量的数据，特别是维度中某些信息还是易变时，我们不希望已经存在几百万的维度表中新增数据（采用类型2），因为这样会使维度表发生膨胀，实际情况中维度表中的数据应该远远小于事实表，那么类型3就派上用场，还是引用上诉两张表，假设现在部门维度有几十万个部门，且组名经常发生变化（即使不太可能），那么我们将才用下面设计 部门表 ID_ 企业名 部门名 1 微软 研发部 组名表 ID_ 组名 1 开发一组 1 开发二组 部门人数事实表 ID_ 部门ID外键 组名外键 人数 1 1 1 10 2 1 2 100 部门表和组名表不再使用星型维度直接做关联，而是在事实表中新建外键来关联部门和组 类型5：微型维度与类型1支架表 之所以称之为类型5是因为其是类型4和类型1的结合 4+1=5，该技术实现为在主维度中用一个外键id和一个微型维度做关联，这样能避免微型维度发生变化时更新主维度的每行的信息，且如果客户需求需要在不关联事实表的情况下完成维度的过滤分析等类型5是很好的处理方法，举例 商店维度表 ID_ 商店名 地区ID 1 一号门店 1 地区维度表 地区ID 省 市 县 1 福建省 福州市 闽清县 如果不采用类型5的话维度表结构为 ID_ 商店名 省 市 县 1 一号门店 福建省 福州市 闽清县 2 二号门店 福建省 福州市 闽清县 那么有一条闽清县更改了名字变成闽清市，如果不采用类型5支架表的话那么将要更改所有商店维度表中有关闽清县的记录，将其改成闽清市，如果你在很多事实表中都使用了地区信息，那就需要更改所有有关地区的维度，这是无法忍受的，但是如果采用类型5则只需要更改地区类型的属性即可完成所有有关地区维度信息的修改。 类型6 类型6为 类型2,3,1的组合（2+3+1=6），回顾类型3，当为了记录维度变化的历史先后关系时我们采用类型3，但是类型3也有一个缺点就是它只记录当前的变化，和上一次的变化，类型6解决了这个问题，其维度表如： ID_ 企业名 当前部门名 之前部门名 组名 生效日期 结束日期 当前是否生效 1 微软 技术部 研发部 开发一组 2011-1-1 2019-9-1 no 2 微软 技术部2 技术部 开发一组 2011-1-1 9999-1-1 yes 部门人数事实表 ID_ 部门ID外键 人数 1 1 10 尽管该技术具有某种诱惑力，但是加大了系统的复杂度，考虑任务是否有这种需求才使用这种方法。 类型7 当需要分析维度表的当前和历史场景的时候可以使用类型7，其运用事实表关联类型2和基于类型2的维度表创建一个当前部门的视图来实现，如下 部门维度 ID_ 部门编码 企业名 当前部门名 生效日期 结束日期 当前是否生效 1 code1 微软 研发部 2011-1-1 2019-9-1 no 2 code1 微软 技术部 2011-1-1 9999-1-1 yes 当前部门视图（可以根据部门问题创建一个当前部门视图 比如:select * from 部门维度 where 当前是否生效=’yes’） 部门编码 部门ID 当前部门名 code1 2 技术部 code1 3 人力资源部 部门人数事实表 ID_ 部门ID外键 部门编码 人数 1 1 code1 10 2 2 code1 10 这样通过事实表中存在，部门ID外键和部门编码就可以分析历史部门数据和当前部门数据所存在的关系 杂项目维度 在建模过程中通常会遇到大量五花八门的指标和描述，它们包行小的范围离散值处理这些离散值有一下几种方法 忽略这些标志和指标,如果这些描述具有业务价值则不能采用这种方式 在事实表中保存这些表示，尽量不要在事实表中保存这些描述，这些描述可能使事实表的列发生膨胀 将每个标志和指标放入各自的维度，如果事实表的外键在合理范围内（不超过20个），则在事实表中加入不同的外键是可接受的。 杂项维度,如下 在交易事实表中存在以下杂项描述 支付方式:CASH,CREDIT购买渠道:ONLINE,OFFLINE对应事实表中一共存在以下4中组合方式（2的二次方），数据为 支付方式 购买渠道 CASH ONLINE CASH OFFLINE CREDIT ONLINE CREDIT OFFLINE 那么与其建这些杂项目反正事实表中，或者维度数目已经较大的情况下，我们可以创建一个杂项维度,将这些杂项的所有可能罗列出来如 ID 支付方式 购买渠道 1 CASH ONLINE 2 CASH OFFLINE 3 CREDIT ONLINE 4 CREDIT OFFLINE 现在在事实表中的数据为 ID_ 杂项外键 金额 1 2 100 2 1 1000 不同粒度的事务事实（表头模式） 实践中应该避免这么模式，应该保证事实表中的粒度和维度是一样的 比如存在订单详细事实表 ID_ 订单ID 商品外键 金额 1 order1 1 1000 2 order1 2 888 订单维度表 ID_ 订单描述 order1 订单1信息 order1 订单2信息 这样的设计存在一个问题，订单详情事实表中的粒度是订单的每个商品，但是却关联了订单维度，这两个关联存在不同的粒度，应该尽量避免这种情况，更好的做法应该是再新建一个关于订单的事实表，在订单明细表中将订单id做为退化维度（只是单纯的记录一下订单id，为了方便分析） 多币种 最常见的分析需求是订单事务以当地交易币种表示，在构建订单事实表时应该包含2种货币信息事实，一种是当地货币，一种是公司采用的标准统计货币，比如公司在日本销售的货物以日元结算，公司财报中的统计标准为美元，那么在订单事实表中应该包行2种货币，一种是日元，一种是公司的标准货币美元。]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>维度</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据仓库维度建模概述]]></title>
    <url>%2F2019%2F08%2F31%2F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[什么是维度 简单的来说维度就是用于分析数据仓库中的事实的描述（关于事实下文讲解）.举个例子在数据库中有两张表，订单明细表和商品表 订单明细表 ID_ ORDER_ID PRODUCT_ID_ quantity 1 1 1 10 商品表 ID_ PRODUCT_NAME 1 华为手机 这两张表中订单明细表使用商品表中的id与之关联，订单明细表为事实表记录了订单明细的事实，商品表就为维度表，因为商品表描述了订单明细表，我们通过商品表中的维度信息去分析订单明细表中的数据，用需求文字来描述就是我想查购买了华为手机的所有订单明细，转换成SQL语句为 1select * from 订单表 t1 inner join 商品表 t2 on t1.PRODUCT_ID_=t2.ID_ where t2.PRODUCT_NAME=&apos;华为手机&apos; 什么是事实 事实一般只是一些单纯的数字，如上文订单表中的数量，它仅仅是订单中的一个度量，没有什么文字描述，文字描述都存在维度表中,通过维度表去分析事实表。 什么是粒度 事实表中的存储数据都要有相同的粒度,粒度用于确定某一事实表中的行表示什么,例如上文订单明细表中的粒度是到商品,不是订单，因为表中有一个产品id，如果该表去掉PRODUCT_ID_和quantity那么该事实表中的粒度就为订单（一个订单中可能包含很多商品）,所有的事实表中的数据都应该有相同的粒度，同样维度表中的关联也需要和事实表中的粒度做对应，就好比上文的订单明细表中最好不要出现订单的维度，比如订单类型等信息. 设计维度的过程选择业务过程 业务过程一般存储在业务系统的关系型数据库中，我们必须根据需求选取对应业务表中的数据，如我需要建立订单为主题的数据集市，则我需要抽取业务系统中关于订单的数据 声明粒度 最好要包行最低粒度，如上文中建立一张订单明细表，而不是只建立订单表，因为细粒度可以根据维度上卷得到粗粒度的数据，反之则不能。 描述维度 维度提供业务的描述，比如谁，什么，何处，何时等。维度表为数据仓库中的灵魂，是数据仓库中最重要的部分，维度描述越丰富，则数据仓库中所挖掘的信息越多。 确认事实 事实涉及业务过程事件的度量,基本上都是以数量值表示，一个事实表中的所有粒度需要保持一致。 数据仓库的分层 目前项目中采用了4层架构分别为 ods贴源层，ods层中存放了业务表中原封不动的数据 dwd数据清洗层,dwd为了清理ods层中的数据 dws主题层,此层获取dwd中的数据根据不同的主题组成不同粒度的事实表和维度供业务方调用 ads层，此层一般为一些汇总数据供前端展示时调用 不同数据集市间的数据划分可以考虑在同一个数据实例中根据表名建立各个数据集市中的4个不同的层，根据表名区分不同数据集市中的表，也可以根据不同数据集市建立不同的数据库实例来存储上文4个层的表，目前由于建立的数据集市较少为了方便才用同一个数据库实例。 数据的仓库架构总线型架构 Kimball总线架构为，在项目开始时，由架构师设计通用维度，这个维度称为总线，设计完成总线后，将总线维度分发给各个数据集市的开发人员同步去开发，比如订单数据集市，库存数据集市。各个集市中的维度根据总线去做扩展，各个数据集市的数据再ads层之前是不做交互的，如果要跨域多个数据集市去分析数据，那么就用通用维度（总线）去连接各个数据集市中的不同事实表去分析数据。 维度表设计 现在维度表的设计一般分为星型结构和雪花型结构 星型结构，采用宽表和冗余的形式存储维度，维度的父子关系都在一张表中关联，不通过外键关联，如下面时间表: id 年 月 日 20190101 2019 01 01 20190102 2019 01 02 那么如果我想查询实时表中id为20190101的数据对应的月份是几月，那么我们可以使用id去时间维度去查找对应的月份 雪花结构,雪花结构的设计更多的用于关系型数据库，上图的时间维度用雪花型表示为年表 id 年 2019 2019 2018 2018 月表 id 月份 1 01 2 02 年月关系表 id year_id month_id 1 2019 1 2 2019 2 两种设计的优缺星型结构：对查找的效率和难度来说更加高效简单，但是存储了大量冗余数据，而且不够灵活不方便修改，如果存在大量描述字段的话，那么冗余结构相比雪花结构使用更大的存储空间雪花结构：数据更加灵活，比如更改维度表的信息不需要更改整个维度的信息，比如上文我要更改月份里面的字段我只需要更改月表中的信息即可，不需要更改整张维度表，但是查询更加麻烦和慢。其实归根到底就是范式设计和非范式设计，在数仓中大多数情况下应该使用星型结构，因为数仓关注的是查询，用存储空间换取查询数据的方便是值得的，至于对于星型结构存在维度变更的问题，我们将在另一篇文章，维度缓慢变化中说明]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>维度</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive mysql元数据表单的主从备份]]></title>
    <url>%2F2019%2F08%2F30%2Fhive-mysql%E5%85%83%E6%95%B0%E6%8D%AE%E8%A1%A8%E5%8D%95%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[hive元数据库和使用介绍 hive 会将表的元数据信息存储在数据库中，这里采用mysql作为元数据库存储hive的元数据 元数据表中记录着很多hive中有用的信息，比如数据库实例，表，表结构，还有表数据的条数 表数据条数只有在hive为内部表时的统计是准确的，如果建立的表为外部表 (external)则需要执行统计语句才能得到准确结果 1ANALYZE TABLE tablename COMPUTE STATISTICS; 使用元数据表中的统计数据可以很简单快捷的得到hive的元数据，比如表的数量，和数据量 mysql主从介绍 mysql主从时利用mysql的日志来完成主从的，所以在做主从设置时，先要保证主数据库和从数据库数据的一致 迁移数据 如果主数据库中已经在做主从时已经存在数据那么，先将主数据库中数据复制到从数据库中，从而保证主数据库和从数据库数据的一致 配置主数据库配置文件 12345678910111213vi /etc/my.cnf#将以下信息填入server-id=1 #Mysql服务的唯一编号 每个mysql服务Id需唯一log-bin=mysql-bin #logbin的名字# 根据高性能mysql中提到，两个参数慎用，不应该开启他们，会导致主备同步出错，应该在备库中使用replicate-do-db或者replicate-ignore-db来过滤，#比如 use test; delete from sakila.film binlog-do-db和 binlog-ignore-db都会在test数据库上过滤delete语句，而不是在sakila上，从而导致同步出错#binlog-do-db=metastore #需要同步的数据库的名字，如果是多个数据库存在多条#binlog-ignore-db=test01 #不需要同步的数据库的名字log-slave-updates=1 #log更新间隔slave-skip-errors=1 #是跳过错误，继续执行复制操作(可选)binlog_format=MIXED #必须制定日志的类型，这里选择混合日志存储，不然无法建立hive表#重启数据库service mysqld restart 配置从数据配置文件 12345678910#Mysql服务的唯一编号 每个mysql服务Id需唯一server-id=2read_only=1#只读模式，可以限定普通用户进行数据修改的操作，但不会限定具有super权限的用户（如超级管理员root用户）的数据修改操作。如果想保证super用户也不能写操作，就可以就需要执行给所有的表加读锁的命令 “flush tables with read lock;”replicate-do-db=metastore #需要复制的数据库名，如果复制多个数据库，重复设置这个选项即可replicate-ignore-db=test05 #需要忽略不复制数据库名，如果个数据库，重复设置这个选项即可replicate-rewrite-db = metastore-&gt;apollo # 如果主数据库名字和从数据库名不一样，则使用这个配置，表明将主数据库metastore#复制到从数据库apollo实例下，和replicate-do-db配置不能共存#重启数据库service mysqld restart 设置主数据库复制账号 123456CREATE USER &apos;slave&apos;@&apos;%&apos; IDENTIFIED BY &apos;mysql&apos;;GRANT REPLICATION SLAVE ON *.* TO &apos;slave&apos;@&apos;%&apos;;FLUSH PRIVILEGES;# 查看赋权状态use mysql;select User,authentication_string,Host from user; 查看是否开启日志 1show variables like &apos;log_bin&apos;; 如果开启value值为on Variable_name Value log_bin ON 查看主节点状态1show master status; 结果示例,表示 metastore实例日志文件为mysql-bin.000005，当前日志偏移量为1242284 File Position Binlog_Do_DB mysql-bin.000005 1242284 metastore 操作从数据库 其中change master语句中的master_log_file 为上一步查看的metastore日志文件，master_log_pos为该日志文件的偏移量，这样主数据库中的数据发生变化，偏移量就会增长，从数据库根据偏移量去同步数据 123456# 停止正在进行的slave(如果有，此方法也用于修改slave的值(如果参数不对))stop slave;# 需要主机名，上面步骤的账户密码以及日志文件名字和位置(请根据实际情况自行修改)change master to master_host=&apos;192.168.1.1&apos;, master_user=&apos;slave&apos;, master_password=&apos;mysql&apos;, master_log_file=&apos;mysql-bin.000005&apos;, master_log_pos=1242284;# 启动start slave; 查看状态 12345show slave status;如果发现Slave_IO_Running和Slave_SQL_Running状态为YES则成功Slave_IO_Running负责和主机通讯Slave_SQL_Running负者执行从数据库sql语句Last_Error复制记录上一次同步出错的出错愿意 遇到的问题 在配置主数据库配置文件时必须指定 binlog_format类型，不然hive建表会出错 配置从数据配置文件时，replicate-do-db=metastore和replicate-rewrite-db不能共存 当同步主数据库的数据到不同名字的从数据库中时，不可直接用Navicat图形化工具去直接操作数据库，应该写语句去执行，不然会导致同步失败 当执行show slave status 查看从节点状态时，发现Slave_IO_Running 一直未connecting，查看mysql错误日志文件(默认在/var/log/mysqld.log)发现Authentication plugin ‘caching_sha2_password’ reported error，从报错可以看出是caching_sha2_password插件的问题执行(将账号和密码替换成自己前面创建复制账号的账号和密码) 1ALTER USER &apos;slave&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;mysql&apos;;]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
        <tag>mysql主从搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将hexo发布到github]]></title>
    <url>%2F2019%2F08%2F29%2F%E5%B0%86hexo%E5%8F%91%E5%B8%83%E5%88%B0github%2F</url>
    <content type="text"><![CDATA[创建一个github仓库 创建一个github公有仓库,点击settings如图 选择GitHub Pages选项 设置git分支为，和访问域名 设置hexo部署目录1234567891011打开项目目录下的_config.yml文件修改deploy:属性type 为类型设置为gitbranch设置为master分支repo为你的仓库地址如deploy:type: gitbranch: masterrepo: https:// 参数解释 参数 描述 repo 库（Repository）地址 branch 分支名称。如果不指定，则默认值为 master message 自定义提交信息,非必须 安装部署插件 12进入项目主目录执行$ npm install hexo-deployer-git --save 上传CNAME文件 在项目目录下source中创建一个名字为CNAME的文件，里面填入你所绑定的域名 发布项目至github pages 123$ hexo clean$ hexo g$ hexo d 解决样式丢失问题 此时发布项目至github，css样式会丢失修改以下内容 12345678910打开项目目录下的_config.yml文件修改如下参数url: https://liushprofessor.github.io/liushaohuang.github.io/root: /liushaohuang.github.iopermalink: :year/:month/:day/:title/permalink_defaults:其中url替换为你github的仓库地址(网址)root 为网站的根目录（github对应的仓库名）重新发布解决问题 绑定域名 将域名cname设置为A记录代表ip ，cname代表绑定域名 ,主机记录www代表匹配www.前置网站如www.liushaohuang.cn@ 表示直接解析主域名，匹配liushaohuang.cn的网站 记录类型 主机记录 记录值 A www ip地址 CNAME @ 域名 CNAME WWW 域名]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo主题的更换]]></title>
    <url>%2F2019%2F08%2F29%2Fhexo%E4%B8%BB%E9%A2%98%E7%9A%84%E6%9B%B4%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[主题主体安装设置 这里以next主题为例，进入hexo项目目录，执行以下命令，从github上下载next主题,并将主题存放在themes目录的next文件夹下 1$ git clone https://github.com/theme-next/hexo-theme-next themes/next 更改主题 12345项目主目录进入主目录，这里以hexo为例$ cd hexo打开该目录下的_config.yml文件将theme属性更改为theme: next 更改主题文字为中文 123同上打开主目录下的_config.yml文件将language属性更改为language: zh-CN 更改主题标题 123同上打开主目录下的_config.yml文件修改title标签为想要的标题title: 标题 主题内部设置 主题内部配置文件为themes/next目录下的_config.yml 更改主题样式 12345在主题配置文件中更改scheme属性来切换不同样式的主题#scheme: Muse#scheme: Mistscheme: Pisces#scheme: Gemini 配置菜单找到menu标签以下配置在主要中打开主页，归档页，分类和标签如下图所示 1234567menu: home: / archives: /archives #about: /about categories: /categories tags: /tags #commonweal: /404.html 每个标签的含义为 键值 设定值 显示文本（简体中文） home home: / 主页 archives archives: /archives 归档页 categories categories: /categories 分类页 tags tags: /tags 标签页 about about: /about 关于页面 commonweal commonweal: /404.html 公益 404 配置标签和分类按钮 现在点击标签和分类按钮是无法使用的，下面进行标签和分类按钮的配置 标签按钮配置 12345678910在hexo项目下执行hexo new page tags执行完成后在source\tags目录下生成index.md文件打开文件在标题中增加 type: &quot;tags&quot;如---title: tagsdate: 2019-08-29 14:35:28type: &quot;tags&quot;--- 配置分类按钮 123456789同上打开工程目录hexo new page categories打开文件在标题中增加 type: &quot;categories&quot;如---title: categoriesdate: 2019-08-29 14:43:25type: &quot;categories&quot;--- 编写博客内容1234567891011121314 执行 hexo new 标题 在source/_posts目录下会出现 标题.md文件 打开文件 给博文添加分类和标签 categories，tags 如下 --- title: 标题 date: 2019-08-29 13:45:29 categories: hexo tags: -hexo -next ---这样这个博文就属于hexo分类，并且其有两个标签hexo和next现在进入首页点击分类和标签按钮即可按分类和标签找到该文章给文章配置图片 方法1 1234567在项目根目下创建images文件夹将图片放入该文件夹如果绑定自己的域名则使用md标签应用图片如![按钮](/images/menu.png)注意：如果使用github提供的域名，由于在github中代码是放在仓库的二级目录中，所以路径需该为![按钮](/仓库名/images/menu.png) 方法2(暂未成功)12345678910更改主目录的_config.yml的文件修改以下配置post_asset_folder: true 当资源文件管理功能打开后，Hexo将会在你每一次通过 hexo new [layout] &lt;title&gt; 命令创建新文章时自动创建一个文件夹。 这个资源文件夹将会有与这个文章文件一样的名字。将所有与你的文章有关的资源放在这个关联文件夹中之后， 你可以通过相对路径来引用它们，这样你就得到了一个更简单而且方便得多的工作流。在md中使用标签&#123;% asset_img menu.png 标题 %&#125;来引入图片 首页展示文章全文的问题 首页中展示的文章是全文，这样导致首页非常的长，可以使用md语法在文章中加入来控制首页展示的长度]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下hexo搭建]]></title>
    <url>%2F2019%2F08%2F29%2Fhexo%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[下载nodejs nodejs下载地址下载 安装hexo1npm install -g hexo-cli 构建hexo项目 安装 Hexo 完成后，执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 123$ cd &lt;folder&gt;$ npm install 安装nodejs的依赖到hexo目录下$ hexo init &lt;folder&gt; 初始化hexo项目 新建完成后，指定文件夹的目录如下： 12345678.├── _config.yml 网站的配置信息,可以在此配置大部分的参数,详细配置参考官网[配置](https://hexo.io/zh-cn/docs/configuration)├── package.json├── scaffolds 模版文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件├── source 资源文件夹，除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去| ├── _drafts| └── _posts└── themes 主题目录，主题有自己的_config.yml文件，用来配置主题自己的属性 编译开启web服务 123hexo ghexo s访问http://localhost:4000 即可看见项目 构建时遇到的错误 12在执行hexo init &lt;folder&gt; 命令时 出现ERROR Local hexo not found in错误删除hexo目录下的node_modules文件 然后在hexo工程目录下重新执行npm install 安装nodejs依赖]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
