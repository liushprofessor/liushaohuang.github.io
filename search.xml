<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CAS详细认证流程]]></title>
    <url>%2F2020%2F01%2F07%2FCAS%E8%AF%A6%E7%BB%86%E8%AE%A4%E8%AF%81%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[简介CAS解决了单点登录的问题，网上有很多关于CAS是如何实现单点的文章，但是很少有对详细认证流程做解释，这里做一下梳理。 &lt;! –more –&gt; 核心概念 TGC：Ticket Granting CookieCAS 会将生成的 TGT 放在 session 中，而 TGC 就是这个 session 的唯一标识(sessionId)，可以认为是 TGT 的key，为 TGT 就是 TGC 的 value，TGC 以 cookie 的形式保存在浏览器中，每个请求都会尝试携带 TGC。（每个服务都会在 session 和 cookie 中保存对应的 TGT 和 TGC） TGT：Ticket Granting TicketTGT 是CAS 为用户签发的登录 ticket，也是用于验证用户登录成功的唯一方式。 TGT 封装了 Cookie 值以及 Cookie 值对应的用户信息，CAS 通过 Cookie 值（TGC）为 key 查询缓存中有无 TGT（TGC:TGT（key:value）），如果有的话就说明用户已经登录成。 ST：Service TicketST 是当用户访问某一服务时提供的 ticket。用户在访问其他服务时，发现没有 cookie 或 ST ，那么就会302到 CAS 服务器获取 ST。然后会携带着 ST 302 回来。 环境准备我们这里准备了3台节点来测试,1和2服务分别对应接入单点的2个系统，我们开启这3个服务 序号 域名 作用 1 app1.com 应用1 2 app2.com 应用2 3 localhost/cas CAS单点登录服务器 第一次访问app1我们访问app1下的接口http://app1.com:8181/book/books ，由于此时浏览器第一次访问app1，之前并没登录，在CAS的client中会做一次跳转，将我们访问的地址重新定向到cas单点登录服务器,我们可以看到此时浏览器一共做了2次操作，第一次如下图，服务器返回302，在respone中返回Location:来标明接下来要重定向的地址，在url中带了一个service的参数，这个参数用来标明在Cas认证完成后，要调转回原来服务的地址接下来浏览器根据上一步浏览器返回的地址进行跳转，跳转到CAS服务器，进行账号密码认证 第一次认证接上上一步，我们在CAS中输入账号和密码，我们可以看到浏览器进行了如下操作提交账号密码并返回302进行重定向，我们可以注意一下在重定向的Location:中返回了一个临时票据ST，并且我们注意到当前在CAS服务器的这个域名下存入了cookieTGC,这里是跨域完成单点登录最重要的一步，因为传统模式下cookie是不能跨域的，但是我们单点登录不同系统往往是跨域名的，如果只将cooike存在当前系统下的不行的，因为不同域不能访问不同的cookie，于是CAS投机取巧的把cookie存放在了CAS所在的域名下，所有子系统在浏览器第一次访问时都要跳转的CAS服务器，那么这时候CAS就可以获取CAS服务端下的cookie，那么这时候CAS服务器只要查看本域名下时候有cookie就知道用户是否已经登陆过，如果登陆了再把信息存入到各个系统的session中，这样就不要每次访问都经过cas服务器，具体原理我们在下面查看 访问重定向的地址，其中地址中带上ST临时票据来进行安全认证，并且返回302，重新定向到我们最开始访问的地址 最后访问我们最开始要访问的地址 这时我们发现请求中已经没有带上任何cookie的信息了，那么CAS是如何知道我们已经完成过登录验证了呢？因为我们使用的CAS提供的client包已经将SESSION_ID存入服务器的SESSION，这里的原理就和我们使用SESSION来做登录原理一样了。我们来查看一下具体源码来证实一下我们的想法CAS客户端主要是由Servlet拦截器去实现的，我们在上一篇提到的博文中在客户端中注册了Cas30ProxyReceivingTicketValidationFilter拦截器和AuthenticationFilter拦截器，而且规定Cas30ProxyReceivingTicketValidationFilter拦截器必须要在AuthenticationFilter的前面，这是为什么呢？因为前者是负责验证ticket的或者是用来做认证的(没有登录的话跳转到CAS服务器)，前者认证完ticket会把验证对象放入到session中，如果AuthenticationFilter发现session中存在验证对象则跳过拦截器。我们查看一下Cas30ProxyReceivingTicketValidationFilter拦截器的父类AbstractTicketValidationFilter，其中的doFilter方法实现了拦截器的主体逻辑，下面我的注释已经写出最主要的逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445public abstract class AbstractTicketValidationFilter extends AbstractCasFilter &#123; public final void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; //此方法验证拦截器的前置条件在Cas30ProxyReceivingTicketValidationFilter中实现的是代理前置过滤，如果拦截器设置了代理地址则不进入拦截器 if (this.preFilter(servletRequest, servletResponse, filterChain)) &#123; HttpServletRequest request = (HttpServletRequest)servletRequest; HttpServletResponse response = (HttpServletResponse)servletResponse; String ticket = this.retrieveTicketFromRequest(request); if (CommonUtils.isNotBlank(ticket)) &#123; this.logger.debug(&quot;Attempting to validate ticket: &#123;&#125;&quot;, ticket); try &#123; //此部分为远程调用CAS服务端接口来验证ticket是否合法，如果合法生成Assertion验证对象 Assertion assertion = this.ticketValidator.validate(ticket, this.constructServiceUrl(request, response)); this.logger.debug(&quot;Successfully authenticated user: &#123;&#125;&quot;, assertion.getPrincipal().getName()); request.setAttribute(&quot;_const_cas_assertion_&quot;, assertion); //将验证对象存入session if (this.useSession) &#123; request.getSession().setAttribute(&quot;_const_cas_assertion_&quot;, assertion); &#125; this.onSuccessfulValidation(request, response, assertion); if (this.redirectAfterValidation) &#123; this.logger.debug(&quot;Redirecting after successful ticket validation.&quot;); response.sendRedirect(this.constructServiceUrl(request, response)); return; &#125; &#125; catch (TicketValidationException var8) &#123; this.logger.debug(var8.getMessage(), var8); this.onFailedValidation(request, response); if (this.exceptionOnValidationFailure) &#123; throw new ServletException(var8); &#125; response.sendError(403, var8.getMessage()); return; &#125; &#125; filterChain.doFilter(request, response); &#125;&#125;&#125; 上面我们说到Cas30ProxyReceivingTicketValidationFilter必须要在AuthenticationFilter拦截器之前，我们现在看下AuthenticationFilter拦截器又做了什么最主要的逻辑就是从session中获取验证过滤器中放入的Assertion对象，如果存在则认为已经登陆过，没有则跳转到CAS服务器去登陆 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class AuthenticationFilter extends AbstractCasFilter &#123; public final void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest)servletRequest; HttpServletResponse response = (HttpServletResponse)servletResponse; //如果跳过验证，白名单 if (this.isRequestUrlExcluded(request)) &#123; this.logger.debug(&quot;Request is ignored.&quot;); filterChain.doFilter(request, response); &#125; else &#123; HttpSession session = request.getSession(false); Assertion assertion = session != null ? (Assertion)session.getAttribute(&quot;_const_cas_assertion_&quot;) : null; //如果session中存在值则跳出拦截器，认为此次访问已经登陆过 if (assertion != null) &#123; filterChain.doFilter(request, response); &#125; else &#123; //如果session中没有值重定向到CAS服务器去登陆 String serviceUrl = this.constructServiceUrl(request, response); String ticket = this.retrieveTicketFromRequest(request); boolean wasGatewayed = this.gateway &amp;&amp; this.gatewayStorage.hasGatewayedAlready(request, serviceUrl); if (!CommonUtils.isNotBlank(ticket) &amp;&amp; !wasGatewayed) &#123; this.logger.debug(&quot;no ticket and no assertion found&quot;); String modifiedServiceUrl; if (this.gateway) &#123; this.logger.debug(&quot;setting gateway attribute in session&quot;); modifiedServiceUrl = this.gatewayStorage.storeGatewayInformation(request, serviceUrl); &#125; else &#123; modifiedServiceUrl = serviceUrl; &#125; this.logger.debug(&quot;Constructed service url: &#123;&#125;&quot;, modifiedServiceUrl); String urlToRedirectTo = CommonUtils.constructRedirectUrl(this.casServerLoginUrl, this.getProtocol().getServiceParameterName(), modifiedServiceUrl, this.renew, this.gateway); this.logger.debug(&quot;redirecting to \&quot;&#123;&#125;\&quot;&quot;, urlToRedirectTo); this.authenticationRedirectStrategy.redirect(request, response, urlToRedirectTo); &#125; else &#123; filterChain.doFilter(request, response); &#125; &#125; &#125; &#125;&#125; 接下来我们第一次访问APP2应用来证实我们上面所说的流程在我们已经登陆过app1的情况下我们访问app2 http://app2.com:8282/book/books ，我们看到服务器发出302请求跳转到CAS服务端 接下来浏览器自动跳转到CAS服务器的域名，这里我们看到这里带上了CAS域名localhost下的cookie 这时CAS就用这个cookie从服务端中查找，发现已经登陆过了，继续发出302请求，并且在Location: 跳转地址中在url中下发st 接下来又下发302请求要求浏览器使用st去验证时候是本人发起的访问，如果验证成功在respone中重新定向到我们之前要访问的地址 最后完成访问，这时候session_id已经存入到app2的session中，所以后续的访问不会再经过上面的逻辑，直接从App2服务端中获取session中就知道应用时候已经登陆 ticket时效总结由上述论证我们可以得到ticket时效，如果ticket（TGT）在CAS服务端中过期，但是应用中session没有过期，仍然有效的话，那么应用仍然可以登录，如果应用中session时效的话，CAS的ticket(TGT)未过期，那么应用仍然可以通过上述方式重新生成session，只有在CAS中的ticket和应用中的session同时失效的情况下，才需要重新登录]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS教程]]></title>
    <url>%2F2020%2F01%2F06%2FCAS%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[参考博文地址https://github.com/X-rapido/CAS_SSO_Record 实践中的问题版本本人使用的是5.3.1版本 配置静态json客户单service问题本人使用的版本是5.3.1，在simple-sso包下实践简单SSO登录在CAS服务端application.properties中静态配置service客户端时比没有设置静态json service的路径，网上查找到如果不配置默认在resources/services下，但是如果不配置此参数在5.3.1版本中无法识别到客户端json配置，所以需要手动加上以下配置cas.serviceRegistry.json.location=classpath:/services博文中–Service 配置介绍中(http://www.ibloger.net/article/3122.html)给定的配置如下，但是将配置配成下面时，CAS 服务端无法开启 #cas.serviceRegistry.config.location=classpath:/services 如果不使用https的情况下在CAS服务端application.properties中关闭SSL，如果不关闭会导致无法跨域单点登录1234server.ssl.enabled=false#解决http下登录状态不互通，无法跨域问题cas.tgc.secure=falsecas.warningCookie.secure=false 解决http下代理模式无法回调成功在http模式下代理模式调用代理端回调函数时会报 1org.jasig.cas.client.validation.TicketValidationException: 所提供的代理回调网址&apos;https://xxxx&apos;不能提供认证。 这是因为CAS默认代理回调函数只支持https我们需要在CAS服务端中的service注册json文件中添加proxyPolicy属性来增加对http的支持 123456789101112&#123; &quot;@class&quot; : &quot;org.apereo.cas.services.RegexRegisteredService&quot;, &quot;serviceId&quot; : &quot;^(https|http|imaps)://.*&quot;, &quot;name&quot; : &quot;HTTPS and HTTP and IMAPS&quot;, &quot;id&quot; : 10000001, &quot;description&quot; : &quot;This service definition authorizes all application urls that support HTTPS and HTTP and IMAPS protocols.&quot;, &quot;evaluationOrder&quot; : 10000, &quot;proxyPolicy&quot;: &#123; &quot;@class&quot;: &quot;org.apereo.cas.services.RegexMatchingRegisteredServiceProxyPolicy&quot;, &quot;pattern&quot;: &quot;^(https|http)?://.*&quot; &#125;&#125;]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring @Import和@Enable*注解和Spring的SPI完成二方包的注入]]></title>
    <url>%2F2019%2F12%2F30%2FSpring-Import%E5%92%8C-Enable-%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[简介最近在写一些基于SpringBoot的jar供其它工程调用，学习了一些开源和了解了Spring的自动配置后做了以下总结，在最开始接触Spring时当时网上说Spring基于xml的控制反转和依赖注入可以很好的将代码解耦，当时并不理解，明明依赖还是存在为什么能很好的解耦？直到接触了多模块后才渐渐理解它的含义，在多模块中代码供应商提供统一的接口，犹如一些插件，软件商提供主要接口，接入商负责实现，接入商的又有很多，那么如何做到可插拔开箱即用而各个接入商之间又不互相影响呢？这是依赖注入就很好的解决了这个问题，开发商和接入商不再进行强耦合，而是依赖类似与中间件一样的组件，将实现都由中间去管理，如果我想替换掉某个接入商的实现就在中间中更换接口的实现即可，对供应商的代码无任何影响，这就是Spring做的事。 将二方包注入到调用者的Spring容器中我们都知道SpringBoot工程的入口需要有一个@SpringBootApplication注解，然后SpringBoot会自动扫描这个类同级或者子包的Spring注解然后注入到Spring容器中，但是我们编写的二方包往往和调用者有者不同的目录结构，如何才能将我们提供的二方包注入到调用者的容器中呢？这里有3中方法。 保持相同的目录结构简单粗暴的方法就是调用者和被调用者有着相同的目录结构，使二方包中的配置类在调用者启动类如果的同级包或者子包下，那么这样SpringBoot在扫描时就会扫描到二方包中的Spring配置自动注入到容器中。 我们创建一个二方包工程,POM文件如下,只引入Spring的容器模块 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_core2&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;!--&lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;配置程序入口如果有的话&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt;--&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;!-- &lt;goal&gt;assembly&lt;/goal&gt; --&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--use commend: mvn assembly:assembly -DskipTests --&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 编写二方包接口 12345678910111213package com.liu.app1;/** * @author Liush * @description * @date 2019/12/30 17:35 **/public interface ServiceI &#123; String getServiceName();&#125; 接口实现类 12345678910111213package com.liu.app1;/** * @author Liush * @description * @date 2019/12/30 17:35 **/public class ServiceImpl implements ServiceI &#123; @Override public String getServiceName() &#123; return &quot;core2...........&quot;; &#125;&#125; Spring配置类 1234567891011121314151617181920package com.liu.app1;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author Liush * @description * @date 2019/12/30 17:36 **/@Configurationpublic class Config &#123; @Bean public ServiceI createService()&#123; return new ServiceImpl(); &#125;&#125; 执行mvn install将二方包打入本地仓库 创建调用工程 我们创建调用者POM文件,创建一个web工程 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--引入自定义二方包 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_core2&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 接着我们编写入口和一个Rest接口 123456789101112131415161718192021222324252627package com.liu.app1;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author Liush * @description * @date 2019/12/30 17:26 **/@RestControllerpublic class Rest &#123; @Autowired private ServiceI serviceI; @RequestMapping(&quot;/getName&quot;) public String getName()&#123; return serviceI.getServiceName(); &#125;&#125; 编写调用包的启动类 1234567891011121314151617181920212223package com.liu.app1;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Import;/** * @author Liush * @description * @date 2019/12/30 16:51 **/@SpringBootApplicationpublic class APP &#123; public static void main(String[] args) &#123; SpringApplication.run(APP.class,args); &#125;&#125; 接着我们访问http://localhost:8080/getName输出 core2……….. 总结这种方法需要调用者和二方包有相同的目录接口才能使调用方扫描到二方包的Spring配置，这种在实际中可行性较低 使用@Import注解 第一种方法在项目中可行性很低于是我们可以采用这种方法来编写二方包 创建工程POM文件,注意这里和第一种方法的POM文件没有什么不同除了我们将 改成了enable_core 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_core&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;!--&lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;配置程序入口如果有的话&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt;--&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;!-- &lt;goal&gt;assembly&lt;/goal&gt; --&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--use commend: mvn assembly:assembly -DskipTests --&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 这次我们在和调用方不同的路径下编写代码,总体和第一步都相同，主要就是包的路径不同,首先编写接口 123456789101112package com.sunnada;/** * @author Liush * @description * @date 2019/12/30 17:05 **/public interface ServiceI &#123; String getServiceName();&#125; 编写实现类 12345678package com.sunnada;public class ServiceImpl implements ServiceI &#123; @Override public String getServiceName() &#123; return &quot;core包中的服务实现&quot;; &#125;&#125; 编写配置文件 123456789101112131415161718192021package com.sunnada;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author Liush * @description * @date 2019/12/30 17:01 **/@Configurationpublic class CoreConfig &#123; @Bean public ServiceI createService()&#123; return new ServiceImpl(); &#125;&#125; 执行mvn clean install将代码打入仓库 调用方代码 创建POM文件，引入二方包 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_test&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.liu&lt;/groupId&gt; &lt;artifactId&gt;enable_core&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 编写Rest接口 12345678910111213141516171819202122232425262728package com.liu.app1;import com.sunnada.ServiceI;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author Liush * @description * @date 2019/12/30 17:26 **/@RestControllerpublic class Rest &#123; @Autowired private ServiceI serviceI; @RequestMapping(&quot;/getName&quot;) public String getName()&#123; return serviceI.getServiceName(); &#125;&#125; 编写调用包的启动类,注意我们这里使用了@Import注解将我们二方包的配置文件导入 1234567891011121314151617181920212223package com.liu.app1;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Import;/** * @author Liush * @description * @date 2019/12/30 16:51 **/@SpringBootApplication@Import(&#123;com.sunnada.CoreConfig.class&#125;)public class APP &#123; public static void main(String[] args) &#123; SpringApplication.run(APP.class,args); &#125;&#125; 访问接口输出 core包中的服务实现 总结我们使用@Import在调用方中的启动类中手动指定需要注入的配置类，完成二方包的注入 更进一步我们在调用开源工程的时候经常引入一些二方包，这些包中我们并不需要使用@Import注解，而是在启动类中使用@Enable* 注解即可完成二方包的注入，我们可以查看@EnableScheduling中的源码,发现其本质也是使用@Import注解完成二方包的注入 1234567891011121314151617181920//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package org.springframework.scheduling.annotation;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import org.springframework.context.annotation.Import;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Import(&#123;SchedulingConfiguration.class&#125;)@Documentedpublic @interface EnableScheduling &#123;&#125; 基于Spring的SPI机制新建配置文件由于我们用maven构建工程，我们在resources下新建目录/META-INF/spring.factories文件,在配置文件中加入以下代码 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.liu.Config 我们注意配置文件等号左边的部分是Spring自动配置提供的类，右边是我们需要注入的类的全路径，到此我们会疑问SpringBoot是如何使用这个方法自动注入的呢？下面我们进入org.springframework.boot.autoconfigure.EnableAutoConfiguration查看源码 12345678910111213141516171819202122232425262728//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package org.springframework.boot.autoconfigure;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Inherited;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import org.springframework.context.annotation.Import;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(&#123;AutoConfigurationImportSelector.class&#125;)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; 我们注意最重要的部分@Import({AutoConfigurationImportSelector.class})，我们进入类中查看,发现其实现DeferredImportSelector接口，而DeferredImportSelector又实现ImportSelector 12345678public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123;...&#125; 那ImportSelector接口的作用又是什么呢？其有只有一个方法 1234567package org.springframework.context.annotation;import org.springframework.core.type.AnnotationMetadata;public interface ImportSelector &#123; String[] selectImports(AnnotationMetadata var1);&#125; 我们通过查找官方API,得知这个接口是决定哪些类可以导入Spring容器，也就是说我们可以通过实现这个接口来通过编码和配置文件的方式注入类到Spring的容器中 1Interface to be implemented by types that determine which @Configuration class(es) should be imported based on a given selection criteria, usually one or more annotation attributes. 接着我们查看AutoConfigurationImportSelector的selectImports方法实现，查看到底在AutoConfigurationImportSelector中做了什么 123456789public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!this.isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; else &#123; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader); AutoConfigurationImportSelector.AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations()); &#125; &#125; 这里我们看的一头雾水，但是我们可以根据方法名来猜测loadMetadata方法大概是加载什么元数据之类的,getAutoConfigurationEntry方法是获取配置实体之类的我们进入该方法查看一下 123456789101112131415protected AutoConfigurationImportSelector.AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; if (!this.isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; else &#123; AnnotationAttributes attributes = this.getAttributes(annotationMetadata); List&lt;String&gt; configurations = this.getCandidateConfigurations(annotationMetadata, attributes); configurations = this.removeDuplicates(configurations); Set&lt;String&gt; exclusions = this.getExclusions(annotationMetadata, attributes); this.checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = this.filter(configurations, autoConfigurationMetadata); this.fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationImportSelector.AutoConfigurationEntry(configurations, exclusions); &#125; &#125; 这里我们根据方法名大概可以知道这里做的就是获取配置文件中的信息，然后做了去重，过滤等一系列查找然后将属性封装出去 12345protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(this.getSpringFactoriesLoaderFactoryClass(), this.getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you are using a custom packaging, make sure that file is correct.&quot;); return configurations; &#125; 这里我们进入getSpringFactoriesLoaderFactoryClass方法看一下发现其返回的是一个EnableAutoConfiguration对象，也就是我们配置文件中配置的org.springframework.boot.autoconfigure.EnableAutoConfiguration类，这里也就是解释了为什么我们需要在配置文件中在org.springframework.boot.autoconfigure.EnableAutoConfiguration类下配置类才能完成自动注入 123protected Class&lt;?&gt; getSpringFactoriesLoaderFactoryClass() &#123; return EnableAutoConfiguration.class; &#125; 现在再根据方法名我们发现this.getCandidateConfigurations方法可能使获取配置类发生的地方我们进入该方法查看一下这里我们发现了SpringFactoriesLoader类的身影，熟悉Spring spi的知道spring spi就是通过这个类来加载配置文件中的类来达成自动配置的目的的，我们在进入SpringFactoriesLoader查看一下,发现其中又一个属性为FACTORIES_RESOURCE_LOCATION ，这里就说明了我们建配置文件为什么必须目录为META-INF/spring.factories 123456public final class SpringFactoriesLoader &#123; public static final String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;;.... &#125; 那么这里逻辑就已经清晰我们在META-INF/spring.factories中配置SpringBoot需要自动注入的类，org.springframework.boot.autoconfigure.EnableAutoConfiguration是Spring帮我们封装好的一个注解我们在其后配置我们需要自动注入的类，那么SpringBoot就会使用AutoConfigurationImportSelector来帮助我们将我们配置的类一个个注入到Spring中]]></content>
      <categories>
        <category>SPI</category>
      </categories>
      <tags>
        <tag>SPI</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA_SPI机制]]></title>
    <url>%2F2019%2F12%2F27%2FJAVA-SPI%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[简介在编写SpringBoot stater时我们会在项目的resources目录下新建META-INF文件夹并且在该目录下新建spring.factories文件,该文件中配置了在SpringBoot开启时需要加载和配置的类，那为什么只要配置了这个文件Spring就能自动去加载这个类呢？这个是因为用到了java的SPI机制 SPI想象一下现在有两个项目A,B。他们之间存在依赖关系B依赖于项目A,也就是说B在A项目的上层，通常反映在我们需要在B的maven POM.xml文件中配置了A的依赖。那么现在处在下层的A工厂有一个抽象接口需要由下层应用去实现，（举个例子A工程是快递公司，B工程是一个电商客户，那么快递公司只要留一个统一的收快递的电话给电商客户，由电商客户去打电话叫快递公司去寄快递即可，对于快递公司它并不关心电商公司是寄送什么货物，快递公司只负责寄送即可，那么具体寄送什么货物的实现就由电商公司自行去实现），想象一下这个系统你会怎么写？我们只要实现快递公司提供的寄送货物的接口，然后再由电商公司调用寄送货物的接口即可，简单暴力完成解耦。那么现在有一个问题，由于快递公司和这家电商公司关系恶化，那么快递公司想把这家公司开除，然后和另外一家快递公司合作，那么我们要怎么做？是不是要修改代码，去掉这家被开除的电商公司的实现，然后加入新的电商公司的实现？有没有一个方法我们不需要修改代码只要修改一下配置文件即可？于是这里就延伸除了SPI机制,其实控制反转的实现依赖注入就是一个变相的SPI实现，我们只要配置Spring的xml文件就能完成替换我们不同的类的实现，这样我们就不要更改我们核心的代码，只要修改我们的配置类即可，这样大大降低了出错的可能和完成了解耦 JDK自带 SPI简单的代码实现定义一个接口我们定义一个父类汽车,他有一个方法获取汽车名 123456789101112package com.liu;/** * @author Liush * @description * @date 2019/12/27 10:36 **/public interface CarI &#123; String getName();&#125; 定义2个实现类分别为奔驰和宝马1234567891011121314package com.liu;/** * @author Liush * @description * @date 2019/12/27 10:43 **/public class BenZ implements CarI &#123; @Override public String getName() &#123; return &quot;我是奔驰&quot;; &#125;&#125; 12345678910111213package com.liu;/** * @author Liush * @description * @date 2019/12/27 10:37 **/public class BMW implements CarI &#123; @Override public String getName() &#123; return &quot;我是宝马&quot;; &#125;&#125; 新建配置文件因为我使用的是maven工程所以我在resources目录下新建services目录注意services目录时固定的，这个在jdk的代码中只识别这个目录，在services目录下新建配置文件，文件名为父接口的全路径名称，比如这里是com.liu.CarI,然后再文件中添加我们想要注入的实现类这里配置如下,我们将宝马和奔驰都注入 12com.liu.BMWcom.liu.BenZ 调用新建main函数，使用ServiceLoader去调用方法，我们会发现系统输入了我是宝马和我是奔驰，那么一个简单的SPI实现完成，这样就完成了代码的配置和代码的实现解耦 1234567891011121314151617181920212223242526package com.liu;import java.sql.Driver;import java.util.Iterator;import java.util.ServiceLoader;/** * @author Liush * @description * @date 2019/12/27 10:39 **/public class MainTest &#123; public static void main(String[] args) &#123; ServiceLoader&lt;CarI&gt; serviceLoader=ServiceLoader.load(CarI.class); Iterator&lt;CarI&gt; carIterator=serviceLoader.iterator(); while (carIterator.hasNext())&#123; System.out.println(carIterator.next().getName()); &#125; &#125;&#125;]]></content>
      <categories>
        <category>SPI</category>
      </categories>
      <tags>
        <tag>SPI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计原本-杂记]]></title>
    <url>%2F2019%2F12%2F12%2F%E8%AE%BE%E8%AE%A1%E5%8E%9F%E6%9C%AC-%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第二章，理性模型工程师对于设计过程有一个清晰但通常来说也是隐含的模型，这个隐含的模型是在项目设计开始时根据目标，必要条件，约束等设计出来的，我们可以在开始设计时将条件设计出一个决策树，将各种暂时能想到的决策用树的形式展示出来，正如本章开篇所说因为设计的理念是普通的搜索理论即巨大的组合空间搜索，我是这样理解这句话，设计就是各个模块的各种可能选择最优解的组合，在项目开始设计时，将我们能想到的各种解用决策树的形式展示出来，并给每个节点（每种设计可能）一个权重，从而取出目前的最优设计.而有了这个决策树的理性模型，就更方便的和项目组中的其它成员分析项目的设计.注意：理性模型不是设计决策，而是暂定的设计方案。 第三章，理性模型的缺陷理性模型不是设计决策，而是暂定的设计方案，我们在项目开发中，刚开始我们并不知道项目树的样子，只有一边设计一般探索才能完善这颗树，而且约束等外部条件也在持续变化。这是一种设计过程的模型，设计过程的模型会影响设计的本身，因为当我们有了这个理性模型后，我们后续的工作都会围绕理性模型开展 第四章，需求软件设计不能在一开始就提出所有的需求，在开始时提出所有的需求必将导致项目的失败，因为在项目开始时我们并不能很好的考虑到每一点，我们应该提出概念模型和主要的需求和约束来进行开发，在根据主要模型和主要约束完成第一个版本后再对这些主要需求进行延伸，而且必须严格控制在开发一个版本进行过程中的需求蠕动(根据原有需求在一个版本未完成时对需求进行更改或者延伸) 第六章，协作设计在多人协作设计一个项目时，必须要有一个人主导设计，概念模型必须要由一个人提出，但是只有两个人的团队除外，因为两个人比多人能更快的达成一致，且沟通更加高效，且可以互相监督和提出意见，这样效率比单人设计效率和质量更高. ####第九章，模型设计:宁错勿淆,错误可以让我们很快接近真理，而混乱却不能设计前应该将对用户的认识和使用系统的目的详细列出，如果面向的是不同的用户，则计算出不同用户的各自权重，根据权重来设计一个折中的设计，在设计时，团队必须对模型定义出通用语言(领域驱动设计)，对一个模型要进行详细的说明，这样才能对由其引发的细节进行更深层的思考(我们在设计原型和开发时，进程随着开发和设计的深入，对原有的流程有了更深的思考，会发现原有的流程并不合理)，另外随着思考的深入，产生的细节和问题也会越来越不明确，这时可以大胆的去假设，因为宁错勿淆,错误可以让我们很快接近真理，而混乱却不能]]></content>
      <categories>
        <category>设计原本</category>
      </categories>
      <tags>
        <tag>设计原本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring security的认证和鉴权]]></title>
    <url>%2F2019%2F12%2F09%2FSpring-security%E7%9A%84%E8%AE%A4%E8%AF%81%E5%92%8C%E9%89%B4%E6%9D%83%2F</url>
    <content type="text"><![CDATA[简介Spring security 总体分为认证和鉴权两部分，认证我们可以理解为对账号密码的验证，鉴权为用户能不能访问资源，我们可以通过实现Spring security的接口来实现自定义的认证和鉴权。Spring security的本质是一连串的拦截器，我们可以拦截器链中加入自定义的拦截器来实现自己的逻辑. 认证部分下面介绍认证的核心接口和概念 Authentication此接口负者存储要认证的具体信息，主要是将认证的账号密码还有权限等信息存放在其中,比如前端传入账号和密码给后端验证，那么需要将账号和密码封装进实现Authentication接口的认证类中，然后将认证信息传给Spring security拦截器链，由Spring security调用认证和鉴权方法,代码如下 12345678910111213141516171819public interface Authentication extends Principal, Serializable &#123; //此账号具有哪些角色或者权限 Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); //认证信息，可以理解为密码 Object getCredentials(); Object getDetails(); //认证主体，如账号 Object getPrincipal(); //这个Authentication是否已经认证过 boolean isAuthenticated(); //设置Authentication是否已经认证过 void setAuthenticated(boolean var1) throws IllegalArgumentException;&#125; AuthenticationManager在框架中AuthenticationManager负责认证，一般我们使用Spring security自带实现类ProviderManager 1234public interface AuthenticationManager &#123; Authentication authenticate(Authentication var1) throws AuthenticationException;&#125; ProviderManager的authenticate(Authentication var1)方法的实现，我们可以看到起主要逻辑是循环调用List providers 中的AuthenticationProvider下的authenticate(Authentication authentication)方法，如果其中有一个AuthenticationProvider认证成功则返回，那么这里认证的逻辑就已经大概清晰，Spring Security 依托ProviderManager的实现去完成认证，而ProviderManager的主要实现类是ProviderManager，ProviderManager中又有一个AuthenticationProvider对象的集合，其负责具体的验证逻辑，如果有一个认证通过，则之前存在Authentication中的信息就认证成功，我们要做的就是实现自己的AuthenticationProvider认证，将其加入到ProviderManager的认证集合List providers中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172private List&lt;AuthenticationProvider&gt; providers;//...省略其余代码public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Class&lt;? extends Authentication&gt; toTest = authentication.getClass(); AuthenticationException lastException = null; AuthenticationException parentException = null; Authentication result = null; Authentication parentResult = null; boolean debug = logger.isDebugEnabled(); Iterator var8 = this.getProviders().iterator(); while(var8.hasNext()) &#123; AuthenticationProvider provider = (AuthenticationProvider)var8.next(); if (provider.supports(toTest)) &#123; if (debug) &#123; logger.debug(&quot;Authentication attempt using &quot; + provider.getClass().getName()); &#125; try &#123; result = provider.authenticate(authentication); if (result != null) &#123; this.copyDetails(authentication, result); break; &#125; &#125; catch (AccountStatusException var13) &#123; this.prepareException(var13, authentication); throw var13; &#125; catch (InternalAuthenticationServiceException var14) &#123; this.prepareException(var14, authentication); throw var14; &#125; catch (AuthenticationException var15) &#123; lastException = var15; &#125; &#125; &#125; if (result == null &amp;&amp; this.parent != null) &#123; try &#123; result = parentResult = this.parent.authenticate(authentication); &#125; catch (ProviderNotFoundException var11) &#123; ; &#125; catch (AuthenticationException var12) &#123; parentException = var12; lastException = var12; &#125; &#125; if (result != null) &#123; if (this.eraseCredentialsAfterAuthentication &amp;&amp; result instanceof CredentialsContainer) &#123; ((CredentialsContainer)result).eraseCredentials(); &#125; if (parentResult == null) &#123; this.eventPublisher.publishAuthenticationSuccess(result); &#125; return result; &#125; else &#123; if (lastException == null) &#123; lastException = new ProviderNotFoundException(this.messages.getMessage(&quot;ProviderManager.providerNotFound&quot;, new Object[]&#123;toTest.getName()&#125;, &quot;No AuthenticationProvider found for &#123;0&#125;&quot;)); &#125; if (parentException == null) &#123; this.prepareException((AuthenticationException)lastException, authentication); &#125; throw lastException; &#125; &#125; AuthenticationProvider上文提到了AuthenticationProvider是负责具体认证的地方，它的代码如下authenticate方法负责接收一个Authentication类，如果认证成功则返回一个Authentication对象，supports(Class&lt;?&gt; var1)负责判定这个AuthenticationProvider可以鉴定什么类型的Authentication，我们可以实现自己的Authentication，和AuthenticationProvider，从而使我们自定义的AuthenticationProvider只去鉴定特定的Authentication 12345public interface AuthenticationProvider &#123; Authentication authenticate(Authentication var1) throws AuthenticationException; boolean supports(Class&lt;?&gt; var1);&#125; UserDetailsServiceUserDetailsService是Spring security抽象的接口其方法如下，其作用是根据参数获取一个用户属性UserDetails，UserDetails为Spring secur为用户做的一个抽象。 123public interface UserDetailsService &#123; UserDetails loadUserByUsername(String var1) throws UsernameNotFoundException;&#125; 在网上我们看到的很多教程叫我们只要自定义实现自己的 UserDetailsService就可以完成认证，这是因为Spring security默认使用的Authentication 是UsernamePasswordAuthenticationToken，而默认对UsernamePasswordAuthenticationToken进行认证的又是AuthenticationProvider 是DaoAuthenticationProvider,下面我们查看DaoAuthenticationProvider源码发现以下代码，其中this.getUserDetailsService().loadUserByUsername就是调用UserDetailsService去获取UserDetailsService对象 12345678910111213141516171819protected final UserDetails retrieveUser(String username, UsernamePasswordAuthenticationToken authentication) throws AuthenticationException &#123; this.prepareTimingAttackProtection(); try &#123; UserDetails loadedUser = this.getUserDetailsService().loadUserByUsername(username); if (loadedUser == null) &#123; throw new InternalAuthenticationServiceException(&quot;UserDetailsService returned null, which is an interface contract violation&quot;); &#125; else &#123; return loadedUser; &#125; &#125; catch (UsernameNotFoundException var4) &#123; this.mitigateAgainstTimingAttack(authentication); throw var4; &#125; catch (InternalAuthenticationServiceException var5) &#123; throw var5; &#125; catch (Exception var6) &#123; throw new InternalAuthenticationServiceException(var6.getMessage(), var6); &#125; &#125; 那retrieveUser又具体做了什么呢，我们查看DaoAuthenticationProvider父类AbstractUserDetailsAuthenticationProvider中的代码,其中以下最重要的一段代码this.additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken)authentication);这段代码的实现在DaoAuthenticationProvider中，且public boolean supports(Class&lt;?&gt; authentication) 表明了其只验证实现了UsernamePasswordAuthenticationToken的Authentication 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Assert.isInstanceOf(UsernamePasswordAuthenticationToken.class, authentication, () -&gt; &#123; return this.messages.getMessage(&quot;AbstractUserDetailsAuthenticationProvider.onlySupports&quot;, &quot;Only UsernamePasswordAuthenticationToken is supported&quot;); &#125;); String username = authentication.getPrincipal() == null ? &quot;NONE_PROVIDED&quot; : authentication.getName(); boolean cacheWasUsed = true; UserDetails user = this.userCache.getUserFromCache(username); if (user == null) &#123; cacheWasUsed = false; try &#123; user = this.retrieveUser(username, (UsernamePasswordAuthenticationToken)authentication); &#125; catch (UsernameNotFoundException var6) &#123; this.logger.debug(&quot;User &apos;&quot; + username + &quot;&apos; not found&quot;); if (this.hideUserNotFoundExceptions) &#123; throw new BadCredentialsException(this.messages.getMessage(&quot;AbstractUserDetailsAuthenticationProvider.badCredentials&quot;, &quot;Bad credentials&quot;)); &#125; throw var6; &#125; Assert.notNull(user, &quot;retrieveUser returned null - a violation of the interface contract&quot;); &#125; try &#123; this.preAuthenticationChecks.check(user); this.additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken)authentication); &#125; catch (AuthenticationException var7) &#123; if (!cacheWasUsed) &#123; throw var7; &#125; cacheWasUsed = false; user = this.retrieveUser(username, (UsernamePasswordAuthenticationToken)authentication); this.preAuthenticationChecks.check(user); this.additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken)authentication); &#125; this.postAuthenticationChecks.check(user); if (!cacheWasUsed) &#123; this.userCache.putUserInCache(user); &#125; Object principalToReturn = user; if (this.forcePrincipalAsString) &#123; principalToReturn = user.getUsername(); &#125; return this.createSuccessAuthentication(principalToReturn, authentication, user); &#125; public boolean supports(Class&lt;?&gt; authentication) &#123; return UsernamePasswordAuthenticationToken.class.isAssignableFrom(authentication); &#125; DaoAuthenticationProvider中我们找到additionalAuthenticationChecks方法,这里的逻辑就很清晰了，将UserDetails中的值和authentication中的值做比对，如果不匹配抛出AuthenticationException异常由spring security去处理异常 123456789101112protected void additionalAuthenticationChecks(UserDetails userDetails, UsernamePasswordAuthenticationToken authentication) throws AuthenticationException &#123; if (authentication.getCredentials() == null) &#123; this.logger.debug(&quot;Authentication failed: no credentials provided&quot;); throw new BadCredentialsException(this.messages.getMessage(&quot;AbstractUserDetailsAuthenticationProvider.badCredentials&quot;, &quot;Bad credentials&quot;)); &#125; else &#123; String presentedPassword = authentication.getCredentials().toString(); if (!this.passwordEncoder.matches(presentedPassword, userDetails.getPassword())) &#123; this.logger.debug(&quot;Authentication failed: password does not match stored value&quot;); throw new BadCredentialsException(this.messages.getMessage(&quot;AbstractUserDetailsAuthenticationProvider.badCredentials&quot;, &quot;Bad credentials&quot;)); &#125; &#125; &#125; 拦截器上文提到我们登陆的时候需要把我们登陆的信息封装成Authentication对象，再由Spring security框架去认证，前文还说到Spring Security的本质就是一连串的拦截器，那我们实现的思路就是这样，我们自定义一个拦截器，拦截登陆的信息，将账号密码组成Authentication对象，再交由Spring security对象去认证即可,之后以我们可以不自定义上述的类就可以使用是因为Spring security中默认加入了一个UsernamePasswordAuthenticationFilter拦截器，且提供了默认实现的DaoAuthenticationProvider.我们查看UsernamePasswordAuthenticationFilter的源码,发现其只是将前传送进来的账号密码组成一个UsernamePasswordAuthenticationToken ，我们注意到this.getAuthenticationManager().authenticate(authRequest)这段代码，这段代码就是调用ProviderManager去完成对Authentication的认证 1234567891011121314151617181920public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; if (this.postOnly &amp;&amp; !request.getMethod().equals(&quot;POST&quot;)) &#123; throw new AuthenticationServiceException(&quot;Authentication method not supported: &quot; + request.getMethod()); &#125; else &#123; String username = this.obtainUsername(request); String password = this.obtainPassword(request); if (username == null) &#123; username = &quot;&quot;; &#125; if (password == null) &#123; password = &quot;&quot;; &#125; username = username.trim(); UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(username, password); this.setDetails(request, authRequest); return this.getAuthenticationManager().authenticate(authRequest); &#125; &#125; 下面我们再查看UsernamePasswordAuthenticationToken的父类AbstractAuthenticationProcessingFilter,发现其调用了UsernamePasswordAuthenticationToken的attemptAuthentication方法，并且将UsernamePasswordAuthenticationToken放入SecurityContextHolder中的SecurityContext里 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest)req; HttpServletResponse response = (HttpServletResponse)res; if (!this.requiresAuthentication(request, response)) &#123; chain.doFilter(request, response); &#125; else &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Request is to process authentication&quot;); &#125; Authentication authResult; try &#123; authResult = this.attemptAuthentication(request, response); if (authResult == null) &#123; return; &#125; this.sessionStrategy.onAuthentication(authResult, request, response); &#125; catch (InternalAuthenticationServiceException var8) &#123; this.logger.error(&quot;An internal error occurred while trying to authenticate the user.&quot;, var8); this.unsuccessfulAuthentication(request, response, var8); return; &#125; catch (AuthenticationException var9) &#123; this.unsuccessfulAuthentication(request, response, var9); return; &#125; if (this.continueChainBeforeSuccessfulAuthentication) &#123; chain.doFilter(request, response); &#125; this.successfulAuthentication(request, response, chain, authResult); &#125; &#125; protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, Authentication authResult) throws IOException, ServletException &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Authentication success. Updating SecurityContextHolder to contain: &quot; + authResult); &#125; SecurityContextHolder.getContext().setAuthentication(authResult); this.rememberMeServices.loginSuccess(request, response, authResult); if (this.eventPublisher != null) &#123; this.eventPublisher.publishEvent(new InteractiveAuthenticationSuccessEvent(authResult, this.getClass())); &#125; this.successHandler.onAuthenticationSuccess(request, response, authResult); &#125; 默认的SecurityContext是由ThredLocal生成,也就是说在同一个线程下我们都可以通过SecurityContextHolder.getContext().getAuthentication()获取到Authentication或者通过 SecurityContextHolder.getContext().setAuthentication()设置Authentication 1234567891011121314151617181920212223242526272829final class ThreadLocalSecurityContextHolderStrategy implements SecurityContextHolderStrategy &#123; private static final ThreadLocal&lt;SecurityContext&gt; contextHolder = new ThreadLocal(); ThreadLocalSecurityContextHolderStrategy() &#123; &#125; public void clearContext() &#123; contextHolder.remove(); &#125; public SecurityContext getContext() &#123; SecurityContext ctx = (SecurityContext)contextHolder.get(); if (ctx == null) &#123; ctx = this.createEmptyContext(); contextHolder.set(ctx); &#125; return ctx; &#125; public void setContext(SecurityContext context) &#123; Assert.notNull(context, &quot;Only non-null SecurityContext instances are permitted&quot;); contextHolder.set(context); &#125; public SecurityContext createEmptyContext() &#123; return new SecurityContextImpl(); &#125;&#125; 在本人的自行实现的拦截器中并没有调用this.getAuthenticationManager().authenticate(authRequest)方法,因为本人只实现了OncePerRequestFilter类，并没有实现Spring security提供的AbstractAuthenticationProcessingFilter抽象类，但是仍然可以实现认证，因为在后面的鉴权拦截器中我实现了AbstractSecurityInterceptor类该中有一段代码Authentication authenticated = this.authenticateIfRequired(); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162protected InterceptorStatusToken beforeInvocation(Object object) &#123; Assert.notNull(object, &quot;Object was null&quot;); boolean debug = this.logger.isDebugEnabled(); if (!this.getSecureObjectClass().isAssignableFrom(object.getClass())) &#123; throw new IllegalArgumentException(&quot;Security invocation attempted for object &quot; + object.getClass().getName() + &quot; but AbstractSecurityInterceptor only configured to support secure objects of type: &quot; + this.getSecureObjectClass()); &#125; else &#123; Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource().getAttributes(object); if (attributes != null &amp;&amp; !attributes.isEmpty()) &#123; if (debug) &#123; this.logger.debug(&quot;Secure object: &quot; + object + &quot;; Attributes: &quot; + attributes); &#125; if (SecurityContextHolder.getContext().getAuthentication() == null) &#123; this.credentialsNotFound(this.messages.getMessage(&quot;AbstractSecurityInterceptor.authenticationNotFound&quot;, &quot;An Authentication object was not found in the SecurityContext&quot;), object, attributes); &#125; Authentication authenticated = this.authenticateIfRequired(); try &#123; this.accessDecisionManager.decide(authenticated, object, attributes); &#125; catch (AccessDeniedException var7) &#123; this.publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated, var7)); throw var7; &#125; if (debug) &#123; this.logger.debug(&quot;Authorization successful&quot;); &#125; if (this.publishAuthorizationSuccess) &#123; this.publishEvent(new AuthorizedEvent(object, attributes, authenticated)); &#125; Authentication runAs = this.runAsManager.buildRunAs(authenticated, object, attributes); if (runAs == null) &#123; if (debug) &#123; this.logger.debug(&quot;RunAsManager did not change Authentication object&quot;); &#125; return new InterceptorStatusToken(SecurityContextHolder.getContext(), false, attributes, object); &#125; else &#123; if (debug) &#123; this.logger.debug(&quot;Switching to RunAs Authentication: &quot; + runAs); &#125; SecurityContext origCtx = SecurityContextHolder.getContext(); SecurityContextHolder.setContext(SecurityContextHolder.createEmptyContext()); SecurityContextHolder.getContext().setAuthentication(runAs); return new InterceptorStatusToken(origCtx, true, attributes, object); &#125; &#125; else if (this.rejectPublicInvocations) &#123; throw new IllegalArgumentException(&quot;Secure object invocation &quot; + object + &quot; was denied as public invocations are not allowed via this interceptor. This indicates a configuration error because the rejectPublicInvocations property is set to &apos;true&apos;&quot;); &#125; else &#123; if (debug) &#123; this.logger.debug(&quot;Public object - authentication not attempted&quot;); &#125; this.publishEvent(new PublicInvocationEvent(object)); return null; &#125; &#125; &#125; 进入 this.authenticateIfRequired();我们发现Authentication的isAuthenticated状态时false时在这里将会完成再次认证,所以我们自定义认证完Authentication后必须将Authentication的isAuthenticated的状态设置为true，避免后续拦截器再次去认证 123456789101112131415161718private Authentication authenticateIfRequired() &#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authentication.isAuthenticated() &amp;&amp; !this.alwaysReauthenticate) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Previously Authenticated: &quot; + authentication); &#125; return authentication; &#125; else &#123; authentication = this.authenticationManager.authenticate(authentication); if (this.logger.isDebugEnabled()) &#123; this.logger.debug(&quot;Successfully Authenticated: &quot; + authentication); &#125; SecurityContextHolder.getContext().setAuthentication(authentication); return authentication; &#125; &#125; 认证异常处理在认证过程中出现认证失败，不管是我们自定义的认证类和Spring security 自带的实现类都抛出AuthenticationException异常，这个异常可以统一由Spring security捕获，从而处理认证异常 认证配置以下配置中关于认证的我们只需要注意几点 public void configure(AuthenticationManagerBuilder authenticationManagerBuilder)此方法下往ProviderManager中配置了AuthenticationProvider认证器，并且设置了UserDetailService类和设置了认证时密码不加密 public void configure(HttpSecurity http)此方法配置了认证的具体逻辑，http.addFilterBefore(validateFilter, UsernamePasswordAuthenticationFilter.class)将我们自定义实现的拦截器加入到UsernamePasswordAuthenticationFilter之前，UsernamePasswordAuthenticationFilter是Spring security中默认最后一个负责认证的拦截器，加入的拦截器负责组装前台提交的账号和密码，将其转换成Authentication。.exceptionHandling().authenticationEntryPoint负责配置认证异常，所有认证抛出的AuthenticationException及其实现都会在这里配置的AuthenticationEntryPointd 的实现类中处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115/** * @author Liush * @description * @date 2019/11/12 16:06 **/@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired private CustomLoginSuccessHandler customLoginSuccessHandler; @Autowired private CustomLoginFailHandler customLoginFailHandler; @Autowired private CustomLogoutSuccessHandler customLogoutSuccessHandler; @Autowired private JWTUtil jwtUtil; @Autowired private SecurityProperties securityProperties; @Autowired private DbUserDetailsService dbUserDetailsService; @Autowired private PasswordProvider passwordProvider; @Autowired private TokenProvider tokenProvider; @Autowired private CustomEntryPointHandler customEntryPointHandler; @Autowired private IdentityUserServiceI identityUserService; @Autowired private RoleAccessDeniedHandler roleAccessDeniedHandler; @Autowired public void configure(AuthenticationManagerBuilder authenticationManagerBuilder) throws Exception &#123; authenticationManagerBuilder.userDetailsService(dbUserDetailsService). passwordEncoder(NoOpPasswordEncoder.getInstance()); authenticationManagerBuilder.authenticationProvider(passwordProvider); authenticationManagerBuilder.authenticationProvider(tokenProvider); &#125; @Bean public RoleAccessSecurityInterceptor roleAccessSecurityInterceptor()&#123; List&lt;AccessDecisionVoter&lt;? extends Object&gt;&gt; voters=new ArrayList&lt;&gt;(); voters.add(new RoleAccessDecisionVoter()); AccessDecisionManager accessDecisionManager=new RoleDecisionManager(voters); RoleMetadataSource roleMetadataSource=new RoleMetadataSource(jwtUtil,identityUserService); return new RoleAccessSecurityInterceptor(securityProperties.getWhiteUrls(),accessDecisionManager,roleMetadataSource); &#125; @Override public void configure(HttpSecurity http) throws Exception &#123; ValidateFilter validateFilter = new ValidateFilter(securityProperties.getLogin_url(),securityProperties.getWhiteUrls(), jwtUtil, customEntryPointHandler); http.addFilterBefore(validateFilter, UsernamePasswordAuthenticationFilter.class) //设置认证异常处理器 .exceptionHandling().authenticationEntryPoint(customEntryPointHandler) //设置鉴权异常处理器 .accessDeniedHandler(roleAccessDeniedHandler) .and() .cors() .and() .csrf().disable(); whiteUrlConfig(http); //设置鉴权拦截器 http.addFilterAfter(roleAccessSecurityInterceptor(),FilterSecurityInterceptor.class); &#125; /** * 白名单配置,调用permitAll方法，此url下的连接可以进入security拦截器，但是不鉴权 */ private void whiteUrlConfig(HttpSecurity http) throws Exception &#123; List&lt;String&gt; whiteUrls= WhiteUrlUtil.createWhiteUrls(securityProperties.getWhiteUrls()); for (String url:whiteUrls)&#123; http.authorizeRequests().antMatchers(url).permitAll(); &#125; http.authorizeRequests().anyRequest().authenticated(); &#125; /* @Override public void configure(HttpSecurity http) throws Exception&#123; http.authorizeRequests().anyRequest().permitAll(); &#125;*/&#125; 鉴权部分鉴权就是对用户可以做什么进行判断 FilterInvocationAPI中给的解释是Holds objects associated with a HTTP filter.意思就是其是保存HTTP过滤器的地方,我们必须在鉴权拦截器中生成FilterInvocation对象，并将FilterInvocation对象传入拦截器链，从而获取http中的信息，因为鉴权很多是和url做关联的，比如什么角色能访问什么url SecurityMetadataSourceAPI中的解释是：提供ConfigAttribute的类实现。 1234567public interface SecurityMetadataSource extends AopInfrastructureBean &#123; Collection&lt;ConfigAttribute&gt; getAttributes(Object var1) throws IllegalArgumentException; Collection&lt;ConfigAttribute&gt; getAllConfigAttributes(); boolean supports(Class&lt;?&gt; var1);&#125; 下面是本人对于这个方法的实现,入参Object var1，是一个FilterInvocation，通过拿到request中的信息，查询到该次请求需要哪些权限（一般是直接获取请求的url，然后去查询这次url访问需要哪些权限），将查询到的需要的权限封装成Collection ，供后续代用 12345678910111213141516@Override public Collection&lt;ConfigAttribute&gt; getAttributes(Object object) throws IllegalArgumentException &#123; HttpServletRequest request = ((FilterInvocation) object).getRequest(); String powerId=request.getHeader(&quot;powerId&quot;); //查询powerId下需要的角色 List&lt;RoleDTO&gt; roles=identityUserService.findRoleByPowerId(powerId); if(roles==null || roles.isEmpty())&#123; throw new AccessDeniedException(&quot;该权限id不存在&quot;); &#125; List&lt;ConfigAttribute&gt; configAttributes=new ArrayList&lt;&gt;(); for(RoleDTO role:roles)&#123; configAttributes.add(new RoleConfigAttribute(role.getAuthority())); &#125; return configAttributes; &#125; ConfigAttributeAPI中的解释:存储与安全系统相关的配置属性 123public interface ConfigAttribute extends Serializable &#123; String getAttribute();&#125; AccessDecisionManagerAPI中的解释:做出最终访问控制（授权）决定。 1234567public interface AccessDecisionManager &#123; void decide(Authentication var1, Object var2, Collection&lt;ConfigAttribute&gt; var3) throws AccessDeniedException, InsufficientAuthenticationException; //判断决策管理器时候支持此属性的验证,关于这两个类的实现可参考Spiring security的默认实现 boolean supports(ConfigAttribute var1); boolean supports(Class&lt;?&gt; var1);&#125; 本人实现,获取AbstractAccessDecisionManager中AccessDecisionVoter，进行投票如果有一个AccessDecisionVoter投票为1说明有权限，如果鉴权失败抛出AccessDeniedException异常，由SpringSecurity统一处理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class RoleDecisionManager extends AbstractAccessDecisionManager &#123; protected RoleDecisionManager(List&lt;AccessDecisionVoter&lt;?&gt;&gt; decisionVoters) &#123; super(decisionVoters); &#125; @Override public void decide(Authentication authentication, Object object, Collection&lt;ConfigAttribute&gt; configAttributes) throws AccessDeniedException, InsufficientAuthenticationException &#123; int deny = -1; //如果等于-1验证失败，如果等于1验证成功 for (AccessDecisionVoter voter : getDecisionVoters()) &#123; int result = voter.vote(authentication, object, configAttributes); switch (result) &#123; //通过验证 case AccessDecisionVoter.ACCESS_GRANTED:&#123; deny=1; break; &#125; //验证失败 case AccessDecisionVoter.ACCESS_DENIED: continue; default: &#125; &#125; if (deny !=1) &#123; throw new AccessDeniedException(&quot;没有权限调用此功能&quot;); &#125; // 如果所有投票者都弃权的话 //checkAllowIfAllAbstainDecisions(); &#125; /** * 被AbstractSecurityInterceptor调用，遍历ConfigAttribute集合，筛选出不支持的attribute */ @Override public boolean supports(ConfigAttribute attribute) &#123; return true; &#125; /** * 被AbstractSecurityInterceptor调用，验证AccessDecisionManager是否支持这个安全对象的类型。 */ @Override public boolean supports(Class&lt;?&gt; clazz) &#123; return true; &#125;&#125; AccessDecisionVoterAPI中的解释:负责对授权决策进行投票 ,int vote(Authentication var1, S var2, Collection var3)如果有权限返回1，没有权限返回-1 1234567891011public interface AccessDecisionVoter&lt;S&gt; &#123; int ACCESS_GRANTED = 1; int ACCESS_ABSTAIN = 0; int ACCESS_DENIED = -1; boolean supports(ConfigAttribute var1); boolean supports(Class&lt;?&gt; var1); int vote(Authentication var1, S var2, Collection&lt;ConfigAttribute&gt; var3);&#125; AbstractSecurityInterceptorAPI中的解释:为安全对象实现安全拦截的抽象类 整体认证逻辑首先我们实现自己的AbstractSecurityInterceptor,在拦截器中生成FilterInvocation对象，调用AbstractSecurityInterceptor的super.beforeInvocation(roleFilterInvocation)完成鉴权 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * @author Liush * @description 鉴权拦截器 * @date 2019/11/17 19:39 **/public class RoleAccessSecurityInterceptor extends AbstractSecurityInterceptor implements Filter &#123; private String whiteUrls; private FilterInvocationSecurityMetadataSource securityMetadataSource; public RoleAccessSecurityInterceptor(String whiteUrls, AccessDecisionManager decisionManager,FilterInvocationSecurityMetadataSource securityMetadataSource) &#123; if(StringUtils.isEmpty(whiteUrls))&#123; whiteUrls= &quot;&quot;; &#125; this.whiteUrls = whiteUrls; super.setAccessDecisionManager(decisionManager); this.securityMetadataSource=securityMetadataSource; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; //查看是否白名单，如果是的话不认证 if(WhiteUrlUtil.isWhite((HttpServletRequest) servletRequest,whiteUrls))&#123; filterChain.doFilter(servletRequest,servletResponse); return; &#125; FilterInvocation roleFilterInvocation=new FilterInvocation(servletRequest,servletResponse,filterChain); InterceptorStatusToken token=super.beforeInvocation(roleFilterInvocation); try&#123; roleFilterInvocation.getChain().doFilter(servletRequest,servletResponse); &#125;finally &#123; super.afterInvocation(token,null); &#125; &#125; @Override public Class&lt;?&gt; getSecureObjectClass() &#123; return FilterInvocation.class; &#125; @Override public SecurityMetadataSource obtainSecurityMetadataSource() &#123; return securityMetadataSource; &#125;&#125; 我们进入super.beforeInvocation(roleFilterInvocation)方法,Collection attributes = this.obtainSecurityMetadataSource().getAttributes(object);此方法调用SecurityMetadataSource来获取，该次调用需要获取什么权限this.authenticateIfRequired()上面文章提到如果之前如果Authenticate的isAuthenticated为false的话会在这里再次鉴权this.accessDecisionManager.decide(authenticated, object, attributes);调用AccessDecisionManager进行鉴权投票,如果没有抛出AccessDeniedException异常则鉴权成功 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162protected InterceptorStatusToken beforeInvocation(Object object) &#123; Assert.notNull(object, &quot;Object was null&quot;); boolean debug = this.logger.isDebugEnabled(); if (!this.getSecureObjectClass().isAssignableFrom(object.getClass())) &#123; throw new IllegalArgumentException(&quot;Security invocation attempted for object &quot; + object.getClass().getName() + &quot; but AbstractSecurityInterceptor only configured to support secure objects of type: &quot; + this.getSecureObjectClass()); &#125; else &#123; Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource().getAttributes(object); if (attributes != null &amp;&amp; !attributes.isEmpty()) &#123; if (debug) &#123; this.logger.debug(&quot;Secure object: &quot; + object + &quot;; Attributes: &quot; + attributes); &#125; if (SecurityContextHolder.getContext().getAuthentication() == null) &#123; this.credentialsNotFound(this.messages.getMessage(&quot;AbstractSecurityInterceptor.authenticationNotFound&quot;, &quot;An Authentication object was not found in the SecurityContext&quot;), object, attributes); &#125; Authentication authenticated = this.authenticateIfRequired(); try &#123; this.accessDecisionManager.decide(authenticated, object, attributes); &#125; catch (AccessDeniedException var7) &#123; this.publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated, var7)); throw var7; &#125; if (debug) &#123; this.logger.debug(&quot;Authorization successful&quot;); &#125; if (this.publishAuthorizationSuccess) &#123; this.publishEvent(new AuthorizedEvent(object, attributes, authenticated)); &#125; Authentication runAs = this.runAsManager.buildRunAs(authenticated, object, attributes); if (runAs == null) &#123; if (debug) &#123; this.logger.debug(&quot;RunAsManager did not change Authentication object&quot;); &#125; return new InterceptorStatusToken(SecurityContextHolder.getContext(), false, attributes, object); &#125; else &#123; if (debug) &#123; this.logger.debug(&quot;Switching to RunAs Authentication: &quot; + runAs); &#125; SecurityContext origCtx = SecurityContextHolder.getContext(); SecurityContextHolder.setContext(SecurityContextHolder.createEmptyContext()); SecurityContextHolder.getContext().setAuthentication(runAs); return new InterceptorStatusToken(origCtx, true, attributes, object); &#125; &#125; else if (this.rejectPublicInvocations) &#123; throw new IllegalArgumentException(&quot;Secure object invocation &quot; + object + &quot; was denied as public invocations are not allowed via this interceptor. This indicates a configuration error because the rejectPublicInvocations property is set to &apos;true&apos;&quot;); &#125; else &#123; if (debug) &#123; this.logger.debug(&quot;Public object - authentication not attempted&quot;); &#125; this.publishEvent(new PublicInvocationEvent(object)); return null; &#125; &#125; &#125; 注意在WebSecurityConfigurerAdapter配置类下配置的白名单http.authorizeRequests().antMatchers(url).permitAll(),这里配置的url仍然会进入拦截器，所以我在进入拦截器前先会去查找白名单，如果是白名单直接跳过拦截器]]></content>
      <categories>
        <category>Spring security</category>
      </categories>
      <tags>
        <tag>Spring security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用mysqlbinlog和mysql日志恢复数据]]></title>
    <url>%2F2019%2F11%2F07%2F%E4%BD%BF%E7%94%A8mysqlbinlog%E5%92%8Cmysql%E6%97%A5%E5%BF%97%E6%81%A2%E5%A4%8D%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[简介有时候我们会误删mysql中的数据，如果有开启binlog日志，那么我们可以通过mysql提供的mysqlbinlog工具来读取出操作日志，并且重新执行操作日志达到恢复数据的效果 备份我们通常会在数据达到一个节点去备份一次数据库使用mysqldump工具可以完成备份,以下输出的备份中会包含当前备份所指向的日志文件和日志position，这个是我们恢复日志的关键 1/usr/bin/mysqldump --single-transaction --master-data=2 -u root -p -A&gt;/mysql/qwe.sql 查看日志事件执行以下语句，把对应的日志换成自己mysql的日志文件的名字，可以查看到该文件的日志详情，其中Pos字段表示执行语句的开始positon，end_log_position表示改语句执行结束时的position，如果是从备份中恢复数据，那么这里要对应上备份sql文件中的position，找到需要恢复数据的日志positon 1show BINLOG EVENTS in &apos;mysql-bin.000004&apos; 回放日志内容以下语句将需要回放日志的开始position和结束position输入，并且传入对应的日志文件，并将结果输出到一个文件中 1mysqlbinlog --start-position 1487 --stop-position 2207 /var/lib/mysql/mysql-bin.000004&gt; /liu/mysql/ppp.sql 重新执行语句恢复数据将上一步导出的日志操作步骤导入mysql中重新执行，即可完成数据恢复 1mysql -u root -p&lt;/liu/mysql/ppp.sql]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysqlbinlog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql不停机主备复制]]></title>
    <url>%2F2019%2F11%2F06%2Fmysql%E4%B8%8D%E5%81%9C%E6%9C%BA%E4%B8%BB%E5%A4%87%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[简介之前在网上找到的关于主备节点的同步数据大多是要在主节点停机或者限制写入，然后将数据拷贝到从节点，然后再进行主从节点的日志同步，其实mysql下提供了mysqldump工具可以在不停机下进行主从数据的同步，将主节点的数据复制到从节点，即使这时候主节点仍在写入数据，将数据导入到从节点后，再将从节点的binlog日志节点指向拷贝主节点数据时的binlog日志位置，最后再由系统追上主节点的数据进度。 搭建主备如何搭建主备参考hive分类下的—hive mysql元数据表单的主从备份这篇文章 导出主库数据 single-transaction保证在innodb引擎下导出数据的一致性 master-data=2表示在导出的文件中现实binlog的名字和position，后续在从节点中根据这里的参数指向主节点的binlog日志 -A表示导出所有数据库，一般导出所有数据库。1/usr/bin/mysqldump --single-transaction --master-data=2 -u root -p -A&gt;/mysql/qwe.sql 关于mysqldump的用法参考 https://www.centos.bz/2018/02/mysqldump-%E5%8F%82%E6%95%B0%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D/ 模拟主从不一致我们需要手动同步主备数据往往就是因为数据库出现异常，导致主从节点数据不一样，这里我们模型主从数据库不一致的情况，然后将主库数据导入到备库中 停止从库 1stop SLAVE 将主库数据导入到从库，qwe.sql是之前主库中导出的数据 1mysql -u root -p&lt;qwe.sql 导入成功后主从的数据已经一致 我们在主库中随意插入几条数据，由于未开启同步，从库中并没有同步新插入的数据，这里模拟了主从数据不同步的问题，在线数据迁移中往往会出现这个问题，在备份过程中，又有新的数据插入到数据库中 开启从节点同步 首先查看我们之前导出的sql数据的binlog的位置和postion 1head -n 30 qwe.sql 查看到如下数据 1-- CHANGE MASTER TO MASTER_LOG_FILE=&apos;mysql-bin.000004&apos;, MASTER_LOG_POS=785; 查看主节点的binlog 1show master status 发现其binlog位置已经和导出数据时发生了改变 1mysql-bin.000004 1410 将从节点的binlog指向主节点 注意我们在这里使用的是导出数据时候的binlog，也就是导出sql里显示的binlog 12change master to master_host=&apos;192.168.1.10&apos;, master_user=&apos;slave&apos;, master_password=&apos;mysql&apos;, master_log_file=&apos;mysql-bin.000004&apos;, master_log_pos=785; 开启从节点同步 1start slave; 执行以下语句，发现现在主从的binlog已经同步，查询从库数据发现已经存在之前插入的数据 1show slave status; 问题 最好保证主从数据库版本的一致，至少主库的数据库版本要大于从库的版本]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>主从备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[平衡内存和磁盘资源]]></title>
    <url>%2F2019%2F11%2F04%2F%E5%B9%B3%E8%A1%A1%E5%86%85%E5%AD%98%E5%92%8C%E7%A3%81%E7%9B%98%E8%B5%84%E6%BA%90%2F</url>
    <content type="text"><![CDATA[简介在项目中往往应用内存来做缓存，这样做是为了避免磁盘I/O，特别是随机磁盘I/O，这里梳理了磁盘的基础知识，和mysql 如何避免磁盘随机I/O 磁盘的物理结构硬盘内部主要部件为磁盘盘片、传动手臂、读写磁头和主轴马达。实际数据都是写在盘片上，读写主要是通过传动手臂上的读写磁头来完成。实际运行时，主轴让磁盘盘片转动，然后传动手臂可伸展让读取头在盘片上进行读写操作。磁盘物理结构如下图所示：、 由于单一盘片容量有限，一般硬盘都有两张以上的盘片，每个盘片有两面，都可记录信息，所以一张盘片对应着两个磁头。盘片被分为许多扇形的区域，每个区域叫一个扇区，硬盘中每个扇区的大小固定为512字节。盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用。磁盘盘片垂直视角如下图所示： 影响硬盘性能的因素寻道时间Tseek是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在3-15ms。 旋转延迟Trotation是指盘片旋转将请求数据所在的扇区移动到读写磁盘下方所需要的时间。旋转延迟取决于磁盘转速，通常用磁盘旋转一周所需时间的1/2表示。比如：7200rpm的磁盘平均旋转延迟大约为60*1000/7200/2 = 4.17ms，而转速为15000rpm的磁盘其平均旋转延迟为2ms。 数据传输时间Ttransfer是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。目前IDE/ATA能达到133MB/s，SATA II可达到300MB/s的接口数据传输率，数据传输时间通常远小于前两部分消耗时间。简单计算时可忽略。 衡量性能的指标机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是IOPS和吞吐量。 IOPSIOPS（Input/Output Per Second）即每秒的输入输出量（或读写次数），即指每秒内系统能处理的I/O请求数量。随机读写频繁的应用，如小文件存储等，关注随机读写性能，IOPS是关键衡量指标。可以推算出磁盘的IOPS = 1000ms / (Tseek + Trotation + Transfer)，如果忽略数据传输时间，理论上可以计算出随机读写最大的IOPS。常见磁盘的随机读写最大IOPS为： 7200rpm的磁盘 IOPS = 76 IOPS 10000rpm的磁盘IOPS = 111 IOPS 15000rpm的磁盘IOPS = 166 IOPS 吞吐量吞吐量（Throughput），指单位时间内可以成功传输的数据数量。顺序读写频繁的应用，如视频点播，关注连续读写性能、数据吞吐量是关键衡量指标。它主要取决于磁盘阵列的架构，通道的大小以及磁盘的个数。不同的磁盘阵列存在不同的架构，但他们都有自己的内部带宽，一般情况下，内部带宽都设计足够充足，不会存在瓶颈。磁盘阵列与服务器之间的数据通道对吞吐量影响很大，比如一个2Gbps的光纤通道，其所能支撑的最大流量仅为250MB/s。最后，当前面的瓶颈都不再存在时，硬盘越多的情况下吞吐量越大。 平和内存和磁盘资源配置大量内存最大的原因其实不是因为可以在内存中保存大量数据:最终目的是避免磁盘I/O，因为磁盘I/O比在内存中访问数据要慢的多，计算机包含一个金字塔型的缓存体系，更小，更快更昂贵的缓存在顶端，如图 在这个高速缓存层次中，最好是利用各级缓存来存放热点数据，以获取更快的访问速度，通常使用一些启发式的方法，如最近被使用的数据很可能会很快的再次使用，以及相邻的数据可能很快需要使用。设计良好的数据库缓存（如innoDB缓冲池），其效率通常超过操作系统的缓存，因为操作系统的缓存是为通用任务设计的，数据库缓存更了解数据库存储的需求，它包含特殊的用途和逻辑(例如写入顺序)一帮助满足这些需求。 随机I/O和顺序I/O数据库服务器同事使用顺序I/O和随机I/O，随机I/O从缓存中受益最多,因为缓存这些数据将有助于避免昂贵的磁盘寻道，相反顺序读取一般只需要扫描一次数据，所以缓存对它是没用的，除非能完全放在内存中缓存起来。 顺序读取不能从缓中受益另一个原因是它们比随机读取快，有以下两个原因： 顺序I/O比随机I/O快 顺序操作的执行速度比随机操作快，无论是在内存还是在磁盘上。假设磁盘每秒可以做100个随机I/O操作，并且可以完成每秒50M的顺序读取（在大概是消费级磁盘现在能达到的水平）。如果每行100字节，随机读取可以每秒读取100行，相比之下顺序读取可以读取每秒500000行这个是随机读取的5000倍，或几个数量级的差异，因此这种情况下随机I/O可以从缓冲中获得很多好处。（注：因为随机读取受到IOPS的限制—100个随机I/O，而顺序读取受到吞吐量的限制—这里是每秒50M） 顺序访问内存行的数据也快于随机访问。现在的内存芯片通常每秒可以随机访问约250000次100字节的行，或者每秒500万次的顺序访问。请注意，内存随机访问速度比磁盘随机访问快了2500倍，而内存中顺序访问通常只有磁盘的10倍的数据。 存储引擎执行顺序读取比随机快 一个随机读取一般意味着存储引擎必须执行索引操作，通常需要通过B树的数据结构查找，并且和其它值比较（innoDB中如果不是覆盖索引则需要回表查询主键索引的B树查询全部数据）。相反，连续读取一般需要遍历一个简单的数据结构，如链表。这样就少了很多工作，反复这样操作，连续读取的速度就比随机读取要快了。 最后随机读取通常只要查找特定的行，但不仅仅只读取一样–而是要读取一整页的数据(因为页数数据再磁盘中存储的最小单位，innodbDB中也可以配置相应的最小页的大小)，其中大部分都是不需要的，这浪费了很多工作。另一方方面，顺序读取数据，通常发生在想要的页面上的所有行，所以更符合成本效益。 缓存，读和写 如果有足够的内存，就完全可以避免磁盘读取请求，如果所有数据文件都可以放在内存中，一旦服务器缓存热起来，所有读取都可以在缓存中命中，虽然有逻辑读取，但是物理读取就没有了。但是写入是不同的问题，写入可以像读一样在内存中完成，但是迟早要写入到磁盘中，所以它需要持久化，换一句话说，缓存可以延迟写入，但是不能像消除读取一样消除写入。 主要通过以下两个方法解决 多次写入，一次刷新 一片数据可以在内存中改变很多次，而不需要吧所有新值写到磁盘，当数据最终被刷新到磁盘后，最后一次物理写入之前发生的所有修改都被持久化了，例如许多语句可以更新内存中的计数器，如果计数器递增100次，然后写入磁盘，100次修改就被合并成一次写入。 I/O合并 许多不同部分的数据可以在内存中修改，并且这些修改可以合并在一起，通过一次磁盘操作完成物理写入。 这就是为什么许多交易系统使用预写日志(WAL)策略。预写日志采用在内存中变更页面，而不是马上刷新到磁盘上的策略，因为刷新磁盘通常需要随机I/O，这非常慢。相反，如果吧变化记录写到一个连续的日志文件中，这就很快了。后台线程可以稍后把修改的页面刷新到磁盘，并且在刷新过程中优化写操作，写入操作从缓冲中受益很大，因为它把随机I/O更多的转换到连续I/O.（注：innodb的事务日志就是这样做的，innodb用日志把随机I/O变为顺序I/O，每次事务的变化将其顺序的写入到日志文件中，后续再由后台进程将数据写入到数据文件中）。 参考资料 高性能Mysql https://tech.meituan.com/2017/05/19/about-desk-io.html]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>磁盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[innoDB的缓冲池和事务日志(为什么innoDB无法存储大数据)]]></title>
    <url>%2F2019%2F10%2F21%2FinnoDB%E7%9A%84%E7%BC%93%E5%86%B2%E6%B1%A0%E5%92%8C%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[简介mysql的innoDB存储引擎提供了缓冲池innodb_buffer_pool_size来设置缓冲池的大小，其可以缓存索引，行数据，自适应哈希索引，插入缓冲等数据，InnoDB还使用缓冲池来帮助延迟写入，这样就能合并多个写入操作，然后一起顺序地回写。之前与另一个配置query_cache_size混淆，query_cache_size在8.0中已经废除，因为如果查询缓存中使用了很大的内存，缓存失效操作会成为一个严重的问题瓶颈导致系统僵死一会(更新表中的数据会导致该表的缓存失效)，因为这个操作是靠一个全局锁保护的，所有需要该操作的查询都要等待这个锁，而且无论是检测是否命中缓存，还是缓存失效检测都需要等待这个全局锁。以下是网上找的对于这两个缓存的定义. Qcacche缓存的是SQL语句及对应的结果集，缓存在内存，最简单的情况是SQL一直不重复，那Qcache的命令率肯定是0 buffer pool中缓存的是整张表中的数据，缓存在内存，SQL再变只要数据都在内存，那么命中率就是100%。 事务日志事务修改的数据和索引通常会映射到表空间的随机位置，这导致大量随机I/O，对机械硬盘来说，随机I/O伴随着磁盘大量寻址操作。InnoDB使用日志把随机I/O变成顺序I/O，一旦日志安全写到磁盘，事务就持久化了，即使变更的数据还没写入到数据文件，一旦系统发生崩溃，InnoDB可以重放日志并且恢复已经提交的事务，当然InnoDB最后必须把日志里的变更数据写入到数据文件当中，因为日志有固定大小。可以通过innodb_log_file_size来设置日志文件大小，在8.0中默认是48M，对于高性能工作来说这太小，至少需要几百M，还有一种说法是能存储1-2个小时的时间. innodb_buffer_pool_size的大小设置缓冲池一般设置为服务器内存的75%-80%(前提是该服务器只部署mysql，如果还部署其它应用需扣除其它应用使用的内存) 大innodb_log_file_size和innodb_buffer_pool_size导致的问题数据大小和访问模式也将影响恢复时间。假设有一个1TB的数据和16G的缓冲池，并且日志大小是128M，如果缓冲池里有很多脏页(例如数据写入了日志文件，但是没有写入数据文件),并且这些数据均匀的分布在1TB数据中，系统崩溃后恢复将需要相当长的一段时间，InnoDB必须从头到尾扫描日志，检查数据文件，并且将事务日志中的数据写到数据文件当中。 日志缓冲刷新到持久化系统（innodb_flush_log_at_trx_commit）当InnoDB变更任何数据时，会写入一条变更记录到内存的日志缓冲区，在缓冲满的时候，或者每一秒中，或者事务提交时—-无论上述三个条件哪个先到，日志缓冲区默认1M，通过innodb_log_buffer_size配置，如果有大事务，将其配置大一些可以帮助减少磁盘I/O，通常不需要设置的很大1M-9M即可。 innodb_flush_log_at_trx_commit有3个值 0：把日志缓冲写到日志文件，并且每秒刷新一次 1: 将日志缓冲写到日志文件，并且每次事务提交都刷新到持久化系统，这是默认的，并且是最安全的，该设置保证不会丢失任何已经提交的事务，除非磁盘或者系统是伪刷新。 2：每次提交时把日志缓冲写到日志文件，但是不刷新，InnoDB每秒刷新一次。0和2的区别是如果mysql挂了，2不会丢失任何事务，因为2会自动刷新缓存到日志文件在事务提交的时候，但是如果整个服务挂了，则还是可能会丢失一部分事务。这个很好理解，如果我提交了事务，数据已经写入了日志文件所以不会丢失，但是缓存区里未提交的事务，且时间还没到1秒，则会丢失这一秒的数据 因此如果设置0或者2另一个以mysql崩溃或者断电会导致最多丢失一秒的数据。 (innodb怎样打开和刷新日志文件和数据文件)innodb_flush_method这个配置既影响日志文件，也影响数据文件 将innodb_flush_method设置为O_DIRECT以避免双重缓冲.唯一一种情况你不应该使用O_DIRECT是当你操作系统不支持时。但如果你运行的是Linux，使用O_DIRECT来激活直接IO。不用直接IO，双重缓冲将会发生，因为所有的数据库更改首先会写入到OS缓存然后才同步到硬盘 – 所以InnoDB缓冲池和OS缓存会同时持有一份相同的数据。特别是如果你的缓冲池限制为总内存的50%，那意味着在写密集的环境中你可能会浪费高达50%的内存。如果没有限制为50%，服务器可能由于OS缓存的高压力会使用到swap。简单地说，设置为innodb_flush_method=O_DIRECT。 以下是InnoDB的缓存和文件的流程图 Buffer pool中将变更写入Log Buffer，Log Buffer将数据写入事务日志文件，InnoDB使用一个后台线程智能的刷新这些变更到数据文件，实际上，事务日志把数据文件的随机I/O转换成为几乎顺序的日志文件和数据文件I/O。把刷新操作转移到后台使查询可以更快完成,并且缓和查询高峰时I/O系统的压力，这个也很好理解，数据更新后将数据存放在Buffer pool中为了保证数据不丢失，并且降低I/O损耗采用日志顺序I/O记录这些变更，在系统崩溃时采用日志恢复，并且后台定时将日志文件刷新到数据文件，查询缓存直接查询Buffer pool中的数据即可。 为什么innoDB无法存储大数据量说白了主要就是innodb_buffer_pool_size缓存不够引起的原因 缓存池可以被认为一条长LRU链表，该链表又分为2个子链表，一个子链表存放old pages(里面存放的是长时间未被访问的数据页)，另一个子链接存放new pages（里面存放的是最近被访问的数据页面）。old pages 默认占整个列表大小的37%（这个值对应my.conf 的 innoDB_old_blocks_pct 参数的默认值为37，取值范围是5~95），其余为new pages占用。 如图下图所示。靠近LRU链表头部的数据页表示最近被访问，靠近LRU链表尾部的数据页表示长时间未被访问，而这两个部分交汇处成为midpoint。 当系统查询数据时当innodb_buffer_pool_size已满时会将排在old pages中的数据挤出缓存，导致innodb_buffer_pool中找不到查询数据，导致磁盘的I/O操作。 另外请参考https://www.cnblogs.com/leefreeman/p/8315844.html 参考资料高性能Mysql https://www.centos.bz/2016/11/mysql-performance-tuning-15-config-item/ http://xiaorui.cc/2016/12/08/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%BB%BA%E8%AE%AEinnodb%E4%BD%BF%E7%94%A8%E4%BA%BF%E7%BA%A7%E5%A4%A7%E8%A1%A8/ https://www.cnblogs.com/leefreeman/p/8315844.html]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>innoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务简介]]></title>
    <url>%2F2019%2F10%2F17%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[简介数据库事务需要满足ACID（原子性、一致性、隔离性、持久性）四个特性。 原子性（Atomicity）指事务作为整体来执行，要么全部执行，要么全不执行。 一致性（Consistency）指事务应确保数据从一个一致的状态转变为另一个一致的状态。 隔离性（Isolation）指多个事务并发执行时，一个事务的执行不应影响其他事务的执行。 持久性（Durability）指已提交的事务修改数据会被持久保存。 在单一数据节点中，事务仅限于对单一数据库资源的访问控制，称之为本地事务。几乎所有的成熟的关系型数据库都提供了对本地事务的原生支持。 但是在基于微服务的分布式应用环境下，越来越多的应用场景要求对多个服务的访问及其相对应的多个数据库资源能纳入到同一个事务当中，分布式事务应运而生。 关系型数据库虽然对本地事务提供了完美的ACID原生支持。 但在分布式的场景下，它却成为系统性能的桎梏。如何让数据库在分布式场景下满足ACID的特性或找寻相应的替代方案，是分布式事务的重点工作。 本地事务在不开启任何分布式事务管理器的前提下，让每个数据节点各自管理自己的事务。 它们之间没有协调以及通信的能力，也并不互相知晓其他数据节点事务的成功与否。 本地事务在性能方面无任何损耗，但在强一致性以及最终一致性方面则力不从心。 现在模拟一个业务场景，游戏的道具交易系统，系统分为金币洗系统和道具系统两个部分，购买道具时先需要扣除金币，然后才能获取道具，采用单数据库的本地事务的流程如下图,所有的事务都在单库中进行，不设计分布式事务，由数据库自身提供的事务功能去保证数据的一致性 分布式事务XAX/Open 组织（即现在的 Open Group ）定义了分布式事务处理模型。 X/Open DTP 模型（ 1994 ）包括应用程序（ AP ）、事务管理器（ TM ）、资源管理器（ RM ）、通信资源管理器（ CRM ）四部分。一般，常见的事务管理器（ TM ）是交易中间件，常见的资源管理器（ RM ）是数据库，常见的通信资源管理器（ CRM ）是消息中间件。 通常把一个数据库内部的事务处理，如对多个表的操作，作为本地事务看待。数据库的事务处理对象是本地事务，而分布式事务处理的对象是全局事务。 所谓全局事务，是指分布式事务处理环境中，多个数据库可能需要共同完成一个工作，这个工作即是一个全局事务，例如，一个事务中可能更新几个不同的数据库。对数据库的操作发生在系统的各处但必须全部被提交或回滚。此时一个数据库对自己内部所做操作的提交不仅依赖本身操作是否成功，还要依赖与全局事务相关的其它数据库的操作是否成功，如果任一数据库的任一操作失败，则参与此事务的所有数据库所做的所有操作都必须回滚。 一般情况下，某一数据库无法知道其它数据库在做什么，因此，在一个 DTP 环境中，交易中间件是必需的，由它通知和协调相关数据库的提交或回滚。而一个数据库只将其自己所做的操作（可恢复）影射到全局事务中。 XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。 二阶提交协议和三阶提交协议就是根据这一思想衍生出来的。可以说二阶段提交其实就是实现XA分布式事务的关键(确切地说：两阶段提交主要保证了分布式事务的原子性：即所有结点要么全做要么全不做) XA的刚性实现二阶段提交是XA的标准实现。它将分布式事务的提交拆分为2个阶段：prepare和commit/rollback。 开启XA全局事务后，所有子事务会按照本地默认的隔离级别锁定资源，并记录undo和redo日志，然后由TM发起prepare投票，询问所有的子事务是否可以进行提交：当所有子事务反馈的结果为“yes”时，TM再发起commit；若其中任何一个子事务反馈的结果为“no”，TM则发起rollback；如果在prepare阶段的反馈结果为yes，而commit的过程中出现宕机等异常时，则在节点服务重启后，可根据XA recover再次进行commit补偿，以保证数据的一致性。 2PC模型中，在prepare阶段需要等待所有参与子事务的反馈，因此可能造成数据库资源锁定时间过长，不适合并发高以及子事务生命周长较长的业务场景。 Sharding-Sphere支持基于XA的强一致性事务解决方案，可以通过SPI注入不同的第三方组件作为事务管理器实现XA协议，如Atomikos和Narayana。 XA 协议它依赖的是数据库层面来保障事务的一致性，也即是说 XA 的各个分支事务是在数据库层面上驱动的，由于 XA 的各个分支事务需要有 XA 的驱动程序，一方面会导致数据库与 XA 驱动耦合，另一方面它会导致各个分支的事务资源锁定周期长，这也是它没有在互联网公司流行的重要因素。 XA的柔性实现柔性实现牺牲了数据的一致性，在刚性实现中，所有节点在完成提交确认时都需要锁定数据库资源，这样在网络不稳定，或者节点故障时很容易发生死锁，或者等待锁资源过长，因此柔性实现中，采用最终一致性原则，先提交，并将执行数据写入日志，如果发现其它节点发生故障，则根据日志回滚数据即可。 2PC二阶段提交(Two-phaseCommit)是指，在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提交也被称为是一种协议(Protocol))。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。 准备阶段 事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。 可以进一步将准备阶段分为以下三个步骤： 协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作 各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。 提交阶段如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源) 接下来分两种情况分别讨论提交阶段的过程。 当协调者节点从所有参与者节点获得的相应消息都为”同意”时: 协调者节点向所有参与者节点发出”正式提交(commit)”的请求。 参与者节点正式完成操作，并释放在整个事务期间内占用的资源。 参与者节点向协调者节点发送”完成”消息。 协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。 如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时： 协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求。 参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。 参与者节点向协调者节点发送”回滚完成”消息。 协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务。 二阶段提交看起来确实能够提供原子性的操作，但是不幸的事，二阶段提交还是有几个缺点的： 同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。 单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题） 数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。 二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。 3pc由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷，所以，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。 三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。 与两阶段提交不同的是，三阶段提交有两个改动点。 引入超时机制。同时在协调者和参与者中都引入超时机制。 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。 也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。 CanCommit阶段 3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。 事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。 响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No PreCommit阶段 协调者根据参与者的反应情况来决定是否可以继续事务的PreCommit操作。根据响应情况，有以下两种可能。 假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。 发送预提交请求 协调者向参与者发送PreCommit请求，并进入Prepared阶段。 事务预提交 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。 响应反馈 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。 假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。 发送中断请求 协调者向所有参与者发送abort请求。 中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。 doCommit阶段该阶段进行真正的事务提交，也可以分为以下两种情况。 执行提交 发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。 事务提交 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。 响应反馈 事务提交完之后，向协调者发送Ack响应。 完成事务 协调者接收到所有参与者的ack响应之后，完成事务。 中断事务 协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。 发送中断请求 协调者向所有参与者发送abort请求 事务回滚 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。 反馈结果 参与者完成事务回滚之后，向协调者发送ACK消息 中断事务 协调者接收到参与者反馈的ACK消息之后，执行事务的中断。 在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。 ） 2PC与3PC的区别相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。 柔性事务的理论基础-BASE理论柔性事务是对XA协议的妥协和补偿，它通过对强一致性要求的降低，已达到降低数据库资源锁定时间的效果。 BASE是对CAP中一致性和可用性权衡的结果，其核心思想是即使无法做到强一致性，但每个应用都可以根据自身的业务特点，采用适当的方法来使系统达到最终一致性。 基本可用（Basically Available） 基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性 响应时间上的损失：正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加到了1-2秒。功能上的损失：在一个电子商务网站上进行购物，消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 软状态（Soft state） 软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 最终一致性（Eventually consistent） 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 柔性事务的实现 补偿型 TCC（Try/Confirm/Cancel）型事务。在一个长事务中，一个由两台服务器一起参与的事务，服务器A发起事务，服务器B参与事务，B的事务需要人工参与，所以处理时间可能很长。如果按照ACID的原则，要保持事务的隔离性、一致性，服务器A中发起的事务中使用到的事务资源将会被锁定，不允许其他应用访问到事务过程中的中间结果，直到整个事务被提交或者回滚。这就造成事务A中的资源被长时间锁定，系统的可用性将不可接受。WS-BusinessActivity提供了一种基于补偿的long-running的事务处理模型。还是上面的例子，服务器A的事务如果执行顺利，那么事务A就先行提交，如果事务B也执行顺利，则事务B也提交，整个事务就算完成。但是如果事务B执行失败，事务B本身回滚，这时事务A已经被提交，所以需要执行一个补偿操作，将已经提交的事务A执行的操作作反操作，恢复到未执行前事务A的状态。这样的SAGA事务模型，是牺牲了一定的隔离性和一致性的，但是提高了long-running事务的可用性。 异步确保型 将一些同步阻塞的事务操作变为异步的操作，避免对数据库事务的争用。比如热点资源的批量更新、异步更新的处理,比如上述交易系统，先扣除金币后往队列中道具系统发送增加道具通知。 最大努力型 通过通知服务器（消息通知）进行，允许失败，有补偿机制（或重发机制）。 参考资料https://shardingsphere.apache.org/document/current/cn/features/transaction/concept/2pc-xa-transaction/ http://www.hollischuang.com/archives/681 https://www.jianshu.com/p/d70df89665b9]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>分布式事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的缓慢日志]]></title>
    <url>%2F2019%2F10%2F15%2Fmysql%E7%9A%84%E7%BC%93%E6%85%A2%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[简介mysql有4种日志，分别为错误日志，一般查询日志，慢查询日志，二进制日志 错误日志错误日志是最重要的日志之一，它记录了MySQL服务启动和停止正确和错误的信息，还记录了mysqld实例运行过程中发生的错误事件信息，mysql默认开启，在my.cnf中log-error=/var/log/mysqld.log 配置对应错误日志的位置。 一般查询日志一般查询日志，记录所有操作记录都记录在日志中，默认不开启，一般也不建议开启，这样会造成I/O等资源的浪费，对于查询分析我们开源开启慢查询日志。 二进制日志二进制日志包含了引起或可能引起数据库改变(如delete语句但没有匹配行)的事件信息，但绝不会包括select和show这样的查询语句。语句以”事件”的形式保存，所以包含了时间、事件开始和结束位置等信息。mysql中主从同步采用二进制日志来进行同步，由my.cnflog-bin来控制,具体配置可查看hive分类中的hive主从配置这篇文章 慢查询日志查询超出变量 long_query_time 指定时间值的为慢查询。但是查询获取锁(包括锁等待)的时间不计入查询时间内。mysql记录慢查询日志是在查询执行完毕且已经完全释放锁之后才记录的，因此慢查询日志记录的顺序和执行的SQL查询语句顺序可能会不一致(例如语句1先执行，查询速度慢，语句2后执行，但查询速度快，则语句2先记录) 慢查询日志配置 在my.cnf中 12345678#是否启用慢日志slow_query_log=ON#慢日志文件的路径slow_query_log_file=/var/log/mysql-slow.log#指定慢查询超时时长(默认10秒)，超出此时长的属于慢查询long_query_time=0.5#没有使用索引时候记录慢日志log_queries_not_using_indexes=OFF 慢语句分析当初的慢日志文件如下,记录着查询时间，锁时间，和执行的记录 123456789101112131415/usr/sbin/mysqld, Version: 8.0.17 (MySQL Community Server - GPL). started with:Tcp port: 0 Unix socket: /var/lib/mysql/mysql.sockTime Id Command Argument# Time: 2019-10-15T03:47:35.922001Z# User@Host: root[root] @ [192.168.169.58] Id: 8# Query_time: 2.061037 Lock_time: 0.000320 Rows_sent: 712182 Rows_examined: 712182use test;SET timestamp=1571111253;SELECT * FROM d_area;# Time: 2019-10-15T03:48:16.302963Z# User@Host: root[root] @ [192.168.169.58] Id: 8# Query_time: 1.250141 Lock_time: 0.000096 Rows_sent: 712182 Rows_examined: 712182SET timestamp=1571111295;SELECT * FROM d_area; 这样查询日志很不直观，mysql提供了mysqldumpslow来查看缓慢日志,用法如下 1234567891011121314151617181920mysqldumpslow -s [Parameter] -t [Parameter] 缓慢日志路径参数-s : 排序方式c：query执行的次数t：sql执行的时间l：lock锁表的时间r：sql返回的行数-t： top，返回前n条数据-g： 正则匹配，大小写不敏感返回执行时间最长的前两个querymysqldumpslow -s t -t 2 /var/log/mysql-slow.log显示执行次数最多的前两个querymysqldumpslow -s c -t 2 /var/log/mysql-slow.log返回按照时间排序的前10条里面含有左连接的查询语句mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/log/mysql-slow.log 执行 1mysqldumpslow -s t -t 2 /var/log/mysql-slow.log 结果如下 123456Reading mysql slow query log from /var/log/mysql-slow.logCount: 2 Time=1.66s (3s) Lock=0.00s (0s) Rows=712182.0 (1424364), root[root]@[192.168.169.58] SELECT * FROM d_areaCount: 2 Time=0.64s (1s) Lock=0.00s (0s) Rows=61757.5 (123515), root[root]@[192.168.169.58] SELECT * FROM d_area where province_ like &apos;S&apos; or town_ like &apos;S&apos; 注意配置的slow_query_log_file（慢日志路径）的文件，mysql账号需要有读写权限执行 1chown mysql:mysql /路径 否则查询 ,语句状态一直未on 1show variables like &apos;%slow_query_log%&apos;; 设置会话基本缓慢日志以上设置的缓慢日志，或者当缓慢日志过大清理时，需要重启数据库，但是在生产环境中是不允许这样做的，所以我们采用SET变量的方法去设置缓慢日志。 关闭缓慢日志服务 1set global slow_query_log=OFF; 查看缓慢日志时候关闭 1show variables like &apos;%slow%&apos;; 迁移缓慢日志 1直接用linux mv命令或者其它方法迁移缓慢日志 重新设置缓慢日志路径 1set global slow_query_log_file=&apos;/路径&apos;; 重新开启缓慢日志 1set global slow_query_log=ON; 实际操作方案实际生产环境中可以采用上述方案，每天编写脚本完成缓慢日志迁移.]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql缓慢日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式唯一id(数据库主键):snowflake算法]]></title>
    <url>%2F2019%2F10%2F14%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%94%AF%E4%B8%80id-snowflake%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[简介项目中大家喜欢用java自带的UUID工具类去生成唯一的数据库主键，这样做的原因是简单。但mysql的innodb存储引擎的主键是聚簇索引（一种索引类型，数据与索引数据放在一起），既然数据和索引数据放在一起，那么在数据插入或者更新的时候，那么在数据插入或者更新的时候，我们需要找到要插入的位置，再把数据写到特定的位置上，这就产生了随机的 IO，而innodb存储引擎采用的是B+树的结果存储索引，一旦发生了页分裂，就不可避免会做数据的移动，也会极大地损耗写入性能,但是如果使用mysql的自增，则在分库分表下无法保证主键id的唯一性，因此我们采用twitter的snowflake算法来生成分布式的唯一id。 snowflake算法snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。41为的时间戳大概可以生成69年((2^41)/1000/60/60/24/365),10bit的工作机器id可以支持1024(2^10)台机器，序列号支持1毫秒产生4096(2^12)个自增序列id 算法java实现Twitter在github上提供了scala的实现版本,以下版本是根据scala转换成java的版本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package com.liu;public class IdWorker&#123; private long workerId; private long datacenterId; private long sequence; //开始时间,比如我想从2000-1-1开始生成日期就填入2000-1-1的时间 private long twepoch = 1288834974657L; /** * * @param workerId 机器id(占用5比特，最大为31) * @param datacenterId 机房id（占用5比特） * @param sequence (12位序列号起始编号) * long twepoch 参数开始时间,比如我想从2000-1-1开始生成日期就填入2000-1-1的时间 */ public IdWorker(long workerId, long datacenterId, long sequence)&#123; // sanity check for workerId if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;worker Id can&apos;t be greater than %d or less than 0&quot;,maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;datacenter Id can&apos;t be greater than %d or less than 0&quot;,maxDatacenterId)); &#125; System.out.printf(&quot;worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d&quot;, timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId); this.workerId = workerId; this.datacenterId = datacenterId; this.sequence = sequence; &#125; private long workerIdBits = 5L; private long datacenterIdBits = 5L; private long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); private long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); private long sequenceBits = 12L; private long workerIdShift = sequenceBits; private long datacenterIdShift = sequenceBits + workerIdBits; private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; private long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); private long lastTimestamp = -1L; public long getWorkerId()&#123; return workerId; &#125; public long getDatacenterId()&#123; return datacenterId; &#125; public long getTimestamp()&#123; return System.currentTimeMillis(); &#125; public synchronized long nextId() &#123; long timestamp = timeGen(); if (timestamp &lt; lastTimestamp) &#123; System.err.printf(&quot;clock is moving backwards. Rejecting requests until %d.&quot;, lastTimestamp); throw new RuntimeException(String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp)); &#125; if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; if (sequence == 0) &#123; timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123; sequence = 0; &#125; lastTimestamp = timestamp; return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift) | (workerId &lt;&lt; workerIdShift) | sequence; &#125; private long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; private long timeGen()&#123; return System.currentTimeMillis(); &#125; //---------------测试--------------- public static void main(String[] args) &#123; IdWorker worker = new IdWorker(3,1,1); for (int i = 0; i &lt; 30; i++) &#123; System.out.println(worker.nextId()); &#125; &#125;&#125;]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>snowflake</tag>
        <tag>唯一id</tag>
        <tag>数据库主键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用sharding-jdbc实现mysql的分库分表并主从读写分离]]></title>
    <url>%2F2019%2F10%2F14%2F%E4%BD%BF%E7%94%A8sharding-jdbc%E5%AE%9E%E7%8E%B0mysql%E7%9A%84%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%B9%B6%E4%B8%BB%E4%BB%8E%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[简介之前的文章中提到了使用sharding-jdbc进行读写分离和分库分表，本文将使用sharding-jdbc并且使用-《使用sharding-jdbc实现mysql的分库分表》这篇文章中的代码，将分库分表和读写分离结结合起来。 配置mysql从库具体步骤依照《hive mysql元数据表单的主从备份》一文配置好主备,举例一下是主库配置,复制主库的test,user_1,user_2数据库到 123456server-id=1log-bin=mysql-binbinlog-do-db=testbinlog-do-db=user_1binlog-do-db=user_2log-slave-updates=1 从库配置,复制主库的test,user_1,user_2数据库 12345server-id=2#read_only=1replicate-do-db=testreplicate-do-db=user_1replicate-do-db=user_2 修改application.properties配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889spring.shardingsphere.datasource.names=master0,master1,master0slave0,master1slave0spring.shardingsphere.datasource.master0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.master0.jdbc-url=jdbc:mysql://192.168.171.76:3306/user_1?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.master0.username=rootspring.shardingsphere.datasource.master0.password=Liush123!@#spring.shardingsphere.datasource.master0.minimum-idle=10spring.shardingsphere.datasource.master0.maximum-pool-size=10spring.shardingsphere.datasource.master0.pool-name=masterHikariCPspring.shardingsphere.datasource.master1.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master1.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.master1.jdbc-url=jdbc:mysql://192.168.171.76:3306/user_2?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.master1.username=rootspring.shardingsphere.datasource.master1.password=Liush123!@#spring.shardingsphere.datasource.master1.minimum-idle=10spring.shardingsphere.datasource.master1.maximum-pool-size=10spring.shardingsphere.datasource.master1.pool-name=masterHikariCP2spring.shardingsphere.datasource.master0slave0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master0slave0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.master0slave0.jdbc-url=jdbc:mysql://192.168.171.77:3306/user_1?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.master0slave0.username=rootspring.shardingsphere.datasource.master0slave0.password=Liush123!@#spring.shardingsphere.datasource.master0slave0.minimum-idle=10spring.shardingsphere.datasource.master0slave0.maximum-pool-size=10spring.shardingsphere.datasource.master0slave0.pool-name=slaveHikariCPspring.shardingsphere.datasource.master1slave0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master1slave0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.master1slave0.jdbc-url=jdbc:mysql://192.168.171.77:3306/user_2?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.master1slave0.username=rootspring.shardingsphere.datasource.master1slave0.password=Liush123!@#spring.shardingsphere.datasource.master1slave0.minimum-idle=10spring.shardingsphere.datasource.master1slave0.maximum-pool-size=10spring.shardingsphere.datasource.master1slave0.pool-name=slaveHikariCP2spring.shardingsphere.sharding.default-database-strategy.inline.sharding-column=user_id_spring.shardingsphere.sharding.default-database-strategy.inline.algorithm-expression=master$-&gt;&#123;user_id_ % 2&#125;#如果不#如果不设置此参数，会产生笛卡尔积查询，使效率大大减慢（表间绑定，比如这里相同的orderID的t_order和t_order_item会划分到同一分片下，这样就不会产生笛卡尔积查询）spring.shardingsphere.sharding.binding-tables=t_order,t_order_itemspring.shardingsphere.sharding.broadcast-tables=t_addressspring.shardingsphere.sharding.tables.t_user.actual-data-nodes=master$-&gt;&#123;0..1&#125;.t_user_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_user.table-strategy.inline.sharding-column=user_id_spring.shardingsphere.sharding.tables.t_user.table-strategy.inline.algorithm-expression=t_user_$-&gt;&#123;user_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_user.key-generator.column=user_id_spring.shardingsphere.sharding.tables.t_user.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_user.key-generator.props.worker.id=123spring.shardingsphere.sharding.tables.t_order.actual-data-nodes=master$-&gt;&#123;0..1&#125;.t_order_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=order_id_spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order_$-&gt;&#123;order_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id_spring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_order.key-generator.props.worker.id=123spring.shardingsphere.sharding.tables.t_order_item.actual-data-nodes=master$-&gt;&#123;0..1&#125;.t_order_item_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.sharding-column=order_id_spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.algorithm-expression=t_order_item_$-&gt;&#123;order_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_order_item.key-generator.column=order_item_id_spring.shardingsphere.sharding.tables.t_order_item.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_order_item.key-generator.props.worker.id=123# 显示执行sqlspring.shardingsphere.props.sql.show=true## 注意这段代码和官方提供的日志不一致，官方提供的配置文件中master0，master1并没有使用，spring.shardingsphere.datasource.names中配置的源，但是实测中不使用spring.shardingsphere.datasource.names中配置的源配置的数据源会报 org.apache.shardingsphere.core.exception.ShardingException: Cannot find data source in sharding rule, invalid actual data nodespring.shardingsphere.sharding.master-slave-rules.master0.master-data-source-name=master0spring.shardingsphere.sharding.master-slave-rules.master0.slave-data-source-names=master0slave0spring.shardingsphere.sharding.master-slave-rules.master1.master-data-source-name=master1spring.shardingsphere.sharding.master-slave-rules.master1.slave-data-source-names=master1slave0 测试方法执行使用sharding-jdbc实现mysql的分库分表中的findOrderItem方法 12@Select(&quot;select item_name_ from t_order t1 inner join t_order_item t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( #&#123;orderId1&#125;,#&#123;orderId2&#125; )&quot;) List&lt;String&gt; findOrderItem(@Param(&quot;orderId1&quot;)long orderId1,@Param(&quot;orderId2&quot;)long orderId2); 查看打印代码,发现所有的读都已经分发到配置的读节点中了 122019-10-14 09:50:04.045 INFO 12276 --- [ main] ShardingSphere-SQL : Actual SQL: master0slave0 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608]2019-10-14 09:50:04.046 INFO 12276 --- [ main] ShardingSphere-SQL : Actual SQL: master1slave0 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608] 事务本地事务在不开启任何分布式事务管理器的前提下，让每个数据节点各自管理自己的事务。 它们之间没有协调以及通信的能力，也并不互相知晓其他数据节点事务的成功与否。 本地事务在性能方面无任何损耗，但在强一致性以及最终一致性方面则力不从心。 完全支持非跨库事务，例如：仅分表，或分库但是路由的结果在单库中。 完全支持因逻辑异常导致的跨库事务。例如：同一事务中，跨两个库更新。更新完毕后，抛出空指针，则两个库的内容都能回滚。 不支持因网络、硬件异常导致的跨库事务。例如：同一事务中，跨两个库更新，更新完毕后、未提交之前，第一个库宕机，则只有第二个库数据提交。 我们查看本地事务提交代码就可看到，如果我们的事务是在commit阶段发生异常，则事务不会生效，如果是发生在预编译PreparedStatement阶段，也就是语句错误，或者业务逻辑异常，这些异常在进入commit方法前就已经跑出则事务生效,所以在不引入分布式事务时，应该保证一次事务提交是在单库中进行的，比如订单，和订单明细都分片到一个库中 1234567891011121314public abstract class AbstractConnectionAdapter extends AbstractUnsupportedOperationConnection &#123; @Override public final void commit() throws SQLException &#123; Collection&lt;SQLException&gt; exceptions = new LinkedList&lt;&gt;(); for (Connection each : cachedConnections.values()) &#123; try &#123; each.commit(); &#125; catch (final SQLException ex) &#123; exceptions.add(ex); &#125; &#125; throwSQLExceptionIfNecessary(exceptions); &#125;&#125;]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>sharding-jdbc</tag>
        <tag>mysql读写分离</tag>
        <tag>mysql分库分表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用sharding-jdbc实现mysql的分库分表]]></title>
    <url>%2F2019%2F10%2F11%2F%E4%BD%BF%E7%94%A8sharding-jdbc%E5%AE%9E%E7%8E%B0mysql%E7%9A%84%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[简介之前提到的用sharding-jdbc对mysql进行读写分离可以很好的处理在读远远大于写的情况下的并发问题，但是无法突破写入大量数据造成性能下降的问题，在数据量达到千万甚至亿级别时，内存可能已经无法缓存全部索引，就要从硬盘中读取索引，这时即便再怎么优化也难免造成性能下降的问题，这时我们需要对数据进行分库分表，mysql中提供了分区功能，但是无法突破单机性能瓶颈,这里我们使用sharding-jdbc来实现分库分表功能。 核心概念简介逻辑表水平拆分的数据库（表）的相同逻辑和数据结构表的总称。例：订单数据根据主键尾数拆分为10张表，分别是t_order_0到t_order_9，他们的逻辑表名为t_order。 真实表在分片的数据库中真实存在的物理表。即上个示例中的t_order_0到t_order_9。 绑定表指分片规则一致的主表和子表。例如：t_order表和t_order_item表，均按照order_id分片，则此两张表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。举例说明，如果SQL为： 1SELECT i.* FROM t_order o JOIN t_order_item i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 在不配置绑定表关系时，假设分片键order_id将数值10路由至第0片，将数值11路由至第1片，那么路由后的SQL应该为4条，它们呈现为笛卡尔积： 1234567SELECT i.* FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11);SELECT i.* FROM t_order_0 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11);SELECT i.* FROM t_order_1 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11);SELECT i.* FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 在配置绑定表关系后，路由的SQL应该为2条： 123SELECT i.* FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11);SELECT i.* FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 其中t_order在FROM的最左侧，ShardingSphere将会以它作为整个绑定表的主表。 所有路由计算将会只使用主表的策略，那么t_order_item表的分片计算将会使用t_order的条件。故绑定表之间的分区键要完全相同。 广播表指所有的分片数据源中都存在的表，表结构和表中的数据在每个数据库中均完全一致。适用于数据量不大且需要与海量数据的表进行关联查询的场景，例如：字典表。 创建数据库在mysql中创建两个数据库user_1和user_2,并且在这两个数据库中分别创建以下测试表 地址表（用于测试广播） 1234CREATE TABLE `t_address` ( `id_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic; 用户表(用于测试分库分区) 12345678910CREATE TABLE `t_user_0` ( `user_id_` bigint(255) NULL DEFAULT NULL, `name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;CREATE TABLE `t_user_1` ( `user_id_` bigint(255) NULL DEFAULT NULL, `name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic; 订单表和订单明细表(用于测试绑定表) 1234567891011121314151617181920212223242526272829303132CREATE TABLE `t_order_0` ( `order_id_` bigint(255) NULL DEFAULT NULL, `order_name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `user_id_` int(255) NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;CREATE TABLE `t_order_1` ( `order_id_` bigint(255) NULL DEFAULT NULL, `order_name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `user_id_` int(255) NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;CREATE TABLE `t_order_item_0` ( `order_item_id_` bigint(255) NULL DEFAULT NULL, `item_name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `user_id_` int(255) NULL DEFAULT NULL, `order_id_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;CREATE TABLE `t_order_item_1` ( `order_item_id_` bigint(255) NULL DEFAULT NULL, `item_name_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL, `user_id_` int(255) NULL DEFAULT NULL, `order_id_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic; 创建maven工程关于sharding-jdbc打包参考之前sharding-jdbc主从分离文章 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;dependencies&gt; &lt;!-- for spring namespace --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-namespace&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 创建application.properties配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263spring.shardingsphere.datasource.names=ds0,ds1#创建数据源spring.shardingsphere.datasource.ds0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.ds0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.ds0.jdbc-url=jdbc:mysql://192.168.171.76:3306/user_1?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.ds0.username=rootspring.shardingsphere.datasource.ds0.password=Liush123!@#spring.shardingsphere.datasource.ds0.minimum-idle=10spring.shardingsphere.datasource.ds0.maximum-pool-size=10spring.shardingsphere.datasource.ds0.pool-name=HikariCP1spring.shardingsphere.datasource.ds1.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.ds1.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.ds1.jdbc-url=jdbc:mysql://192.168.171.76:3306/user_2?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.ds1.username=rootspring.shardingsphere.datasource.ds1.password=Liush123!@#spring.shardingsphere.datasource.ds1.minimum-idle=10spring.shardingsphere.datasource.ds1.maximum-pool-size=10spring.shardingsphere.datasource.ds1.pool-name=HikariCP2# 设置分库键和分库算法spring.shardingsphere.sharding.default-database-strategy.inline.sharding-column=user_id_spring.shardingsphere.sharding.default-database-strategy.inline.algorithm-expression=ds$-&gt;&#123;user_id_ % 2&#125;#设置绑定表规则#如果不#如果不设置此参数，会产生笛卡尔积查询，使效率大大减慢（表间绑定，比如这里相同的orderID的t_order和t_order_item会划分到同一分片下，这样就不会产生笛卡尔积查询）spring.shardingsphere.sharding.binding-tables=t_order,t_order_item#设置广播表spring.shardingsphere.sharding.broadcast-tables=t_address#设置t_user表分片规则，和主键生成规则（主键生成规则采用SNOWFLAKE）spring.shardingsphere.sharding.tables.t_user.actual-data-nodes=ds$-&gt;&#123;0..1&#125;.t_user_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_user.table-strategy.inline.sharding-column=user_id_spring.shardingsphere.sharding.tables.t_user.table-strategy.inline.algorithm-expression=t_user_$-&gt;&#123;user_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_user.key-generator.column=user_id_spring.shardingsphere.sharding.tables.t_user.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_user.key-generator.props.worker.id=123#设置t_order分片规则，和主键生成规则（主键生成规则采用SNOWFLAKE）spring.shardingsphere.sharding.tables.t_order.actual-data-nodes=ds$-&gt;&#123;0..1&#125;.t_order_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=order_id_spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order_$-&gt;&#123;order_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id_spring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_order.key-generator.props.worker.id=123#设置t_order_item分片规则，和主键生成规则（主键生成规则采用SNOWFLAKE）spring.shardingsphere.sharding.tables.t_order_item.actual-data-nodes=ds$-&gt;&#123;0..1&#125;.t_order_item_$-&gt;&#123;0..1&#125;spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.sharding-column=order_id_spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.algorithm-expression=t_order_item_$-&gt;&#123;order_id_ % 2&#125;spring.shardingsphere.sharding.tables.t_order_item.key-generator.column=order_item_id_spring.shardingsphere.sharding.tables.t_order_item.key-generator.type=SNOWFLAKEspring.shardingsphere.sharding.tables.t_order_item.key-generator.props.worker.id=123# 显示执行sqlspring.shardingsphere.props.sql.show=true 编写mybatis测试代码1234567891011121314@Insert(&quot;insert into t_user(name_) values(#&#123;name&#125;)&quot;)void insertUserShardingByName(@Param(&quot;name&quot;)String name);@Insert(&quot;insert t_address(id_,name_) values(#&#123;id&#125;,#&#123;name&#125;)&quot;)void insertAddress(@Param(&quot;id&quot;)String id,@Param(&quot;name&quot;)String name);@Insert(&quot;insert into t_order(order_name_,user_id_) values(#&#123;name&#125;,#&#123;userId&#125;)&quot;)void insertOrder(@Param(&quot;userId&quot;)int userId,@Param(&quot;name&quot;)String name);@Insert(&quot;insert into t_order_item(item_name_,user_id_,order_id_) values(#&#123;name&#125;,#&#123;userId&#125;,#&#123;orderId&#125;)&quot;)void insertItem(@Param(&quot;userId&quot;)int userId,@Param(&quot;name&quot;)String name,@Param(&quot;orderId&quot;) Long orderId);@Select(&quot;select item_name_ from t_order t1 inner join t_order_item t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( #&#123;orderId1&#125;,#&#123;orderId2&#125; )&quot;)List&lt;String&gt; findOrderItem(@Param(&quot;orderId1&quot;)long orderId1,@Param(&quot;orderId2&quot;)long orderId2); 执行结果 insertUserShardingByName执行此代码数据库会自动根据之前配置的SNOWFLAKE的策略生成分布式唯一主键，在对应的库和对应的表中插入数据 insertAddress插入广播数据在所有的库中的t_address表都插入数据，因为是广播表(类似与字典，所以不会分表分区) insertOrder和insertItem在对应设置的库和分表中插入语句 findOrderItem我们重点看一下这个执行结果,这里我们做了一个t_order表和t_order_item的连表查询，这两张表使用oder_id_进行关联，并且在配置文件中配置了这两张表Z为绑定关系(spring.shardingsphere.sharding.binding-tables=t_order,t_order_item),我们执行查询语句在日志中发现一下信息 12Actual SQL: ds0 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? )Actual SQL: ds1 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) 发现其只是在各个分库中对对应的分片进行了连表查询(因为我们传入的order_id_根据我们的分片方式都在分片0上)，并没有进行笛卡尔积查询，现在我们注释掉spring.shardingsphere.sharding.binding-tables=t_order,t_order_item，不设置表间绑定，我们查看日志,发现产生了笛卡尔积查询，所以必须配置spring.shardingsphere.sharding.binding-tables参数，不然查询效率很有可能比单表更慢 12342019-10-12 10:37:19.557 INFO 2632 --- [ main] ShardingSphere-SQL : Actual SQL: ds0 ::: select item_name_ from t_order_0 t1 inner join t_order_item_1 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608]2019-10-12 10:37:19.557 INFO 2632 --- [ main] ShardingSphere-SQL : Actual SQL: ds0 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608]2019-10-12 10:37:19.557 INFO 2632 --- [ main] ShardingSphere-SQL : Actual SQL: ds1 ::: select item_name_ from t_order_0 t1 inner join t_order_item_1 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608]2019-10-12 10:37:19.557 INFO 2632 --- [ main] ShardingSphere-SQL : Actual SQL: ds1 ::: select item_name_ from t_order_0 t1 inner join t_order_item_0 t2 on t1.order_id_=t2.order_id_ where t1.order_id_ in ( ?,? ) ::: [389458016099348480, 389458016128708608] 问题与思考分库分表的瓶颈传统数据库的分库分表很多都是依赖于中间件去实现的，不同于new sql(tidb)，或者nosql(mongo,hdfs)，这些数据库或者组件提供了auto sharding的特性，即系统可以自动对数据进行分区分片并完成数据平衡，当系统扩展后(增加计算节点)，这些系统会自动将数据再平衡，可以实现0维护扩展节点（只需当初的将节点加入集群其余的什么也不用做），传统数据库进行扩展需要重新手动对数据进行迁移，重新设计分片(如上文如果我们根据userId将2个库扩展为3个库那么原来的分库策略就不能使用了，因为运来采用分库策略是对userId和2进行取模运算{user_id_ % 2}，如果改成3个节点那么算法就要改成{user_id_ % 3}，那么需要手动将原来的数据做再平衡，将匹配的数据分配到第三台节点上)，所以使用关系型数据库做分库分片最好一次性就计划好未来的数据量，最好节点的规划.还有一个问题就是分片键的问题，为了查询能准确定位到数据所在的分片，每次查询时都要带上分片键，那么就会产生这么一个问题，如果现在有需求需要根据用户名查询用户数据，那么怎么办？因为数据都是根据userId进行分库分片的，这种情况下我们可以建立一张用户名和userId的映射表，这张表也可以进行分库分表，这张表根据用户名进行hash运算后进行分库分表，这样我们就可以先通过用户名，用户id关系表进行查询到用户id后，再根据用户id获取用户信息。 什么情况下对数据进行分库分表只有在有需要的情况下才对数据进行分库分表，分库分表比单表会带来很多限制，比如数据的join查询等（因为分片的原因需要考虑查询效率）,或者限制要在根据用户id进行分片的数据中对用户名进行模糊查询怎么办？有些时候就要对业务进行一些妥协，或者采用其它方案去解决如NOSQL，同时分表分库也带来了复杂度的提升，维护难度的提升.]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>sharding-jdbc</tag>
        <tag>mysql分库分表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用sharding-jdbc实现mysql的读写分离]]></title>
    <url>%2F2019%2F10%2F10%2F%E4%BD%BF%E7%94%A8sharding-jdbc%E5%AE%9E%E7%8E%B0mysql%E7%9A%84%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[简介在读数据远远大于写数据时，且写数据连在千万级别，为了扩展数据库的可读性可以采用数据库的读写分离结构来减轻读数据的压力。其实现方案就是利用数据库的主备，将读请求分发到各个从库中，来减轻读压力，实现这部分方案往往依赖中间件去屏蔽数据库访问信息(开发者像使用单数据源一样进行开发),而这类中间件又可以分为两部分，一部分为植入应用程序，通常为jar包，如淘宝的 TDDL，在访问数据源时由植入的中间件完成对数据请求的分发，将读请求分发到不同的数据库中，采用这部分中间的优点是简单易用，缺点是不能跨语言去使用。还有一部分中间件为独立部署到服务器中，应用程序去访问这部分服务，然后由服务去完成请求的处理和转发。sharding-jdbc（现在托管给Apache改名为ShardingSphere）兼备了这两种功能，这里我们使用ShardingSphere的sharding-jdbc模块来植入应用程序来实现一个读写分离的应用。 配置mysql主从这部分可以参考之前hive分类下的hive mysql元数据表单的主从备份这篇文章 下载sharding-jdbc源码并编译打包https://shardingsphere.apache.org/document/current/cn/downloads/下载完毕后使用maven在父目录下执行maven clean install将源码打包并安装到本地仓库,在打包过程中会遇到一些问题，可以查看下文问题一节. 在主库中创建测试表这张表中简单的创建了一张用户表包含了一个id字段和一个name字段 12345CREATE TABLE `t_user` ( `id_` int(255) UNSIGNED NOT NULL AUTO_INCREMENT, `name_` varchar(255) , PRIMARY KEY (`id_`)) 创建SpringBoot工程并且引入sharding-jdbc 引入sharding-jdbc-spring,mysql驱动，mybatis依赖 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;!-- for spring namespace --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-namespace&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置application.properties配置文件,配置连接池和数据源设置主从数据源，和配置主从节点 1234567891011121314151617181920212223242526272829303132#配置数据源名字spring.shardingsphere.datasource.names=master,slave0#配置数据源和连接池spring.shardingsphere.datasource.master.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.master.jdbc-url=jdbc:mysql://192.168.171.76:3306/test?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.master.username=rootspring.shardingsphere.datasource.master.password=Liush123!@#spring.shardingsphere.datasource.master.minimum-idle=10spring.shardingsphere.datasource.master.maximum-pool-size=10spring.shardingsphere.datasource.master.pool-name=masterHikariCPspring.shardingsphere.datasource.slave0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.slave0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.slave0.jdbc-url=jdbc:mysql://192.168.171.77:3306/test?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.slave0.username=rootspring.shardingsphere.datasource.slave0.password=Liush123!@#spring.shardingsphere.datasource.slave0.minimum-idle=10spring.shardingsphere.datasource.slave0.maximum-pool-size=10spring.shardingsphere.datasource.slave0.pool-name=slave0HikariCPspring.shardingsphere.masterslave.name=ms# 配置主节点spring.shardingsphere.masterslave.master-data-source-name=master# 多个从节点逗号分隔spring.shardingsphere.masterslave.slave-data-source-names=slave0# 显示执行sqlspring.shardingsphere.props.sql.show=true 编写mybaits测试代码12345678910111213141516171819202122package com.liu;import org.apache.ibatis.annotations.Insert;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Param;import org.apache.ibatis.annotations.Select;/** * @author Liush * @description * @date 2019/10/10 17:20 **/@Mapperpublic interface UserMapper &#123; @Select(&quot;select name_ from t_user where id_=#&#123;id&#125;&quot;) String findUserNameBy(@Param(&quot;id&quot;) String id); @Insert(&quot;insert into t_user(name_) values(#&#123;name&#125;) &quot;) void insertUser(@Param(&quot;name&quot;)String name);&#125; 编写Springboot 测试方法1234567891011121314151617181920212223242526272829303132333435package com.liu;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;/** * @author Liush * @description * @date 2019/10/10 17:22 **/@RunWith(SpringRunner.class)@SpringBootTestpublic class AppTest &#123; @Autowired private UserMapper userMapper; @Test public void findUser()&#123; userMapper.findUserNameBy(&quot;1&quot;); &#125; @Test public void insertUser()&#123; userMapper.insertUser(&quot;liuSH&quot;); &#125;&#125; 执行insertUser方法在控制台打印日志中我们发现插入数据永远都是在主节点中进行 1SQL: insert into t_user(name_) values(?) ::: DataSources: master 执行findUser 查询数据永远都是在从节点中进行*1SQL: select name_ from t_user where id_=? ::: DataSources: slave0 由此可见我们采用中间件实现了数据库的主从读写分离 问题maven打包问题在windows下用maven将ShardingSphere部署到本地仓库执行 install命令时出现 1MavenReportException: Error while generating Javadoc: 这里我们跳过javadoc生成 1mvn clean install -Dmaven.javadoc.skip=true -Dmaven.test.skip=true -Pbpfle 这时候又出现 1Unknown lifecycle phase &quot;.javadoc.skip=true&quot;. You must specify a valid lifecycle phase or a goal in the format &lt;plugin-prefix&gt;:&lt;goal&gt; or &lt;plugin-group-id&gt;:&lt;plugin-artifact-id&gt;[:&lt;plugin-version&gt;]:&lt;goal&gt;. 这是由于在windows下.具有其它含义，我们在点前加入`解决问题 1mvn clean install `-Dmaven`.javadoc`.skip=true `-Dmaven`.test`.skip=true `-Pbpfle]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>sharding-jdbc</tag>
        <tag>mysql读写分离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot中使用HikariCP连接池]]></title>
    <url>%2F2019%2F10%2F09%2FSpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8HikariCP%E8%BF%9E%E6%8E%A5%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[简介数据库连接池是为了规避每次查询时都向数据库建立连接而采用的技术，而向数据库创建连接往往比一次简单的查询所耗费的时间多好几倍，采用连接池在项目中可以有效的提升数据库查询的响应速度，而在SpringBoot中的spring-boot-starter-jdbc模块中又默认集成了HikariCP连接池，使我们很方便的在Springboot中使用数据库连接池.注意一下，由于本人使用的是mybatis持久化框架，HikariCP的依赖包含在spring-boot-starter-jdbc模块中，而mybatis-spring-boot-starter又包含了spring-boot-starter-jdbc，所以只需要引入mybatis-spring-boot-starter即可 引入maven POM依赖12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 本人新建SpringBoot Web项目，也可只创建SpringBoot项目 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置application.properties文件连接池中最重要两个配置，最小连接数和最大连接数 spring.datasource.hikari.minimum-idle 最小空闲连接数量 spring.datasource.hikari.maximum-pool-size 连接池最大连接数 如果当前连接数小于最小连接数，则创建新的连接处理数据库请求 如果连接池中有空闲连接则复用空闲连接； 如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接 如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间（HikariCP中为connectionTimeout）等待旧的连接可用 如果等待超过了这个设定时间则向用户抛出错误。 使用mysql中有一点需要注意，就是mysql中wait_timeout参数控制了一个连接多长时间后将会被回收，所以我们将max-lifetime参数设置的比mysql中的这个参数值稍微小写 connection-test-query,此参数为在应用程序每次获取连接池连接时都会去执行一下语句，如果正常，则使用这个个连接，但是在官网的简介中新版本的jdbc不再推荐使用这个参数，而是自动会调用jdbc4接口中的Connection.isValid()方法去判断连接是否可用，因此我们去除这个参数 1234567891011121314151617181920212223242526spring.datasource.url=jdbc:mysql://127.0.0.1:3306/mytest?serverTimezone=UTCspring.datasource.username=rootspring.datasource.password=rootspring.datasource.driver-class-name=com.mysql.jdbc.Driver## Hikari 连接池配置 ------ 详细配置请访问：https://github.com/brettwooldridge/HikariCP## 最小空闲连接数量spring.datasource.hikari.minimum-idle=10## 空闲连接存活最大时间，默认600000（10分钟）spring.datasource.hikari.idle-timeout=180000## 连接池最大连接数，默认是10spring.datasource.hikari.maximum-pool-size=20## 此属性控制从池返回的连接的默认自动提交行为,默认值：truespring.datasource.hikari.auto-commit=true## 连接池的用户定义名称，主要出现在日志记录和JMX管理控制台中以识别池和池配置spring.datasource.hikari.pool-name=MyHikariCP## 此属性控制池中连接的最长生命周期，值0表示无限生命周期，默认1800000即30分钟,如果是mysql可以将值配置的比mysql中wait_timeout参数稍小些spring.datasource.hikari.max-lifetime=1800000## 数据库连接超时时间,默认30秒，即30000spring.datasource.hikari.connection-timeout=30000## 如果支持驱动jdbc4不要设置#spring.datasource.hikari.connection-test-query=SELECT 1]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>HikariCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么不允许在高并发下使用JDK中的Executors去创建线程池]]></title>
    <url>%2F2019%2F10%2F09%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%85%81%E8%AE%B8%E4%BD%BF%E7%94%A8JDK%E4%B8%AD%E7%9A%84Executors%E5%8E%BB%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[简介Executors 是JDK 1.5中提供的一个创建线程池的建议类，其是对ThreadPoolExecutor进行了一次封装，屏蔽了ThreadPoolExecutor复杂的参数，简单使用且暴力。Executors提供了3种线程池分别为newCachedThreadPool(无固定大小线程池,如果线程空闲时间超过60s则回收),固定线程池newFixedThreadPool,和单一线程池newSingleThreadExecutor(只有一个线程)，相比使用ThreadPoolExecutor，Executors虽然也是使用ThreadPoolExecutor去创建线程池，但是其给ThreadPoolExecutor提供了默认参数，这就使我们在使用Executors时比ThreadPoolExecutor简单的多得多，往往只有传入一个创建线程的个数参数即可，但就是由于其屏蔽了ThreadPoolExecutor的细节导致在使用Executors在处理大量任务时存在OOM的隐患，所以在阿里巴巴编程规范中明确禁止使用Executors去创建线程池，我们可以通过查看api和查看Executors代码可以得知为什么会这样. ThreadPoolExecutorapi中关于ThreadPoolExecutor构造方法的解释1234567891011121314151617public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 参数： corePoolSize - 池中所保存的线程数，包括空闲线程。 maximumPoolSize - 池中允许的最大线程数。 keepAliveTime - 当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间。 unit - keepAliveTime 参数的时间单位。 workQueue - 执行前用于保持任务的队列。此队列仅保持由 execute 方法提交的 Runnable 任务。 threadFactory - 执行程序创建新线程时使用的工厂。 handler - 由于超出线程范围和队列容量而使执行被阻塞时所使用的处理程序。 ThreadPoolExecutor执行流程，当需要线程时调用参数中的ThreadFactory方法去创建线程，JDK中提供了默认的工具类去创建默认的线程工程Executors.defaultThreadFactory(),其有一个newThread方法去创建一个线程，在实际使用中我们可以自行实现线程工程(修改线程名字等)，方便后续日志追踪线程信息 12345678910public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125; 在创建线程时会先去判断当前活动的线程数是否达到corePoolSize设置的数量，如果没有的话则调用ThreadFactory去新建线程，如果当前正在使用执行任务的线程已经达到corePoolSize设置的数量，则将任务存放到构造方法中设置的BlockingQueue workQueue队列中,如果BlockingQueue使用的无解队列如LinkedBlockingDeque的话，那么等待执行的任务就会无限往无界队列中添加，如果使用的是有界队列的话如ArrayBlockingQueue,当任务数达到有界队列的数量后，如果目前执行任务的线程数量小于maximumPoolSize设置的线程数量则继续创建线程执行任务，直到线程数到达设置的maximumPoolSize时，执行拒绝策略RejectedExecutionHandler中实现的方法丢弃任务。 以下是线程执行的流程图 Executors Executors创建3种线程池的构造方法 12345678910111213141516171819202122public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; Executors存在的问题如果你认真查看上文关于，也许你就会发现一些问题 在newCachedThreadPool中maximumPoolSize最大数量为Integer.MAX_VALUE，那么根据上文所说，如果线程有大量任务需要执行，那么会不断的开启新的线程直到线程数达到Integer.MAX_VALUE，但是往往还没达到这个线程数，服务器就OOM了。 编写测试代码 首先编写一个拒绝处理器类RejectedExecutionHandler的实现,其功能为当执行队列已满且执行线程数已经达到设置的最大线程时打印文字 123456789101112131415161718package com.liu;import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadPoolExecutor;/** * @author Liush * @description * @date 2019/10/9 9:46 **/public class MyRejectedExecutionHandler implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; System.out.println(&quot;线程队列已满，且线程数已达最大线程数&quot;); &#125;&#125; 创建线程池，且设置参数,我们设置了一个10个大小的队列，为了方便查看拒绝执行线程时调用RejectedExecutionHandler中的代码我们设置了最小线程数为1，最大线程数为2 123456789101112131415161718192021222324252627282930313233343536package com.liu;import java.util.concurrent.*;/** * @author Liush * @description * @date 2019/10/9 9:40 **/public class ThreadPoolTest &#123; public static void main(String[] args) &#123; BlockingQueue&lt;Runnable&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;(10); ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(1, 2, 5000, TimeUnit.MILLISECONDS, blockingQueue, Executors.defaultThreadFactory(), new MyRejectedExecutionHandler()); for (int i = 0; i &lt; 100; i++) &#123; threadPoolExecutor.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(&quot;阻塞队列中有待执行任务个数&quot; + blockingQueue.size()); Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125;&#125; 执行结果,我们看到了任务出现了大量失败，因为我们将最大线程数设置为2，且队列大小设置为10，所以最多同时处理12个任务(2个任务正在执行，其余10个在队列中)，直到最后当循环快结束时（此时大量任务已经被丢弃），阻塞队列中的任务数量才降低 12345678910111213141516171819202122232425线程队列已满，且线程数已达最大线程数阻塞队列中有待执行任务个数10线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数阻塞队列中有待执行任务个数10线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数线程队列已满，且线程数已达最大线程数...阻塞队列中有待执行任务个数9阻塞队列中有待执行任务个数8阻塞队列中有待执行任务个数6阻塞队列中有待执行任务个数6阻塞队列中有待执行任务个数4阻塞队列中有待执行任务个数4阻塞队列中有待执行任务个数3阻塞队列中有待执行任务个数2阻塞队列中有待执行任务个数1阻塞队列中有待执行任务个数0 SynchronousQueue SynchronousQueue实现了BlockingQueue，BlockingQueue的实现类都是安全线程的 SynchronousQueue是阻塞队列，只能单进单出，也就是说多个线程调用queue的put或者offer方法只能有一个线程往里插入元素，除非消费者take出元素后才能继续插入元素。 BlockingQueue插入元素和移除元素有4种方法，分别对应当队列为空或者队列已满时不同的生产策略和消费策略 操作 抛出异常（当队列已满或者这队列为空） 特殊值（当队列已满或者这队列为空） 阻塞（当队列已满或者这队列为空） 超时（当队列已满或者这队列为空） 插入 add(e) offer(e) put(e) offer(e, time, unit) 移除 remove() poll() take() poll(time, unit) 检查 element() peek() 不可用 不可用 由上文可知我们在Executors中的 newCachedThreadPool中使用的是SynchronousQueue队列，也就是说当多个线程一起往SynchronousQueue调用offer返回时会返回false，从而使线程池开启新的线程，又由于newCachedThreadPool将 maximumPoolSize（池中允许的最大线程数）设置为Integer.MAX_VALUE，从而导致在大规模并发下导致OOM，以下是ThreadPoolExecutor中execute方法的源码，其注释和代码描述上述ThreadPoolExecutor的执行策略 123456789101112131415161718192021222324252627282930313233343536373839public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&apos;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; SynchronousQueue的公平队列,虽然SynchronousQueue只允许只有一个元素，但是其却可以维护一个公平队列，在新建SynchronousQueue实例时在构造方法中传入true即可，这个公平队列的作用就是按照线程玩队列插入元素的先后顺序插入元素，实践代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.liu;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.SynchronousQueue;/** * @author Liush * @description * @date 2019/10/9 14:03 **/public class QueueTest &#123; public static void main(String[] args) throws Exception&#123; //不使用公平队列 SynchronousQueue&lt;String&gt; synchronousQueue=new SynchronousQueue(); //使用公平队列 //SynchronousQueue&lt;String&gt; synchronousQueue=new SynchronousQueue(true); ExecutorService executorService =Executors.newCachedThreadPool(); executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; synchronousQueue.put(&quot;1&quot;); Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); Thread.sleep(1000); executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; synchronousQueue.put(&quot;2&quot;); Thread.sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); Thread.sleep(1000); executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; synchronousQueue.put(&quot;3&quot;); Thread.sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); Thread.sleep(1000); executorService.execute(new Runnable() &#123; @Override public void run() &#123; while (true)&#123; try &#123; System.out.println(synchronousQueue.take() +&quot;消费&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;); &#125;&#125; 上述代码开启了3个生产者，开启期间线程睡眠了1秒，保证其先后调用顺序，以下结果是我们不使用公平队列的情况的生产者输出，我们看到消费者并没有满足先进先出的原则， 1233消费2消费1消费 如果我们使用公平队列，结果如下,满足了队列先进先出的原则 1231消费2消费3消费]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Executors</tag>
        <tag>ThreadPoolExecutor</tag>
        <tag>SynchronousQueue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CDH安装集群教程]]></title>
    <url>%2F2019%2F09%2F26%2FCDH%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[下载地址下载地址]]></content>
      <categories>
        <category>CDH</category>
      </categories>
      <tags>
        <tag>CDH</tag>
        <tag>大数据</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用agentmain进行运行时热部署]]></title>
    <url>%2F2019%2F09%2F26%2F%E4%BD%BF%E7%94%A8agentmain%E8%BF%9B%E8%A1%8C%E8%BF%90%E8%A1%8C%E6%97%B6%E7%83%AD%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[简介在&lt;使用agent和javassist实现基于jvm的aop日志打印系统&gt;一文中，我使用了javaagent完成了一个基于JVM的aop，在main方法运行前动态的修改class文件的字节码，从而达到aop的效果，而java应用代码的编写者却感觉不到我们修改了代码,但是使用javaagent我们在启动java的main方时启动premain方法(虽然inst.addTransformer启动的ClassFileTransformer是永久存在的，也就是说后续用户自定义类加载器，并放弃双亲委派时（因为使用双亲委派模式每次加载的都是同一个class对象）也会调用ClassFileTransformer里的方法)(具体实践可查看使用agent和javassist实现基于jvm的aop日志打印系统 中的更进一步一节),但是这要求我们每次在主代码启动时必须加上javaagent参数去启动主代码包，如果我们转换器ClassFileTransformer需要变动的话那还是要停掉jvm，那么有无一种可以在运行时可以动态修改字节码的方法呢？答案就是JDK1.6提供的agentmain。 1234public static void premain(String agentArgs, Instrumentation inst) &#123; inst.addTransformer(new ClassFileTransformer() //省略实现类...); &#125; 实现思路实例一个分层3个jar包 agentmain代码负责从外部读取class文件，并且加载到虚拟机中 运行的测试工程 jvm加载代码，从本机中查找目标虚拟机，将运行agentmain的jar包插入到目标虚拟机中完成热部署 agentmain代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.liu;import java.io.IOException;import java.lang.instrument.*;import java.net.*;import java.nio.file.Files;import java.nio.file.Path;import java.nio.file.Paths;/** * @author Liush * @description * @date 2019/9/25 14:57 **/public class AgentMain &#123; public static void agentmain(String agentArgs, Instrumentation inst) throws ClassNotFoundException, UnmodifiableClassException, URISyntaxException, IOException &#123; if(agentArgs.trim()==null)&#123; return; &#125; //从参数中截取文件路径和要修改的类 String[] args=agentArgs.split(&quot; &quot;); //查找所有已经加载的类 Class[] classes=inst.getAllLoadedClasses(); for(Class&lt;?&gt; c:classes)&#123; //查找需要重新加载的类 if(!c.getName().endsWith(&quot;.&quot;+args[1]))&#123; continue; &#125; //获取修改后的类的字节码 //格式 file:///C:/Users/Administrator/Desktop/test/Test.class Path path = Paths.get(new URI(args[0])); byte[] classBytes = Files.readAllBytes(path); //重新定义类，完成热部署 inst.redefineClasses(new ClassDefinition(c,classBytes)); &#125; &#125;&#125; 打包,我们需要在MANIFEST.MF 中指定Agent-Class和Can-Redefine-Classes，Can-Retransform-Classes属性，我们采用maven打包方式加入如下插件,并且打成jar包 12345678910111213141516171819202122232425262728293031323334&lt;build&gt; &lt;plugins&gt; &lt;!-- http://maven.apache.org/shared/maven-archiver/index.html#class_manifest --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;index&gt;true&lt;/index&gt; &lt;manifestEntries&gt; &lt;Agent-Class&gt;com.liu.AgentMain&lt;/Agent-Class&gt; &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- 将插件绑定maven的package命令--&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!-- append to the packaging phase. --&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;!-- goals == mojos --&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 测试工程并没有什么特别循环执行Test.test()方法 1234567891011121314151617181920212223242526package com.liu;/** * @author Liush * @description * @date 2019/9/25 16:31 **/public class MainTest &#123; public static void main(String[] args) &#123; while (true)&#123; Test test=new Test(); test.test(); System.out.println(&quot;running........................&quot;); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; Test 类 12345678910111213141516package com.liu;/** * @author Liush * @description * @date 2019/9/25 16:54 **/public class Test &#123; public void test()&#123; System.out.println(&quot;未修改之前的数据..............&quot;); &#125;&#125; jvm加载代码注意VirtualMachine类是在${JAVA_HOME}/lib包下的tool.jar包下，需要在编译器中加入这个jar包,以idea为例点击Files-&gt;Project Structure-&gt;Libraiest 在此节目中添加tool.jar包即可 123456789101112131415161718192021222324252627282930313233343536package com.liu;import com.sun.tools.attach.*;import java.io.IOException;import java.util.List;/** * @author Liush * @description * @date 2019/9/25 15:16 **/public class JVMLoader &#123; public static void main(String[] args) throws IOException, AgentLoadException, AgentInitializationException, AttachNotSupportedException &#123; List&lt;VirtualMachineDescriptor&gt; list=VirtualMachine.list(); for (VirtualMachineDescriptor vmd : list) &#123; //查找MainTest虚拟机 if (vmd.displayName().endsWith(&quot;MainTest&quot;)) &#123; VirtualMachine virtualMachine = VirtualMachine.attach(vmd.id()); //在目标虚拟机中加载agentmainjar包，并且传入修改后的Test.class文件 和要修改的类这里是Test，传入一个字符串参数，这个字符串将在agentmain中进行分割得到对应的参数，比如这里使用&quot; &quot;做区分不同参数 virtualMachine.loadAgent(&quot;C:\\Users\\Administrator\\Desktop\\test\\agentmain-1.0-SNAPSHOT-jar-with-dependencies.jar &quot;, &quot;file:///C:/Users/Administrator/Desktop/test/Test.class Test&quot;); System.out.println(&quot;ok&quot;); virtualMachine.detach(); &#125; &#125; &#125;&#125; 开始执行 将agentmain打成jar包 运行测试工程main方法出现 1234未修改之前的数据..............running........................未修改之前的数据..............running........................ 修改Test文件并且重新编译 1234567891011121314151617package com.liu;/** * @author Liush * @description * @date 2019/9/25 16:54 **/public class Test &#123; public void test()&#123; System.out.println(&quot;Test已经修改完毕..............&quot;); &#125;&#125; 执行jvm加载代码的main方法，在目标虚拟机中执行agentmain方法，在代码中传入agentmain包的路径，重新编译完成的Test文件的路径，和要替换的类（这是是Test类），详情查看jvm加载代码中的注释 结果之前的Test已经完成了热部署，但是我们并没有重启测试工程的JVM 123456未修改之前的数据..............running........................未修改之前的数据..............running........................Test已经修改完毕..............running........................ 使用agentmain的限制通过查看JDK Instrumentation 的redefineClasses说明发现以下限制，也就是用此方法热部署不能更改类的继承关系，类名，方法名，方法参数，而且如果在从新加载类后如果，之前已经存在正在运行的未重从定义的方法，那么运行的仍然是原来的方法 1234567重定义可能会更改方法体、常量池和属性。重定义不得添加、移除、重命名字段或方法；不得更改方法签名、继承关系。在以后的版本中，可能会取消这些限制。在应用转换之前，类文件字节不会被检查、验证和安装。如果结果字节错误，此方法将抛出异常。如果此方法抛出异常，则不会重定义任何类如果重定义的方法有活动的堆栈帧，那么这些活动的帧将继续运行原方法的字节码。将在新的调用上使用此重定义的方法。此方法不会引起任何初始化操作，JVM 惯例语义下发生的初始化除外。换句话说，重定义一个类不会引起其初始化方法的运行。静态变量的值将与调用之前的值一样。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>热部署</tag>
        <tag>instrument</tag>
        <tag>agentmain</tag>
        <tag>maven打包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用agent和javassist实现基于jvm的aop日志打印系统]]></title>
    <url>%2F2019%2F09%2F25%2F%E4%BD%BF%E7%94%A8agent%E5%92%8Cjavassist%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8Ejvm%E7%9A%84aop%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[简介java在JDK1.5中提供了java.lang.Instrument包,该包提供了一些工具帮助开发人员在 Java 程序运行时动态的修改class,此文介绍其中的agent组件来实现基于jvm层面的aop. 命令如果我们在cmd输入java -help就会看到关于javaagent命令的简介 1234567java -help用法: java [-options] class [args...]其中选项包括: -javaagent:&lt;jarpath&gt;[=&lt;选项&gt;] 加载 Java 编程语言代理, 请参阅 java.lang.instrument 实例如下 1java -javaagent:/to/agent.jar -jar /main.jar 其中javaagent参数后的路径就是我们要编写的代码,其可以在要代理运行的jar运行前进行一些class字节的操作,如果在此期间使用犹如javassist,或者asm字节码操作的框架则可以实现在类运行前对要运行的class进行修改. agent简介 参数 javaagent 可以用于指定一个 jar 包，并且对该 java 包有2个要求： 这个jar 包的MANIFEST.MF 文件必须指定 Premain-Class 项。 Premain-Class 指定的那个类必须实现 premain（）方法。关于第一点我们在后续创建工程中使用maven 打包插件maven-assembly-plugin去解决这一点.现在我们解释一下第二点:javaagent程序不需要实现任何接口,只需要创建一个类其中类中必须要有以下方法之一即可 public static void premain(String agentArgs, Instrumentation inst)public static void premain(String agentArgs) 一般我们使用第一个方法 ,参数 agentArgs 时通过命令行传给 Java Agent 的参数，inst 是Java Class 字节码转换的工具，Instrumentation 常用方法如下： void addTransformer(ClassFileTransformer transformer, boolean canRetransform);增加一个Class 文件的转换器，转换器用于改变 Class 二进制流的数据，参数 canRetransform 设置是否允许重新转换我们可以使用ClassFileTransformer对象结合javassist或者asm对class文件进行修改。 void redefineClasses(ClassDefinition… definitions) hrows ClassNotFoundException, UnmodifiableClassException;在类加载之前，重新定义 Class 文件，ClassDefinition 表示对一个类新的定义，如果在类加载之后，需要使用 retransformClasses 方法重新定义。 本文中我们使用addTransformer方法在class文件加载前,我们对class字节码进行处理,添加打印日志代码,此方法接收一个ClassFileTransformer对象,Transformer 类包含了一个 transform 方法，它的签名会接受 ClassLoader、类名、要重定义的类所对应的 Class 对象、定义权限的 ProtectionDomain 以及这个类的原始字节。如果从 transform 方法中返回 null 的话，将会告诉运行时环境我们并没有对这个类进行变更。 123public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; return new byte[0]; &#125; 实现思路简介我们实现的原理很简单,首先我们在运行的主工程中定义个注解,此注解的功能是标识出哪些方法和哪些参数需要打印log,其作用域为在方法上,fields属性为数组,我们将需要打印的参数的角标放入其中如, 123456//打印方法的第一个参数@PrintLog(fields = &#123;&quot;1&quot;&#125;) public void test(String name,String name2)&#123; &#125; 123456789101112131415package com.liu;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface PrintLog &#123; String[] fields();&#125; 然后我们对需要打印日志的方法如上加上注解即可,在运行agent程序的时候我们会在class文件加载前,逐个扫描方法,查看是否有@PrintLog注解,如果有注解我们则应用javassist框架在class文件中加入打印代码,由于在之前文章讲述的类加载器的双亲委派模型,同一个class文件在双亲委派模式下只会加载一次,所以只有在class文件第一次被加载时才会触发此修改class的条件,因此也不必过多担心效率问题. 搭建agent工程创建agent主题类我们新建一个maven工程,首先新建一个类,其只包含上文简介的premain方法,并添加一个日志打印转换器,此方法会在代码里jar文件执行main方法前执行 12345678910111213141516171819202122package com.liu;import java.lang.instrument.Instrumentation;/** * @author Liush * @description 自定义agent在main方法执行前执行 * @date 2019/9/23 15:32 **/public class MyAgent &#123; public static void premain(String agentArgs, Instrumentation inst) &#123; inst.addTransformer(new LogPrintTransformer()); &#125;&#125; 创建ClassFileTransformer转换类上文提到premain方法中有一个Instrumentation对象,其的addTransformer方法可以添加一个创建ClassFileTransformer转换类,其可以在class第一次加载时对class文件进行处理,修改java代码因此我们现在创建一个ClassFileTransformer的实现类,类中主要使用javassist框架扫描加载的类的信息,和方法,查看方法上时候有我们之前标识的@PrintLog注解,如果有的话获取注解中的值,然后最后根据获取的值打印对应的参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104package com.liu;import javassist.*;import javassist.bytecode.AnnotationsAttribute;import javassist.bytecode.CodeAttribute;import javassist.bytecode.LocalVariableAttribute;import javassist.bytecode.MethodInfo;import javassist.bytecode.annotation.Annotation;import javassist.bytecode.annotation.ArrayMemberValue;import javassist.bytecode.annotation.MemberValue;import javassist.bytecode.annotation.StringMemberValue;import java.io.IOException;import java.lang.instrument.ClassFileTransformer;import java.lang.instrument.IllegalClassFormatException;import java.security.ProtectionDomain;import java.util.ArrayList;import java.util.Arrays;import java.util.Collections;import java.util.List;/** * @author Liush * @description * @date 2019/9/23 15:41 **/public class LogPrintTransformer implements ClassFileTransformer &#123; /** * 签名会接受 ClassLoader、类名、要重定义的类所对应的 Class 对象、定义权限的 ProtectionDomain 以及这个类的原始字节。 * 如果从 transform 方法中返回 null 的话，将会告诉运行时环境我们并没有对这个类进行变更。 */ @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; try &#123; CtClass ctClass=ClassPool.getDefault().get(className.replaceAll(&quot;/&quot;, &quot;.&quot;)); CtMethod[] ctMethods =ctClass.getDeclaredMethods(); for(CtMethod ctMethod:ctMethods)&#123; if(getAnnotation(ctMethod)!=null) &#123; List&lt;String&gt; value = getParamIndexes(getAnnotation(ctMethod)); ctMethod.insertBefore(createJavaString(className, ctMethod, value)); &#125; &#125; return ctClass.toBytecode(); &#125; catch (NotFoundException e) &#123; e.printStackTrace(); &#125; catch (CannotCompileException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; //在javassist中$1代表方法的第一个参数,$2代表第二个参数以此类推可参考https://www.jianshu.com/p/b9b3ff0e1bf8 private String createJavaString(String className,CtMethod ctMethod,List&lt;String&gt; params)&#123; StringBuilder stringBuilder=new StringBuilder(); for(String index:params)&#123; stringBuilder.append(&quot;System.out.println($&quot;); stringBuilder.append(index); stringBuilder.append(&quot;);&quot;); &#125; return stringBuilder.toString(); &#125; //查找方法注解 public Annotation getAnnotation(CtMethod method) &#123; MethodInfo methodInfo = method.getMethodInfo(); AnnotationsAttribute attInfo = (AnnotationsAttribute) methodInfo .getAttribute(AnnotationsAttribute.visibleTag); if (attInfo != null) &#123; return attInfo.getAnnotation(&quot;com.liu.PrintLog&quot;); &#125; return null; &#125; //获得注解中的属性值 public List&lt;String&gt; getParamIndexes(Annotation annotation) &#123; ArrayMemberValue fields = (ArrayMemberValue) annotation.getMemberValue(&quot;fields&quot;); if (fields != null) &#123; MemberValue[] values = fields.getValue(); List&lt;String&gt; parameterIndexes = new ArrayList&lt;&gt;(); for (MemberValue val : values) &#123; parameterIndexes.add(((StringMemberValue) val).getValue()); &#125; return parameterIndexes; &#125; return Collections.emptyList(); &#125;&#125; 生成MANIFEST.MF文件使用agent必须在MANIFEST.MF中指定Premain-Class表示我们只想的agent的类,设置Can-Redefine-Classes和Can-Retransform-Classes属性为true,我们采用maven插件的方式进行打包,由maven自动生成MANIFEST.MF文件在maven pom依赖中加入 1234567891011121314151617181920212223242526272829303132333435&lt;build&gt; &lt;plugins&gt; &lt;!-- http://maven.apache.org/shared/maven-archiver/index.html#class_manifest --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;index&gt;true&lt;/index&gt; &lt;manifestEntries&gt; &lt;!-- 设置MANIFEST中的属性 --&gt; &lt;Premain-Class&gt;com.liu.MyAgent&lt;/Premain-Class&gt; &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- 将插件绑定maven的package命令--&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!-- append to the packaging phase. --&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;!-- goals == mojos --&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 创建主工程创建打印注解此类为了标识哪些方法的哪些参数需要打印 123456789101112131415package com.liu;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface PrintLog &#123; String[] fields();&#125; 创建一个测试类 12345678910111213141516171819package com.liu;/** * @author Liush * @description * @date 2019/9/23 18:12 **/public class LogTest &#123; @PrintLog(fields = &#123;&quot;1&quot;&#125;) public void test(String name,String name2)&#123; System.out.println(&quot;over...........................&quot;); &#125;&#125; 创建main方法 1234567891011121314151617package com.liu;/** * @author Liush * @description * @date 2019/9/23 18:06 **/public class MainTest &#123; public static void main(String[] args) &#123; LogTest logTest=new LogTest(); logTest.test(&quot;liushaohuang111&quot;,&quot;liushaohuang2222&quot;); &#125;&#125; 同样我是使用maven maven-assembly-plugin插件进行打包,与上面不同的是我们这次不要指定Premain-Class,Can-Redefine-Classes和Can-Retransform-Classes参数我们只需要声明main函数的入口即可 1234567891011121314151617181920212223242526272829303132&lt;build&gt; &lt;plugins&gt; &lt;!-- http://maven.apache.org/shared/maven-archiver/index.html#class_manifest --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;index&gt;true&lt;/index&gt; &lt;manifest&gt; &lt;mainClass&gt;com.liu.MainTest&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- this is used for inheritance merges --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!-- append to the packaging phase. --&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;!-- goals == mojos --&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 打包运行在两个工程目录下执行 1mvn clean package 运行javaagent命令 1java -javaagent:.\agent-1.0-SNAPSHOT-jar-with-dependencies.jar -jar .\main_test-1.0-SNAPSHOT-jar-with-dependencies.jar 在控制台中出现,成功打印出传入的第一个参数,并且在原始方法执行打印overing之前执行打印 12liushaohuang111over........................... 更进一步在实践中本人思考premain 中的Instrumentation 添加的转换器到底什么时候才起作用呢？这里再做一个实践，我们修改premain方法，往里面加入一行打印代码，为了方便在运行的时候发现什么时候触发转化器,其余代码和之前的代码一模一样 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package com.liu;import javassist.*;import javassist.bytecode.AnnotationsAttribute;import javassist.bytecode.CodeAttribute;import javassist.bytecode.LocalVariableAttribute;import javassist.bytecode.MethodInfo;import javassist.bytecode.annotation.Annotation;import javassist.bytecode.annotation.ArrayMemberValue;import javassist.bytecode.annotation.MemberValue;import javassist.bytecode.annotation.StringMemberValue;import java.io.IOException;import java.lang.instrument.ClassFileTransformer;import java.lang.instrument.IllegalClassFormatException;import java.security.ProtectionDomain;import java.util.ArrayList;import java.util.Arrays;import java.util.Collections;import java.util.List;/** * @author Liush * @description * @date 2019/9/23 15:41 **/public class LogPrintTransformer implements ClassFileTransformer &#123; /** * 签名会接受 ClassLoader、类名、要重定义的类所对应的 Class 对象、定义权限的 ProtectionDomain 以及这个类的原始字节。 * 如果从 transform 方法中返回 null 的话，将会告诉运行时环境我们并没有对这个类进行变更。 */ @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; try &#123; System.out.println(&quot;in transform....................&quot;); CtClass ctClass=ClassPool.getDefault().get(className.replaceAll(&quot;/&quot;, &quot;.&quot;)); CtMethod[] ctMethods =ctClass.getDeclaredMethods(); for(CtMethod ctMethod:ctMethods)&#123; if(getAnnotation(ctMethod)!=null) &#123; List&lt;String&gt; value = getParamIndexes(getAnnotation(ctMethod)); ctMethod.insertBefore(createJavaString(className, ctMethod, value)); &#125; &#125; return ctClass.toBytecode(); &#125; catch (NotFoundException e) &#123; e.printStackTrace(); &#125; catch (CannotCompileException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; //在javassist中$1代表方法的第一个参数,$2代表第二个参数以此类推可参考https://www.jianshu.com/p/b9b3ff0e1bf8 private String createJavaString(String className,CtMethod ctMethod,List&lt;String&gt; params)&#123; StringBuilder stringBuilder=new StringBuilder(); for(String index:params)&#123; stringBuilder.append(&quot;System.out.println($&quot;); stringBuilder.append(index); stringBuilder.append(&quot;);&quot;); &#125; return stringBuilder.toString(); &#125; //查找方法注解 public Annotation getAnnotation(CtMethod method) &#123; MethodInfo methodInfo = method.getMethodInfo(); AnnotationsAttribute attInfo = (AnnotationsAttribute) methodInfo .getAttribute(AnnotationsAttribute.visibleTag); if (attInfo != null) &#123; return attInfo.getAnnotation(&quot;com.liu.PrintLog&quot;); &#125; return null; &#125; //获得注解中的属性值 public List&lt;String&gt; getParamIndexes(Annotation annotation) &#123; ArrayMemberValue fields = (ArrayMemberValue) annotation.getMemberValue(&quot;fields&quot;); if (fields != null) &#123; MemberValue[] values = fields.getValue(); List&lt;String&gt; parameterIndexes = new ArrayList&lt;&gt;(); for (MemberValue val : values) &#123; parameterIndexes.add(((StringMemberValue) val).getValue()); &#125; return parameterIndexes; &#125; return Collections.emptyList(); &#125;&#125; 现在我们更改主项目中被代理的main方法代码,里面一共new了4次LogTest对象 第一个是第一次触发class加载(class文件只有被调用时候才会第一次加载到虚拟机)，则会触发premain方法中的转换器 第二个是直接调用堆栈中的class又new一次对象对象，没有触发转化器 第三个我们使用自定义类加载器，并且不突破双亲委派模式(还是调用堆栈中的LogTest)，同样也没有触发转化器 第四个，我们又创建了一个类加载器，并且突破双亲委派模式，重新加载一个LogTest，不再使用之前堆栈中的LogTest对象，最后发现触发了转化器 结论：只有在class重新被加载时才会触发ClassFileTransformer转换器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.liu;import java.io.IOException;import java.io.InputStream;/** * @author Liush * @description * @date 2019/9/23 18:06 **/public class MainTest &#123; public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException &#123; //第一次次加载触发ClassFileTransformer LogTest logTest = new LogTest(); logTest.test(&quot;liushaohuang111&quot;, &quot;liushaohuang2222&quot;); //重新创建对象,不会触发premain中的ClassFileTransformer(类已经加载到堆栈中) LogTest logTest1 = new LogTest(); logTest1.test(&quot;shao111111111111&quot;, &quot;shao22222222222222&quot;); //不突破双亲委派类进行类加载,不会触发premain中的ClassFileTransformer(类已经加载到堆栈中) ClassLoader classLoader = new ClassLoader() &#123; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; return super.loadClass(name); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; e.printStackTrace(); throw new ClassNotFoundException(name); &#125; &#125; &#125;; Class aClass = classLoader.loadClass(&quot;com.liu.LogTest&quot;); LogTest logTest2 = (LogTest)aClass.newInstance(); logTest2.test(&quot;Parents Delegation Model 1&quot;,&quot;Parents Delegation Model 2&quot;); //突破双亲委派模式 ClassLoader classLoader2=new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; return super.loadClass(name); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; e.printStackTrace(); throw new ClassNotFoundException(name); &#125; &#125; &#125;; Class aClass2 = classLoader.loadClass(&quot;com.liu.LogTest&quot;); LogTest logTest3 = (LogTest)aClass.newInstance(); logTest3.test(&quot;No Parents Delegation Model1&quot;,&quot;No Parents Delegation Model 2&quot;); &#125;&#125; 输出结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................in transform....................liushaohuang111over...........................shao111111111111over...........................Parents Delegation Model 1over...........................in transform....................No Parents Delegation Model1over...........................in transform....................in transform....................]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>instrument</tag>
        <tag>javassist</tag>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql存储过程游标的嵌套和使用(统计局地区维度表的创建)]]></title>
    <url>%2F2019%2F09%2F24%2Fmysql%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E6%B8%B8%E6%A0%87%E7%9A%84%E5%B5%8C%E5%A5%97%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介之前主要使用oracle来实现存储过程,今天在写mysql存储过程时发现mysql并没有类似oracle的for循环语法,因此通过游标方式来实现类似功能,本过程通过正则切割地区id将统计局的全国到村和街道的数据装换成供数据仓库使用的宽表结构 (因为统计局提供的地区层次是通过id来区分的,code字段共有12个字符，第1、2位标识省份，第3、4位标识地市、第5、6位标识县区，第7-9位标识乡镇、第10-12位标识村。其数据来自http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/), 转化后的表结构如下 注意这里多了一列当前正在使用的id,这是为了应对后续存在的地区名字或结构变化,这里本人采用的是维度变化的类型6的变种,如果id和正在使用的id相同则代表当前地区是最新结构,否则通过子查询去寻找当前的正在使用的地区id,因为这张表中目前有70多万条数据,如果重新生成较为耗时,且这是一个通用维度,历史数据还是关联就的地区状态,所以需要保留地区维度表的历史信息,且地区信息是拉平的(数据仓库维度表中数据都是拉平的,以此表来说如果有些数据是关联在福建省下则,需要创建,福建省,福建市,福建县,福建镇,福建乡),因为如果维度不拉平则在统计分析时会漏掉直接关联在福建省下的数据. id 省 市 县 镇 村 当前正在使用的id id 福建 福州 闽清 镇 村 id 代码和注释如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210CREATE DEFINER=`root`@`%` PROCEDURE `F_AREA`()BEGIN declare v_sheng_code VARCHAR(20); declare v_sheng_name VARCHAR(255); declare v_shi_code VARCHAR(20); declare v_shi_name VARCHAR(255); declare v_shi_code_short VARCHAR(20); declare v_xian_code VARCHAR(20); declare v_xian_name VARCHAR(255); declare v_xian_code_short VARCHAR(20); declare v_zhen_code VARCHAR(20); declare v_zhen_name VARCHAR(255); declare v_zhen_code_short VARCHAR(20); declare v_cun_code VARCHAR(20); declare v_cun_name VARCHAR(255); -- 游标变量必须在游标前声明 declare v_done int; declare c_sheng cursor for SELECT code ,name from region_code4stat_2018 where code REGEXP &apos;^[0-9][0-9]$&apos; ; -- 声明市游标 declare c_shi cursor for SELECT code ,name from region_code4stat_2018 where code REGEXP concat(concat(&apos;^(&apos;,v_sheng_code),&apos;)[0-9][0-9]0&#123;8,8&#125;$&apos;) ; -- 声明县游标 declare c_xian cursor for SELECT code ,name from region_code4stat_2018 where code REGEXP concat(concat(concat(&apos;^(&apos;,v_sheng_code),v_shi_code_short),&apos;)[0-9][0-9][0]&#123;6,6&#125;$&apos;) and code!= concat(concat(v_sheng_code,v_shi_code_short),&apos;00000000&apos;); -- 声明镇游标 declare c_zhen cursor for SELECT code ,name from region_code4stat_2018 where code REGEXP concat(concat(concat(concat(&apos;^(&apos;,v_sheng_code),v_shi_code_short),v_xian_code_short),&apos;)[0-9][0-9][0-9][0]&#123;3,3&#125;$&apos;) and code!=concat(concat(concat(v_sheng_code,v_shi_code_short),v_xian_code_short),&apos;000000&apos;); -- 声明村游标 declare c_cun cursor for SELECT code ,name from region_code4stat_2018 where code REGEXP concat(concat(concat(concat(concat(&apos;^(&apos;,v_sheng_code),v_shi_code_short),v_xian_code_short),v_zhen_code_short),&apos;)[0-9]&#123;3,3&#125;$&apos;) and code!=concat(concat(concat(concat(v_sheng_code,v_shi_code_short),v_xian_code_short),v_zhen_code_short),&apos;000&apos;) ; -- 声明游标完成状态必须要在游标声明后 DECLARE CONTINUE HANDLER FOR NOT FOUND SET v_done = 1;-- ------------------------------------------------------------------------------------------------------------ -- 打开省游标 open c_sheng; sheng_loop:LOOP FETCH c_sheng INTO v_sheng_code,v_sheng_name; IF v_done = 1 THEN LEAVE sheng_loop; END IF; -- 省数据拉平(数据仓库维度表中数据都是拉平的,以此表来说如果有些数据是关联在福建省下则,需要创建,福建省,福建市,福建县,福建镇,福建乡) INSERT INTO D_AREA(CODE_,PROVINCE_,CITY_,COUNTRY_,TOWN_,VILLAGE,CURR_CODE_) VALUES(v_sheng_code,v_sheng_name,v_sheng_name,v_sheng_name,v_sheng_name,v_sheng_name, v_sheng_code); -- ----------------------------------------------------------------------------------------------------------- -- 打开市游标 open c_shi; shi_loop:LOOP FETCH c_shi INTO v_shi_code,v_shi_name; IF v_done = 1 THEN LEAVE shi_loop; END IF; -- 市数据拉平 INSERT INTO D_AREA(CODE_,PROVINCE_,CITY_,COUNTRY_,TOWN_,VILLAGE,CURR_CODE_) VALUES(v_shi_code,v_sheng_name,v_shi_name,v_shi_name,v_shi_name,v_shi_name, v_shi_code); set v_shi_code_short=substring(v_shi_code,3,2); -- ------------------------------------------------------------ -- 打开县游标 open c_xian; xian_loop:LOOP FETCH c_xian INTO v_xian_code,v_xian_name; IF v_done = 1 THEN LEAVE xian_loop; END IF; -- 县数据拉平 INSERT INTO D_AREA(CODE_,PROVINCE_,CITY_,COUNTRY_,TOWN_,VILLAGE,CURR_CODE_) VALUES(v_xian_code,v_sheng_name,v_shi_name,v_xian_name,v_xian_name,v_xian_name, v_xian_code); set v_xian_code_short=substring(v_xian_code,5,2); -- --------------------------------------------- -- 打开镇游标 open c_zhen; zhen_loop:LOOP FETCH c_zhen INTO v_zhen_code,v_zhen_name; IF v_done = 1 THEN LEAVE zhen_loop; END IF; -- 镇数据拉平 INSERT INTO D_AREA(CODE_,PROVINCE_,CITY_,COUNTRY_,TOWN_,VILLAGE,CURR_CODE_) VALUES(v_zhen_code,v_sheng_name,v_shi_name,v_xian_name,v_zhen_name,v_zhen_name, v_zhen_code); set v_zhen_code_short=substring(v_zhen_code,7,3); -- --------------------------------------------------------------------- -- 打开村游标 open c_cun; cun_loop:LOOP FETCH c_cun INTO v_cun_code,v_cun_name; IF v_done = 1 THEN LEAVE cun_loop; END IF; INSERT INTO D_AREA(CODE_,PROVINCE_,CITY_,COUNTRY_,TOWN_,VILLAGE,CURR_CODE_) VALUES(v_cun_code,v_sheng_name,v_shi_name,v_xian_name,v_zhen_name,v_cun_name, v_cun_code); end LOOP cun_loop; CLOSE c_cun; -- 注意这里需要将v_done初始化,不然外层循环也将跳出 SET v_done=0; end LOOP zhen_loop; CLOSE c_zhen; SET v_done=0; end LOOP xian_loop; CLOSE c_xian; SET v_done=0; end LOOP shi_loop; CLOSE c_shi; SET v_done=0; end LOOP sheng_loop; CLOSE c_sheng;END 参考游标嵌套部分参考代码https://www.cnblogs.com/phao123/p/6006780.html]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>存储过程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用类加载器简单实现热部署]]></title>
    <url>%2F2019%2F09%2F19%2F%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0%E7%83%AD%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[用类加载器实现热部署如果你写过jsp,你会发现在修改jsp后并不需要重启服务器就能实现jsp页面的替换,jsp本质也是java代码,那它是如何实现不重启JVM实现热部署的呢?答案是类加载器. 实践在前面博客中已经简介过类加载器和双亲委托加载,当中提及java中的class文件只会加在一次,比如我创建的一个类A,在第一次实例A类时会在JAVA默认提供的AppClassLoader加载器中去加载A类,后续如果需要实例化A对象只需要调用加载器的loadClass方法其会去先调用findLoadedClass查找是否class文件以及被加载过,如果被加载过则直接读取,没有的话则通过调用子类实现的findClass的方法去读取加载class文件,由于我们这里想实现热部署,如果使用双亲委托就会导致我们的类每次都是从AppClassLoader中的findLoadedClass中读取堆中的class信息,这样做事无法实现热部署的,因为你每次变更的class并没有加载到堆中,于是我们需要突破双亲委派 1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); //子类负责实现findClass方法 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 突破双亲委派实现自己的类加载器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.liu;import java.io.IOException;import java.io.InputStream;/** * @author Liush * @description * @date 2019/9/18 11:07 **/public class Test &#123; public static void main(String[] args) throws Exception &#123; while (true) &#123; ClassLoader classLoader = new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; return super.loadClass(name); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; e.printStackTrace(); throw new ClassNotFoundException(name); &#125; &#125; &#125;; Class aClass = classLoader.loadClass(&quot;com.liu.A&quot;); Object o = aClass.newInstance(); Object o2 = new A(); //输出false System.out.println(o.getClass().isInstance(o2)); //输出AppClassLoader System.out.println(o.getClass().getClassLoader().getParent()); //调用test方法 o.getClass().getMethod(&quot;test&quot;).invoke(o); //如果不休眠会提示java.lang.ClassFormatError: Truncated class file(class文件被删除) System.out.println(); Thread.sleep(2000); &#125; &#125;&#125; A类 12345678910111213141516package com.liu;/** * @author Liush * @description * @date 2019/9/19 13:49 **/public class A &#123; public void test()&#123; System.out.println(&quot;old.......&quot;); &#125;&#125; 执行Test中的main方法输出 1234falsecom.liu.Test$1@3f99bd52sun.misc.Launcher$AppClassLoader@18b4aac2old....... 下面我们修改A类为 123456789101112131415package com.liu;/** * @author Liush * @description * @date 2019/9/19 13:49 **/public class A &#123; public void test()&#123; System.out.println(&quot;new.......&quot;); &#125;&#125; 重新编译A类为新的class文件(由于我使用的是IDEA,会自动编译所以这步我就省略了),打开控制台发现已经输出新的代码,但是我们并没有重启JVM,原因就是我们每次都是从新的ClassLoader去加载新的class文件. 123456789falsecom.liu.Test$1@3af49f1csun.misc.Launcher$AppClassLoader@18b4aac2old.......falsecom.liu.Test$1@31befd9fsun.misc.Launcher$AppClassLoader@18b4aac2new.......]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>类加载器</tag>
        <tag>热部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java类加载器]]></title>
    <url>%2F2019%2F09%2F19%2Fjava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[类加载器简介Kotlin,Scala等语言也是运行在JAVA虚拟机的语言,那为什么这些不是java的语言也能够运行在jvm虚拟机上呢?原因就是Class 文件,对虚拟机来说Class文件是一个重要的接口,无论使用何种语言进行软件开发，只要能将源文件编译为正确的 Class 文件，那么这种语言就可以在 Java 虚拟机上运行.可以说，Class 文件就是虚拟机的基石,而加载Class文件又是通过类加载器进行的. 类加载器的工作流程Class 文件通常是以文件的方式存在（任何二进制流都可以是 Class 类型），但只有能被 JVM 加载后才能被使用，才能运行编译后的代码。系统载入 Class 过程可以分为加载，链接和初始化三个步骤。其中，链接也可分为验证，准备和解析3步骤,其中，只有加载过程是程序员能够控制的，后面的几个步骤都是有虚拟机自动运行的。因此，我们的关注点主要放在加载阶段 类加载JVM第一次使用到这个类时需要对，这个类的信息进行加载。一个类只会加载一次，之后这个类的信息放在堆空间，静态属性放在方法区. 什么时候加载类 当创建一个类的实例是，比如使用 new 关键字，或者通过反射，克隆，反序列化。 当调用类的静态方法时，即当使用字节码 invokstatic 指令。 当使用类或接口的静态字段时（final 常量除外），比如，使用 getstatic 或者 pustatic 指令。 当时用 Java.lang.reflect 包中的方法反射类的方法时。 当初始化子类，要求先初始化父类。 作为启动虚拟机，含有 main（）方法的那个类。 类加载器的分类类加载器主要分为以下几类,除了启动类加载器外,其余扩展器都实现了ClassLoader类 启动类加载器（BootStrap ClassLoader），C++ 语言实现，虚拟机自身的一部分 启动类加载器主要加载${JAVA_HOME}/lib 目录中的包,负责加载JDK中的核心类库,如 rt.jar,我们是无法访问这个类加载器的如下代码 1System.out.println(String.class.getClassLoader()); 控制台中打印的是null,因为String为jdk的核心类由BootStrap ClassLoader加载,我们无法访问这个类加载器. 扩展类加载器 扩展类加载器有 sun.misc.Launcher$ExtClassLoader 实现，负责加载 /lib/ext 目录中的。或者被 java.ext.dirs 系统变量所指定的路径中的所有类库。 应用类加载器 sun.misc.Launcher$AppClassLoader 实现，由于这个类是 ClassLoader 中的 getSystemClassLoader 方法的返回值，也称为系统类加载器，负载加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器。一般情况下，这个就是程序中默认的类加载器。 自定义类加载器 自定义类加载器用于加载一些特殊途径的类，一般也是用户程序类。 类加载器的双亲委派模式 JVM为了保证同一个Class只被加载一次采用了双亲委派模式进行控制,因为同一个Class文件如果被不同类加载器加载那么他们就不是相同的一个类(如同一个类由应用类加载器加载,之后又由自定义类加载器加载,这两个类不是同一个类,即使他们的包名编写的代码时相同的,我们可以简单根据此简单的实现热部署,我们后续会介绍),那么什么是双亲委派模式呢?类加载器的层级关系是启动类加载器&gt;扩展类加载器&gt;应用类加载器&gt;自定义加载器,现在我们在程序中new了一个对象,那么它首先会调用findLoadedClass(name)方法去底层查找这个类时候已经加载(底层堆中),如果有就返回,如果没有就委托父类进行加载,如果父类可以加载则加载不行则退回到子类加载.比如我们自定义了一个A对象,在我们第一次调用new A()实例化对象时,它首先会去启动类加载器中寻找,因为启动类加载器只会加载${JAVA_HOME}/lib目录下的类所以无法加载A这个类,接下来由扩展类加载器(ExtClassLoader)进行加载,由于 其只会加载${JAVA_HOME}/lib/ext 目录下的类所以也不会进行加载,最后退回到应用类加载器(AppClassLoader)加载器,由于其加载用户类路径（ClassPath）上所指定的类库,而我们新建的对象在工程目录下,所以由此加载器完成加载 1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; //在启动类加载器(BootStrap ClassLoader)中查找类 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; loadClass（）、findClass（）、defineClass（）区别loadClass 源码如下其会先调用findLoadedClass去查找是否以及加载了class文件如果没有的话再委托双亲加载 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; findClass()这个方法为子类扩展方法,在ClassLoader中并没有对其进行具体的实现,预留出这个接口的我个人理解是,如果你不想突破双亲委派则只需要实现该方法即可,我们可以在loadClass方法中发现,其调用findClass了,如果我们想要使用默认的双亲委派功能去重新编写loadClass代码的话会产生大量冗余代码,所以开放出此接口来实现用户自定义的class加载方式,其通常会在最后调用defineClass去加载class文件,这个方法是父类中已经实现好的加载class文件的方法,至于为什么不突破双亲委派?举个例子:前文提到双亲委派模式加载类的先后顺序是,启动类加载器&gt;扩展类加载器&gt;应用类加载器&gt;自定义加载器,只有当父类加载不了这个类才由子类去实现,比如启动类加载器加载${JAVA_HOME}/lib目录下的类,如果采用双亲模式则这些类就无法通过扩展类加载器去加载,同理,我现在自定义了一个ClassLoader,如果我去实例化这个类的话,那么它会在应用类加载器(AppClassLoader)中去加载这个class文件,因为我编写的java文件路径是在工程目录下的,应用类加载器(AppClassLoader)有权去加载工程目录下的文件,那么我在调用以下代码时得到的是true,因为我调用new 方法去实例对象是使用应用类加载器(AppClassLoader)去构造对象的,而我通过自定义类加载器加载的(classLoader.loadClass(“com.liu.A”))class对象由于使用了双亲加载模式,其委托给了AppClassLoader去加载对象,这两个类都是使用同一个类加载器去生成对象,所以输出true,反之如果我重写loadClass方法,绕过双亲加载模式那么输出的就是false,,因为class虽然是同一个,但是我使用了不同的类加载器去加载class文件,java认定这两个对象不是相同的对象 1234Class aClass = classLoader.loadClass(&quot;com.liu.A&quot;);Object o = aClass.newInstance();Object o2 = new A();System.out.println(o.getClass().isInstance(o2)); 123protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name); &#125; definclass()把字节码转化为Class 我们现在编写代码来测试 12345678910public class Test &#123; public static void main(String[] args) &#123; ClassLoader classLoader=Test.class.getClassLoader(); System.out.println(classLoader);//获取应用类加载器 System.out.println(classLoader.getParent());//获取扩展类加载器 System.out.println(classLoader.getParent().getParent());//我们无法访问启动类加载器，当试图获取启动类加载器的时候，返回 null，因此，如果返回的是 null，并不意味没有类加载器为它服务，而是指哪个类为启动类加载器 System.out.println(String.class.getClassLoader());//证明String类由启动类加载器加载,由此可见无法找到类加载器那么这个类有可能是由启动类加载器完成加载的 &#125;&#125; 控制台打印出的代码为 1234sun.misc.Launcher$AppClassLoader@18b4aac2sun.misc.Launcher$ExtClassLoader@f6f4d33nullnull 注意 同一个类不能加载两次一个class文件(多次调用load方法),不然会报 attempted duplicate class definition for name:,所以如果用类加载器实现热部署需要每次都要创建一个新的类加载器,在热部署章节中会体现 参考资料本文部分内容参考 https://www.jianshu.com/p/85eba062b9c1]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>类加载器</tag>
        <tag>热部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bistoury非入侵式java生产环境诊断工具]]></title>
    <url>%2F2019%2F09%2F18%2Fbistoury%E9%9D%9E%E5%85%A5%E4%BE%B5java%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[简介 最近闲来无事逛github时发现bistoury,Bistoury是去哪儿网的java应用生产问题诊断工具，提供了一站式的问题诊断方案,可以在生产环境中实现非入侵式系统信息查看,包括堆栈信息,机器情况,在线调试,应用线程信息等. 下载首先去github中下载编译好的文件https://github.com/qunarcorp/bistoury/releases 准备 需要Linux环境 JDK1.8 本机 9090，9091，9880，9881 端口未被占用，这些端口会被 Bistoury 使用，如果已占用需要进行配置 以下为github中提供的快速开始说明快速开始Bistoury 具有多个模块，并且和公司自身环境有一定的关联，想要合理部署需要进行一些相关的配置。 为了能够快速启动和体验 Bistoury，我们提供快速部署脚本在单机部署整套 Bistoury 服务。 使用快速部署脚本，会在本机部署一整套 Bistoury 服务，其中包括 ui、proxy、agent。 注意，这里提供的快速部署脚本仅适用于快速上手进行单机诊断，想要获得完整的体验，还是需要进行合理的部署。 目前在我们公司内部的使用方式，也是推荐的部署方式为： ui 独立部署，推荐部署在多台机器，并提供独立的域名 proxy 独立部署，推荐部署在多台机器，并提供独立的域名 agent 需要和应用部署在同一台机器上。推荐在测试环境全环境自动部署，线上环境提供单机一键部署，以及应用下所有机器一键部署 独立的应用中心，管理所有功能内部应用和机器信息，这是一个和 Bistoury 相独立的系统，Bistoury 从中拿到不断更新的应用和机器信息 构建获取快速部署包 我们在项目 Release 页面提供了已经构建好的快速部署包，你也可以直接下载。 你也可以下载源码然后自己构建快速启动包，这同样很简单。首先 clone 项目到本地，运行 script/quick_start_build.sh，运行完成后 script 目录下会生成相应的快速部署包，名字格式为 bistoury-quick-start.tar.gz 准备 目前仅支持 Linux 环境，所以需要一个 Linux 环境 本机已安装 jdk1.8+，并且设置了 JAVA_HOME 环境变量，如果没有设置也可以在启动脚本中传递 -j 参数，详情见下文：启动参数 本机 9090，9091，9880，9881 端口未被占用，这些端口会被 Bistoury 使用，如果已占用需要进行配置，详情见下文：当端口冲突了怎么解决 本机已经启动一个待诊断 JAVA 应用，如果是 Spring Web 应用不需要做处理，非 Spring Web 应用需要配置启动脚本的 -c 参数，详情见下文：启动参数 启动首先我们将快速启动包 bistoury-quick-start.tar.gz 拷贝到想要安装的位置。 然后解压启动包： 12tar -zxvf bistoury-quick-start.tar.gzcd bistoury 最后是启动 Bistoury，因为 Bistoury 会用到 jstack 等操作，为了保证所有功能可用，需要使用和待诊断 JAVA 应用相同的用户启动。 假设应用进程 id 为 1024 如果应用以本人用户启动，可以直接运行 1./quick_start.sh -p 1024 start 如果应用以其它帐号启动，比如 tomcat，需要指定一下用户然后运行 1sudo -u tomcat ./quick_start.sh -p 1024 start 停止运行 1./quick_start.sh stop 访问可以通过 http://ip:9091 来对 ui 进行访问，比如部署的机器 ip 为 192.168.1.20，则可以通过 http://192.168.1.20:9091/ 访问，初始化用户名密码均为 admin 具体实施中遇到的问题websocket连接失败原因是本机可能存在多个ip，导致获取的ip不是当前正在使用的ip（获取到的ip可以在各个日志中查看，也可以在应用中心查看），从而出错， 可以通过quick_start.sh脚本中的-i参数指定当前的ip。 例子 : 1./quick_start.sh -i 127.0.0.1 -p 1024 start 提示 not find proxy for agent端口冲突,修改端口即可 端口 作用 1. 9880 agent和proxy通信默认使用9880端口 2. 9881 ui和proxy通信默认使用9881端口 3. 9090 proxy默认使用9090端口 4. 9091 ui默认使用9091端口 5. 9092 h2数据库默认使用9092端口 端口 端口定义的位置 9880 解压缩目录/bistoury-proxy-bin/conf/global.properties中的agent.newport值 9881 解压缩目录/bistoury-proxy-bin/conf/global.properties中的server.port值和quick_start.sh中PROXY_WEBSOCKET_PORT的值 9090 解压缩目录/bistoury-proxy-bin/conf/server.properties中的tomcat.port值和quick_start.sh中PROXY_TOMCAT_PORT的值以及bistoury-agent-bin/bin/bistoury-agent-env.sh中的BISTOURY_PROXY_HOST的值 9091 解压缩目录/bistoury-ui-bin/conf/server.properties中的tomcat.port值 9092 解压缩目录/h2/h2.sh中的H2_PORT值]]></content>
      <categories>
        <category>性能测试和监控</category>
      </categories>
      <tags>
        <tag>bistoury</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java应用在linux中性能和堆栈信息的排查]]></title>
    <url>%2F2019%2F09%2F18%2Fjava%E5%9C%A8linux%E4%B8%AD%E5%8D%A0%E7%94%A8%E8%B5%84%E6%BA%90%E8%BF%87%E5%A4%9A%E7%9A%84%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[####简介在线上环境中有时会遇到cpu等资源占用过多的资源我们可以使用top命令和jstack命令对问题进行排查 编写循环代码下面代码开启两个线程循环打印 1234567891011121314151617181920212223242526272829public class Test &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newFixedThreadPool(2); service.submit(new Runnable() &#123; @Override public void run() &#123; runTest(); &#125; &#125;); service.submit(new Runnable() &#123; @Override public void run() &#123; runTest(); &#125; &#125;); &#125; public static void runTest() &#123; while (true) &#123; System.out.println(1); &#125; &#125;&#125; 将代码发布到linux上并执行开启jar应用 1nohup java -jar test.jar &gt;/dev/null 2&gt;&amp;1 &amp; 使用top命令查看进程情况我们可以从命令中看到pid 19384占用了大量资源 1top 使用top命令查看线程情况从上一步我们得到进程pid,现在我们使用top命令查看进程pid下的线程 1top -Hp 19384 我们可以看到19436 和19437这两个线程占用了大量资源 使用jstack命令进行具体分析根据进程pid进行查询 1jstack -l 19437 我们由上面的top线程查询到19436和19437这两个线程占用了大量资源将其转化成16进制分别为4bec和4bed根据16进制的pid查询对应的nid,如图我们找到了pool-1-thread-2 这个线程名对应的nid为4bed,这个线程就是我们之前开启的一个线程,我们可以查看之中的堆栈信息发现其在runTest方法中持续执行,并且持续在执行io流(打印) 通过thread dump分析线程状态 除了上述的分析，大多数情况下会基于thead dump分析当前各个线程的运行情况，如是否存在死锁、是否存在一个线程长时间持有锁不放等等。在dump中，线程一般存在如下几种状态： RUNNABLE，线程处于执行中 BLOCKED，线程被阻塞 WAITING，线程正在等待 问题在实际调试中这两个线程无法并发执行,始终都是一个线程为RUNNABLE,一个为BLOCKED,但是实际代码并未加锁,根据堆栈打印出的信息线程中是在io流中加了锁 1locked &lt;0x0000000085c3d2e0&gt; (a java.io.OutputStreamWriter) 于是查看System.out.println(“ “)的源代码,可以看出源码中打印代码时加了锁的,所以导致两个线程无法并发 123456public void println(String x) &#123; synchronized (this) &#123; print(x); newLine(); &#125; &#125; 系统资源监控命令 vmstat iostat]]></content>
      <categories>
        <category>性能测试和监控</category>
      </categories>
      <tags>
        <tag>top</tag>
        <tag>jstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C2 CompilerThread1]]></title>
    <url>%2F2019%2F09%2F18%2Fjava-%E5%B8%B8%E8%A7%81%E7%BA%BF%E7%A8%8B%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[C2 CompilerThread1 线程 C2 Compiler 线程 是JVM在server模式下字节码编译器，JVM启动的时候所有代码都处于解释执行模式，当某些代码被执行到一定阈值次数，这些代码(称为热点代码)就会被 C2 Compiler编译成机器码，编译成机器码后执行效率会得到大幅提升。流量进来后，大部分代码成为热点代码，这个过程中C2 Compiler需要频繁占用CPU来运行，当大部分热点代码被编译成机器代码后，C2 Compiler就不再长期占用CPU了，这个过程也可以看作抖动。解决C2 CompilerThread1抖动方法,可以使用Jmeter等压测工具模拟线上访问流量，让C2 Compiler预先将热点代码编译成机器码, 减少对正式环境流量的影响。]]></content>
      <categories>
        <category>性能测试和监控</category>
      </categories>
      <tags>
        <tag>java常见线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见线程说明]]></title>
    <url>%2F2019%2F09%2F18%2F%E5%B8%B8%E8%A7%81%E7%BA%BF%E7%A8%8B%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch单节点安装]]></title>
    <url>%2F2019%2F09%2F11%2Felasticsearch%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[下载下载elasticsearch 6.8.2版本 解压目录tar -xvf 文件路径 开启服务$ ./bin/elasticsearch &amp; max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 问题 1234567#切换到root用户修改vim /etc/security/limits.conf# 在最后面追加下面内容*** hard nofile 65536*** soft nofile 65536*** 是启动ES的用户 root无法启动问题 123root用户无法启动elasticsearch,切换至其他用户并执行chown -R 文件目录 用户修改目录权限 非本机无法访问rest服务 12修改 config/elasticsearch.yml 修改以下标签为值network.host: 0.0.0.0]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小型项目领域驱动设计实践]]></title>
    <url>%2F2019%2F09%2F05%2F%E5%B0%8F%E5%9E%8B%E9%A1%B9%E7%9B%AE%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[前言 前面已经简介过领域驱动的基本概念，前文介绍的COLA框架在大型项目或者微服务架构中目测有较好的实践，但是对于一个中小项目或者小公司来说管理大量依赖包模块简直就是噩梦，或者就是项目达不到那种规模，采用分包模式也是一种浪费，但是采用领域驱动设计在本人实践过程中确实大大提升了代码质量，最主要的改善就是使开发人员不再以数据库驱动开发，而是真正的开始从业务和领域入手，这样开发出的代码往往能更好的实现面向对象，将代码划分出边界，使代码的可读性更强，代码更加健壮。本文结合现实中使用领域驱动设计时遇到的问题进行了总结，如果错误还需海涵。 项目说明 本文代码存放在 https://github.com/liushprofessor/ddd-demo 中 关于领域驱动设计的基础概念可查看本人个人博客中关于领域驱动部分，另外这纯属个人在实践中的总结，如有错误欢迎拍砖指导。 本项目主要有3个大包分别包含3次不同的实践，实践的具体内容如全文所述 user 为第一次实践包含各种模型设计和简介 user2 正对user包下存在的一些问题做了一些优化设计，请查看全文来看具体说明 project 为了针对实际项目中出现的大聚合来做的一些设计，这个包下只建立了模型设计，其余部分如果感兴趣可以自己补充(其实就是本人偷懒) 使用方法如果你使用的是mysql数据库那么修改application.properties中的数据源即可，liquibase会自动将所需要的表建立完毕 分包 和COLA框架采用模块不同，我采用一个项目下分不同的包的模式来区分领域设计的各个模块项目结构如下 demo └─com └─liu └─demo ├─app 客户端服务代码 ├─controller 控制层代码 ├─domain 领域层 │ ├─client 领域层防腐对象 │ └─modal 领域模型 └─infrastructure 基础层 ├─repository 仓库 │ └─mapper mybatis持久包 └─serviceimpl 领域服务包 app包：客户端代码存放的地方，负责组装调用领域模型，仓库，控制事务，对应六边形架构的应用服务层 controller包: 控制层代码，我用SpringMVC实现，对应六边形架构的输入适配器 domain包: 为项目中最核心的领域模型相关类存放的地方，对应六边形架构的领域(domain)层,另外在此根目录下会存放领域服务的接口，该接口由基础设施层去实现，因为领域层是最核心的层，根据六边形架构领域层需要放在最里层，但是领域服务却有需求调用基础设施层(infrastructure)下的仓库(repository),因此在这个层中定义一个接口由infrastructure层去实现，实现依赖倒置。 client包: 我创建此包是为了反腐，为了不使领域模型外泄，有效的控制代码的边界访问而设立，举例在http协议调用中dto对象从controller层到app层，当要进入到领域层（domain）时必须将其转化成领域模型，同样数据持久化在数据库中，从数据库中直接查找到的数据对象和领域对象同样存在差异，因此需要对外创建一个过渡对象提供给基础设施层调用，也许很多人会对这些对象放在domain层有疑问，但是我认为外部数据的访问领域对象数据的范围和权限是由领域模型去控制的，因此我觉得将其放在领域(domain)包中和适合的。 modal此包主要存放实体(Entity)，值对象(VO),生成领域模型的工厂方法,领域对象验证类. infrastructure基础设施层：主要存放基础设施的地方，比如数据库持久化，调用外部服务，队列等 repository仓库，对持久化的抽象，屏蔽数据库对象生成领域对象，领域对象从创建开始就已经开始生命周期，一直到删除才结束，中间会把领域对象存储在数据库中，存储在数据库时领域对象仍然处于生命周期，因此仓库层的作用就是屏蔽持久层，让调用者觉得领域对象一直存在内存中一样. mapper 由于我使用的是mybatis，所以我创建此层建mybatis的类放在此 serviceimpl 领域服务包，同样有很多人可能会有疑问为什么我讲领域服务的实现类放在基础设施层中，这一点我上面提过，为了实现依赖导致，只要是领域服务的接口存放在领域层(domain)那么我们仍然认为领域服务属于领域层，因为接口规定了领域服务的功能和方法。 建模 在这里我们假设我们和业务方沟通需要实现这样的功能,用户可以有自己的基础信息，这些信息包括用户名，email地址，且用户可以根据用户id和密码登录系统，且用户可以单独修改登录密码，也可以修改用户信息,根据需求分析我们可以得出用户有一个唯一型标识用户id，因此我们得出用户是实体，用户名和email这两个属性对用户来说并不需要维护状态的变化，修改时候为了简单将其整个对象替换即可，因此我们将其设计成值对象VO,由于用户可以单独修改密码因此修改密码对应前端一个单独入口，所有我们将密码这个属性放在用户对象中，因此我们得到以下模型,实体对象UserE中有一个修改用户的方法，只有一个构造方法，并且可以进行密码验证和获取用户基础信息，注意这里并没有set方法，而是用了类似changePassword等方法名代替set方法，这是为了使领域模型充血，为了使模型更好的体现业务，如果使用set修改密码的话，那我们怎么和业务人员解释修改密码这个方法？难道说我set了密码？这明显无法表示出领域对象的意图，反之将其命名changePassword修改密码那么就可以很好的表示出领域模型的意图，领域方法名需要表示出领域和业务的意图。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859 public class UserE &#123; private String userId; private String password; private BaseInfoVO baseInfo ; /** * 修改用户密码 */ public void changePassword(String password)&#123; if(password==null)&#123; throw new IllegalArgumentException(&quot;密码不能为空&quot;); &#125; this.password=password; &#125; public UserE(String userId, String password, BaseInfoVO baseInfo) &#123; this.userId = userId; this.password = password; this.baseInfo = baseInfo; &#125; public String getUserId() &#123; return userId; &#125; public String getPassword() &#123; return this.password; &#125; /** * 认证服务，查询传入密码是否匹配 * @param password 需要认证的密码 * @return 认证结果 */ public boolean authentication(String password) &#123; return password != null &amp;&amp; password.equals(this.password); &#125; public BaseInfoVO getBaseInfo() &#123; return baseInfo; &#125; /** * 修改用户基础信息 */ public void changeInfo(BaseInfoVO baseInfoVO)&#123; this.baseInfo=baseInfoVO; &#125;&#125; 下面是BaseInfoVO为用户的基础信息,同样我们也没有暴露set方法,由于它只是一个用户的值对象，因此并没有那么多的领域方法,至此我们的核心领域对象就已经建立完成了 123456789101112131415161718192021222324252627282930/** * @author Liush * @description 用户基础信息 * @date 2019/9/5 9:48 **/public class BaseInfoVO &#123; private String username; private String email; public BaseInfoVO(String username, String email) &#123; if(username==null)&#123; throw new IllegalArgumentException(&quot;用户名不能为空&quot;); &#125; if(email==null)&#123; throw new IllegalArgumentException(&quot;邮箱不能为空&quot;); &#125; this.username = username; this.email = email; &#125; public String getUsername() &#123; return username; &#125; public String getEmail() &#123; return email; &#125;&#125; 现在让我们考虑如何新增一个用户，创建用户对应领域模型就是创建一个用户实体(UserE),那我们如何做到将领域层的模型信息不外泄到其它地方呢?因为新增用户也属于领域（业务的一部分），举个例子我们去银行开个户也要到银行才能办理，我们不能到公安局去开银行账户，所以我们把创建用户对象放在领域层，而创建用户实体(UserE)有两种方法，一种是直接调用其构造，一种是通过工厂类来创建，但是这里又会出现一个问题，用户实体(UserE)需要一个BaseInfoVO（基础信息）来构造，但是按照领域驱动设计的理念来设计BaseInfoVO（基础信息）只能有领域在领域层中才能去创建，因为我们的通用语言是用户创建和修改了基础信息，如果我们将BaseInfoVO（基础信息）放在领域层外创建就好比一句话少了主语。我采用在领域层中使用工厂类去创建用户实体(UserE)，在工厂方法中传入一个DTO来隔离领域层外部的信息，代码如下,其创建了一个用户实体(UserE)并且使用UUID分配了一个默认的用户ID给用户，最后调用用户实体(UserE)的构造方法去创建用户实体对象，执行完这一行代码，一个用户对象就已经进入了生命周期，直到在数据库中删除或者将用户状态改成不可能用这个用户的生命周期才结束。 123456789101112131415161718192021package com.liu.demo.user.domain.modal;import com.liu.demo.user.domain.client.UserDTO;import org.springframework.stereotype.Component;import java.util.UUID;/** * @author Liush * @description 领域工厂类 * @date 2019/9/5 14:10 **/@Componentpublic class UserFactory &#123; public UserE createUser(UserDTO userDTO )&#123; BaseInfoVO baseInfoVO=new BaseInfoVO(userDTO.getUsername(),userDTO.getEmail()); return new UserE(UUID.randomUUID().toString(),userDTO.getPassword(),baseInfoVO); &#125;&#125; 持久化现在是时候考虑用户对象持久化的问题了，毕竟用户对象不能永远存留在内存中，必须在不使用对象时将其持久化到硬盘中基础设施层包infrastructure下的repository就是为了解决这个问题,它的作用是屏蔽数据库持久化的一些代码，让代码看起来更贴近领域设计一些，我们可以从仓库中根据查找条件直接还原出一个用户实体对象，对领域代码来说数据库持久化代码就好像不存在一样，下面是用户仓库代码,这里注意一下一个方法findUsersByName，这是一个查询方法，从数据库中查询出UserPO然后将其转成UserDTO，这里我们看到我们并没有走领域模型，因为查询往往为了效率特别是批量查询我们做了一部分妥协，但是这部分妥协是可以接受的，因为我们并没有执行领域动作(command)的代码，只是返回一个dto对象给前端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.liu.demo.user.infrastructure.repository;import com.liu.demo.user.domain.client.UserDTO;import com.liu.demo.user.domain.client.UserPO;import com.liu.demo.user.domain.modal.UserE;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Repository;import com.liu.demo.user.infrastructure.repository.mapper.UserMapper;import java.util.ArrayList;import java.util.List;/** * @author Liush * @description 用户仓库 * @date 2019/9/5 11:17 **/@Repositorypublic class UserRepository &#123; @Autowired private UserMapper userMapper; @Autowired private UserRepositoryConvert userRepositoryConvert; /** * 根据用户id查找用户 */ public UserE findUser(String userId)&#123; UserPO userPO =userMapper.findUser(userId); return userRepositoryConvert.convertToUserE(userPO); &#125; /** * 添加用户 */ public void addUser(UserE user)&#123; UserPO userPO= userRepositoryConvert.convertToUserPO(user); userMapper.insertUser(userPO); &#125; /** * 修改密码 */ public void changePassword(UserE userE)&#123; userMapper.updateUserPassword(userE.getUserId(),userE.getPassword()); &#125; /** *根据用户姓名批量查询，查询可以不走领域模型 */ public List&lt;UserDTO&gt; findUsersByName(String name)&#123; List&lt;UserPO&gt; userPOs=userMapper.findUsersByName(name); List&lt;UserDTO&gt; userDTOs=new ArrayList&lt;&gt;(); if (userPOs==null)&#123; return userDTOs; &#125; userPOs.forEach(userPO-&gt;userDTOs.add(userRepositoryConvert.convertToUserDTO(userPO))); return userDTOs; &#125;&#125; 领域服务下面考虑一下这个问题，修改密码，我们在修改密码时一般都会调用远程接口，比如获取短信验证码和校验验证码，这部分放在用户实体中是不合适的，但是远程调用短信接口这部分代码又属于基础设施层的内容，但是在提供给app层调用的时候我们又不想把这部分属于业务逻辑暴露给app层，因为由app层去组装的话，那么开发app层的人员就需要知道业务的流程，他必须知道修改密码内部的流程走向（调用短信验证接口），我们想做的就是客户端开发人员只要调用一个修改密码的方法就好了，至于里面执行什么业务逻辑客户端开发人员不要操心，所以我们采用领域服务去封装修改密码的业务，由客户端开发人员去调用领域服务来屏蔽业务的细节，那么现在就会产生这样一个问题，领域层要依赖基础设施层，但是这样是有悖于六边形架构的（领域层应该放在依赖的最内部），于是我们使用依赖倒置技术，在领域层中创建一个领域服务接口，由基础设施去实现，这样就实现了基础设施层依赖领域层，但是领域层又通过接口对基础设施层领域服务可以做什么做了规定和约束。下面是领域层中的领域服务接口的定义，它提供了一个修改密码的接口 123456789101112package com.liu.demo.user.domain;/** * @author Liush * @description 用户领域服务 * @date 2019/9/5 11:07 **/public interface UserServiceI &#123; void changePassword(String userId,String password);&#125; 下面由基础设施层去实现这个接口 123456789101112131415161718192021222324252627package com.liu.demo.user.infrastructure.serviceimpl;import com.liu.demo.user.domain.UserServiceI;import com.liu.demo.user.domain.modal.UserE;import com.liu.demo.user.infrastructure.repository.UserRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/*** @author Liush* @description User领域服务* @date 2019/9/5 11:12**/@Servicepublic class UserServiceImpl implements UserServiceI &#123; @Autowired private UserRepository userRepository; @Override public void changePassword(String userId, String password) &#123; //执行短信验证代码这边省略 UserE user =userRepository.findUser(userId); user.changePassword(password); userRepository.changePassword(user); &#125;&#125; 现在由APP层去调用修改密码 123public void changePassword(String userId,String password)&#123; userServiceI.changePassword(userId,password); &#125; 关于client二方包的思考在我最开始接触领域设计的时候这些二方包我是没有放在领域模型层里的，当时我会创建一个common包，把这些东西放在common包下，当时随着理解的深入，我认为领域驱动最核心的内容之一就是边界的划分，边界的划分就以为着可以由不同开发者去开发不同的模块(比如一个人去开发领域模型，一个人去开发app层负责组装),如果我们把写代码放在common包中，那么app层开发人员就要去建立自己的领域防腐模型(DTO,PO等)，这样一定程度上也将领域模型的内容泄露出去，与其让客户端开发人员去编写防腐代码，比如有领域层开发人员去设计这部分代码，规定领域层的输入和输出，当然还包括一些领域层和防腐层对象的装换比如示例代码中提供的UserConvert对象装换类其实现如下,这样即让领域层代码不外泄，也很好的把控客户端可以访问什么属性。 1234567891011121314151617181920package com.liu.demo.user.domain.client;import com.liu.demo.user.domain.modal.UserE;import org.springframework.stereotype.Component;/** * @author Liush * @description 转换类 * @date 2019/9/5 14:52 **/@Componentpublic class UserConvert &#123; public UserDTO convertToUserDTO(UserE userE)&#123; String username=userE.getBaseInfo().getUsername(); String email=userE.getBaseInfo().getEmail(); return new UserDTO(userE.getUserId(),userE.getPassword(),username,email); &#125;&#125; 更进一步上诉代码在一般小项目中其实也已经够用，但是眼尖的同学可能会发现存在两个问题 用户实体(UserE)中的changePassword方法是暴露给客户端的，客户端人员在APP层可以直接获取UserE对象然后绕过领域服务去修改密码，这样就不要去验证短信服务等接口了，这样做明显是不符合业务逻辑的。 实体的整体验证，上面代码用户实体(UserE)只对单个属性进行验证比如属性是否为空，但是有些实体对象存在整体验证，比如用户实体(UserE)中如果业务规定密码和邮箱都必须以数字开头怎么办？ 这一节将着手解决这个问题，这部分代码在user2包下 首先我们解决第一个问题，我们创建了一个用户抽象类,这个抽象类并没有修改密码的方法，它只暴露了客户端可以调用的代码 123456789101112131415161718192021222324252627282930313233343536package com.liu.demo.user2.domain.modal;import com.liu.demo.user2.common.DoNothingValidateHandler;import com.liu.demo.user2.common.ValidateHandlerI;/** * @author Liush * @description * @date 2019/9/5 15:27 **/public abstract class UserAbstract &#123; protected String userId; protected String password; protected BaseInfoVO baseInfo ; protected ValidateHandlerI validateHandlerI; public UserAbstract(String userId, String password, BaseInfoVO baseInfo) &#123; this.userId = userId; this.password = password; this.baseInfo = baseInfo; this.validateHandlerI=new DoNothingValidateHandler(); &#125; public abstract boolean authentication(String password); public abstract BaseInfoVO getBaseInfo(); public abstract String getUserId();&#125; 然后我们实现这个类，子类中包行了changePassword方法， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.liu.demo.user2.domain.modal;/** * @author Liush * @description 用户实体类 * @date 2019/9/5 9:47 **/public class UserE extends UserAbstract &#123; public void changePassword(String password)&#123; if(password==null)&#123; validateHandlerI.handlerError(&quot;密码不能为空&quot;,new IllegalArgumentException()); &#125; this.password=password; &#125; /** * 构造完实体后对实体进行整体验证 */ public UserE(String userId, String password, BaseInfoVO baseInfo) &#123; super(userId,password,baseInfo); new UserValidate(this).validate(); &#125; public String getUserId() &#123; return super.userId; &#125; public String getPassword() &#123; return super.password; &#125; /** * 认证服务，查询传入密码是否匹配 * @param password 需要认证的密码 * @return 认证结果 */ public boolean authentication(String password) &#123; return password != null &amp;&amp; password.equals(this.password); &#125; public BaseInfoVO getBaseInfo() &#123; return baseInfo; &#125;&#125; 现在我们在所有返回给客户端代码中的返回用户实体对象不再是UserE而是UserAbstract,如repository包下的repository对象，这样客户端就不能直接通过用户实体去修改密码，而不需通过领域服务去修改密码，而在对应的领域层代码或者基础设施代码中完成一次对象的装换即可（将UserE转成UserAbstract） 123456789101112131415161718192021222324252627282930313233343536373839package com.liu.demo.user2.infrastructure.repository;import com.liu.demo.user2.domain.client.UserPO;import com.liu.demo.user2.domain.modal.UserE;import com.liu.demo.user2.domain.modal.UserAbstract;import com.liu.demo.user2.infrastructure.repository.mapper.UserMapper2;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Repository;/** * @author Liush * @description 用户仓库 * @date 2019/9/5 11:17 **/@Repositorypublic class UserRepository2 &#123; @Autowired private UserMapper2 userMapper; @Autowired private UserRepositoryConvert2 userRepositoryConvert; public UserAbstract findUser(String userId)&#123; UserPO userPO =userMapper.findUser(userId); return userRepositoryConvert.convertToUserE(userPO); &#125; public void addUser(UserAbstract user)&#123; UserPO userPO= userRepositoryConvert.convertToUserPO((UserE) user); userMapper.insertUser(userPO); &#125;&#125; 第二个问题解决方法这次我们定义了一个common包下面有两个基类ValidateAbstract（验证抽象类）,此类为实体整体验证的一个基类，其构成方法中需要传入一个验证处理器，这个处理器的作用是为了如过验证类整体验证失败则调用验证处理器完成错误信息处理，这样做的目的是为了可以将验证和异常处理做解耦，同样在没有参数的构造方法中体用了一个默认的验证处理器 1234567891011121314151617181920212223242526package com.liu.demo.user2.common;/** * @author Liush * @description 验证抽象类 * @date 2019/9/5 17:11 **/public abstract class ValidateAbstract &#123; protected ValidateHandlerI validateHandlerI; public ValidateAbstract(ValidateHandlerI validateHandlerI) &#123; this.validateHandlerI = validateHandlerI; &#125; public ValidateAbstract() &#123; this.validateHandlerI=ValidateHandlerFactory.doNothingValidateHandler(); &#125; public abstract void validate(); public void setValidateHandlerI(ValidateHandlerI validateHandlerI) &#123; this.validateHandlerI = validateHandlerI; &#125;&#125; 用户实体整体验证类实现 1234567891011121314151617181920212223242526272829303132333435package com.liu.demo.user2.domain.modal;import com.liu.demo.user2.common.ValidateAbstract;import com.liu.demo.user2.common.ValidateHandlerI;import org.springframework.util.StringUtils;/** * @author Liush * @description * @date 2019/9/5 17:24 **/public class UserValidate extends ValidateAbstract &#123; protected UserE userE; public UserValidate(UserE userE) &#123; super(); this.userE=userE; &#125; public UserValidate(UserE userE,ValidateHandlerI validateHandlerI) &#123; super(validateHandlerI); this.userE=userE; &#125; @Override public void validate() &#123; if(StringUtils.isEmpty(userE.getPassword()) &amp;&amp; StringUtils.isEmpty(userE.getBaseInfo().getUsername()))&#123; super.validateHandlerI.handlerError(&quot;密码和用户名不能同时为空&quot;,new RuntimeException(&quot;UserE对象整体验证失败&quot;)); &#125; &#125;&#125; 验证处理器 123456789101112package com.liu.demo.user2.common;/** * @author Liush * @description 验证错误处理器 * @date 2019/9/5 17:03 **/public interface ValidateHandlerI &#123; void handlerError(String message,Exception e);&#125; 一个默认实现的验证处理器 1234567891011121314151617181920212223package com.liu.demo.user2.common;/** * @author Liush * @description * @date 2019/9/5 17:05 **/public class DoNothingValidateHandler implements ValidateHandlerI &#123; @Override public void handlerError(String message,Exception e) &#123; System.out.println(message); if(e instanceof IllegalArgumentException)&#123; throw new IllegalArgumentException(message); &#125; if(e instanceof RuntimeException)&#123; throw new RuntimeException(message); &#125; &#125;&#125; 下面我们进行代码整合，你会发现现在再用户实体(UserE)的构造中最后多了一行代码 1234567/** * 构造完实体后对实体进行整体验证 */ public UserE(String userId, String password, BaseInfoVO baseInfo) &#123; super(userId,password,baseInfo); new UserValidate(this).validate(); &#125; 在创建用户实体(UserE)时会进行整体验证，如果不通过就抛出异常此处这两个问题解决完毕 大聚合对象在实际实践过程中遇到过一些大聚合对象，什么是大聚合对象？举个例子，现在有这么一个业务，一个软件项目，下面有成败上千的子项目，子项目都必须在父项目中创建，如果我们按照原始的设计那么代码就会变这样,这样做有什么不妥呢？比如我们以后想查看工程的名字或者修改，那么我们就必须加载整个工程的子项目，如果子项目较小，这样设计也是可以接受的，但是如果子项目有成千上万个，那么这样做有些浪费资源，而且我只是单纯的修改工程名，和子项目并没有什么关联 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.liu.demo.project.domain.modal;import java.util.Date;import java.util.List;/** * @author Liush * @description 项目旧模型 * @date 2019/9/6 10:59 **/public class ProjectEOld &#123; //项目ID private String projectId; //项目名 private String name; //项目开始日期 private Date beginDate; //子项目 private List&lt;ItemE&gt; items; public ProjectEOld(String projectId, String name, Date beginDate, List&lt;ItemE&gt; items) &#123; this.projectId = projectId; this.name = name; this.beginDate = beginDate; this.items = items; &#125; //创建子项目 public void createItem(ItemE itemE)&#123; items.add(itemE); &#125; public String getProjectId() &#123; return projectId; &#125; public String getName() &#123; return name; &#125; public Date getBeginDate() &#123; return beginDate; &#125; public List&lt;ItemE&gt; getItems() &#123; return items; &#125;&#125; 于是我们退而求次改建模型,我们现在创建了两个模型ProjectE，ItemE我们现在将这两个实体分开，ProjectE不再包含ItemE集合，在ItemE我们加入了一个属性projectId和父工程做关联，需要注意的是为了凸显领域和我们的模型是对应的我们在ProjectE中有一个createItem的方法，这个方法符合领域描述子项目是在工程中创建的，也许你们有疑问这样在视图展示方法是不是很不方便？（比如我要一次查找工程名字和工程下面所有的子项目列表），这一点我在上文已经说过，在领域设计中查询和命令是可以做分离的，查询设计可以不走领域模型. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.liu.demo.project.domain.modal;import java.util.Date;/** * @author Liush * @description 工程实体 * @date 2019/9/6 10:49 **/public class ProjectE &#123; //项目ID private String projectId; //项目名 private String name; //项目开始日期 private Date beginDate; /** *由于工程子项目属于工程，按照通用语言，工程子项目要由工程去穿件，这样保证了领域和业务模型的统一性 */ public ItemE createItem(String itemId,String name)&#123; return new ItemE(itemId,name); &#125; public ProjectE(String projectId, String name, Date beginDate) &#123; this.projectId = projectId; this.name = name; this.beginDate = beginDate; &#125; public String getProjectId() &#123; return projectId; &#125; public String getName() &#123; return name; &#125; public Date getBeginDate() &#123; return beginDate; &#125;&#125; 子项目模型 1234567891011121314151617181920212223242526272829303132333435package com.liu.demo.project.domain.modal;/** * @author Liush * @description 项目实体 * @date 2019/9/6 10:49 **/public class ItemE &#123; //工程id private String projectId; //项目实体 private String itemId; //项目名 private String name; public ItemE(String itemId, String name) &#123; this.itemId = itemId; this.name = name; &#125; public String getItemId() &#123; return itemId; &#125; public String getName() &#123; return name; &#125; public String getProjectId() &#123; return projectId; &#125;&#125; 总结使用了领域驱动设计是一个长期过程，随着业务的变化原来的模型可能不再适用，或者有一天觉得原来的模型并不合理，这些都是非常常见的现象，领域驱动设计的另一个核心就是不断重构来创造出合适的模型，没有什么所谓银弹，只有不断摸着石头过河才能构建出好的设计。最后说一点在现实生活中肯定会有一些设计和需求的矛盾，比如客户坚持要批量新增而且又要快速响应怎么办？领域设计可能会影响一部分效率，但是什么才是慢？我觉得的在合理时间内就不算是慢，比如采用过程化开发调用一个接口的响应速度是1秒，采用领域驱动设计是1.1秒那我觉得这个慢是可接受的，并不影响用户体验，但是这0.1秒换来的是代码设设计的清晰，我觉得这是一笔稳赚不赔的买卖，最后再次声明，没有所谓的银弹，世界上没有完美的事，代码一样，人生也一样，不要和甲方爸爸过不去，因为他是你的爸爸。]]></content>
      <categories>
        <category>领域驱动设计(DDD)</category>
      </categories>
      <tags>
        <tag>领域驱动设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis的缓存机制]]></title>
    <url>%2F2019%2F09%2F04%2Fmybatis%E7%9A%84%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[缓存简介 一级缓存 会话缓存 mybatis对应sqlsession，对应于一个连接 二级缓存 应用缓存，不同会话也可访问统一缓存 mybatis对应namespace 三级缓存 跨jvm 如redis mybatis缓存实践 spring事务有四个等级，在mysql inndbn内核中默认采用可重复读（两个事务同时处理一条数据 一个事务更新了，在另一个事务中读取到的仍然是旧的值），mybatis中默认开启一级缓存，如果事务等级低于可重复读 那么在两个事务同时操作一条记录中如（@Transactional( isolation =Isolation.READ_COMMITTED )），一个 事务修改另一个事务就会看见该修改，但是mybatis默认会在当前事务中从缓存中读取，需要手动调用sqlSession.clearCache(); 或者在xml select标签中加上 flushCache=”true”读取时刷新缓存，如果采用java编码方式则加上@Options(flushCache =Options.FlushCachePolicy.TRUE )注解读取时刷新mybatis缓存 在Spring中只有同一锁中读取数据才能用到一级缓存，因为同一锁中使用的是sqlSession是同一个实例对象，如果两次调用是获取不同的sqlSession,所以一级缓存无效,同样因为sqlsession不同所以update也无法对一级缓存进行刷新,另外尽量不要对mybatis返回的对象进行操作，因为返回的对象是缓存在一级缓存中的，改变返回对象一级缓存中的对象也会改变 二级缓存是基于namespqce的缓存（xml中 中的namespace）， 所有对于一张表的操作都需要放在一个namespace中，这样保证更新或者insert操作后后二级缓存可以更新，不然会导致 脏读（在另一个namespace中操作后二级缓存没更新，因为没在用一个namespace下），xml开启二级缓存在xml中添加即可， 注解版开启二级缓存在mapper接口上添加@CacheNamespace(blocking = true)]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[COLA-复杂项目领域驱动设计框架源码和架构解析]]></title>
    <url>%2F2019%2F09%2F04%2FCOLA-%E5%A4%8D%E6%9D%82%E9%A1%B9%E7%9B%AE%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%92%8C%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[COLA简介 可自行到github上查看md简介 https://github.com/alibaba/COLA 目录结构分析COAL提供了一个很方便的maven生成模板，按照项目说明我们生成一个web项目，打开目录我们发现如下几个子模块 父项目 └── start 项目启动模块 └── app 项目应用服务模块（可以理解为客户端程序员在此编写代码） └── client 提供给客户端程序员使用的二方包，为应用服务模块提供一下基础类 └── controller 控制层SpringMVC实现 └── domain 领域层 └── infrastructure 基础设施层，包含数据库持久化，一些其它基础设施调用代码放在此，如RPC调用，队列调用等基础设施代码其项目依赖目录如下start依赖controller，controller依赖app，app同时依赖client和infrastructure，infrastructure依赖domain start └── controller └── app ├── client ├── infrastructure └── domain从依赖中我们明显可以看到前文提到的六边形架构的影子，controller为输入端适配器，infrastructure为持久化输出适配器，而核心服务domain领域层作为软件的核心和最稳定的部分放在依赖的最底层 结合领域驱动设计分析目录结构从目录结构当中划分其实这个框架应该分为两部分，app层之下（不包括）为领域部分，这部分由对领域知识理解较好的开发人员去建模，而app层（包括）之上则为客户端代码，可以由对领域知识不那么了解的开发人员去开发，作者之所以引入client模块一方面是提供了一些二方包和接口功能客户端调用，最主要的原因是反腐，为了反腐在client包中引入DTO，为了读写分离（在领域驱动中这点很重要）又有Command和Query两个实现类，以此完成写命令和读命令的区分，因为在写命令中需要完全遵守领域模型去完成，但是在查询中往往为了响应速度等的妥协而放弃领域模型，直接从基础设施层中读取查询对象返回给前端. 应用框架方面提供了一些注解如示例中的@Command注解,其需要作用在CommandExecutorI的实现类下，这部分内容放在app层代码由客户端人员去实现，这样可以将客户端的业务逻辑放在CommandExecutorI接口规定的方法下，客户端逻辑更加清晰，一个@Command代表着一个客户单操作，每个客户端操作的代码又放在不同的CommandExecutorI实现类下，而框架显示的将操作分为查询操作和命令操作来实现读写分离，实现了各个功能模块的解耦。 client包作为约束客户端（APP）层的重要模块，其下面定义了一个CustomerServiceI接口，此结构的实现类由app层去实现，这种依赖反转的方式很好的控制了app端能做什么也简化了开发。 domain包为领域开发人员所使用的包，领域开发人员将设计的领域模型都放在此提供app层和infrastructure层去调用 infrastructure包可以由数据库开发人员去实现，里面包含领域对象持久化内容和一些基础服务，并且其提供了一个SpringBean的配置文件负责整合了框架 核心源码解析在demo app层中我们发现了被@Command注解的实现类 123456789101112@Commandpublic class CustomerListByNameQryExe implements QueryExecutorI&lt;MultiResponse&lt;Customer&gt;, CustomerListByNameQry&gt; &#123; @Override public MultiResponse&lt;Customer&gt; execute(CustomerListByNameQry cmd) &#123; List&lt;Customer&gt; customerList = new ArrayList&lt;&gt;(); Customer customer = new Customer(); customer.setCustomerName(&quot;Frank&quot;); customerList.add(customer); return MultiResponse.ofWithoutTotal(customerList); &#125;&#125; 在app服务类调用中仅仅是将customerListByNameQry对象发送给CommandBusI（CommandBus总线）即完成调用 1234567891011121314151617@Servicepublic class CustomerServiceImpl implements CustomerServiceI &#123; @Autowired private CommandBusI commandBus; @Override public Response addCustomer(CustomerAddCmd customerAddCmd) &#123; return (Response)commandBus.send(customerAddCmd); &#125; @Override public MultiResponse&lt;Customer&gt; listByName(CustomerListByNameQry customerListByNameQry) &#123; return (MultiResponse&lt;Customer&gt;)commandBus.send(customerListByNameQry); &#125;&#125; 我们使用编译器进入CommandBusI实现类发现CommandBusI下对应着一个CommandBus的实现类 123456789101112@Componentpublic class CommandBus implements CommandBusI&#123; @Autowired private CommandHub commandHub; @Override public Response send(Command cmd) &#123; return commandHub.getCommandInvocation(cmd.getClass()).invoke(cmd); &#125;&#125; 我们再进入CommandHub查看getCommandInvocation方法，发现其实CommandInvocation是从一个HashMap中来的，那么HashMap里的值是合适初始化的呢 12345678private Map&lt;Class/*CommandClz*/, CommandInvocation&gt; commandRepository = new HashMap&lt;&gt;();public CommandInvocation getCommandInvocation(Class cmdClass) &#123; CommandInvocation commandInvocation = commandRepository.get(cmdClass); if (commandRepository.get(cmdClass) == null) throw new ColaException(cmdClass + &quot; is not registered in CommandHub, please register first&quot;); return commandInvocation; &#125; 在infrastructure模块下我们发现框架的入口配置类ColaConfig 123456789101112@Configurationpublic class ColaConfig &#123; @Bean(initMethod = &quot;init&quot;) public Bootstrap bootstrap() &#123; Bootstrap bootstrap = new Bootstrap(); List&lt;String&gt; packagesToScan = new ArrayList&lt;&gt;(); packagesToScan.add(&quot;com.liu&quot;); bootstrap.setPackages(packagesToScan); return bootstrap; &#125;&#125; 于是我们定位到框架的入口,顺着初始化代码在源码COLA-master的cola-framework下找到Bootstrap类,找到初始化方法init 1234public void init() &#123; Set&lt;Class&lt;?&gt;&gt; classSet = scanConfiguredPackages(); registerBeans(classSet); &#125; 看到这里我们就已经明白了scanConfiguredPackages（）方法是扫描编译目录下的Class文件，registerBeans是注册bean对象我们进入registerBeans方法,发现其遍历之前扫描的class文件,并且传入在registerFactory 123456789private void registerBeans(Set&lt;Class&lt;?&gt;&gt; classSet) &#123; for (Class&lt;?&gt; targetClz : classSet) &#123; RegisterI register = registerFactory.getRegister(targetClz); if (null != register) &#123; register.doRegistration(targetClz); &#125; &#125; &#125; 进入registerFactory.getRegister(targetClz)方法，发现代码在registerFactory中根据类上的注解返回对应的注册器，之前对应的@Command注解对应的就是为commandRegister注册器 1234567891011121314151617181920212223public RegisterI getRegister(Class&lt;?&gt; targetClz) &#123; PreInterceptor preInterceptorAnn = targetClz.getDeclaredAnnotation(PreInterceptor.class); if (preInterceptorAnn != null) &#123; return preInterceptorRegister; &#125; PostInterceptor postInterceptorAnn = targetClz.getDeclaredAnnotation(PostInterceptor.class); if (postInterceptorAnn != null) &#123; return postInterceptorRegister; &#125; Command commandAnn = targetClz.getDeclaredAnnotation(Command.class); if (commandAnn != null) &#123; return commandRegister; &#125; Extension extensionAnn = targetClz.getDeclaredAnnotation(Extension.class); if (extensionAnn != null) &#123; return extensionRegister; &#125; EventHandler eventHandlerAnn = targetClz.getDeclaredAnnotation(EventHandler.class); if (eventHandlerAnn != null) &#123; return eventRegister; &#125; return null; &#125; 我们再看commandRegister中的doRegistration方法，现在结果一目了然，这里获取Spring容器中的CommandInvocation对象，并且调用commandHub.getCommandRepository().put(commandClz, commandInvocation)将之前被@Command注解的实现类传入commandRepository中也就是之前上面从HashMap中获取CommandInvocation的地方，代码中还提供了自定义AOP功能，但这部分并未开发接口，至此，整个框架的代码流程就已清晰。 123456789@Override public void doRegistration(Class&lt;?&gt; targetClz) &#123; Class&lt;? extends Command&gt; commandClz = getCommandFromExecutor(targetClz); CommandInvocation commandInvocation = ApplicationContextHelper.getBean(CommandInvocation.class); commandInvocation.setCommandExecutor((CommandExecutorI) ApplicationContextHelper.getBean(targetClz)); commandInvocation.setPreInterceptors(collectInterceptors(commandClz, true)); commandInvocation.setPostInterceptors(collectInterceptors(commandClz, false)); commandHub.getCommandRepository().put(commandClz, commandInvocation); &#125;]]></content>
      <categories>
        <category>领域驱动设计(DDD)</category>
      </categories>
      <tags>
        <tag>领域驱动设计</tag>
        <tag>COLA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[领域驱动设计DDD简介]]></title>
    <url>%2F2019%2F09%2F03%2F%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1DDD%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[什么是领域驱动设计 接触领域驱动设计已经有一年多的时间了，其更关注的是解决复杂的软件设计。这期间也拿一些小项目尝试实践过，也看过一些领域驱动的框架如Halo，Cola,在实践过程中发现如果小项目如果采用简化版的领域驱动设计的理念去实践，代码结构也会有明显的改善，在小项目实践过程中更关注的是边界的划分，和不同功能模块代码的解耦，把核心的领域代码和其它代码区分出来，更好的将代码和现实业务结合起来，更好的执行面向对象，在使用领域驱动设计时能让我们从数据库驱动设计的理念中转换出来，在设计时假设计算机内存是无限大，只考虑领域模型，而不考虑数据库模型，从而使代码更贴近业务，我觉得这是领域驱动设计给我带来的感触。就比如架构，架构的本质无非就是把代码的边界区分好，把代码放在该放的地方Eric Evans提出的领域驱动设计是一个很好的解决这部分问题的方法。领域驱动设计，领域代表着行业，你的软件是应用在哪个行业实现什么样的功能，比如你编写了一个财务软件，那么财务行业就是你编写软件的领域，Eric Evans强调软件一定是要由领域专家和领域知识去驱动开发的，因为软件最终是要应用到领域当中，如果绕过这部分内容直接开发软件，那么开发的软件往往无法交付或者无法满足功能，在我认为，软件是现实生活中的映射，在开发第一个版本的时候，可以和领域专家或者领域中的从业人员进行交流业务流程(现实往往只能找到产品经理)，交流一下在没有软件的情况下，线下业务是如何进行的，然后再根据这些流程去建立领域对象，去驱动整体的软件设计。 领域驱动设计的核心概念通用语言 在开发准备之前必须要和领域人员(如果没有，那只能是需求人员)建立好一套通用的开发语言，我曾经在没接触过过领域驱动设计时实现一个功能时并没有和当时对应需求人员建立一套通用的语言，就是产品说的一个名词和你说的名词并不是同一个名词，但是你以为你理解了产品经理的意思，然后就去开发，结果到交付时发现整个理念完全错误，导致最后返工。建立通用语言的过程往往要经过反复沟通后才能得出的，在反复沟通的过程中，抓住一个反复提及的名词，然后确定这个名词代表的含义，反复提及的名词往往就是找到通用语言的关键,在软件建模中也要紧紧围绕这个名词去建模，当你建立完模型后（通常是UML图），把这部分模型拿给领域专家看，因为你这时候的模型就代表着现实的业务，和领域人员确认模型这样设计是否合理。 领域模型贫血型模型 在领域驱动设计中Eric Evans一直不赞成使用贫血型模型，什么是贫血型模型，简单来说就是我们平常建立的java bean对象，只包行一些字段和get，set方法，因为贫血型对象不能很好的展示出领域模型，有一些本该属于领域模型的方法外泄到其它类比如Service类中去了，所有和领域相关的代码都要包含在领域模型中或者领域服务中，举个例子,有一个用户信息模型，一般我们是这样设计和调用的 12345678910111213141516171819202122public class User &#123; private String userId; private String userName; public String getUserId() &#123; return userId; &#125; public void setUserId(String userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125;&#125; 现在我要修改用户的名字那边就要用Service去实现 1234567891011public class UserService &#123; public void changeUserName(String userName,User user)&#123; if(userName!=null)&#123; user.setUserName(userName); &#125; &#125;&#125; 认真考虑一下现实项目中采用上文编写代码所产生的问题 代码不能很好的体现业务changeUserName这个方法应该是属于用户类中的方法，但是现实中该类却放在了调用方的Service中，上文提到了通用语言，在和领域人员沟通时，他们会说到用户修改了用户名，这里作用的主体是用户，只有用户有权利修改自己的用户名，但是体现在代码中却变成了用户把修改用户名的权利交给了调用方，这样的代码并不能很好的反应出业务，也并不是很好的面向对象的模型。 Service上帝类采用上述方法去建模，将会导致service类的代码快速膨胀，久而久之service类负责所有的功能，包括校验，对象持久化，远程调用等待代码，如果在项目开始时还可以接受，但是随着时间的发展，service变成了乱麻，再也没有人能够轻松分清里面的逻辑了。 充血模型 现在我们采用充血模型实现上述代码 12345678910111213public class User &#123; private String userId; private String userName; public void updateUserName(String userName) &#123; if(userName!=null)&#123; this.userName=userName; &#125; &#125;&#125; 现在我们将原本存在Service中的updateUserName方法放到领域模型中，就修改用户名时传入用户名即可完成用户名修改，这完全符合通用语言的用户修改了用户名，并且在修改用户名时候进行了校验，校验本身也是领域对象提供的功能之一，修改用户名的规则应该由领域对象去觉得，而不是由调用方去决定 现在第三方人员修改用户名变的简单了,再也不需要处理本该属于领域对象校验等功能，这样将属于领域的代码和属于调用方的代码很好的分开,代码的层次也更加分明。 12345678public class UserService &#123; public void changeUserName( User user,String userName) &#123; user.changeUserName(userName); &#125; &#125; 实体（Entity） 采用领域驱动设计建模的一个很重要的概念就是实体,书中给的定义是主要由标识定义的对象称为实体(Entity)，现在我们扩展上诉的User对象，在对象里加入一个Address家庭住址对象 12345678 public class User &#123; private String userId; private String userName; private Address address;&#125; 家庭住址对象包含街道名和邮编 123456public class Address &#123; private String street; private String postcode;&#125; 在通用语言中我们会这样描述，我想根据用户id找到对应用户所居住的地址，这里的用户id就是User的标识定义，那么我们认为User它就是一个实体，但是这里的Address并不是实体，它只是一个VO(键值对对象)在用户模型中给地址一个唯一标识定义是没有意义的，因为在用户跟换地址时我直接将整个Address对象替换掉即可，我并不关心地址的状态。 在现实模型中同一个事物可能需要标识为实体，也有可能不需要表示实体，举个例子上述的User为实体，但是换一个场景，订单对象下关联了一个用户对象来表明这个订单是谁买的，在这里我们关注的是订单，把用户作为实体是没有意义的，所以这里订单是实体，User只是一个VO(键值对对象) VO很多对象没有概念上的标识，它们描述了一个事务的某种特性,我们称这些对象为VO 如果将所有对象设计成实体会有什么问题？在书中有一个很好的例子：小孩子总是可以很好的分清楚那副画是自己画的，因为每幅画都有一些标识来区分哪些是自己画的哪些不是，但是如果必须记住哪些线条使用哪只笔画的那情况该有多复杂？上文的User对象的Address就是一个VO，因为我并不关心Address 的状态，它在User对象中只是单纯是键值属性，但是什么情况下地址为实体什么情况下为VO呢？书中举了另外一个例子:在购物系统中需要用地址来标识发货地址，如果室友也从这家店购买了商品，那么意识到他们是否住在同一个地方并不重要（不需要维护地址标识），这里是地址是VO,如果你和舍友同时去申请宽带，那么这里的地址就是实体，因为电信公司需要知道你和你的舍友居住在同一个地方，这样他们只要上门一次即可。 另一个VO的重要特性是VO是可以整个被替换的，其没有包含副作用的方法，举个例子上文User关联的Address对象,将Address对象传给其它人调用里面的方法并不会对User类产生影响，因此可以放心的将VO传给任何人调用，在设计中尽量将对象设计成VO来减少系统的复杂性，大举个例子，上文中User如果修改Address如果Address的话我们直接在User对象中整个替换Address对象即可完成地址的修改，但是如果地址为实体的话，那么我们必须用地址标识还原出Address对象，然后将地址对象的属性做修改 领域服务 在书中是给领域服务这样定义的：在领域中的某个操作过程或转换过程不是实体或者值对象（VO）的职责时，我们应该将操作放在一个单独的接口中，即领域服务，请确保领域服务和通用语言是一致的，并且保证它是无状态的。 在现实代码中我更喜欢把领域当成客户端调用的代码，领域模型由建模人员编写完代码，然后将这部门代码交给客户端人员去调用，领域建模人员必须保证客户端代码的易用性，如果有些方法并不适合在领域模型中，那么可以将其放在领域服务中，这样可以对客户端人员屏蔽领域细节，例如用户登录时可能涉及到鉴权，鉴权部分可能是另一个模型对象，如果我们不使用领域服务将这些工作全部交给客户端人员去做的话，那么客户端的程序员就必须知道业务的逻辑，要知道原来登录要先鉴权，他先去执行鉴权代码再去执行验证用户密码的代码，这样就导致领域信息暴露，更好的做法应该是用领域服务将鉴权和验证用户信息的方法放在领域服务中，然后再对外暴露一个登陆验证的服务，这样就对客户端程序员屏蔽了领域信息，他只需要调用一个登陆的领域服务即可，不用去关心领域里的逻辑,关于领域服务的具体实践和分包我讲在后续小项目领域驱动实践中介绍。 聚合 在日常开发中将实体和VO进行聚合组成聚合对象是非常普遍的，我们将这些对象称之为聚合，聚合对象都有一个主体我们称之为聚合跟，在使用聚合时对客户端程序员暴露的都应该是聚合根，而不是聚合根下的对象，举例 123456789101112 public class User &#123; private String userId; private String userName; private Address address; public void saveAddress(Address address)&#123; this.address=address; &#125;&#125; 上文中的User对象包就是一个聚合它包含了用户的用户名，用户id属性，也包含了一个地址VO，我们在对外提供领域模型给客户端程序员时我们只能建User对象中的方法,比如上文的saveAddress保存地址方法，而不是将一个个调用Address对象中的get set方法。在实际设计过程中有时候由于聚合包含太多的VO和实体导致聚合过于庞大，我们可以将聚合进行拆分，具体的实践方法我讲在后续小项目领域驱动实践的文章中表述。 资源库（Repository） Repository对领域模型屏蔽了持久化的代码，因为现实软件设计中领域对象不可能全部都存留在内存中，当一个领域对象从创建开始我们就认为其已开始其的生命周期，即使后续将这个领域对象存储在数据库等持久化的对象中我们仍然认为其仍处于生命周期内，直到我们在数据库中将其删除我们才认为一个领域对象生命的结束，资源库就是为了在领域对象存储在数据库或者其它一些持久化组件中时将其还原成领域对象而设计的，比如如下代码 1234567891011121314public class UserRepository &#123; public void addUser(User user)&#123; //持久化代码 &#125; public User findUserById(String userId)&#123; //模拟从数据库中生成对象 User user=new User(); return user; &#125;&#125; 在客户端服务调用完领域服务生成领域对象后，客户端将领域对象传入到资源库中将其持久化(addUser)，同样，资源库也可以根据各种条件去还原一个领域对象（findUserById） 架构设计（六边形架构） 在采用领域驱动设计时我采用的是六边形架构如图 下面是我在网上摘抄的对六边形架构的简介 六边形架构还是一种分层架构，如上图所示，它被分为了三层：端口适配器、应用层与领域层。而端口又可以分为输入端口和输出端口。 输入端口用于系统提供服务时暴露API接口，接受外部客户系统的输入，并客户系统的输入转化为程序内部所能理解的输入。系统作为服务提供者是对外的接入层可以看成是输入端口。 输出端口为系统获取外部服务提供支持，如获取持久化状态、对结果进行持久化，或者发布领域状态的变更通知（如领域事件）。系统作为服务的消费者获取服务是对外的接口（数据库、缓存、消息队列、RPC调用）等都可以看成是输入端口。 应用层定义系统可以完成的工作，很薄的一层。它并不处理业务逻辑通过协调领域对象或领域服务完成业务逻辑，并通过输入端口输出结果。也可以在这一层进行事物管理。 领域层负责表示业务概念、规则与状态，属于业务的核心。 应用层与领域层的不变性可以保证核心领域不受外部的干扰，而端口的可替换性可以很方便的对接不用的外部系统 我在这里对以上的解释说明下 输入端口在上图中对应适配器A,B,C,D比如在http服务中其对应的就是Controller层，用Spring的话就是SpringMVC框架，适配器完成了http对应用用程序的转化，因为应用层提供了固定的API来满足各种渠道的调用，比如现在我要增加一个人RPC调用，我只要根据应用层所提供的API写一个转换器将应用层的API转化成RPC调用的方法即可，图中领域模型作为为核心最稳定的内容放在了六边形的中央，其它所有的组件都必须依赖领域模型，这符合了领域驱动的模型。最后是输出端口，我们将持久化的代码放入这里（资源库Repository）下面给出我们架构设计的依赖结构* 输出层 -&gt; 应用程序(APP) -&gt; 资源库（Repository）-&gt; 领域层 实际中领域层中的领域服务有可能会调用到资源库（Repository），但是我们又不能让领域层去依赖资源库层，因为领域层是项目的核心，应该是最稳定的部分，会被大量的组件依赖，而资源库层相对领域层更加不稳定（比如数据库中新增一个字段等），那么我们这里就要用依赖倒置技术使资源库依赖领域层，具体实践放在小项目领域驱动实践中去讲解*]]></content>
      <categories>
        <category>领域驱动设计(DDD)</category>
      </categories>
      <tags>
        <tag>领域驱动设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[greenplum集群安装]]></title>
    <url>%2F2019%2F09%2F02%2Fgreenplum%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Greenplum集群搭建 关闭所有主机防火墙12systemctl stop firewalld.servicesystemctl disable firewalld.service 关闭SELINUX 12vi /etc/selinux/config将属性 SELINUX 改为 disabled 系统设置设置hostname12345vi /etc/hosts添加各个主机的hostname如:192.168.171.75 master192.168.171.76 node1192.168.171.77 node2 设置系统参数至sysctl.conf12345678910111213141516171819202122232425262728vi /etc/sysctl.conf在文件中添加以下代码kernel.shmmax = 500000000kernel.shmmni = 4096kernel.shmall = 4000000000kernel.sem = 500 2048000 200 40960kernel.sysrq = 1kernel.core_uses_pid = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.msgmni = 2048net.ipv4.tcp_syncookies = 1net.ipv4.conf.default.accept_source_route = 0net.ipv4.tcp_max_syn_backlog = 4096net.ipv4.conf.all.arp_filter = 1net.ipv4.ip_local_port_range = 10000 65535net.core.netdev_max_backlog = 10000net.core.rmem_max = 2097152net.core.wmem_max = 2097152vm.overcommit_memory = 2vm.swappiness = 10vm.zone_reclaim_mode = 0vm.dirty_expire_centisecs = 500vm.dirty_writeback_centisecs = 100vm.dirty_background_ratio = 0vm.dirty_ratio = 0vm.dirty_background_bytes = 1610612736vm.dirty_bytes = 4294967296 在/etc/security/limits.conf中修改以下参数123456vi /etc/security/limits.conf修改以下参数* soft nofile 65536* hard nofile 65536* soft nproc 131072* hard nproc 131072 同步集群时间1234567891011在所有主机上安装ntpyum install -y ntp添加如下内容server 127.127.1.0fudge 127.127.1.0 stratum 10保存退出，然后启动ntp 服务并设为开机启动：systemctl start ntpdsystemctl enable ntpd在集群其他节点安装ntp 服务，并将ntp 服务server 指向主节点echo &quot;server &lt;ip&gt; iburst&quot; &gt; /etc/ntp.conf&lt;ip&gt; 替换为主节点ip 地址 免密登录1234567891011121314151617181920用root用户登录所有主机编辑文件 /etc/ssh/sshd_config将以下两行前面的#号去掉，保存RSAAuthentication yesPubkeyAuthentication yes在所有主机上执行以下命令ssh-keygen -t rsa按四下回车得到public key在所有主机上执行以下命令，将所有主机的public key 拷贝到主节点上ssh-copy-id root@&lt;hostname&gt;&lt;hostname&gt;更换为主节点主机的主机名在主节点机器上通过scp 命令将文件 /root/.ssh/authorized_keys 发送到所有其他节点主机的 /root/.ssh/ 目录下：scp /root/.ssh/authorized_keys root@&lt;hostname&gt;:/root/.ssh/重启所有主机的sshd 服务systemctl restart sshd.servicesystemctl enable sshd.service验证免密码登陆 ：ssh &lt;hostname&gt;&lt;hostname&gt; 更换为主机名。 在主节点安准Greenplum123456rpm -Uvh ./greenplum-db-&lt;version&gt;-&lt;platform&gt;.rpm数据库软件安装在/usr/local/greenplum-db-&lt;version&gt;目录下修改目录权限为gpadmin所有chown -R gpadmin /usr/local/greenplum*chgrp -R gpadmin /usr/local/greenplum* 在集群中安装Greenplum1234567891011121314151617181920su -切换至root用户touch hostfile_exkeys创建一个hostfile_exkeys文件将所有主机hostname放入其中（主机包含所有master, standby master,segments）如mdwmdw-1mdw-2smdwsmdw-1smdw-2sdw1sdw1-1sdw1-2sdw2sdw2-1sdw2-2sdw3sdw3-1sdw3-2 12345创建groupadd账号和groupadd组groupadd gpadminuseradd gpadmin -g gpadminpasswd gpadmin 1234567安装Greenplum rpm包rpm -Uvh ./greenplum-db-&lt;version&gt;-&lt;platform&gt;.rpm数据库默认安装在/usr/local/greenplum-db-&lt;version&gt;目录下更改安装目录权限为gpadmin用户所有 chown -R gpadmin /usr/local/greenplum* chgrp -R gpadmin /usr/local/greenplum* 12345678910111213141516171819202122232425262728将安装分发给集群其它主机执行创建一个空文件touch hostfile_exkeys将集群所有hostname写入文件，如: mdw mdw-1 mdw-2 smdw smdw-1 smdw-2 sdw1 sdw1-1 sdw1-2 sdw2 sdw2-1 sdw2-2 sdw3 sdw3-1 sdw3-2执行以下命令在集群中安装数据库gpseginstall -f hostfile_exkeys确认集权是否安装成功su - gpadminsource /usr/local/greenplum-db/greenplum_path.shgpssh -f hostfile_exkeys -e ls -l $GPHOME如果可以看到集群信息则安装成功 创建数据目录12345678在主节点中创建目录，目录地址根据实际情况更改mkdir -p /data/master改变目录所有者chown gpadmin /data/master如果有副主节点，执行以下命令在副主节点中创建相同目录，smdw为副主节点hostnamesource /usr/local/greenplum-db/greenplum_path.shgpssh -h smdw -e &apos;mkdir -p /data/master&apos;gpssh -h smdw -e &apos;chown gpadmin /data/master&apos; 创建段节点（数据节点）目录123456创建空文件touch hostfile_gpssh_segonly将所有段节点（数据节点）的hostname填入如:sdw1sdw2sdw3 用gpssh命令在段节点(数据节点)创建目录和更改其权限1234source /usr/local/greenplum-db/greenplum_path.shgpssh -f hostfile_gpssh_segonly -e &apos;mkdir -p /data/primary&apos;gpssh -f hostfile_gpssh_segonly -e &apos;mkdir -p /data/mirror&apos;gpssh -f hostfile_gpssh_segonly -e &apos;chown -R gpadmin /data/*&apos; 配置数据库123456789101112131415161718192021222324252627282930313233343536切换至gpadminsu - gpadmincp $GPHOME/docs/cli_help/gpconfigs/gpinitsystem_config /home/gpadmin/gpconfigs/gpinitsystem_config备份配置文件到新目录下修改备份文件gpinitsystem_config，修改以下参数DATA_DIRECTORY（将创建主段数据目录的文件系统位置,有几个DATA_DIRECTORY, 每个节点上便会启动几个segments#### 指定Primary Segment的数据目录, DATA_DIRECTORY参数指定每个Segment主机配置多少个Instance。如果#### 在host文件中为每个Segment主机列出了多个网口，这些Instance将平均分布到所有列出的网口上。#### 这里的案例，hosts里有2个segment，sdw1，sdw2俩主机，都是单网卡段的数量划分要根据服务器的cpu，网卡，磁盘因数划分最好达到share nothing的效果，每个段都有独自的处理器，磁盘或者网卡）MASTER_HOSTNAME(主节点hostname)MASTER_DIRECTORY（将创建主数据目录的文件系统位置）MIRROR_DATA_DIRECTORY（建立节点的镜像mirror节点的地址，镜像的数量必须和DATA_DIRECTORY的数量一致）详细参数说明查阅https://gpdb.docs.pivotal.io/5190/utility_guide/admin_utilities/gpinitsystem.html----------------------------------------------------------------ARRAY_NAME=&quot;Greenplum Data Platform&quot;SEG_PREFIX=gpsegPORT_BASE=40000declare -a DATA_DIRECTORY=(/data/primary)MASTER_HOSTNAME=mdwMASTER_DIRECTORY=/data/masterMASTER_PORT=5432TRUSTED SHELL=sshCHECK_POINT_SEGMENTS=8ENCODING=UNICODE...MIRROR_PORT_BASE=7000REPLICATION_PORT_BASE=8000MIRROR_REPLICATION_PORT_BASE=9000declare -a MIRROR_DATA_DIRECTORY=(/data1/mirror /data1/mirror /data1/mirror /data2/mirror /data2/mirror /data2/mirror)----------------------------------------------------------------- 运行初始化脚本1234567891011121314151617181920 创建文件里面所有段节点（数据节点）hostname touch vi hostfile_gpinitsystem 数据如: sdw1-1 sdw1-2 sdw2-1 sdw2-2 sdw3-1 sdw3-2 sdw4-1 sdw4-2执行以下命令，gpconfigs/gpinitsystem_config为上面更改的配置文件，hostfile_gpinitsystem为所有的段节点hostname，standby_master_hostname为副主节点的hostnamecd ~gpinitsystem -c gpconfigs/gpinitsystem_config -h gpconfigs/hostfile_gpinitsystem \ -s standby_master_hostname -S 当出现Continue with Greenplum creation? Yy/Nn时 输入y回车 出现以下提示表示安装成功 Greenplum Database instance successfully created. 在主节点和备份主节点设置环境变量12345678su - gpadminvi ~/.bashrc添加以下内容，MASTER_DATA_DIRECTORY为实际master目录路径source /usr/local/greenplum-db/greenplum_path.shexport MASTER_DATA_DIRECTORY=/data/master/gpseg-1(注意)如果是RHEL 7 or CentOS 7系统，需要在.bashrc文件的末尾添加如下内容:export LD_PRELOAD=/lib64/libz.so.1 ps至此安装完成 设置账号123456789登录master节点运行psql修改管理员密码alter role gpadmin with password &apos;hzt_2019&apos;;输入\q退出客户端设置账号访问权限,路径根据实际路径填写vi /data/master/gpseg-1添加以下代码，设置gpadmin可远程登录host all gpadmin 0.0.0.0/0 trust]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>greenplum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓慢维度的设计和处理]]></title>
    <url>%2F2019%2F09%2F02%2F%E7%BC%93%E6%85%A2%E7%BB%B4%E5%BA%A6%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[关于缓慢维度变化的简介 在数据仓库设计中理想状态下维度是不会变化的，但是事与愿违，大部分业务系统中的维度是会发生变化的，那么如何去处理这些变化的维度就是本文关注的内容，举个例子如下企业组织架构维度表 ID_ 企业名 部门名 组名 1 微软 研发部 开发一组 如果有一天上表中的部门名发生变化怎么办?根据Kimball的数据仓库工具箱，我们把处理缓慢维度的方法分为7种类型，其为类型1至类型7 类型1:重写 顾名思义，就是将维度表中的字段简单的替换，如上表中如果采用类型1的话，如果部门后续由研发部变成技术部，那么维度表将变成下表，部门维度表和部门人数事实表做关联 ID_ 企业名 部门名 组名 1 微软 技术部 开发一组 部门人数事实表 ID_ 部门ID外键 人数 1 1 10 类型1的优劣势 有点是简单易于实现，仅需重写维度表中的属性值而不需要去更改事实表，但是无法保留历史值，如果业务中存在对维度的历史值进行分析，那么就无法采用该类型，举例：采用类型1将部门名改成技术部后，现在需要分析在部门叫研发部时，研发部下有多少人?那么如果采用类型1将无从下手，因为维度表中没有保存历史维度数据,而部门人数事实表中的数据是用部门ID去与其关联的。但是实际中如果采用类似hive无法执行update语句的数据仓库工具去建设的话，那么只能重新全量生成维度表 类型2：增加新行 类型2是最常用的处理缓慢维度的办法,如果采用此设计方式则在部门名变更为技术部时维度表和事实表如下 ID_ 企业名 部门名 组名 行有效日期 行失效日期 是否生效 1 微软 研发部 开发一组 2011-1-1 2019-9-1 no 2 微软 技术部 开发一组 2019-9-2 9999-1-1 yes 部门人数事实表 ID_ 部门ID外键 人数 1 1 10 2 2 100 在事实表中原来旧的数据仍然和研发部关联，但是新增的数据已经和新的维度（技术部）做关联。这样数据就保留了历史变化的信息，如果需求中存在对历史维度进行分析的话可以采用此类型应对维度缓慢维度变化。 类型3：新增新列 采用维度2去处理维度变化时存在一个缺点，如果需求需要将新的属性值和旧的属性值做关联分析，那么采用类型2将很难实现，因为类型2并没有记录维度变化的关联关系，如果存在这方面需求则可以采用类型3处理，事实表通过代理键ID关联维度表(维度表在创建时自己生产的id，不是业务方提供的ID)但实际中类型3不经常使用 如： ID_ 企业名 当前部门名 之前部门名 组名 1 微软 技术部 研发部 开发一组 部门人数事实表 ID_ 部门ID外键 人数 1 1 10 类型4：微型维度 其解决问题的场景为应对维度表中存在大量数据（几百万），且一些属性快速变化。因为当维度表中存在大量的数据，特别是维度中某些信息还是易变时，我们不希望已经存在几百万的维度表中新增数据（采用类型2），因为这样会使维度表发生膨胀，实际情况中维度表中的数据应该远远小于事实表，那么类型3就派上用场，还是引用上诉两张表，假设现在部门维度有几十万个部门，且组名经常发生变化（即使不太可能），那么我们将才用下面设计 部门表 ID_ 企业名 部门名 1 微软 研发部 组名表 ID_ 组名 1 开发一组 1 开发二组 部门人数事实表 ID_ 部门ID外键 组名外键 人数 1 1 1 10 2 1 2 100 部门表和组名表不再使用星型维度直接做关联，而是在事实表中新建外键来关联部门和组 类型5：微型维度与类型1支架表 之所以称之为类型5是因为其是类型4和类型1的结合 4+1=5，该技术实现为在主维度中用一个外键id和一个微型维度做关联，这样能避免微型维度发生变化时更新主维度的每行的信息，且如果客户需求需要在不关联事实表的情况下完成维度的过滤分析等类型5是很好的处理方法，举例 商店维度表 ID_ 商店名 地区ID 1 一号门店 1 地区维度表 地区ID 省 市 县 1 福建省 福州市 闽清县 如果不采用类型5的话维度表结构为 ID_ 商店名 省 市 县 1 一号门店 福建省 福州市 闽清县 2 二号门店 福建省 福州市 闽清县 那么有一条闽清县更改了名字变成闽清市，如果不采用类型5支架表的话那么将要更改所有商店维度表中有关闽清县的记录，将其改成闽清市，如果你在很多事实表中都使用了地区信息，那就需要更改所有有关地区的维度，这是无法忍受的，但是如果采用类型5则只需要更改地区类型的属性即可完成所有有关地区维度信息的修改。 类型6 类型6为 类型2,3,1的组合（2+3+1=6），回顾类型3，当为了记录维度变化的历史先后关系时我们采用类型3，但是类型3也有一个缺点就是它只记录当前的变化，和上一次的变化，类型6解决了这个问题，其维度表如： ID_ 企业名 当前部门名 之前部门名 组名 生效日期 结束日期 当前是否生效 1 微软 技术部 研发部 开发一组 2011-1-1 2019-9-1 no 2 微软 技术部2 技术部 开发一组 2011-1-1 9999-1-1 yes 部门人数事实表 ID_ 部门ID外键 人数 1 1 10 尽管该技术具有某种诱惑力，但是加大了系统的复杂度，考虑任务是否有这种需求才使用这种方法。 类型7 当需要分析维度表的当前和历史场景的时候可以使用类型7，其运用事实表关联类型2和基于类型2的维度表创建一个当前部门的视图来实现，如下 部门维度 ID_ 部门编码 企业名 当前部门名 生效日期 结束日期 当前是否生效 1 code1 微软 研发部 2011-1-1 2019-9-1 no 2 code1 微软 技术部 2011-1-1 9999-1-1 yes 当前部门视图（可以根据部门问题创建一个当前部门视图 比如:select * from 部门维度 where 当前是否生效=’yes’） 部门编码 部门ID 当前部门名 code1 2 技术部 code1 3 人力资源部 部门人数事实表 ID_ 部门ID外键 部门编码 人数 1 1 code1 10 2 2 code1 10 这样通过事实表中存在，部门ID外键和部门编码就可以分析历史部门数据和当前部门数据所存在的关系 杂项目维度 在建模过程中通常会遇到大量五花八门的指标和描述，它们包行小的范围离散值处理这些离散值有一下几种方法 忽略这些标志和指标,如果这些描述具有业务价值则不能采用这种方式 在事实表中保存这些表示，尽量不要在事实表中保存这些描述，这些描述可能使事实表的列发生膨胀 将每个标志和指标放入各自的维度，如果事实表的外键在合理范围内（不超过20个），则在事实表中加入不同的外键是可接受的。 杂项维度,如下 在交易事实表中存在以下杂项描述 支付方式:CASH,CREDIT购买渠道:ONLINE,OFFLINE对应事实表中一共存在以下4中组合方式（2的二次方），数据为 支付方式 购买渠道 CASH ONLINE CASH OFFLINE CREDIT ONLINE CREDIT OFFLINE 那么与其建这些杂项目反正事实表中，或者维度数目已经较大的情况下，我们可以创建一个杂项维度,将这些杂项的所有可能罗列出来如 ID 支付方式 购买渠道 1 CASH ONLINE 2 CASH OFFLINE 3 CREDIT ONLINE 4 CREDIT OFFLINE 现在在事实表中的数据为 ID_ 杂项外键 金额 1 2 100 2 1 1000 不同粒度的事务事实（表头模式） 实践中应该避免这么模式，应该保证事实表中的粒度和维度是一样的 比如存在订单详细事实表 ID_ 订单ID 商品外键 金额 1 order1 1 1000 2 order1 2 888 订单维度表 ID_ 订单描述 order1 订单1信息 order1 订单2信息 这样的设计存在一个问题，订单详情事实表中的粒度是订单的每个商品，但是却关联了订单维度，这两个关联存在不同的粒度，应该尽量避免这种情况，更好的做法应该是再新建一个关于订单的事实表，在订单明细表中将订单id做为退化维度（只是单纯的记录一下订单id，为了方便分析） 多币种 最常见的分析需求是订单事务以当地交易币种表示，在构建订单事实表时应该包含2种货币信息事实，一种是当地货币，一种是公司采用的标准统计货币，比如公司在日本销售的货物以日元结算，公司财报中的统计标准为美元，那么在订单事实表中应该包行2种货币，一种是日元，一种是公司的标准货币美元。]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>维度</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据仓库维度建模概述]]></title>
    <url>%2F2019%2F08%2F31%2F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[什么是维度 简单的来说维度就是用于分析数据仓库中的事实的描述（关于事实下文讲解）.举个例子在数据库中有两张表，订单明细表和商品表 订单明细表 ID_ ORDER_ID PRODUCT_ID_ quantity 1 1 1 10 商品表 ID_ PRODUCT_NAME 1 华为手机 这两张表中订单明细表使用商品表中的id与之关联，订单明细表为事实表记录了订单明细的事实，商品表就为维度表，因为商品表描述了订单明细表，我们通过商品表中的维度信息去分析订单明细表中的数据，用需求文字来描述就是我想查购买了华为手机的所有订单明细，转换成SQL语句为 1select * from 订单表 t1 inner join 商品表 t2 on t1.PRODUCT_ID_=t2.ID_ where t2.PRODUCT_NAME=&apos;华为手机&apos; 什么是事实 事实一般只是一些单纯的数字，如上文订单表中的数量，它仅仅是订单中的一个度量，没有什么文字描述，文字描述都存在维度表中,通过维度表去分析事实表。 什么是粒度 事实表中的存储数据都要有相同的粒度,粒度用于确定某一事实表中的行表示什么,例如上文订单明细表中的粒度是到商品,不是订单，因为表中有一个产品id，如果该表去掉PRODUCT_ID_和quantity那么该事实表中的粒度就为订单（一个订单中可能包含很多商品）,所有的事实表中的数据都应该有相同的粒度，同样维度表中的关联也需要和事实表中的粒度做对应，就好比上文的订单明细表中最好不要出现订单的维度，比如订单类型等信息. 设计维度的过程选择业务过程 业务过程一般存储在业务系统的关系型数据库中，我们必须根据需求选取对应业务表中的数据，如我需要建立订单为主题的数据集市，则我需要抽取业务系统中关于订单的数据 声明粒度 最好要包行最低粒度，如上文中建立一张订单明细表，而不是只建立订单表，因为细粒度可以根据维度上卷得到粗粒度的数据，反之则不能。 描述维度 维度提供业务的描述，比如谁，什么，何处，何时等。维度表为数据仓库中的灵魂，是数据仓库中最重要的部分，维度描述越丰富，则数据仓库中所挖掘的信息越多。 确认事实 事实涉及业务过程事件的度量,基本上都是以数量值表示，一个事实表中的所有粒度需要保持一致。 数据仓库的分层 目前项目中采用了4层架构分别为 ods贴源层，ods层中存放了业务表中原封不动的数据 dwd数据清洗层,dwd为了清理ods层中的数据 dws主题层,此层获取dwd中的数据根据不同的主题组成不同粒度的事实表和维度供业务方调用 ads层，此层一般为一些汇总数据供前端展示时调用 不同数据集市间的数据划分可以考虑在同一个数据实例中根据表名建立各个数据集市中的4个不同的层，根据表名区分不同数据集市中的表，也可以根据不同数据集市建立不同的数据库实例来存储上文4个层的表，目前由于建立的数据集市较少为了方便才用同一个数据库实例。 数据的仓库架构总线型架构 Kimball总线架构为，在项目开始时，由架构师设计通用维度，这个维度称为总线，设计完成总线后，将总线维度分发给各个数据集市的开发人员同步去开发，比如订单数据集市，库存数据集市。各个集市中的维度根据总线去做扩展，各个数据集市的数据再ads层之前是不做交互的，如果要跨域多个数据集市去分析数据，那么就用通用维度（总线）去连接各个数据集市中的不同事实表去分析数据。 维度表设计 现在维度表的设计一般分为星型结构和雪花型结构 星型结构，采用宽表和冗余的形式存储维度，维度的父子关系都在一张表中关联，不通过外键关联，如下面时间表: id 年 月 日 20190101 2019 01 01 20190102 2019 01 02 那么如果我想查询实时表中id为20190101的数据对应的月份是几月，那么我们可以使用id去时间维度去查找对应的月份 雪花结构,雪花结构的设计更多的用于关系型数据库，上图的时间维度用雪花型表示为年表 id 年 2019 2019 2018 2018 月表 id 月份 1 01 2 02 年月关系表 id year_id month_id 1 2019 1 2 2019 2 两种设计的优缺星型结构：对查找的效率和难度来说更加高效简单，但是存储了大量冗余数据，而且不够灵活不方便修改，如果存在大量描述字段的话，那么冗余结构相比雪花结构使用更大的存储空间雪花结构：数据更加灵活，比如更改维度表的信息不需要更改整个维度的信息，比如上文我要更改月份里面的字段我只需要更改月表中的信息即可，不需要更改整张维度表，但是查询更加麻烦和慢。其实归根到底就是范式设计和非范式设计，在数仓中大多数情况下应该使用星型结构，因为数仓关注的是查询，用存储空间换取查询数据的方便是值得的，至于对于星型结构存在维度变更的问题，我们将在另一篇文章，维度缓慢变化中说明]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>维度</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive mysql元数据表单的主从备份]]></title>
    <url>%2F2019%2F08%2F30%2Fhive-mysql%E5%85%83%E6%95%B0%E6%8D%AE%E8%A1%A8%E5%8D%95%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[hive元数据库和使用介绍 hive 会将表的元数据信息存储在数据库中，这里采用mysql作为元数据库存储hive的元数据 元数据表中记录着很多hive中有用的信息，比如数据库实例，表，表结构，还有表数据的条数 表数据条数只有在hive为内部表时的统计是准确的，如果建立的表为外部表 (external)则需要执行统计语句才能得到准确结果 1ANALYZE TABLE tablename COMPUTE STATISTICS; 使用元数据表中的统计数据可以很简单快捷的得到hive的元数据，比如表的数量，和数据量 mysql主从介绍 mysql主从时利用mysql的日志来完成主从的，所以在做主从设置时，先要保证主数据库和从数据库数据的一致 迁移数据 如果主数据库中已经在做主从时已经存在数据那么，先将主数据库中数据复制到从数据库中，从而保证主数据库和从数据库数据的一致 配置主数据库配置文件 12345678910111213vi /etc/my.cnf#将以下信息填入server-id=1 #Mysql服务的唯一编号 每个mysql服务Id需唯一log-bin=mysql-bin #logbin的名字# 根据高性能mysql中提到，两个参数慎用，不应该开启他们，会导致主备同步出错，应该在备库中使用replicate-do-db或者replicate-ignore-db来过滤，#比如 use test; delete from sakila.film binlog-do-db和 binlog-ignore-db都会在test数据库上过滤delete语句，而不是在sakila上，从而导致同步出错#binlog-do-db=metastore #需要同步的数据库的名字，如果是多个数据库存在多条#binlog-ignore-db=test01 #不需要同步的数据库的名字log-slave-updates=1 #log更新间隔slave-skip-errors=1 #是跳过错误，继续执行复制操作(可选)binlog_format=MIXED #必须制定日志的类型，这里选择混合日志存储，不然无法建立hive表#重启数据库service mysqld restart 配置从数据配置文件 12345678910#Mysql服务的唯一编号 每个mysql服务Id需唯一server-id=2read_only=1#只读模式，可以限定普通用户进行数据修改的操作，但不会限定具有super权限的用户（如超级管理员root用户）的数据修改操作。如果想保证super用户也不能写操作，就可以就需要执行给所有的表加读锁的命令 “flush tables with read lock;”replicate-do-db=metastore #需要复制的数据库名，如果复制多个数据库，重复设置这个选项即可replicate-ignore-db=test05 #需要忽略不复制数据库名，如果个数据库，重复设置这个选项即可replicate-rewrite-db = metastore-&gt;apollo # 如果主数据库名字和从数据库名不一样，则使用这个配置，表明将主数据库metastore#复制到从数据库apollo实例下，和replicate-do-db配置不能共存#重启数据库service mysqld restart 设置主数据库复制账号 123456CREATE USER &apos;slave&apos;@&apos;%&apos; IDENTIFIED BY &apos;mysql&apos;;GRANT REPLICATION SLAVE ON *.* TO &apos;slave&apos;@&apos;%&apos;;FLUSH PRIVILEGES;# 查看赋权状态use mysql;select User,authentication_string,Host from user; 查看是否开启日志 1show variables like &apos;log_bin&apos;; 如果开启value值为on Variable_name Value log_bin ON 查看主节点状态1show master status; 结果示例,表示 metastore实例日志文件为mysql-bin.000005，当前日志偏移量为1242284 File Position Binlog_Do_DB mysql-bin.000005 1242284 metastore 操作从数据库 其中change master语句中的master_log_file 为上一步查看的metastore日志文件，master_log_pos为该日志文件的偏移量，这样主数据库中的数据发生变化，偏移量就会增长，从数据库根据偏移量去同步数据 123456# 停止正在进行的slave(如果有，此方法也用于修改slave的值(如果参数不对))stop slave;# 需要主机名，上面步骤的账户密码以及日志文件名字和位置(请根据实际情况自行修改)change master to master_host=&apos;192.168.1.1&apos;, master_user=&apos;slave&apos;, master_password=&apos;mysql&apos;, master_log_file=&apos;mysql-bin.000005&apos;, master_log_pos=1242284;# 启动start slave; 查看状态 12345show slave status;如果发现Slave_IO_Running和Slave_SQL_Running状态为YES则成功Slave_IO_Running负责和主机通讯Slave_SQL_Running负者执行从数据库sql语句Last_Error复制记录上一次同步出错的出错愿意 遇到的问题 在配置主数据库配置文件时必须指定 binlog_format类型，不然hive建表会出错 配置从数据配置文件时，replicate-do-db=metastore和replicate-rewrite-db不能共存 当同步主数据库的数据到不同名字的从数据库中时，不可直接用Navicat图形化工具去直接操作数据库，应该写语句去执行，不然会导致同步失败 当执行show slave status 查看从节点状态时，发现Slave_IO_Running 一直未connecting，查看mysql错误日志文件(默认在/var/log/mysqld.log)发现Authentication plugin ‘caching_sha2_password’ reported error，从报错可以看出是caching_sha2_password插件的问题执行(将账号和密码替换成自己前面创建复制账号的账号和密码) 1ALTER USER &apos;slave&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;mysql&apos;;]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
        <tag>mysql主从搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将hexo发布到github]]></title>
    <url>%2F2019%2F08%2F29%2F%E5%B0%86hexo%E5%8F%91%E5%B8%83%E5%88%B0github%2F</url>
    <content type="text"><![CDATA[创建一个github仓库 创建一个github公有仓库,点击settings如图 选择GitHub Pages选项 设置git分支为，和访问域名 设置hexo部署目录1234567891011打开项目目录下的_config.yml文件修改deploy:属性type 为类型设置为gitbranch设置为master分支repo为你的仓库地址如deploy:type: gitbranch: masterrepo: https:// 参数解释 参数 描述 repo 库（Repository）地址 branch 分支名称。如果不指定，则默认值为 master message 自定义提交信息,非必须 安装部署插件 12进入项目主目录执行$ npm install hexo-deployer-git --save 上传CNAME文件 在项目目录下source中创建一个名字为CNAME的文件，里面填入你所绑定的域名 发布项目至github pages 123$ hexo clean$ hexo g$ hexo d 解决样式丢失问题 此时发布项目至github，css样式会丢失修改以下内容 12345678910打开项目目录下的_config.yml文件修改如下参数url: https://liushprofessor.github.io/liushaohuang.github.io/root: /liushaohuang.github.iopermalink: :year/:month/:day/:title/permalink_defaults:其中url替换为你github的仓库地址(网址)root 为网站的根目录（github对应的仓库名）重新发布解决问题 绑定域名 将域名cname设置为A记录代表ip ，cname代表绑定域名 ,主机记录www代表匹配www.前置网站如www.liushaohuang.cn@ 表示直接解析主域名，匹配liushaohuang.cn的网站 记录类型 主机记录 记录值 A www ip地址 CNAME @ 域名 CNAME WWW 域名]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo主题的更换]]></title>
    <url>%2F2019%2F08%2F29%2Fhexo%E4%B8%BB%E9%A2%98%E7%9A%84%E6%9B%B4%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[主题主体安装设置 这里以next主题为例，进入hexo项目目录，执行以下命令，从github上下载next主题,并将主题存放在themes目录的next文件夹下 1$ git clone https://github.com/theme-next/hexo-theme-next themes/next 更改主题 12345项目主目录进入主目录，这里以hexo为例$ cd hexo打开该目录下的_config.yml文件将theme属性更改为theme: next 更改主题文字为中文 123同上打开主目录下的_config.yml文件将language属性更改为language: zh-CN 更改主题标题 123同上打开主目录下的_config.yml文件修改title标签为想要的标题title: 标题 主题内部设置 主题内部配置文件为themes/next目录下的_config.yml 更改主题样式 12345在主题配置文件中更改scheme属性来切换不同样式的主题#scheme: Muse#scheme: Mistscheme: Pisces#scheme: Gemini 配置菜单找到menu标签以下配置在主要中打开主页，归档页，分类和标签如下图所示 1234567menu: home: / archives: /archives #about: /about categories: /categories tags: /tags #commonweal: /404.html 每个标签的含义为 键值 设定值 显示文本（简体中文） home home: / 主页 archives archives: /archives 归档页 categories categories: /categories 分类页 tags tags: /tags 标签页 about about: /about 关于页面 commonweal commonweal: /404.html 公益 404 配置标签和分类按钮 现在点击标签和分类按钮是无法使用的，下面进行标签和分类按钮的配置 标签按钮配置 12345678910在hexo项目下执行hexo new page tags执行完成后在source\tags目录下生成index.md文件打开文件在标题中增加 type: &quot;tags&quot;如---title: tagsdate: 2019-08-29 14:35:28type: &quot;tags&quot;--- 配置分类按钮 123456789同上打开工程目录hexo new page categories打开文件在标题中增加 type: &quot;categories&quot;如---title: categoriesdate: 2019-08-29 14:43:25type: &quot;categories&quot;--- 编写博客内容1234567891011121314 执行 hexo new 标题 在source/_posts目录下会出现 标题.md文件 打开文件 给博文添加分类和标签 categories，tags 如下 --- title: 标题 date: 2019-08-29 13:45:29 categories: hexo tags: -hexo -next ---这样这个博文就属于hexo分类，并且其有两个标签hexo和next现在进入首页点击分类和标签按钮即可按分类和标签找到该文章给文章配置图片 方法1 1234567在项目根目下创建images文件夹将图片放入该文件夹如果绑定自己的域名则使用md标签应用图片如![按钮](/images/menu.png)注意：如果使用github提供的域名，由于在github中代码是放在仓库的二级目录中，所以路径需该为![按钮](/仓库名/images/menu.png) 方法2(暂未成功)12345678910更改主目录的_config.yml的文件修改以下配置post_asset_folder: true 当资源文件管理功能打开后，Hexo将会在你每一次通过 hexo new [layout] &lt;title&gt; 命令创建新文章时自动创建一个文件夹。 这个资源文件夹将会有与这个文章文件一样的名字。将所有与你的文章有关的资源放在这个关联文件夹中之后， 你可以通过相对路径来引用它们，这样你就得到了一个更简单而且方便得多的工作流。在md中使用标签&#123;% asset_img menu.png 标题 %&#125;来引入图片 首页展示文章全文的问题 首页中展示的文章是全文，这样导致首页非常的长，可以使用md语法在文章中加入来控制首页展示的长度]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下hexo搭建]]></title>
    <url>%2F2019%2F08%2F29%2Fhexo%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[下载nodejs nodejs下载地址下载 安装hexo1npm install -g hexo-cli 构建hexo项目 安装 Hexo 完成后，执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 123$ cd &lt;folder&gt;$ npm install 安装nodejs的依赖到hexo目录下$ hexo init &lt;folder&gt; 初始化hexo项目 新建完成后，指定文件夹的目录如下： 12345678.├── _config.yml 网站的配置信息,可以在此配置大部分的参数,详细配置参考官网[配置](https://hexo.io/zh-cn/docs/configuration)├── package.json├── scaffolds 模版文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件├── source 资源文件夹，除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去| ├── _drafts| └── _posts└── themes 主题目录，主题有自己的_config.yml文件，用来配置主题自己的属性 编译开启web服务 123hexo ghexo s访问http://localhost:4000 即可看见项目 构建时遇到的错误 12在执行hexo init &lt;folder&gt; 命令时 出现ERROR Local hexo not found in错误删除hexo目录下的node_modules文件 然后在hexo工程目录下重新执行npm install 安装nodejs依赖]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
